{"meta":{"title":"Lant's Blog","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MySQL锁 - 01","slug":"2018-01-02-mysql_locks-01","date":"2018-01-02T13:08:27.000Z","updated":"2018-01-10T01:35:22.000Z","comments":true,"path":"2018/01/02/2018-01-02-mysql_locks-01/","link":"","permalink":"http://blog.renyimin.com/2018/01/02/2018-01-02-mysql_locks-01/","excerpt":"","text":"参考: http://blog.csdn.net/tanga842428/article/details/52748531 前言 之前已经学习了事务及事务在高并发下所面临的问题, 并且介绍了事务的隔离级别是如何解决这些问题的; 那这些问题已经通过事务解决了, 为什么还要学习锁的相关知识? 我们之前介绍的事务的隔离级别，其实它的核心就是锁; 虽然之前也了解到事务的最隔离级别是可以解决 丢失更新 的问题;高级别如果在非事务场景中, 要能在高并发的时候解决非事务下(不使用事务)的 丢失更新 的问题, （乐观,悲观锁的使用） 所以我们也需要对锁有一定的认识; 常见锁相关的词 在学习锁相关知识之前, 先看一些关于锁的名词: 锁冲突 锁等待 锁争用 死锁 两段锁 2PL (https://www.cnblogs.com/rainwang/p/4429211.html) 表级锁(MYISAM, INNODB引擎) 意向锁(意向共享锁, 意向排他锁) 行级锁(记录锁) (INNODB引擎) 页级锁(BDB引擎) 共享锁(S锁)(读锁) 排他锁(X锁)(写锁) 记录锁 Gap Locks(间隙锁) next-key锁 自动锁 显示锁 乐观锁 悲观锁 自旋锁: 传统的互斥锁，只要一检测到锁被其他线程所占用了，就立刻放弃cpu时间片，把cpu留给其他线程，这就会产生一次上下文切换。当系统压力大的时候，频繁的上下文切换会导致sys值过高。自旋锁，在检测到锁不可用的时候，首先cpu忙等一小会儿，如果还是发现不可用，再放弃cpu，进行切换。互斥锁消耗cpu sys值，自旋锁消耗cpu usr值。 递归锁: 如果在同一个线程中，对同一个互斥锁连续加锁两次，即第一次加锁后，没有释放，继续进行对这个锁进行加锁，那么如果这个互斥锁不是递归锁，将导致死锁。可以把递归锁理解为一种特殊的互斥锁。 死锁: 构成死锁有四大条件，其中有一个就是加锁顺序不一致，如果能保证不同类型的锁按照某个特定的顺序加锁，就能大大降低死锁发生的概率，之所以不能完全消除，是因为同一种类型的锁依然可能发生死锁。另外，对同一个锁连续加锁两次，如果是非递归锁，也将导致死锁。http://mysql.taobao.org/monthly/2017/01/01/ (DML锁和DDL锁：http://www.hollischuang.com/archives/909) 锁冲突线程1将A上锁后, 线程2又对A上锁, 锁不能共存否则会出现锁冲突; (共享锁和共享锁可以共存, 共享锁和排它锁不能共存, 排它锁和排他锁也不可以共存) 死锁 死锁通常发生在多个线程同时但以不同的顺序请求同一组锁的时候; 比如: 线程1锁住了A, 然后尝试对B进行加锁, 于此同时线程2已经锁住了B, 接着尝试对A进行加锁, 这时死锁就发生了, 线程1永远得不到B, 线程2也永远得不到A, 并且它们永远也不会知道发生了这样的事情; 为了得到彼此的对象(A和B), 它们将永远阻塞下去, 这种情况就是一个死锁; 有多种方法可以避免死锁, 这里只介绍常见的三种: 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表, 可以大大降低死锁机会; 在同一个事务中, 尽可能做到一次锁定所需要的所有资源, 减少死锁产生概率; 对于非常容易产生死锁的业务部分, 可以尝试使用升级锁定颗粒度, 通过表级锁定来减少死锁产生的概率; 表级锁 表级锁是MySQL中锁定粒度最大的一种锁, 表示对当前操作的整张表加锁, 它实现简单, 资源消耗较少, 被大部分MySQL引擎支持, 最常使用的MYISAM与INNODB引擎都支持表级锁定, 但INNODB默认采用的是行级锁, 表级锁定分为表共享读锁(共享锁)与表独占写锁(排他锁); (意向锁就属于表锁) 特点: 加锁快(开销小) 锁定粒度大(出现锁冲突(即:锁等待)的概率最高, 并发度最低) MYISAM引擎默认就是表级锁 (另外, 由于MYISAM引擎不支持事务, 每次操作执行完后会立即提交, 也就是每次操作只加一个锁, 其他操作只用等待就行; 而在InnoDB中, 锁是逐步获得的, 就造成了死锁的可能) 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁, 表级锁加锁速度快,但冲突多,行级锁冲突少,但加锁速度慢, 所以取了折衷的页级, 一次锁定相邻的一组记录; (BDB支持页级锁) 特点: 加锁时间和开销界于表锁和行锁之间 锁定粒度界于表锁和行锁之间, 并发度一般 BDB引擎使用的就是页级锁, 会出现死锁 行级锁 行级锁是Mysql中锁定粒度最细的一种锁, 只对当前操作的行进行加锁, 行级锁能大大减少数据库操作的冲突, 因为其加锁粒度最小, 但行级锁加锁的开销也最大。行级锁分为共享锁 和 排他锁; 特点: 加锁慢, 开销大 锁定粒度最小(发生锁冲突的概率最低, 并发度也最高) INNODB引擎使用行锁, 支持事务, 会出现死锁 Innodb中的行锁与表锁注意事项 前面提到过, Innodb引擎中既支持行锁也支持表锁, 那么什么时候会锁住整张表, 什么时候或只锁住一行? InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的; InnoDB这种行锁实现特点意味着: 只有通过索引条件检索数据, InnoDB才使用行级锁, 否则, InnoDB将使用表锁!(不过, 在实际应用中, 一般在做更改的时候, 都是使用主键进行筛选, 所以自然是行锁) 在实际应用中, 要特别注意InnoDB行锁的这一特性, 不然的话, 可能导致大量的锁冲突, 从而影响并发性能; 在不通过索引条件查询的时候,InnoDB 确实使用的是表锁,而不是行锁; 由于 MySQL 的行锁是针对索引加的锁, 而不是针对记录加的锁, 所以虽然是访问不同行的记录, 但是如果是使用相同的索引键, 是会出现锁冲突的, 应用设计的时候要注意这一点;(也就是Innodb引擎中, 写操作即使是操作不同的行, 也可能由于使用一样的索引而导致锁冲突) 当表有多个索引的时候, 不同的事务可以使用不同的索引锁定不同的行, 另外, 不论是使用主键索引、唯一索引或普通索引, InnoDB 都会使用行锁来对数据加锁; 即便在条件中使用了索引字段, 但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的, 如果 MySQL 认为全表扫效率更高, 比如对一些很小的表, 它就不会使用索引, 这种情况下 InnoDB 将使用表锁, 而不是行锁;因此, 在分析锁冲突时, 别忘了检查 SQL 的执行计划, 以确认是否真正使用了索引; 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。 共享锁(Share Lock) 共享锁又称读锁, 是读取操作创建的锁。 其他事务可以并发读取数据, 但不能对数据进行修改(获取数据上的排他锁), 直到已释放所有共享锁; (也就是共享锁只可以和共享锁共存) 如果事务T对数据A加上共享锁后, 则其他事务只能对A再加共享锁, 不能加排他锁, 获准共享锁的事务只能读数据, 不能修改数据; 对于一般的select语句, InnoDB不会加任何锁, 当然, 也可以显示手动去自己加: SELECT ... LOCK IN SHARE MODE; 在查询语句后面增加LOCK IN SHARE MODE, Mysql会对查询结果中的每行都加共享锁, 当没有其他线程对查询结果集中的任何一行使用排他锁时, 可以成功申请共享锁, 否则会被阻塞; 其他线程也可以读取使用了共享锁的表, 而且这些线程读取的是同一个版本的数据; 排他锁(Xclusive Lock) 排他锁又称写锁, 如果事务T对数据A加上排他锁后, 则其他事务不能再对A加任任何类型的锁; 获准排他锁的事务既能读数据, 又能修改数据。 对于insert、update、delete，InnoDB会自动给涉及的数据加排他锁(X), 当然, 也可以显示手动去自己加: SELECT ... FOR UPDATE; 在查询语句后面增加FOR UPDATE, Mysql会对查询结果中的每行都加排他锁, 当没有其他线程对查询结果集中的任何一行使用排他锁时, 可以成功申请排他锁, 否则会被阻塞; 意向锁 (不用干预) 意向锁是表级锁, 其设计目的主要是为了在一个事务中揭示下一行将要被请求锁的类型; InnoDB中的两个表锁: 意向共享锁(IS): 表示事务准备给数据行加入共享锁, 也就是说一个数据行加共享锁前必须先取得该表的IS锁; 意向排他锁(IX): 类似上面, 表示事务准备给数据行加入排他锁, 说明事务在一个数据行加排他锁前必须先取得该表的IX锁; 3.意向锁是InnoDB自动加的,不需要用户干预; 4.显示加共享锁或排他锁: 共享锁：SELECT ... LOCK IN SHARE MODE; 排他锁：SELECT ... FOR UPDATE; 共享锁和意向共享锁，排他锁与意向排他锁的区别 共享锁和排他锁: 系统在特定的条件下会自动添加共享锁或者排他锁, 也可以手动添加共享锁或者排他锁; 意向共享锁和意向排他锁都是系统自动添加和自动释放的, 整个过程无需人工干预; 共享锁和排他锁都是锁的行记录,意向共享锁和意向排他锁锁定的是表。 间隙锁 间隙锁是innodb中 行锁 的一种，但是这种锁锁住的却不止一行数据, 他锁住的是多行, 是一个数据范围; 通过生活中的一个小场景来认识间隙锁: a,b,c 三个人依次站成一排, 此时, 新来了一个d, 如何让新来的d不站在小红旁边? 其实只要将b和它前面的a之间的空隙封锁; 再将b和它后面的c之间的空隙封锁; 那么d就不能站到b的旁边了; 这里的a, b, c, d 如果对应到数据表中, 那就是就是一条条记录； 他们之间的空隙也就是间隙, 而封锁他们之间间隙的锁, 就叫做间隙锁; (http://www.jianshu.com/p/bf862c37c4c9) next-key锁 MYISAM 和 INNODB相比:MYISAM不会出现死锁(因为MYISAM没有事务)","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"mysql(InnoDB)事务隔离级别(REPEATABLE READ) 与 锁,MVCC","slug":"2017-12-31-mysql_transaction-05","date":"2017-12-31T08:01:47.000Z","updated":"2018-01-02T01:32:58.000Z","comments":true,"path":"2017/12/31/2017-12-31-mysql_transaction-05/","link":"","permalink":"http://blog.renyimin.com/2017/12/31/2017-12-31-mysql_transaction-05/","excerpt":"","text":"REPEATABLE READ(可重复读) 之前已经了解到, 该隔离级别可以解决不可重复读问题 (当然, 也能解决脏读问题), 那么如果单纯用锁来实现, 可能会是如下这样子: 既然REPEATABLE READ 隔离级别可以解决脏读, 不可重复读的问题, 也就是它既可以让事务只能读其他事务已提交的的记录, 又能在同一事务中保证多次读取的数据即使被其他事务修改, 也是一致的。 解决脏读问题: 试想一下, 当在事务A中读取数据D的时候, 假设D之前已经在事务B中了, 并且事务B中对数据D做了修改, 但是事务B还没有完成(commit/rollback), 那如何让事务A无法读取数据D呢? 当事务B在对数据D做写操作的时候, 假设给数据D加上了行级的排他锁(X lock), 那事务A自然只能阻塞等事务A完成后才能读取数据D了, 这样就解决了脏读问题。 解决 不可重复读问题: 试想一下, 当在事务A中第一次读取了数据D之后, 直接给该数据D加S共享锁, 那其他事务自然只能阻塞等事务A完成后才能对数据D做修改操作了, 这样就解决了不可重复读, 在事务A中多次读取数据D, 都是一样的。 上面使用S锁+X锁确实可以实现 READ COMMITTED 隔离级别的效果, 也就避免了脏读问题和不可重复读问题, 当然, 这里的问题仍然是低效！！！！ 因为 MySQL 在事务隔离级别Read committed 、Repeatable Read下，InnoDB 存储引擎采用非锁定的一致性读－－即读取数据不用加锁，即采用的是MVCC中一致性非锁定读模式, 所以, InnoDB的做法是: 读不影响写，写不影响读。 读不影响写: 当数据正在执行读操作时，其他事务的写操作不会因此去等待当前事务行上S锁的释放，而是会去读取行的一个快照数据。 写不影响读：当数据正在执行写操作时，其他事务的读操作不会因此去等待当前事务行上X锁的释放，而是会去读取行的一个快照数据。 所以总结来看, READ UNCOMMITTED 和 REPEATABLE READ 这两个隔离级别都是使用 写用排他锁 + 读用MVCC, 区别可以参考 MySQL-InnoDB-MVCC多版本并发控制 MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"mysql(InnoDB)事务隔离级别(READ COMMITTED) 与 锁,MVCC","slug":"2017-12-31-mysql_transaction-04","date":"2017-12-31T02:01:47.000Z","updated":"2018-01-02T01:33:33.000Z","comments":true,"path":"2017/12/31/2017-12-31-mysql_transaction-04/","link":"","permalink":"http://blog.renyimin.com/2017/12/31/2017-12-31-mysql_transaction-04/","excerpt":"","text":"READ COMMITTED(提交读) 了解了之前 READ UNCOMMITTED 隔离级别是如何加锁的, 并且在文章中, 已经知道 READ COMMITTED 隔离级别可以解决脏读的问题, 那接下来, 对于 READ COMMITTED 隔离级别, 试想一下如果让你用锁来设计, 你会怎么做? 既然READ COMMITTED 隔离级别可以解决脏读的问题, 也就是他可以让事务只能读其他事务已提交的的记录。 如果用锁机制来实现该隔离级别: 试想一下, 当在事务A中读取数据D的时候, 假设D之前已经在事务B中了, 并且事务B中对数据D做了修改, 但是事务B还没有完成(commit/rollback), 那如何让事务A无法读取数据D呢? 当事务B在对数据D做写操作的时候, 假设给数据D加上了行级的排他锁(X lock), 那事务A自然只能阻塞等事务A完成后才能读取数据D了! 数据库这样做的话确实实现了READ COMMITTED隔离级别的效果, 也就避免了脏读, 但问题是这是一种很低效的做法, 因为对于大部分应用来说, 读操作是多于写操作的, 当写操作加锁时, 那么读操作全部被阻塞, 这样在大用户量高并发的情况下, 会直接降低数据库的读效率。 那么, 既然用锁机制实现该隔离级别是低效的做法, 数据库是如何做的? 之前在相关MVCC的文章中可以得到答案: 数据库是使用了 排他锁+MVCC 的机制来实现该隔离级别的, 而不是单纯的使用锁或者单纯的使用MVCC READ COMMITTED与锁 测试 数据表结构如下: 1234567891011mysql&gt; select * from test_transaction;+----+---------------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+---------------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 2 | 我有一双铁爪 || 2 | 钢铁侠-rym | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+---------------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 重新设置客户端1事务隔离级别为read committed: SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED; 1234567891011121314151617181920mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.00 sec) mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-COMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; 再重新打开一个客户端2并设置事务隔离级别为read committed; 在客户端1中打开事务, 然后更改数据, 先不提交; 然后在客户端2中打开事务, 读取客户端1中尚未提交的那条被修改数据 结果发现在客户端2中可以正常读取到那条数据, 只不过, 那条数据并不是被客户端1事务中修改后的数据, 而是最初的稳定数据, 这就避免了脏读!! 对于该隔离级别修改数据时使用的锁类型, 其分析方法, 和之前一篇MySQL(INNODB引擎)事务READ UNCOMMITTED隔离级别和锁的关系 是一样的： 可以在客户端1的事务在修改数据并且未提交时, 在客户端2中对同一数据进行修改, 然后在客户端2阻塞阶段通过查看表的加锁情况: select * from information_schema.INNODB_LOCKS;,事务状态: select * from information_schema.INNODB_TRX;,进行分析, 结果就不展示了, 可以自行测试一下, 该隔离级别修改数据时使用的也是排他锁, 并且客户端2的修改语句会锁等待~(和之前分析READ UNCOMMITTED隔离级别一样, 既然使用了排他锁, 竟然别的事务还能读取, 这特么不就又违反了排他锁的特性么? 还是那句话, 另一个事务在读取的时候并不会加锁, 而是用的MVCC机制读取的镜像) 小结: InnoDB在该隔离级别(READ COMMITTED)写数据是使用排他锁, 读取数据不加锁而是使用了MVCC机制, 这样就可以大大提高并发读写效率, 写不影响读, 因为读并未加锁, 读的是记录的镜像版本!! MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"mysql(InnoDB)事务隔离级别(READ UNCOMMITTED) 与 锁","slug":"2017-12-29-mysql_transaction-02","date":"2017-12-29T11:12:11.000Z","updated":"2018-01-04T01:56:07.000Z","comments":true,"path":"2017/12/29/2017-12-29-mysql_transaction-02/","link":"","permalink":"http://blog.renyimin.com/2017/12/29/2017-12-29-mysql_transaction-02/","excerpt":"","text":"前言先针对自己以前错误的思维做个记录, 可以直接跳过 由于以前看到很多资料在谈到并发控制的时候, 都会提到用锁来控制并发, MySQL也不例外, 也有很多和锁相关的概念(留到后面会单独整理一篇笔记出来), 所以一提到高并发产生的问题, 我会不自觉地提出一个疑问: 现在并发出问题了, 那怎么用锁的相关知识来解决?; 而且近期一段时间也一直在看很多有关MySQL锁相关的资料,书籍, 于是乎 死锁, 锁冲突, 行锁,表锁, 读锁, 写锁, 乐观锁, 悲观锁 ……等等 N多锁相关的名词(后面的笔记会把所有自己遇到的, 全部整理并进行分析), 大量的篇幅, 高深晦涩的描述, 直接导致我意识里认为嗯, 锁真tm高大上, 真tm高端, 肯定tm就是它了; 于是就进入了思想误区, 认为在解决脏读,不可重复读,幻读的资料中, 应该大篇幅的描述如何用锁相关的知识来解决这些问题, 然而略失落了, 资料倒是提了点儿锁的知识, 但更多的是用事务的哪个隔离级别来解决这些问题, 锁哪儿去了? 尤其是在分析脏读,不可重复读,幻读这几个问题的时候, 一上去就全乱了, 比如 脏读, 如果总是以MySQL锁的相关知识作为前提来分析, 就会陷入误区 ‘事务A读取数据的时候肯定会加S锁的, 事务B自然是无法对未完成的事务A中的数据进行修改的, 我Ca, 这种脏读的场景根本就不成立嘛!‘, 那为什么不提锁, 而是用隔离级别来解决。 ………… 晕了几天之后,终于稍微醒了点…… 参考美团技术博客 显然, 事务隔离级别的核心就是锁, 各隔离级别使用了不同的加锁策略，在分析之前的几个高并发事务问题的时候, 隔离级别(锁)自然是不能作为前置知识点的, 而是最终问题的解决方案! “READ UNCOMMITTED与锁”的困惑(未提交读) 在READ UNCOMMITTED级别, 事务中的修改, 即使还没有提交, 对其他事务也都是可见的; 也就是说事务可以读取未提交的数据, 这也就造成了 脏读(Dirty Read) 的出现。 这个级别会导致很多问题, 而且从性能上来说, READ COMMITTED 并不会比其他的级别好太多, 却缺乏其他级别的很多好处, 在实际应用中一般很少使用。 虽然很少使用, 但还是有必要了解一下, 它这个隔离级别究竟是怎么隔离的, 竟然还能容许很多问题的存在？ (老兄亏你还算个隔离级别, 怎么办事儿的…) 网上相关资料五花八门, 下面列几个出来(希望你看完不要激动): 美团技术博客: segmentfault一篇文章 CSDN一篇文章 CSDN一篇文章 说实话, 资料查到这份儿上, 我已经快崩溃了, 就READ UNCOMMITTED这个隔离级别: 有说读写都不加锁的 有说’修改完数据立即加S锁的, 修改时撤掉S锁’ 有说’写加S锁,事务结束释放’的 有说’写加X锁,事务结束释放’的 行啦, 不查了, 再查就崩溃了, 自己去测一下吧!!! 本次测试是使用MAMP PRO中mysql5.6版本 先准备一张测试表test_transaction: 1234567891011121314DROP TABLE IF EXISTS `test_transaction`;CREATE TABLE `test_transaction` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `user_name` char(20) NOT NULL COMMENT &apos;姓名&apos;, `age` tinyint(3) NOT NULL COMMENT &apos;年龄&apos;, `gender` tinyint(1) NOT NULL COMMENT &apos;1:男, 2:女&apos;, `desctiption` text NOT NULL COMMENT &apos;简介&apos;, PRIMARY KEY (`id`), KEY `name_age_gender_index` (`user_name`,`age`,`gender`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;INSERT INTO `test_transaction` VALUES (1, &apos;金刚狼&apos;, 127, 1, &apos;我有一双铁爪&apos;);INSERT INTO `test_transaction` VALUES (2, &apos;钢铁侠&apos;, 120, 1, &apos;我有一身铁甲&apos;);INSERT INTO `test_transaction` VALUES (3, &apos;绿巨人&apos;, 0, 2, &apos;我有一身肉&apos;); 如下: 123456789mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 2 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) READ UNCOMMITTED与锁 测试演示该隔离级别脏读效果 先查看当前会话(当前客户端)事务的隔离级别: SELECT @@SESSION.tx_isolation; 可以看到: REPEATABLE READ 是InnoDB存储引擎的默认事务隔离级别 123456789mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; 重新设置当前客户端事务隔离级别为read uncommitted: SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; 注意, 此时只是当前会话端的隔离级别被改, 其余客户端连接自然还是默认的REPEATABLE READ隔离级别 接下来将客户端2的事务隔离级别也设置为read uncommitted; 客户端1开启事务,并执行一个查询’读取数据’: 1234567891011121314151617181920mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction where id=2;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 |+----+-----------+-----+--------+--------------------+1 row in set (0.00 sec) mysql&gt; 注意, 客户端1此时的事务并未提交 客户端2开启事务, 并修改客户端1查询的数据 123456789101112131415mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-托尼&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 此时发现, 客户端2可以对客户端1正在读取的记录进行修改, 而根据锁相关知识, 如果说客户端1在读取记录的时候加了S锁, 那么客户端2是不能加X锁对该记录进行更改的, 所以可以得出结论: 要么是客户端1读取记录的时候没有加S锁, 要么是客户端2更改该记录的时候没有加X锁(这样即使客户端1加了S锁,对它这个不加锁的事务也无可奈何), 那么究竟是哪种情况导致的? 下面继续进行分析… 注意, 客户端2此时的事务也并未提交 切换到客户端1, 再次查询数据, 发现数据已经变成了’钢铁侠-托尼’; 然后客户端2 rollback 事务, 再到客户端1中查询,发现user_name又变成了’钢铁侠’, 那之前独到’钢铁侠-托尼’就是脏数据了, 这就是一次 脏读 测试,分析该隔离级别如何加锁 重新构造测试条件 客户端1开启事务, 然后对数据做修改 1234567mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rymuscle&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 注意, 客户端1此时的事务并未提交 客户端2开启事务, 对相同的数据行做修改 12345mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rym&apos; where id=2;....阻塞等待了 最终会如下: 注意: 在上面的过程, 在客户端2阻塞阶段, 你可以通过一个新的客户端来分析, 客户端2在锁等待的情况下的 加锁情况 和 事务状态: 查看表的加锁情况: select * from information_schema.INNODB_LOCKS; 事务状态 select * from information_schema.INNODB_TRX; 所以, READ UNCOMMITTED 隔离级别下, 写操作是会加锁的, 而且是X排他锁, 直到客户端1事务完成, 锁才释放, 客户端2才能进行写操作 接下来你肯定会纳闷 “既然该隔离级别下事务在修改数据的时候加的是x锁, 并且是事务完成后才释放, 那之前的测试客户端2在事务中修改完数据之后, 为什么事务还没完成, 也就是x锁还在, 结果客户端1却能读取到客户端2修改的数据”？这完全不符合排他锁的特性啊(要知道,排他锁会阻塞除当前事务之外的其他事务的读,写操作) 其实网上已经有人在sqlserver的官网上找到了相关资料: 12345ansactions running at the READ UNCOMMITTED level do not issue shared locks to prevent other transactions from modifying data read by the current transaction. READ UNCOMMITTED transactions are also not blocked by exclusive locks that would prevent the current transaction from reading rows that have been modified but not committed by other transactions. When this option is set, it is possible to read uncommitted modifications, which are called dirty reads. Values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. This option has the same effect as setting NOLOCK on all tables in all SELECT statements in a transaction. This is the least restrictive of the isolation levels. 翻译翻译, 在思考思考, 其实说的是在 READ UNCOMMITTED 级别运行的事务不会发出共享锁来防止其他事务修改当前事务读取的数据, 既然不加共享锁了, 那么当前事务所读取的数据自然就可以被其他事务来修改。而且当前事务要读取其他事务未提交的修改, 也不会被排他锁阻止, 因为排他锁会阻止其他事务再对其锁定的数据加读写锁, 但是可笑的是, 事务在该隔离级别下去读数据的话根本什么锁都不加, 这就让排他锁无法排它了, 因为它连锁都没有。这就导致了事务可以读取未提交的修改, 称为脏读。 所以可以得出: READ UNCOMMITTED隔离级别下, 读不会加任何锁。而写会加排他锁，并到事务结束之后释放。 参考资料:-《高性能MySQL》 MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"MySQL-InnoDB-MVCC多版本并发控制","slug":"2017-12-28-mysql_mvcc","date":"2017-12-28T13:07:12.000Z","updated":"2018-01-09T07:57:31.000Z","comments":true,"path":"2017/12/28/2017-12-28-mysql_mvcc/","link":"","permalink":"http://blog.renyimin.com/2017/12/28/2017-12-28-mysql_mvcc/","excerpt":"","text":"(Multiversion Concurrency Control) 前言最近正在啃《高性能MySQL》这本书, 当看到事务相关知识时, 决定对该知识点稍微深入一下,《高性能MySQL》中在介绍事务相关知识点时, 显然不是特别深入, 很多比较底层的知识点并没有太多的深入, 当然此处并不是要对本书做什么评判, 言归正传, 这里主要先说一下本人在啃相关知识点时的曲折之路: 首先是事务相关ACID特性, 之前已经有相关笔记进行过介绍, 这里不再重复; 接下来是高并发事务相关的问题, 像是 脏读, 不可重复读, 幻读, 更新丢失等问题之前也有相关笔记; 再下来就是MySQL应对高并发事务是如何给出解决方案的(其中包含各个隔离级别的简介); 然后就是各个隔离级别的具体介绍及与锁的关系, 也就是在这部分知识点, 发现了之前并没有过多关心的知识点 MVCC多版本并发控制, 然后一发不可收拾了… 入题下面先引用一些前辈们比较优秀的文章: 阿里数据库内核’2017/12’月报中对MVCC的解释是:多版本控制: 指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。在内部实现中，与Postgres在数据行上实现多版本不同，InnoDB是在undolog中实现的，通过undolog可以找回数据的历史版本。找回的数据历史版本可以提供给用户读(按照隔离级别的定义，有些读请求只能看到比较老的数据版本)，也可以在回滚的时候覆盖数据页上的数据。在InnoDB内部中，会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性。&lt;高性能MySQL&gt;中对MVCC的部分介绍 MySQL的大多数事务型存储引擎实现的其实都不是简单的行级锁。基于提升并发性能的考虑, 它们一般都同时实现了多版本并发控制(MVCC)。不仅是MySQL, 包括Oracle,PostgreSQL等其他数据库系统也都实现了MVCC, 但各自的实现机制不尽相同, 因为MVCC没有一个统一的实现标准。 可以认为MVCC是行级锁的一个变种, 但是它在很多情况下避免了加锁操作, 因此开销更低。虽然实现机制有所不同, 但大都实现了非阻塞的读操作，写操作也只锁定必要的行。 MVCC的实现方式有多种, 典型的有乐观(optimistic)并发控制 和 悲观(pessimistic)并发控制。 MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作。其他两个隔离级别够和MVCC不兼容, 因为 READ UNCOMMITTED 总是读取最新的数据行, 而不是符合当前事务版本的数据行。而 SERIALIZABLE 则会对所有读取的行都加锁。从书中可以了解到: MVCC是被Mysql中 事务型存储引擎InnoDB 所支持的; 应对高并发事务, MVCC比单纯的加锁更高效; MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作; MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现; 各数据库中MVCC实现并不统一 但是书中提到 “InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的”(网上也有很多此类观点), 但其实并不准确, 可以参考MySQL官方文档, 可以看到, InnoDB存储引擎在数据库每行数据的后面添加了三个字段, 不是两个!! 相关概念1.read view, 快照snapshot 淘宝数据库内核月报/2017/10/01/此文虽然是以PostgreSQL进行的说明, 但并不影响理解, 在”事务快照的实现”该部分有细节需要注意: 事务快照是用来存储数据库的事务运行情况。一个事务快照的创建过程可以概括为： 查看当前所有的未提交并活跃的事务，存储在数组中 选取未提交并活跃的事务中最小的XID，记录在快照的xmin中 选取所有已提交事务中最大的XID，加1后记录在xmax中根据不同的情况，赋值不同的satisfies，创建不同的事务快照注意: 上文中在PostgreSQL中snapshot的概念, 对应MySQL中, 其实就是你在网上看到的read view,快照这些概念;比如何登成就有关于Read view的介绍;而 此文 却仍是使用快照来介绍; 2.read view 主要是用来做可见性判断的, 比较普遍的解释便是”本事务不可见的当前其他活跃事务”, 但正是该解释, 可能会造成一节理解上的误区, 所以此处提供两个参考, 供给大家避开理解误区: read view中的高水位low_limit_id可以参考 “https://github.com/zhangyachen/zhangyachen.github.io/issues/68“, “https://www.zhihu.com/question/66320138(呵呵一笑百媚生)” 如果单纯按照https://www.jianshu.com/p/fd51cb8dc03b中的的read view介绍来理解, 在rc级别下算法可能就会出错! 其实上面第1点中加粗部分也是相关高水位的介绍( 注意进行了+1 ) 3.另外, 对于read view快照的生成时机, 也非常关键, 正是因为生成时机的不同, 造成了RC,RR两种隔离级别的不同可见性, 可以参考 http://www.sohu.com/a/194511597_610509, https://www.cnblogs.com/digdeep/p/4947694.html 两篇文章; 在innodb中(默认repeatable read级别), 事务在begin/start transaction之后的第一条select读操作后, 会创建一个快照(read view), 将当前系统中活跃的其他事务记录记录起来; 在innodb中(默认repeatable committed级别), 事务中每条select语句都会创建一个快照(read view); 参考1234With REPEATABLE READ isolation level, the snapshot is based on the time when the first read operation is performed. 使用REPEATABLE READ隔离级别，快照是基于执行第一个读操作的时间。With READ COMMITTED isolation level, the snapshot is reset to the time of each consistent read operation.使用READ COMMITTED隔离级别，快照被重置为每个一致的读取操作的时间。 4.undo-log 可以参考数据库内核月报2015/04/01 前言 Undo log是InnoDB MVCC事务特性的重要组成部分。当我们对记录做了变更操作时就会产生undo记录，Undo记录默认被记录到系统表空间(ibdata)中，但从5.6开始，也可以使用独立的Undo 表空间。 Undo记录中存储的是老版本数据，当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着undo链找到满足其可见性的记录。当版本链很长时，通常可以认为这是个比较耗时的操作（例如bug#69812）。 大多数对数据的变更操作包括INSERT/DELETE/UPDATE，其中INSERT操作在事务提交前只对当前事务可见，因此产生的Undo日志可以在事务提交后直接删除（谁会对刚插入的数据有可见性需求呢！！），而对于UPDATE/DELETE则需要维护多版本信息，在InnoDB里，UPDATE和DELETE操作产生的Undo日志被归成一类，即update_undo 另外, 在回滚段中的undo logs分为: insert undo log 和 update undo log insert undo log : 事务对insert新记录时产生的undolog, 只在事务回滚时需要, 并且在事务提交后就可以立即丢弃。 update undo log : 事务对记录进行delete和update操作时产生的undo log, 不仅在事务回滚时需要, 一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被purge线程删除。 5.InnoDB存储引擎在数据库每行数据的后面添加了三个字段 6字节的事务ID(DB_TRX_ID)字段: 用来标识最近一次对本行记录做修改(insert|update)的事务的标识符, 即最后一次修改(insert|update)本行记录的事务id。 至于delete操作，在innodb看来也不过是一次update操作，更新行中的一个特殊位将行表示为deleted, 并非真正删除。 7字节的回滚指针(DB_ROLL_PTR)字段: 指写入回滚段(rollback segment)的 undo log record (撤销日志记录记录)。 如果一行记录被更新, 则 undo log record 包含 ‘重建该行记录被更新之前内容’ 所必须的信息。 6字节的DB_ROW_ID字段: 包含一个随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。 结合聚簇索引的相关知识点, 我的理解是, 如果我们的表中没有主键或合适的唯一索引, 也就是无法生成聚簇索引的时候, InnoDB会帮我们自动生成聚集索引, 但聚簇索引会使用DB_ROW_ID的值来作为主键; 如果我们有自己的主键或者合适的唯一索引, 那么聚簇索引中也就不会包含 DB_ROW_ID 了 。 关于聚簇索引, 《高性能MySQL》中的篇幅对我来说已经够用了, 稍后会整理一下以前的学习笔记, 然后更新上来。 6.可见性比较算法（这里每个比较算法后面的描述是建立在rr级别下，rc级别也是使用该比较算法,此处未做描述）设要读取的行的最后提交事务id(即当前数据行的稳定事务id)为 trx_id_current当前新开事务id为 new_id当前新开事务创建的快照read view 中最早的事务id为up_limit_id, 最迟的事务id为low_limit_id(注意这个low_limit_id=未开启的事务id=当前最大事务id+1)比较: 1.trx_id_current &lt; up_limit_id, 这种情况比较好理解, 表示, 新事务在读取该行记录时, 该行记录的稳定事务ID是小于, 系统当前所有活跃的事务, 所以当前行稳定数据对新事务可见, 跳到步骤5. 2.trx_id_current &gt;= trx_id_last, 这种情况也比较好理解, 表示, 该行记录的稳定事务id是在本次新事务创建之后才开启的, 但是却在本次新事务执行第二个select前就commit了，所以该行记录的当前值不可见, 跳到步骤4。 3.trx_id_current &lt;= trx_id_current &lt;= trx_id_last, 表示: 该行记录所在事务在本次新事务创建的时候处于活动状态，从up_limit_id到low_limit_id进行遍历，如果trx_id_current等于他们之中的某个事务id的话，那么不可见, 调到步骤4,否则表示可见。 4.从该行记录的 DB_ROLL_PTR 指针所指向的回滚段中取出最新的undo-log的版本号, 将它赋值该 trx_id_current，然后跳到步骤1重新开始判断。 5.将该可见行的值返回。 案例分析1.下面是一个非常简版的演示事务对某行记录的更新过程, 当然, InnoDB引擎在内部要做的工作非常多:2.下面是一套比较算法的应用过程也可参考https://github.com/zhangyachen/zhangyachen.github.io/issues/68中的案例 当前读和快照读1.MySQL的InnoDB存储引擎默认事务隔离级别是RR(可重复读), 是通过 “行排他锁+MVCC” 一起实现的, 不仅可以保证可重复读, 还可以部分防止幻读, 而非完全防止; 2.为什么是部分防止幻读, 而不是完全防止? 效果: 在如果事务B在事务A执行中, insert了一条数据并提交, 事务A再次查询, 虽然读取的是undo中的旧版本数据(防止了部分幻读), 但是事务A中执行update或者delete都是可以成功的!! 因为在innodb中的操作可以分为当前读(current read)和快照读(snapshot read): 3.快照读(snapshot read) 简单的select操作(当然不包括 select … lock in share mode, select … for update) 4.当前读(current read) 官网文档 Locking Reads select … lock in share mode select … for update insert update delete在RR级别下，快照读是通过MVVC(多版本控制)和undo log来实现的，当前读是通过加record lock(记录锁)和gap lock(间隙锁)来实现的。innodb在快照读的情况下并没有真正的避免幻读, 但是在当前读的情况下避免了不可重复读和幻读!!! 小结 一般我们认为MVCC有下面几个特点： 每行数据都存在一个版本，每次数据更新时都更新该版本 修改时Copy出当前版本, 然后随意修改，各个事务之间无干扰 保存时比较版本号，如果成功(commit)，则覆盖原记录, 失败则放弃copy(rollback) 就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道, 因为这看起来正是，在提交的时候才能知道到底能否提交成功 而InnoDB实现MVCC的方式是: 事务以排他锁的形式修改原始数据 把修改前的数据存放于undo log，通过回滚指针与主数据关联 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） 二者最本质的区别是: 当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ Innodb的实现真算不上MVCC, 因为并没有实现核心的多版本共存, undo log 中的内容只是串行化的结果, 记录了多个事务的过程, 不属于多版本共存。但理想的MVCC是难以实现的, 当事务仅修改一行记录使用理想的MVCC模式是没有问题的, 可以通过比较版本号进行回滚, 但当事务影响到多行数据时, 理想的MVCC就无能为力了。 比如, 如果事务A执行理想的MVCC, 修改Row1成功, 而修改Row2失败, 此时需要回滚Row1, 但因为Row1没有被锁定, 其数据可能又被事务B所修改, 如果此时回滚Row1的内容，则会破坏事务B的修改结果，导致事务B违反ACID。 这也正是所谓的 第一类更新丢失 的情况。 也正是因为InnoDB使用的MVCC中结合了排他锁, 不是纯的MVCC, 所以第一类更新丢失是不会出现了, 一般说更新丢失都是指第二类丢失更新。 参考 最初读的一篇文章 关于read view创建时机: http://www.sohu.com/a/194511597_610509 https://www.cnblogs.com/digdeep/p/4947694.html https://www.zhihu.com/question/265280455/answer/292022808 关于比较算法 low_limit_id 高水位事务: https://github.com/zhangyachen/zhangyachen.github.io/issues/68 https://www.zhihu.com/question/66320138 https://www.zhihu.com/question/265280455/answer/292022808 大咖问答:https://www.zhihu.com/inbox/4577674200 更多可以参考数据库内核月报: https://yq.aliyun.com/articles/303200?spm=5176.100240.searchblog.9.271fd153pQ9FgV 官方文档","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"}]},{"title":"MySQL(INNODB引擎)高并发事务问题及解决方案","slug":"2017-12-27-mysql_transaction-01","date":"2017-12-27T13:01:07.000Z","updated":"2018-01-09T06:48:45.000Z","comments":true,"path":"2017/12/27/2017-12-27-mysql_transaction-01/","link":"","permalink":"http://blog.renyimin.com/2017/12/27/2017-12-27-mysql_transaction-01/","excerpt":"","text":"事务的概念 事务 可以理解为一个 独立的工作单元, 在这个独立的工作单元中, 有一组操作; 放在事务(独立工作单元)中的多个操作, 要么全部执行成功, 要么全部执行失败。 不免俗套, 这还是通过最经典的银行转账应用来解释一下 假设有两个角色 ‘Iron Man’(余额500), ‘Wolverine’(余额15), 现在 Iron Man 通过该银行应用给 Wolverine 转账100元, 那么本次转账操作至少需要三个步骤: 123检查`Iron Man`余额`&gt;=100`元从`Iron Man`余额中`-100`元给`Wolverine`余额`+100`元 注意: 上面的三个步骤的操作必须打包在一个事务中, 从而可以作为一个 独立的工作单元 来执行。在这个 独立工作单元(即事务) 中的这三个操作, 只要有任何一个操作失败, 则事务就整体就是失败的, 那就必须回滚所有的步骤。 假设第二步操作成功, 但是第三步操作失败, 那么整个事务也就应该是失败的, 那就必须将第二步的操作也回滚。(到这里我们也看到了事务最基本的特性之一: 保证数据的一致性) 要知道, 在真实的高并发场景下, 事务需要做的事情其实很多很多, 因为高并发会出现很多意想不到的问题, 接下来会分析这些问题。 事务的ACID特性在分析高并发事务的问题前, 我们要先知道事务的几个标准特性, 因为一个运行良好的事务处理系统必须具备这些标准特性, 而且这些问题的解决离不开事务的这几个标准特性!!! Atomicity 原子性 一个事务必须被视为一个不可分割的最小工作单元, 整个事务中的所有操作要么全部提交成功, 要么全部失败回滚。对于一个事务来说, 不能只成功执行其中的一部分操作, 这就是事务的原子性。 Consistency 一致性 虽然可数据表中的数据可能一直在变化, 但是事务的一致性特性会保证 数据库总是从一个一致性的状态 转换到 另一个一致性的状态; 比如在之前的转账例子: 123转账前的一致性状态是: &apos;Iron Man&apos;(余额500), &apos;Wolverine&apos;(余额15)转账成功后的一致性状态是: &apos;Iron Man&apos;(余额400), &apos;Wolverine&apos;(余额115)转账如果失败的话, 一致性的状态应该回滚到转账前的状态: &apos;Iron Man&apos;(余额500), &apos;Wolverine&apos;(余额15) Isolation 隔离性 通常来说, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的;比如在之前的转账例子中, 在执行完成第二步, 但是第三步还没开始的时候, 此时有另一个账户汇总的程序开始运行, 那么这个程序所拿到的A账户余额应该是没有被 -100 的余额才对 后面我们还会详细讨论事务隔离性的 隔离级别, 到时候就知道这里为什么说通常来说对其他事务是不可见的; (也就是还有特例, 比如最低隔离级别 READ UNCOMMITTED, 对其他事务的可见就造成了脏读问题的出现) 事务有四种隔离级别(从低到高: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE) Durability 持久性 一旦事务被最终提交, 则在事务这个独立单元中的所有操作所做的修改将会 永久保存到数据库中; (这里所说的永久可以理解为 被事务修改的数据 是真正存放到了表中, 而不是存放在了诸如临时表之类的地方。) 高并发事务的问题在并发量比较大的时候, 很容易出现 多个事务同时进行 的情况。假设有两个事务正在同时进行, 值得注意的是: 它们两者之间是互相不知道对方的存在的, 各自都对自身所处的环境过分乐观, 从而并没有对自己所操作的数据做一定的保护处理, 所以最终导致了一些问题的出现;接下来, 在分析高并发事务的问题时, 你可能已经了解了一些关于锁的概念, 但是在分析这些问题的时候, 先不要带入锁的概念, 本小节只会列出问题, 并直接告诉你各个问题是使用事务隔离性的哪个隔离级别解决掉的, 锁是解决方案, 如果带入锁的概念, 是无法去分析这些问题的。所以本节不需要带入锁!以后将会有文章分析这些解决方案(各隔离级别)具体是如何解决问题的。 脏读 如果mysql中一个事务A读取了另一个并行事务B未最终提交的写数据, 那事务A的这次读取就是脏读。(因为事务A读取的是’脏数据’, 是’非持久性’的数据) 之所以说是’非持久性数据’, ‘脏数据’, 是因为事务B最终可能会因为内部其他后续操作的失败或者系统后续突然崩溃等原因, 导致事务最终整体提交失败, 那么事务A此时读取到的数据在表中其实会被回滚, 那事务A拿到的自然就是脏的数据了。 图示: 事务A在T4阶段读取库存为20, 这个库存其实就属于脏数据, 因为事务B最终会回滚这个数据, 所以如果事务A使用库存20进行后续的操作, 就会引发问题, 因为事务A拿到的数据已经和表中的真实数据不一致了。 那么这个问题如何解决呢? 在MySQL中, 其实事务已经用自身特性（隔离性的 – READ COMMITED或以上隔离级别）解决了这个问题; READ COMMITED级别保证了, 只要是当前语句执行前已经提交的数据都是可见的。注意和REPEATABLE READ级别的区!!! 不可重复读 假设现在上面的 脏读问题 已经被完全解决了, 那就意味着事务中每次读取到的数据都是 持久性 的数据(被别的事务最终 提交/回滚 完成后的数据)。 但是你还需要知道的是: 解决了脏读问题, 只是能保证你在事务中每次读到的数据都是持久性的数据而已!!!! 如果在一个事务中多次读取同一个数据, 正好在两次读取之间, 另外一个事务确实已经完成了对该数据的修改并提交, 那问题就来了: 可能会出现多次读取结果不一致的现象。 那么这个问题如何解决呢? 在MySQL中, 其实事务已经用自身特性（隔离性的 – REPEATABLE READ或以上隔离级别）解决了这个问题; REPEATABLE READ级别保证了, 只要是当前事务执行前已经提交的数据都是可见的。注意和READ COMMITED级别的区!!! 幻读 由于很多人(当然也包括本人), 容易搞混 不可重复读 和 幻读, 这两者确实非常相似。 但 不可重复读 主要是说多次读取一条记录, 发现该记录中某些列值被修改过。 而 幻读 主要是说多次读取一个范围内的记录(包括直接查询所有记录结果或者做聚合统计), 发现结果不一致(标准档案一般指记录增多, 记录的减少应该也算是幻读)。(可以参考MySQL官方文档对 Phantom Rows 的介绍) 其实对于 幻读, MySQL的InnoDB引擎默认的RR级别已经通过MVCC自动帮我们解决了（并非完全解决）, 所以该级别下, 你也模拟不出幻读的场景; 退回到 RC 隔离级别的话, 你又容易把幻读和不可重复读搞混淆, 所以这可能就是比较头痛的点吧! 具体可以参考《高性能MySQL》对 RR 隔离级别的描述, 理论上RR级别是无法解决幻读的问题, 但是由于InnoDB引擎的RR级别还使用了MVCC, 所以也就避免了幻读的出现! 幻读的延伸MVCC虽然解决了幻读问题, 但严格来说只能说是部分解决幻读问题, 接下来进行演示: 打开客户端1查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 打开客户端2查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端2中开启事务, 然后查询数据 1234567891011121314mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端1中插入一条id为4的新数据 (直接自动提交) 1234567891011121314mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 || 4 | 死侍 | 18 | 0 | A bad boy |+----+-----------+-----+--------+--------------------+4 rows in set (0.00 sec) mysql&gt; 在客户端2事务中再次查询数据, 发现数据没有变化(表示可以重复读, 并且克服了幻读)!! 但是在客户端2事务中插入一条id为4的新数据, 发现提示数据已经存在!!! 12345678910111213141516171819202122232425262728mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);1062 - Duplicate entry &apos;4&apos; for key &apos;PRIMARY&apos;mysql&gt; //并且, 此时`update/delete`也是可以操作这条在事务中看不到的记录的! 那么这是什么问题呢? 可以参考MySQL官方文档 – 一致性非阻塞读 The snapshot of the database state applies to SELECT statements within a transaction, not necessarily to DML statements. If you insert or modify some rows and then commit that transaction, a DELETE or UPDATE statement issued from another concurrent REPEATABLE READ transaction could affect those just-committed rows, even though the session could not query them. If a transaction does update or delete rows committed by a different transaction, those changes do become visible to the current transaction.个人认为应该翻译为: 数据库状态的快照适用于事务中的SELECT语句, 而不一定适用于所有DML语句。 如果您插入或修改某些行, 然后提交该事务, 则从另一个并发REPEATABLE READ事务发出的DELETE或UPDATE语句就可能会影响那些刚刚提交的行, 即使该事务无法查询它们。 如果事务更新或删除由不同事务提交的行, 则这些更改对当前事务变得可见。 因此不少资料将MVCC并发控制中的读操作分成两类: 快照读 (snapshot read) 与 当前读 (current read)。 快照读, 读取专门的快照 (对于RC，快照（ReadView）会在每个语句中创建。对于RR，快照是在事务启动时创建的) 1简单的select操作即可(不需要加锁,如: select ... lock in share mode, select ... for update) 针对的也是select操作 当前读, 读取最新版本的记录, 没有快照。 在InnoDB中，当前读取根本不会创建任何快照。 12select ... lock in share modeselect ... for update 针对如下操作, 会让如下操作阻塞: 123insertupdatedelete 在RR级别下, 快照读是通过MVVC(多版本控制)和undo log来实现的, 当前读是通过手动加record lock(记录锁)和gap lock(间隙锁)来实现的。所以从上面的显示来看，如果需要实时显示数据，还是需要通过加锁来实现。这个时候会使用next-key技术来实现。 当然, 使用隔离性的最高隔离级别SERIALIZABLE也可以解决幻读, 但该隔离级别在实际中很少使用! 更新丢失 最后聊一下高并发事务的另一个问题 – 丢失更新问题, 该问题和之前几个问题需要区分开, 因为解决方案不是一类! 第一类丢失更新: A事务撤销时, 把已经提交的B事务的更新数据覆盖了。 不过, 通过后面MVCC相关文章最后的小结你会了解到, 这类更新丢失问题是不会出现的, 因为InnoDB存储引擎的隔离级别都使用了排他锁, 即使是 MVCC也不是纯MVCC, 也用到了排他锁! 这样的话事务A在未完成的时候, 其他事务是无法对事务A涉及到的数据做修改并提交的。 第二类丢失更新: A事务覆盖B事务已经提交的数据，造成B事务所做操作丢失。 此类更新丢失问题, 无法依靠前三种隔离级别来解决, 只能用最高隔离级别 Serializable 或者手动使用乐观锁, 悲观锁来解决。 当然, 更新操作不是在所有情况下都会导致丢失更新问题, 如果你更改的最终状态是确定的, 而不是类似递减或者递增, 那是不会造成丢失更新问题的!! 最高隔离级别Serializable在实际应用场景中并不被采用, 对于手动使用乐观锁, 悲观锁的方案, 将会在以后关于锁的文章中一并给出! 参考资料: 淘宝数据库内核6月报 《高性能MySQL》 美团技术博客 MySQL官方文档","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"Laravel-Facade","slug":"2017-03-10-Laravel-Facade","date":"2017-03-10T13:13:05.000Z","updated":"2018-01-10T12:28:29.000Z","comments":true,"path":"2017/03/10/2017-03-10-Laravel-Facade/","link":"","permalink":"http://blog.renyimin.com/2017/03/10/2017-03-10-Laravel-Facade/","excerpt":"","text":"代码追踪 以获取配置项的 Illuminate\\Support\\Facades\\Config 追踪Facade? 追踪到 Illuminate\\Support\\Facades 123456789101112131415161718192021public static function __callStatic($method, $args) &#123; $instance = static::getFacadeRoot(); if (! $instance) &#123; throw new RuntimeException(&apos;A facade root has not been set.&apos;); &#125; switch (count($args)) &#123; case 0: return $instance-&gt;$method(); case 1: return $instance-&gt;$method($args[0]); case 2: return $instance-&gt;$method($args[0], $args[1]); case 3: return $instance-&gt;$method($args[0], $args[1], $args[2]); case 4: return $instance-&gt;$method($args[0], $args[1], $args[2], $args[3]); default: return call_user_func_array([$instance, $method], $args); &#125; &#125; 这也就是为什么使用Facade的类可以直接使用静态调用的方式来调用方法, 正是Facade中的 __callStatic 方法生效了!","categories":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.renyimin.com/categories/Laravel/"}],"tags":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.renyimin.com/tags/Laravel/"},{"name":"Facade","slug":"Facade","permalink":"http://blog.renyimin.com/tags/Facade/"}]},{"title":"OOP-Factory","slug":"2016-06-03-OOP-Factory","date":"2016-06-03T05:10:39.000Z","updated":"2018-01-12T08:42:45.000Z","comments":true,"path":"2016/06/03/2016-06-03-OOP-Factory/","link":"","permalink":"http://blog.renyimin.com/2016/06/03/2016-06-03-OOP-Factory/","excerpt":"","text":"简单工厂https://www.cnblogs.com/lovecucu/p/6069943.html123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384```1. 如果要实现自己的框架, 在实现 `数据模型层` 时, 需要将 `MySQL`, `Oracle`, `SQLServer`, `Sqlite` 等多种数据库考虑进来传统设计可能会在客户端代码中通过大量 `if...else` 或者 `switch case` 来判断配置项, 并通过 `new` 实例化出相关模型类这样造成的问题是: - 如果模型类是单例模式还好, 客户端只用实例化一次; 如果是别的什么小工具类, 可能你需要在客户端中多次 `new tool()`, 一旦这个工具类类名发生变更, 需要更改的地方就很多了 ; - 而且如果需要兼容的数据库类型更多, 那`if...else` 或者 `switch case`就会变得更长 ;2. 简单工厂模式 ```php &lt;?php abstract class Driver &#123; //当前连接ID protected $_linkID = null; //配置项 protected $config = array( 'type' =&gt; '', // 数据库类型 //..... ); // ......更多属性此处就不涉及了, 重点不是完成ORM public function __construct() &#123; echo static::select() , '&lt;br/&gt;'; &#125; public function select() &#123; return 'driver'; &#125; &#125; class Mysql extends Driver &#123; public function select() &#123; return 'mysql'; &#125; &#125; class Oracle extends Driver &#123; public function select() &#123; return 'oracle'; &#125; &#125; class ModelFactory &#123; //配置项 protected $config = array( 'type' =&gt; '', // 数据库类型 //..... ); public function __construct($config) &#123; $this-&gt;config = $config; &#125; public function getDbInstance() &#123; switch ($this-&gt;config['type']) &#123; case 'oracle': return new Oracle($this-&gt;config); break; //.....其余数据库类型 default: return new Mysql($this-&gt;config); break; &#125; &#125; &#125; $f1 = new ModelFactory(['type' =&gt; 'oracle']); $f1-&gt;getDbInstance(); //oracle $f2 = new ModelFactory(['type' =&gt; 'mysql']); $f2-&gt;getDbInstance(); //mysql 优点: 客户端不用自己直接去创建对象, 而是使用ModelFactory来创建所需的数据库驱动; 它是符合 开闭原则 的 —— 对扩展开放、对修改关闭； 但是工厂类不太理想，因为每增加一个驱动类型, 都要在工厂类中增加相应的判断逻辑, 这显自然是违背开闭原则的; 而在实际应用中，很可能产品是一个多层次的树状结构。由于简单工厂模式中只有一个工厂类来对应这些产品，所以这可能会把我们的上帝类坏了。因此简单工厂模式只适用于业务简单的情况下或者具体产品很少增加的情况。而对于复杂的业务环境可能不太适应了。这就应该由工厂方法模式来出场了！！ 业务部门的新需求来了: 工厂方法12 抽象工厂12 工厂模式 和 依赖注入容器","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP-Singleton","slug":"2016-05-26-OOP-Singleton","date":"2016-05-26T10:21:21.000Z","updated":"2018-01-12T06:54:13.000Z","comments":true,"path":"2016/05/26/2016-05-26-OOP-Singleton/","link":"","permalink":"http://blog.renyimin.com/2016/05/26/2016-05-26-OOP-Singleton/","excerpt":"","text":"常见场景举例 框架底层的 数据库模型层 就可以使用单例 ThinkPHP3.2中, 虽然 数据库模型层 使用了单例模式, 但并非传统意义上所谓 三公一私 的单例: 1234567891011121314TP3.2创建数据库模型实例的过程大概为: Think\\Model -&gt; Think\\Db -&gt; Think\\Db\\Driver\\Mysql -&gt; Think\\Db\\DriverD()/M() 方法都可以调用 Think\\Model 这个模型类虽然 Think\\Model 层并未做到单例, 即 new Model(...) 实例出的对象为非单例, 但其通过调用下层 Think\\Db 的 getInstance(), 然后简单结合一个 数据库对象池$_db(注册树模式) 来保证底层各不同数据库对象的单例性; Think\\Db 的 getInstance() 通过 数据库连接池$instance 保证了下层 Think\\Db\\Driver\\Mysql 数据库连接实例的单例性而 Think\\Db 其内部与底层沟通的方法全是static型, 用户在顶层控制器中直接new也没意义只有在顶层控制器直接 new `Think\\Db\\Driver\\Mysql` 你会获得不同的数据库连接实例, 但一般也不会直接new底层!最下层 Think\\Db\\Driver 为抽象层 所以实现单例未必需要严格按照传统的规则来, 有很多变体都可以保证实现单例; 日志类TP3中的Log类比较简单, 作为基础类, 直接各方法为静态, 很简单就做到了要想使用, 就必然是单例, 基本上你new也没什么用!…未完待续 项目的配置类…未完待续 优点 提供了对唯一实例的受控访问 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象单例模式无疑可以提高系统的性能缺点 PHP语言是一种解释型的脚本语言, 这种运行机制使得每个PHP页面被解释执行后, 所有的相关资源都会被回收。 在PHP中, 所有的变量无论是全局变量还是类的静态成员, 都是页面级的, 每次页面被执行时, 都会重新建立新的对象, 所以PHP单例模式貌似只是针对单次页面级请求时出现多个应用场景并需要共享同一对象资源时是有意义的; 几个基本注意事项 通常我们都是遵循正常的”三私一公”来写单例, 但是可以看到如下代码会因为序列化,反序列化而导致单例出问题 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpclass Singleton&#123; private static $instance = null; private function __construct() &#123; &#125; private function __clone() &#123; &#125; public static function getInstance() &#123; if (null === self::$instance) self::$instance = new self(); return self::$instance; &#125;&#125;echo &apos;&lt;pre/&gt;&apos;;$test_1 = Singleton::getInstance();$test_2 = Singleton::getInstance();var_dump($test_1); //实例1var_dump($test_2); //实例1var_dump($test_1 === $test_2); // trueecho &apos;unserialize, serialize:---------------------------&lt;br/&gt;&apos;;$test_1 = unserialize(serialize($test_1));var_dump($test_1); //实例2var_dump(Singleton::getInstance()); //实例1var_dump( Singleton::getInstance() === $test_1); //falseecho &apos;unserialize, serialize:---------------------------&lt;br/&gt;&apos;;$test_3 = Singleton::getInstance();var_dump($test_3); //实例1$test_3 = unserialize(serialize($test_3));var_dump($test_3); //实例3var_dump(Singleton::getInstance()); //实例1var_dump( Singleton::getInstance() === $test_3); //false 鸟哥博文其实并不能完全解决, 看下面例子: 虽然每次反序列化后的所有实例都一致, 但是一旦碰到再次反序列化, 还是会出问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?phpclass Singleton&#123; private static $instance = null; private function __construct() &#123; &#125; private function __clone() &#123; &#125; public function __wakeup() &#123; self::$instance = $this; &#125; public static function getInstance() &#123; if (null === self::$instance) self::$instance = new self(); return self::$instance; &#125; public function __destruct() &#123; &#125;&#125;echo '&lt;pre/&gt;';$test_1 = Singleton::getInstance(); $test_2 = Singleton::getInstance(); var_dump($test_1); //实例1var_dump($test_2); //实例1var_dump($test_1 === $test_2); //trueecho 'unserialize, serialize:---------------------------&lt;br/&gt;';$test_1 = unserialize(serialize($test_1));var_dump($test_1); //实例2var_dump(Singleton::getInstance()); //实例2var_dump( Singleton::getInstance() === $test_1); //trueecho 'unserialize, serialize:---------------------------&lt;br/&gt;';$test_3 = Singleton::getInstance();var_dump($test_3); //实例2$test_3 = unserialize(serialize($test_3));var_dump($test_3); //实例3var_dump(Singleton::getInstance()); //实例3var_dump( Singleton::getInstance() === $test_3); //true 可以看到还是出现了多个不同的实例!!! 博文中有个评论比较有意思, 可以看一下: 另外, 单例模式出现继承关系时, 需要注意PHP的 self 和 static 关键字的区别 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?phpclass Singleton&#123; protected static $instance = null; protected function __construct() &#123; &#125; protected function __clone() &#123; &#125; protected function __wakeup() &#123; static::$instance = $this; &#125; public static function getInstance() &#123; if (null === static::$instance) static::$instance = new static(); return static::$instance; &#125;&#125;echo &apos;&lt;pre/&gt;&apos;;$test_1 = Singleton::getInstance();$test_2 = Singleton::getInstance();var_dump($test_1);var_dump($test_2);var_dump($test_1 === $test_2);class Log extends Singleton&#123; // 注意: 每个继承单例的子类, 必须要做清空, 否则所有的实例都是上面的实例结果 protected static $instance = null; public function write() &#123; echo &apos;success write something&apos;; &#125;&#125;class Model extends Singleton&#123; // 注意: 每个继承单例的子类, 必须要做清空, 否则所有的实例都是上面的实例结果 protected static $instance = null; public function select() &#123; echo &apos;success select something&apos;; &#125;&#125;$log_1 = Log::getInstance();$log_2 = Log::getInstance();var_dump($log_1);var_dump($log_2);var_dump($log_1 === $log_2);$model_1 = Model::getInstance();$model_2 = Model::getInstance();var_dump($model_1);var_dump($model_2);var_dump($model_1 === $model_2);var_dump($model_1 === $test_2); // false","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOD-S.O.L.I.D","slug":"2016-05-23-OOP-SOLID","date":"2016-05-23T10:21:21.000Z","updated":"2018-01-12T09:25:03.000Z","comments":true,"path":"2016/05/23/2016-05-23-OOP-SOLID/","link":"","permalink":"http://blog.renyimin.com/2016/05/23/2016-05-23-OOP-SOLID/","excerpt":"","text":"The Single Responsibility Principle（单一职责原则 SRP）高内聚, 低耦合 单一职责原则是最简单的面向对象设计原则，它用于控制类的粒度大小。 单一职责原则定义为: 一个类或者模块应该有且只有一个被改变的原因。 如果一个类承担的职责过多, 就等于把这些职责 耦合 在一起了。 一个职责的变化可能会影响其他的职责, 这种耦合会导致脆弱的设计, 当发生变化时, 设计会遭受到意想不到的破坏。 而如果想要避免这种现象的发生, 就要尽可能的遵守单一职责原则。此原则的核心就是解耦和增强内聚性。 单一职责原则告诉我们: 一个类不能太“累”！在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即,将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则也可考虑将它们封装在同一类中。 遵循单一职责原的优点有: 可以降低类的复杂度, 一个类只负责一项职责, 其逻辑肯定要比负责多项职责简单的多; 提高类的可读性, 提高系统的可维护性; 变更引起的风险降低, 变更是必然的, 如果单一职责原则遵守的好, 当修改一个功能时, 可以显著降低对其他功能的影响; 需要说明的一点是单一职责原则不只是面向对象编程思想所特有的, 只要是模块化的程序设计, 都适用单一职责原则; 参考: http://blog.csdn.net/lovelion/article/details/7536542 The Open/Closed Principle（开闭原则OCP）对抽象编程, 而不对具体编程 开放-封闭原则: 一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 任何软件都需要面临一个很重要的问题, 即, 它们的需求会随时间的推移而发生变化。当软件系统需要面对新的需求时，我们应该尽量保证系统的设计框架是稳定的。如果一个软件设计符合开闭原则，那么可以非常方便地对系统进行扩展，而且在扩展时无须修改现有代码，使得软件系统在拥有适应性和灵活性的同时具备较好的稳定性和延续性。随着软件规模越来越大，软件寿命越来越长，软件维护成本越来越高，设计满足开闭原则的软件系统也变得越来越重要。 为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。在Java、C#等编程语言中，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。在很多面向对象编程语言中都提供了接口、抽象类等机制，可以通过它们定义系统的抽象层，再通过具体类来进行扩展。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。 有必要用例子来简单说明一下, 假设公司开发的CRM系统可以显示各种类型的图表, 如 饼状图 和 柱状图 等, 为了支持多种图表显示方式, 原始设计方案如下图: 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?phpclass PieChart&#123; public function display() &#123; echo 'piechart', '&lt;br/&gt;'; &#125;&#125;class BarChart&#123; public function display() &#123; echo 'barchart', '&lt;br/&gt;'; &#125;&#125;class ChartDisplay&#123; public $chartObject = null; public function __construct() &#123; //TODO &#125; public function display($chartType) &#123; switch ($chartType) &#123; case 'pie' : $piechart = new PieChart(); $piechart-&gt;display(); break; case 'bar' : $barchart = new BarChart(); $barchart-&gt;display(); break; default: //TODO break; &#125; &#125;&#125; 问题: 现在如果需要增加一个图表类, 如折线图LineChart, 则需要修改ChartDisplay类的display()方法的源代码, 增加新的判断逻辑, 违反了开闭原则!! 现对该系统进行重构, 使之符合开闭原则 我们引入了抽象图表类AbstractChart, 并且让ChartDisplay针对抽象图表类进行编程(依赖抽象), 在ChartDisplay的display()方法中调用chart对象的display()方法显示图表。 如果需要增加一种新的图表, 如折线图LineChart, 只需要将LineChart也作为AbstractChart的子类, 在客户端向ChartDisplay中注入一个LineChart对象即可, 无须修改现有类库的源代码。 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpabstract class AbstractChart&#123; protected function display() &#123; &#125;&#125;class PieChart extends AbstractChart&#123; public function display() &#123; echo 'piechart', '&lt;br/&gt;'; &#125;&#125;class BarChart extends AbstractChart&#123; public function display() &#123; echo 'barchart', '&lt;br/&gt;'; &#125;&#125;class ChartDisplay&#123; public function __construct() &#123; //TODO &#125; public function display(AbstractChart $chart) &#123; $chart-&gt;display(); &#125;&#125;$cd = new ChartDisplay();$cd-&gt;display(new PieChart());$cd-&gt;display(new BarChart()); 参考: http://blog.csdn.net/lovelion/article/details/7537584 The Liskov Substitution Principle（里氏替换原则LSP） 所有引用基类（父类）的地方必须能透明地使用其子类对象。 子类可以实现父类的抽象方法, 但是不能覆盖父类的非抽象方法, 也就是子类可以扩展父类的功能, 但是不能改变父类原有的功能; 当子类覆盖或实现父类的方法时, 方法的前置条件(即方法的形参)要比父类方法的输入参数更宽松。(PHP是弱类型语言) 当子类的方法实现父类的抽象方法时, 方法的后置条件(即方法的返回值)要比父类更严格。(PHP是弱类型语言)参考: http://blog.csdn.net/lovelion/article/details/7540445里氏代换原则是实现开闭原则的重要方式之一, 由于使用基类对象的地方都可以使用子类对象, 因此在程序中尽量使用基类类型来对对象进行定义, 而在运行时再确定其子类类型, 用子类对象来替换父类对象。 The Interface Segregation Principle（接口分离原则ISP）该原则比较好理解 不要定义过于臃肿的接口, 接口中不要有很多不相关的逻辑方法(否则一定也违背单一职责原则); 过于臃肿的接口可能会强迫用户去实现接口内部用户并不需要的方法。换句话说, 使用 多个专门的接口 比使用 一个臃肿的总接口 要好很多; 如果你在类中实现了你不需要使用的接口方法, 估计也是重写为空方法, 这其实已经违背了接口分离原则。 也就是说，一个接口或者类应该拥有尽可能少的行为, 就是少到恰好能完成它自身的职责, 这也是保证 “软件系统模块的粒度尽可能少, 以达到高度可重用的目的”; 接口包含太多的方法会降低其可用性，像这种包含了无用方法的”胖接口”会增加类之间的耦合。 如果一个类想实现该接口,那么它需要实现所有的方法,尽管有些对它来说可能完全没用，所以这样做会在系统中引入不必要的复杂度, 降低代码的可维护性或鲁棒性。 接口分离原则确保实现的接口有它们共同的职责, 它们是明确的, 易理解的, 可复用的. The Dependency Inversion Principle（依赖反转原则DIP）要针对接口编程, 而不是针对实现编程 如果说开闭原则是面向对象设计的目标的话, 那么依赖倒转原则就是面向对象设计的主要实现机制之一, 它是系统抽象化的具体实现; 上层不用去定义自己要依赖哪个具体的类, 而是定义自己依赖哪个 抽象; 然后让底层代码根据上层的要求, 去实现相应的 抽象; 这样就变成了底层对上层的依赖, 底层代码需要去 实现 上层代码定义的抽象; 依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。 在实现依赖倒转原则时, 我们需要针对抽象层编程，将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和 接口注入。 构造注入是指通过构造函数来传入具体类的对象 设值注入是指通过Setter方法来传入具体类的对象 而接口注入是指通过在接口中声明的业务方法来传入具体类的对象这些方法在定义时使用的是抽象类型, 在运行时再传入具体类型的对象, 由子类对象来覆盖父类对象。 有必要用例子来简单说明一下 由于CustomerDAO针对具体数据转换类编程, 因此在增加新的数据转换类或者更换数据转换类时都不得不修改CustomerDAO的源代码。 我们可以通过引入抽象数据转换类解决该问题，在引入抽象数据转换类DataConvertor之后，CustomerDAO针对抽象类DataConvertor编程，符合依赖倒转原则。 根据里氏代换原则，程序运行时，具体的数据转换类对象 将替换DataConvertor类型的对象，程序不会出现任何问题。更换具体数据转换类时无须修改源代码，只需要说明你需要哪个具体的类(可以在配置文件中配置)。 如果需要增加新的具体数据转换类，只要将新增数据转换类作为DataConvertor的子类即可，原有代码无须做任何修改，满足开闭原则。 重构后的结构如图2所示： 在上述重构过程中, 我们使用了 开闭原则、里氏代换原则 和 依赖倒转原则 , 在大多数情况下, 这三个设计原则会同时出现, 开闭原则是目标, 里氏代换原则是基础, 依赖倒转原则是手段, 它们相辅相成, 相互补充, 目标一致, 只是分析问题时所站角度不同而已。参考: http://blog.csdn.net/lovelion/article/details/7562783 小结开闭原则是目标, 里氏代换原则 和 依赖倒转原则 都是为了实现开闭原则! 怪不得举的例子都那么相似~~","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]}]}