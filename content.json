{"meta":{"title":"Lant's","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"10. ES的写一致机制","slug":"elasticsearch/2018-06-17-10","date":"2018-06-17T08:43:02.000Z","updated":"2018-11-09T03:46:17.000Z","comments":true,"path":"2018/06/17/elasticsearch/2018-06-17-10/","link":"","permalink":"http://blog.renyimin.com/2018/06/17/elasticsearch/2018-06-17-10/","excerpt":"","text":"当我们在发送任何一个增删改操作时, 比如 put /index/type/id, 都可以带上一个 consistency 参数, 指明我们想要的写一致性是什么 consistency 有如下几个值 one : 要求这个写操作, 只要有一个 primary-shard 是active活跃可用的, 就可以执行 all : 要求这个写操作, 必须所有的 primary-shard 和 replica-shard 都是活跃可用的, 才可以执行 quorum : 默认的值, 要求所有的shard中, 必须是大部分的shard都是活跃可用的, 才可以执行 quorum机制:写之前必须确保大多数shard都是可用的 quorum的计算公式: quorum = int(primary+number_of_replicas) / 2) + 1 如果节点数少于quorum的数量, 可能会导致quorum不齐全, 进而无法执行任何写操作比如有一个index对应3个primary-shard, number_of_replica=1, 总共有 3+3*1=6 个shardquorum=int((3+1)/2)+1=3, 所以要求6个shard中至少有3个shard是active状态, 对该文档的写操作才可以执行假设此时只有2个node是active的, 则该document所在的分片, 最多也就只有2个shard是活跃的, 不满足quorum, 所以对该文档的写操作不能执行成功 quorum不齐全时, 会 wait(等待) 1分钟 (默认1分钟, 可以设置timeout手动去调, 默认单位毫秒)等待期间, 期望活跃的shard数量可以增加, 最后实在不行就会timeout, 我们其实可以在写操作的时加一个timeout参数,比如说 PUT /index/type/id?timeout=30s, 自己去设定quorum不齐全的时候, ES的timeout时长默认是毫秒, 加个s代表秒 另外, ES提供了一种特殊处理场景, 当number_of_replicas&gt;1时才生效, 假如就一个primary shard, replica=1,此时就2个shard, ((1 + 1) / 2) + 1 = 2要求必须有2个shard是活跃的, 但如果此时只有1个node, 即只有1个shard是活跃的, 若你不特殊处理的话, 会导致单节点集群无法工作 put /index/type/id/consistency=quorun","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"09. 简单了解ES 分布式, 扩容, 分片, 数据路由","slug":"elasticsearch/2018-06-16-09","date":"2018-06-16T06:01:19.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/16/elasticsearch/2018-06-16-09/","link":"","permalink":"http://blog.renyimin.com/2018/06/16/elasticsearch/2018-06-16-09/","excerpt":"","text":"前言 通过之前的几篇文章应该大概了解了ES是什么, 它能做些什么, 并且简单尝试了一下它的几种查询方式, 聚合分析功能; 这些简单的尝试会让你提前对其语法有个大概认识; 在继续深入ES的相关用法前, 这里也准备先提前对ES的一些基础架构相关内容有个简单了解 复杂分布式的透明 之前在使用ES索引的数据时, 我们并没有关心过数据是如何进行分片的, 也没有关心过数据是到哪个分片中去的; 另外, 之前在用ES做了很多实验之后, 如果留意的话, 你会发现 ES集群状态仍然是 yellow: 如果想让集群达到 green 状态, 之前在 ES 一些基本概念中也介绍过, 此处由于 product 索引默认是 5个primary shard,每个主节点各1个副本节点, 所以需要再启用 1个 ES节点, 集群状态即可变为 GREEN; 而启动节点之后, 我们也并没有关心集群是如何发现该节点的 并且之前未被分配的 replica shard 也自动被均匀分配到了新的节点上, 这也不用我们去关心; ES的复杂分布式对使用它的开发人员来说,都是非常透明的 垂直扩容 与 水平扩容 垂直扩容: 一般是指 对服务器进行升配 或者 采购更强大的服务器; 这种方式会有瓶颈, 而且成本较高; 水平扩容: 比较常用, 可以通过采购更多的普通服务器 来构成强大的计算和存储能力, 成本比较低(10台普通服务器的价钱 和 与其等性能的1台强大服务器相比, 成本相对还是比较低), 而且扩展比较方便, 对开发人员也是透明的; 一个扩容的案例: 假设有5台服务器, 每台可以容纳1T数据, 当数据量要涨到7T时 如果采用垂直扩容: 比如重新替换两台容纳2T数据的服务器, 3+2*2 即可达到7T 如果采用水平扩容: 直接启两台容纳2T数据的服务器, 5+2*1 即可达到7T 水平扩容极限? 假设一个分片对应了3个主分片, 每个主分片对应1个副本分片, 总共6个分片 此时, 只需要2个节点(number_of_replicas+1), 就可以保证集群是 green 状态, 但此时性能并不优, 每个点上节有3个shard, 也就是3个shard共享了节点的资源;如果进行水平扩容的话, 极限就是最多启动6个ES节点, 此时, 每个分片都可以独占单台服务器, 性能最好; 要超出上面的极限, 可以通过动态修改索引对应的副本分片数, 比如修改每个主分片对应2个副本分片, 此时 3+3*2=9 个分片虽然只用3个节点(number_of_replicas+1)就可以保证集群是green但如果要达到极限扩容, 可以最多将ES节点增加到9个, 很显然, 9个节点相比集群刚好green时的3个节点, 吞吐量直接是其3倍 容错性分析 容错性分析: 一个索引 如果对应 3个 Primary-shard, 每个 Primary-shard 对应2个 replica-shard, 总共 3+3*2 = 9首先要知道的是, 要保证集群是 green, 共需要启动3个节点(number_of_replicas+1)如果启动3个节点(此时的shard分配类似 [P1,R2,R3], [P2,R1,R3], [P3,R1,R2]), 此时可以允许有2台机器宕机, 仍然可以提供完整数据如果启动到性能最优的9个节点, 不仅性能会最优, 而且可以容许最多6台机器宕机; 如果对应 3个 Primary-shard, 每个 Primary-shard 对应1个 replica-shard, 总共 3+3*1 = 6如果启动2个节点(此时的shard分配类似 [P1,P2,P3], [R1,R2,R3]), 此时可以允许有1台机器宕机, 仍然可以提供完整数据如果启动3个节点(此时的shard分配类似 [P1,P2], [R2,R3], [P3,R1]), 此时可以允许有1台机器宕机, 仍然可以提供完整数据, 2台则不行;如果启动到性能最优的6个节点, 不仅性能会最优, 而且可以容许最多3台机器宕机; 容错大致过程 如果master节点宕机, es会自动选举一个新的节点作为master节点, 承担master节点的责任; 新master将丢失的 primary-shard 的某个 replica-shard 提升为 primary-shard, 此时 cluster status 会变为yellow, 因为节点宕机后, 自然有 shard 会处于未分配状态; 重启故障的 节点, 如果在重启后有新的 replica-shard, 这些shard会被copy到启动的节点上, 而对于宕机前该node已有的shard, 该node自然会使用之前已有的shard数据, 只是会同步一下宕机后发生过的修改; 分片再次梳理 ES中, 每个 index 默认会物理地对应5个shard; 每个shard都是一个lucene实例, 也是ES中最小的工作单元, 它承载了index中的部分数据; ES集群增加节点时, shard会自动在节点中均匀分布 shard 可以分为 primary shard 和 replica shard index中每个document只存在于一个 primary shard(及该主分片的所有 replica shard)中, 不可能存在于多个 primary shard 中; replica shard 是 primary shard 的副本, 负责容灾以及分担请求负载 primary shard 的数量是在创建索引时就固定的(默认为5个主分片,每个主分片有1个副本分片), 而 replica shard 的数量可以随时修改 primary shard 不会和自己的 replica shard 放在同一个节点上; 多个相同的replica shard也不能放在同一个节点上; (否则该节点宕机, 主分片和副本分片就都丢失, 起不到容错作用)不过 primary shard 可以和其他 index 的primary shard 或 replica shard放在同一节点上; 两个具有相同内容的分片在同一个节点上是起不到容灾作用的, 因此: 对于每个索引, 必须保证 ES节点数 &gt;= number_of_replicas+1, 才能保证该索引的所有包含相同内容的分片都能成功被分配到不同的节点中; 对于任何一个索引, 只要有任何具有相同内容的分片在同一个节点上(相同主分片的两个副本分片在同一节点, 或者主分片和其某个副本分片在同一节点), 集群状态就不可能是green而是yellow; 数据路由 数据路由: 之前已经了解到, 在ES中, 每个index会对应多个物理分片, 所以index中的document也都会分布在各个分片上, 一个document也只可能存在于一个shard中, 那么document分配到哪个分片是如何决定的? 路由算法: hash(routing)%number_of_primary_shards 决定了文档会被放在哪个 primary-shard 上; 默认情况下, 每次增删改查一个document的时候, 都会带过来一个routing, 默认就是document的id(可以手动指定,也可以自动生成) 也可以手动指定 routing: put /index/type/id?routing=user_id手动指定 routing 是很有用的, 这样可以保证某一类document一定被路由到一个shard上去, 在后续进行应用级别的负载均衡, 以及提升批量读取的性能的时候, 是很有帮助的 primary-shard数量不可变的谜底 上面已经了解到了 document 被分配到哪个 primary-shard 是由hash(routing)%number_of_primary_shards决定, 但是如果在后续查询该文档的时候, 你变更了该索引的主分片数, 即number_of_primary_shards, 那么自然就找不到该文档了","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"08. ES 乐观锁并发控制","slug":"elasticsearch/2018-06-16-08","date":"2018-06-16T05:21:07.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/16/elasticsearch/2018-06-16-08/","link":"","permalink":"http://blog.renyimin.com/2018/06/16/elasticsearch/2018-06-16-08/","excerpt":"","text":"前言 悲观锁: 优点: 方便, 直接, 对应用程序来说不需要做额外的操作(比如重试之类的操作) 缺点: 同一时间只有一个线程对数据做操作, 并发能力很低 乐观锁: 优点: 比悲观锁的并发能力要高 缺点: 应用程序在提交时需要对比版本号, 然后可能还需要做一些额外的重试工作; es是使用乐观锁进行并发控制的: 主要是为了防止写覆盖问题 首先乐观锁是不会对数据进行加锁的, 因此可以允许多个线程同时对数据进行读写操作 当多个线程同时对es中的数据进行写操作时, es会对当前文档的version版本号进行检查, 看是否与你写操作时传递的version一致, 一致的话, 则可以写如果写时发现version版本号不同, 则表示数据被其他线程修改过, 此时写操作就会失败;(当然, 后续要看RD想做什么了, 如果类似减库存的操作的话, 如果操作失败, 可以重试 进行库存判断, 可以的话继续做递减操作) es内部版本号 并发控制 es内部是基于 _version元数据 来进行乐观锁并发控制的 模拟两个线程同时对一条 version 为1数据做修改 线程1 123456789GET /products/computer/1# 更改部分字段即可POST /products/computer/1/_update&#123; &quot;doc&quot;: &#123; &quot;name&quot; : &quot;线程1&quot; &#125;&#125;# 结果该文档的version已经变为2了 线程2基于version=1去对文档做修改 12345678# 更改部分字段即可POST /products/computer/1/_update?version=1&#123; &quot;doc&quot;: &#123; &quot;name&quot; : &quot;线程2&quot; &#125;&#125;# 结果发现更新失败, 因为当前传递的 version=1 和 文档中的version=2 不匹配 ES外部版本号 并发控制 另外, es还提供了一个功能, 就是你可以不用它内部提供的 _version 版本号来进行并发控制, 而是基于自己维护的一个版本号来进行并发控制 比如你的数据之前是在mysql中的, 本身应用程序也在mysql中维护了一个版本号(使用已有的规则生成的), 此时进行乐观锁并发控制的时候, 你可以选择不去使用es内部的_version来进行控制, 而是用自己维护的version来进行并发控制 比如 version=1&amp;version_type=external 注意: 外部版本号和内部版本号唯一的区别就是:内部版本号_version只有当你提供的version和es中当前文档的version完全一样时, 才可以进行修改, 不一样就报错而外部版本号则是只有当你提供的version比es中当前文档的version大的时候, 才能完成修改 模拟两个线程同时对一条 version 为1数据做修改 线程1 123456789GET /products/computer/2# 更改部分字段即可POST /products/computer/2/_update&#123; &quot;doc&quot;: &#123; &quot;name&quot; : &quot;线程1&quot; &#125;&#125;# 结果该文档的version已经变为2了 线程2基于version=1去对文档做修改 1234567# 更改部分字段即可POST /products/computer/2/_update?version=1&#123; &quot;doc&quot;: &#123; &quot;name&quot; : &quot;线程2&quot; &#125;&#125; 结果发现更新失败, 提示说 update 操作不支持外部版本号! 但是使用 PUT 尝试后发现生效, 当线程2基于版本1,2都不行, 不许大于2才行","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"07. ES 批量操作 mget, bulk","slug":"elasticsearch/2018-06-10-07","date":"2018-06-10T12:09:13.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/10/elasticsearch/2018-06-10-07/","link":"","permalink":"http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-07/","excerpt":"","text":"mget 批量查询 批量查询可以只发送一次网络请求, 返回多条查询结果, 能大大缩减网络请求的性能开销 练习 : 12345678GET /_mget&#123; &quot;docs&quot; : [ &#123;&quot;_index&quot;:&quot;products&quot;,&quot;_type&quot;:&quot;computer&quot;,&quot;_id&quot;:1&#125;, &#123;&quot;_index&quot;:&quot;products&quot;,&quot;_type&quot;:&quot;computer&quot;,&quot;_id&quot;:2&#125;, &#123;&quot;_index&quot;:&quot;blogs&quot;,&quot;_type&quot;:&quot;php&quot;,&quot;_id&quot;:1&#125; ]&#125; bulk 语法: 每个操作要两个json串, 语法如下: 12&#123;&quot;action&quot;:&#123;&quot;metadata&quot;&#125;&#125;&#123;&quot;data&quot;&#125; 可以执行的操作类型如: delete: 删除一个文档, 只要一个json串就可以了 create: PUT /index/type/id/_create 创建, 存在会报错 index: 即普通的 put 操作, 可以是创建也可以是全量替换文档 update: 执行部分字段更新 练习: 12345678910111213141516171819DELETE /productsPUT /products/computer/1 # 先创建一个文档&#123; &quot;name&quot; : &quot;lenovo&quot;, &quot;desc&quot; : &quot;lianxiang diannao chaobao&quot;, &quot;price&quot; : 4500, &quot;tag&quot; : [&quot;jieneng&quot;, &quot;xuhang&quot;, &quot;chaobao&quot;] &#125;GET /products/computer/_searchPOST /products/_bulk&#123;&quot;delete&quot; : &#123;&quot;_type&quot; : &quot;computer&quot;, &quot;_id&quot; : 1&#125;&#125; # 删除id为1的文档 (1行json即可)&#123;&quot;create&quot; : &#123;&quot;_type&quot; : &quot;computer&quot;, &quot;_id&quot; : 2&#125;&#125; # 创建id为2的文档 (2行json)&#123;&quot;test_field&quot; : &quot;_bulk-create-test2&quot;&#125;&#123;&quot;index&quot; : &#123;&quot;_type&quot; : &quot;computer&quot;&#125;&#125; # 创建一个文档 (es生成id, 2行json)&#123;&quot;test_field&quot; : &quot;_bulk-index-test3&quot;&#125;&#123;&quot;index&quot; : &#123;&quot;_type&quot; : &quot;computer&quot;, &quot;_id&quot; : 3&#125;&#125; # 创建一个id为3的文档 (2行json)&#123;&quot;test_field&quot; : &quot;_bulk-index-test3&quot;, &quot;test_field2&quot; : &quot;_bulk-index-test3&quot;&#125;&#123;&quot;update&quot; : &#123;&quot;_type&quot; : &quot;computer&quot;, &quot;_id&quot; : 3, &quot;_retry_on_conflict&quot;: 3 &#125;&#125; # 更改id为3的文档中的test_field字段&#123;&quot;doc&quot; : &#123;&quot;test_field&quot; : &quot;_bulk-index-update-test3&quot;&#125;&#125; bulk操作中, 任何一个操作失败, 不会影响其他的操作, 但是在返回结果里会有异常日志 bulk的请求会被加载到内存中, 所以如果太大的话, 性能反而会下降, 因此需要通过反复测试来获取一个比较合理的bulk size, 一般从1000~5000条数据开始尝试增加数据; 如果看大小的话, 最好在5-15M之间;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"06. 提前了解查询相关知识点概要, 练习","slug":"elasticsearch/2018-06-10-06","date":"2018-06-10T06:36:57.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/10/elasticsearch/2018-06-10-06/","link":"","permalink":"http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-06/","excerpt":"","text":"提前接触ES的查询和过滤 在es中检索文档时候, 对文档的筛选分为 查询和过滤, 这两种方式是不太一样的, 现在只用先简单了解到 ES中的 结构化检索(精确类型字段的检索) 一般会被放到filter过滤语句中, 不会进行分词和相关度排名, 但会对过滤进行缓存 而 全文检索(全文类型字段的检索) 一般用查询语句进行筛选, 全文检索会进行分词和相关度排名 练习, 搜索商品desc字段中包含 ‘diannao’, 并且售价大于5000的商品 1234567891011121314151617GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;bool&quot;: &#123; &quot;must&quot; : &#123; &quot;match&quot;: &#123; &quot;desc&quot;:&quot;diannao&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;price&quot; : &#123;&quot;gt&quot;: 5000&#125; &#125; &#125; &#125; &#125;&#125; full-text 检索 ES可以进行全文检索并可以进行相关度排名 重新准备数据 1234567891011121314151617181920212223242526272829DELETE /productsPUT /products/computer/1&#123; &quot;name&quot; : &quot;lenovo&quot;, &quot;desc&quot; : &quot;lianxiang diannao chaobao&quot;, &quot;price&quot; : 4500, &quot;tag&quot; : [&quot;jieneng&quot;, &quot;xuhang&quot;, &quot;chaobao&quot;] &#125;PUT /products/computer/2&#123; &quot;name&quot; : &quot;acer&quot;, &quot;desc&quot; : &quot;gaoqing hongji diannao&quot;, &quot;price&quot; : 4870, &quot;tag&quot; : [&quot;jieneng&quot;, &quot;chaobao&quot;, &quot;gaoqing&quot;] &#125;PUT /products/computer/3&#123; &quot;name&quot; : &quot;dell&quot;, &quot;desc&quot; : &quot;daier chaoji diannao&quot;, &quot;price&quot; : 5499, &quot;tag&quot; : [&quot;shishang&quot;, &quot;gaoqing&quot;, &quot;gaoxingneng&quot;] &#125;POST /products/computer/&#123; &quot;name&quot; : &quot;huawei&quot;, &quot;desc&quot; : &quot;china best diannao gaoqing&quot;, &quot;price&quot; : 6080, &quot;tag&quot; : [&quot;gaoxingneng&quot;, &quot;gaoqing&quot;, &quot;jieneng&quot;] &#125; 练习, 全文检索 12345678GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;match&quot;: &#123; &quot;desc&quot;:&quot;gaoqing diannao&quot; &#125; &#125;&#125; 练习 全文高亮检索 12345678910111213GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;desc&quot;:&quot;gaoqing diannao&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot; : &#123; &quot;desc&quot; : &#123;&#125; &#125; &#125;&#125; 结果:12345678910111213141516171819202122232425262728293031323334&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 4, &quot;max_score&quot;: 0.5753642, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;products&quot;, &quot;_type&quot;: &quot;computer&quot;, &quot;_id&quot;: &quot;AWbE6HmlWC0s-aachNUv&quot;, &quot;_score&quot;: 0.5753642, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;huawei&quot;, &quot;desc&quot;: &quot;china best diannao gaoqing&quot;, &quot;price&quot;: 6080, &quot;tag&quot;: [ &quot;gaoxingneng&quot;, &quot;gaoqing&quot;, &quot;jieneng&quot; ] &#125;, &quot;highlight&quot;: &#123; &quot;desc&quot;: [ &quot;china best &lt;em&gt;diannao&lt;/em&gt; &lt;em&gt;gaoqing&lt;/em&gt;&quot; ] &#125; &#125;, ...... 结构化精确检索phrase search(短语搜索) 与全文索引不同, 全文索引会对你发送的 查询串 进行拆分(做分词处理), 然后去倒排索引中与之前在存储文档时分好的词项进行匹配, 只要你发送的查询内容拆分后, 有一个词能匹配到倒排索引中的词项, 该词项所对应的文档就可以返回; phrase search(短语搜索)则不会对你发送的 查询串 进行分词, 而是要求在指定查询的字段中必须包含和你发送的查询串一模一样的内容 才算是匹配, 否则该文档不能作为结果返回; 短语搜索 和 结构化搜索还是不一样 结构化搜索是 你的查询串 和 指定的文档字段内容 是完全一致的, 查询串和字段本身都不会做分词, 一般该字段也是精确类型的字段类型; 而 短语搜索 则是, 你的 查询串 不会做分词, 但是你查询的字段可能会做分词, 你的查询串需要包含在 指定字段中; 搜索商品desc字段中包含 ‘gaoqing diannao’短语 的文档 123456789# 短语检索GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;desc&quot;: &quot;diannao gaoqing&quot; &#125; &#125;&#125; 结果发现, 虽然还是查询的全文字段desc, 但是结果却只有一个 提前了解ES统计语法 统计商品 每个tag下的商品数量, 即, 根据商品的tag进行分组 12345678GET /products/computer/_search&#123; &quot;aggs&quot; : &#123; &quot;group_by_tag&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;:&quot;tag&quot;&#125; &#125; &#125;&#125; 初次运行报错 1234567891011121314151617181920212223242526&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Fielddata is disabled on text fields by default. Set fielddata=true on [tag] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead.&quot; &#125; ], &quot;type&quot;: &quot;search_phase_execution_exception&quot;, &quot;reason&quot;: &quot;all shards failed&quot;, &quot;phase&quot;: &quot;query&quot;, &quot;grouped&quot;: true, &quot;failed_shards&quot;: [ &#123; &quot;shard&quot;: 0, &quot;index&quot;: &quot;products&quot;, &quot;node&quot;: &quot;eCgKpl8JRbqwL3QY0Vuz3A&quot;, &quot;reason&quot;: &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Fielddata is disabled on text fields by default. Set fielddata=true on [tag] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead.&quot; &#125; &#125; ] &#125;, &quot;status&quot;: 400&#125; 解决方案: 将文本field的 filedata 属性设置为true (现在不用知道这玩意儿, 先尽快解决, 看到聚合分析的预发和效果, 后面讲在详聊该问题) 123456789PUT /products/_mapping/computer&#123; &quot;properties&quot;: &#123; &quot;tag&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fielddata&quot;: true &#125; &#125;&#125; 重新执行统计语句, 发现返回中除了分析的结果, 还包含了查询的文档内容; 如果只想显示聚合分析的结果, 可以如下设置size为0: 123456789GET /products/computer/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot; : &#123; &quot;group_by_tag&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;:&quot;tag&quot;&#125; &#125; &#125;&#125; 练习, 针对名称中包含”china”的商品, 计算每个tag下的商品数 12345678910111213GET /products/computer/_search&#123; &quot;query&quot;: &#123; &quot;match&quot; : &#123; &quot;desc&quot; : &quot;gaoqing&quot; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;group_by_tag&quot; : &#123; &quot;terms&quot; : &#123;&quot;field&quot;: &quot;tag&quot;&#125; &#125; &#125;&#125; 练习, 计算每个tag下商品的平均价格 (先分组, 再计算每组的平均值) 1234567891011121314GET /products/computer/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_tag&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;tag&quot;&#125;, &quot;aggs&quot;: &#123; &quot;avg_by_price&quot; : &#123; &quot;avg&quot; : &#123;&quot;field&quot;:&quot;price&quot;&#125; &#125; &#125; &#125; &#125;&#125; 结果: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&#123; &quot;took&quot;: 5, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 16, &quot;max_score&quot;: 0, &quot;hits&quot;: [] &#125;, &quot;aggregations&quot;: &#123; &quot;group_by_tag&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;gaoqing&quot;, &quot;doc_count&quot;: 3, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5483 &#125; &#125;, &#123; &quot;key&quot;: &quot;jieneng&quot;, &quot;doc_count&quot;: 3, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5150 &#125; &#125;, &#123; &quot;key&quot;: &quot;chaobao&quot;, &quot;doc_count&quot;: 2, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4685 &#125; &#125;, &#123; &quot;key&quot;: &quot;gaoxingneng&quot;, &quot;doc_count&quot;: 2, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5789.5 &#125; &#125;, &#123; &quot;key&quot;: &quot;shishang&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5499 &#125; &#125;, &#123; &quot;key&quot;: &quot;xuhang&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4500 &#125; &#125; ] &#125; &#125;&#125; 练习, 计算每个tag下商品的平均价格, 并且按照平均价格进行排序 1234567891011121314GET /products/computer/_search&#123; &quot;size&quot;:0, &quot;aggs&quot;: &#123; &quot;group_by_tag&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;:&quot;tag&quot;, &quot;order&quot;: &#123;&quot;avg_by_price&quot;:&quot;desc&quot;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;avg_by_price&quot;: &#123; &quot;avg&quot;: &#123;&quot;field&quot;: &quot;price&quot;&#125; &#125; &#125; &#125; &#125;&#125; 结果: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&#123; &quot;took&quot;: 3, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 16, &quot;max_score&quot;: 0, &quot;hits&quot;: [] &#125;, &quot;aggregations&quot;: &#123; &quot;group_by_tag&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;gaoxingneng&quot;, &quot;doc_count&quot;: 2, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5789.5 &#125; &#125;, &#123; &quot;key&quot;: &quot;shishang&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5499 &#125; &#125;, &#123; &quot;key&quot;: &quot;gaoqing&quot;, &quot;doc_count&quot;: 3, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5483 &#125; &#125;, &#123; &quot;key&quot;: &quot;jieneng&quot;, &quot;doc_count&quot;: 3, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5150 &#125; &#125;, &#123; &quot;key&quot;: &quot;chaobao&quot;, &quot;doc_count&quot;: 2, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4685 &#125; &#125;, &#123; &quot;key&quot;: &quot;xuhang&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4500 &#125; &#125; ] &#125; &#125;&#125; 练习, 按照指定的价格范围区间进行分组, 然后再每个分组内再按照tag进行分组, 最后在计算每组的平均价格 1234567891011121314151617181920212223242526GET /products/computer/_search&#123; &quot;size&quot;:0, &quot;aggs&quot;: &#123; &quot;group_by_price_range&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;price&quot;, &quot;ranges&quot;: [ &#123;&quot;from&quot;:4500, &quot;to&quot;:5000&#125;, &#123;&quot;from&quot;:5000, &quot;to&quot;:5500&#125;, &#123;&quot;from&quot;:5500, &quot;to&quot;:6100&#125; ] &#125;, &quot;aggs&quot;: &#123; &quot;group_by_tags&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;tag&quot;&#125;, &quot;aggs&quot;:&#123; &quot;avg_by_price&quot;: &#123; &quot;avg&quot;: &#123;&quot;field&quot;:&quot;price&quot;&#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 结果: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126&#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 16, &quot;max_score&quot;: 0, &quot;hits&quot;: [] &#125;, &quot;aggregations&quot;: &#123; &quot;group_by_price_range&quot;: &#123; &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;4500.0-5000.0&quot;, &quot;from&quot;: 4500, &quot;to&quot;: 5000, &quot;doc_count&quot;: 2, &quot;group_by_tags&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;chaobao&quot;, &quot;doc_count&quot;: 2, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4685 &#125; &#125;, &#123; &quot;key&quot;: &quot;jieneng&quot;, &quot;doc_count&quot;: 2, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4685 &#125; &#125;, &#123; &quot;key&quot;: &quot;gaoqing&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4870 &#125; &#125;, &#123; &quot;key&quot;: &quot;xuhang&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 4500 &#125; &#125; ] &#125; &#125;, &#123; &quot;key&quot;: &quot;5000.0-5500.0&quot;, &quot;from&quot;: 5000, &quot;to&quot;: 5500, &quot;doc_count&quot;: 1, &quot;group_by_tags&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;gaoqing&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5499 &#125; &#125;, &#123; &quot;key&quot;: &quot;gaoxingneng&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5499 &#125; &#125;, &#123; &quot;key&quot;: &quot;shishang&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 5499 &#125; &#125; ] &#125; &#125;, &#123; &quot;key&quot;: &quot;5500.0-6100.0&quot;, &quot;from&quot;: 5500, &quot;to&quot;: 6100, &quot;doc_count&quot;: 1, &quot;group_by_tags&quot;: &#123; &quot;doc_count_error_upper_bound&quot;: 0, &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;gaoqing&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 6080 &#125; &#125;, &#123; &quot;key&quot;: &quot;gaoxingneng&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 6080 &#125; &#125;, &#123; &quot;key&quot;: &quot;jieneng&quot;, &quot;doc_count&quot;: 1, &quot;avg_by_price&quot;: &#123; &quot;value&quot;: 6080 &#125; &#125; ] &#125; &#125; ] &#125; &#125;&#125;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"05. ES的搜索方式 Query-string 与 query DSL","slug":"elasticsearch/2018-06-10-05","date":"2018-06-10T03:05:39.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/10/elasticsearch/2018-06-10-05/","link":"","permalink":"http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-05/","excerpt":"","text":"Query-string 搜索 之所以叫 query-string, 是因为search的参数都是以http请求的 query-string 来传递的 练习, 搜索全部商品 GET /products/computer/_search 练习, 搜索商品desc字段中包含 ‘diannao’, 并按照售价排序 GET /products/computer/_search?q=desc:diannao&amp;sort=price:desc query-string这种搜索比较适合在命令行使用curl快速地发一个请求来检索信息, 如果查询比较复杂, 一般不太适用, 正式开发中比较少用; query DSL DSL(Domain Specified Language): 领域特定语言 (这里即 ES的领域特定语言), 是在HTTP的请求体中通过json构建查询语法, 比较方便, 可以构建各种复杂语法; 练习, 查询所有商品 123456GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 练习, 搜索商品desc字段中包含 ‘diannao’, 并按照售价排序 1234567891011GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;match&quot;: &#123; &quot;desc&quot;:&quot;diannao&quot; &#125; &#125;, &quot;sort&quot; : [ &#123;&quot;price&quot; : &quot;desc&quot;&#125; ]&#125; 练习, 分页查询商品 12345678GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;from&quot; : 0, &quot;size&quot; : 2&#125; 练习, 指定需要返回的字段 (使用_source元数据: 可以指定返回哪些field) 1GET /products/computer/1?_source=name,price 1234567GET /products/computer/_search&#123; &quot;query&quot; : &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;_source&quot; : [&quot;name&quot;, &quot;desc&quot;, &quot;tag&quot;]&#125; query DSL 可以在HTTP请求体中构建非常复杂的查询语句, 所以比较常用; 更多复杂用法后面会聊到;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"04. 简单尝试 CURD","slug":"elasticsearch/2018-06-08-04","date":"2018-06-08T13:33:46.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/08/elasticsearch/2018-06-08-04/","link":"","permalink":"http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-04/","excerpt":"","text":"Cat Api ES提供的 Cat Api 可以用来查看 集群当前状态, 涉及到 shard/node/cluster 几个层次 尝试使用 GET /_cat/health?v 查看 时间戳、集群名称、集群状态、集群中节点的数量 等等 12epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1540815645 20:20:45 elasticsearch yellow 1 1 6 6 0 0 6 0 - 50.0% 返回信息 和 集群健康API(GET _cluster/health) 返回都一样 索引文档ES 中可以使用 POST 或 PUT 来索引一个新文档, 熟悉HTTP协议的话, 应该知道 PUT是幂等的, 而POST是非幂等的, ES也遵循了这一点 PUT PUT 创建文档的时候需要手动设定文档ID (类似已知id, 进行修改) 如果文档不存在, 则会创建新文档; 如果文档存在, 则会覆盖整个文档 (所以需要留意) 虽然使用PUT可以防止POST非幂等引起的多次创建, 但也要留意使用PUT带来的文档覆盖问题 练习: 12345678910111213141516171819202122# 此处创建一个 索引为 products , 类型为 computer, 文档ID为1的商品 PUT /products/computer/1&#123; &quot;name&quot; : &quot;lenovo&quot;, &quot;desc&quot; : &quot;lianxiang diannao chaobao&quot;, &quot;price&quot; : 4500, &quot;tag&quot; : [&quot;jieneng&quot;, &quot;xuhang&quot;, &quot;chaobao&quot;] &#125;# 返回&#123; &quot;_index&quot;: &quot;products&quot;, &quot;_type&quot;: &quot;computer&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, # 表示应该写入的有两个分片(1个主分片和1个副本分片, 但注意: 这里代表的可不是总分片数, 显然es的索引默认对应5个主分片, 每个主分片又对应一个副本分片, 总共会有10个分片) &quot;successful&quot;: 1, # 表示成功写入一个分片, 即写入了主分片, 但是副本分片并未写入, 因为目前只启了一个节点 &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true&#125; 另外, 注意: 使用PUT创建文档时, 如果不指定ID, 则会报错 POST POST 创建文档时不需要手动传递文档ID, es会自动生成全局唯一的文档ID 练习 12345678910111213141516171819202122POST /products/computer/&#123; &quot;name&quot; : &quot;huawei&quot;, &quot;desc&quot; : &quot;china best diannao gaoqing&quot;, &quot;price&quot; : 6080, &quot;tag&quot; : [&quot;gaoxingneng&quot;, &quot;gaoqing&quot;, &quot;jieneng&quot;] &#125;# 返回, 可以看到文档ID是自动生成的, 其他字段和使用`PUT`时返回的信息相同&#123; &quot;_index&quot;: &quot;products&quot;, &quot;_type&quot;: &quot;computer&quot;, &quot;_id&quot;: &quot;AWa_MgAhWC0s-aachNUS&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true&#125; 检索文档先尝试最简单的一种 query-string 查询方式: GET /products/computer/_search : 查询/products/computer/下的所有文档 更新文档 PUT、POST PUT 对整个文档进行覆盖更新 1234PUT /products/computer/2&#123; &quot;name&quot; : &quot;acer-hongji&quot;&#125; partial update: 如果只是想更新文档的部分指定字段, 可以使用 POST 结合 _update : (partial update内置乐观锁并发控制) 123456POST /products/computer/2/_update?retry_on_conflict=5&#123; &quot;doc&quot;: &#123; &quot;name&quot; : &quot;acer-hongji-鸿基&quot; &#125;&#125; 这里注意一下_update的内部机制其实是: es先获取整个文档, 然后更新部分字段, 最后老文档标记为deleted, 然后创建新文档此时在标记老文档为deleted时就可能会出现并发问题, 如果线程1抢先一步将老文档标注为deleted, 那么线程2在将新文档标注为deleted时就会失败(version内部乐观锁机制)此时在es内部会做处理, 他内部完成了对乐观锁的实现, 如果失败后, 其实也是进行重试, 你可以手动传递 retry_on_conflict参数来决定其内部的重试次数 PUT如何只创建不替换: 由于创建文档与全量替换文档的语法是一样的, 都是 PUT, 而有时我们只是想新建文档, 不想替换文档 可以使用 op_type=create 来说明此命令只是用来执行创建操作的PUT /index/type/id?op_type=create 或 PUT /index/type/id/_create 可以看到, 此时, 如果文档已经存在, 会进行报错提示冲突, 而不会帮你直接替换1234567PUT /products/computer/1?op_type=create&#123; &quot;name&quot; : &quot;huawei create&quot;, &quot;desc&quot; : &quot;china best diannao gaoqing create&quot;, &quot;price&quot; : 6080, &quot;tag&quot; : [&quot;gaoxingneng&quot;, &quot;gaoqing&quot;, &quot;jieneng&quot;, &quot;create&quot;] &#125; 删除文档 ES的文档替换: 上面已经了解过, 其实就是PUT创建文档, 如果传递的文档id不存在, 就是创建, 如果文档id已经存在, 则是替换操作; 注意: es在做文档的替换操作时, 会将老的document标记为deleted, 然后新增我们给定的那个document, 当后续创建越来越多的document时, es会在适当的时机在后台自动删除标记为delete的document; ES的删除: 不会直接进行物理删除, 而是在数据越来越多的时候, es在合适的时候在后台进行删除 练习: 123456789101112131415DELETE /products/computer/2# 返回&#123; &quot;found&quot;: true, &quot;_index&quot;: &quot;products&quot;, &quot;_type&quot;: &quot;computer&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 6, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;&#125;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"03. ES 一些基本概念","slug":"elasticsearch/2018-06-08-03","date":"2018-06-08T10:23:07.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/08/elasticsearch/2018-06-08-03/","link":"","permalink":"http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-03/","excerpt":"","text":"近实时 从文档被索引到可以被检索会有轻微延时, 约1s Index(索引 n) 这里的Index是个名词, 类似于传统RDS的一个数据库, 是存储document的地方 一个Index可以包含多个 type (索引的复数词为 indices 或 indexes) index 名称必须是小写, 不能用下划线开头, 不能包含逗号 一般将不同的项目数据放到不同的index中 每个index会物理地对应多个分片, 这样, 每个项目都有自己的分片, 互相物理地独立开, 如果有项目是做复杂运算的, 也不会影响其他项目的分片 索引(v) : ES中的还会提到 索引一个文档, 这里的 索引 是动词, 存储文档并建立倒排索引的意思; Type(类型) 一个Index中可以有多个type 代表document属于index中的哪个类别(type 可以对同一个index中不同类型的document进行逻辑上的划分,可以粗略地理解成传统数据库中的数据表?) 名称可以是大小写, 不能用下划线开头, 不能包含逗号 注意: type是对index做的逻辑划分, 而shard是对index做的物理划分 Document(文档) ES中的最小数据单元, ES使用 JSON 作为文档的序列化格式 (ES中的文档可以通俗地理解成传统数据库表中的一条记录) _id: 文档id 可以手动指定, 也可以由es为我们生成; 手动指定id: 根据应用情况来判断是否符合手动指定 document id, 一般如果是从某些其他的系统中导入数据到es, 就会采用这种方式, 就是使用系统中已有的数据的唯一标识作为es中的document的id;比如从数据库中迁移数据到es中, 就比较适合采用数据在数据库中已有的primary key;put /index/type/id 自动生成id: 如果说我们目前要做的系统主要就是将数据存储到es中, 数据产生出来以后直接就会存放到es, 所以不需要手动指定document id的形式, 可以直接让es自动生成id即可;post /index/typees自动生成的id长度为20个字符, URL安全, base64编码, GUID, 分布式并行生成时, es会通过全局id来保证不会发生冲突; Cluster(集群) 集群是由一个或者多个拥有相同 cluster.name 配置项的节点组成, 一个ES节点属于哪个集群, 是由其配置中的 cluster.name 决定的; 节点启动后, 其默认name是elasticsearch, 因此如果在一个机器中启动一堆节点, 那它们会自动组成一个es集群(因为它们的cluster.name都是elasticsearch) 这些节点共同承担数据和负载的压力; 当有节点加入集群中或者从集群中移除节点时, 集群将会重新平均分布所有的数据; Shard(分片): type是对index做的逻辑划分, 而shard是对index做的物理划分 一个分片就是一个 Lucene 的实例, 它是一个底层的工作单元, 其本身就是一个完整的搜索引擎; 分片是数据的容器, 文档其实是保存在分片中的: 当我们将很多条document数据添加到索引中时, 索引实际上是指向一个或者多个物理分片; 因此, 你要存储到索引中的数据其实会被分发到不同的分片中, 而每个分片也仅保存了整个索引中的一部分文档; 当你的集群规模扩大或者缩小时(即增加或减少节点时), ES 会自动的在各节点中迁移分片, 而数据是存放在shard中的, 所以最终会使得数据仍然均匀分布在集群里 shard 可以分为 primary shard(主分片), replica shard(副本分片) replica shard 可以容灾, 水平扩容节点时, 还可以自动分配来提高系统负载 默认情况下, 每个index有5个parimary shard, 而每个parimary shard都有1个replica shard, 即每个index默认会对应10个shard 另外, ES规定了, 每个index的 parimary shard 和 replica shard 不能在全部都在同一个节点上, 相同内容的 replica shard 也不能在同一节点上, 不然起不到容灾作用; 集群状态 yellow 在ES中, 每个索引可能对应多个主分片, 每个主分片也都可能对应多个副本分片 对于每个索引, 要保证不会导致es集群为 yellow, 需要注意: es节点数 &gt;= number_of_replicas+1 当索引的 `number_of_replicas=1` 时, 无论 `number_of_shards` 为多少, 2个节点 (`es节点数 = number_of_replicas+1`) 就可以保证集群是 green; 当索引的 `number_of_replicas&gt;1` 时, 只有当 `es节点数 = number_of_replicas+1` 时, 集群才会变为green; 对于任何一个索引, 由于任何具有相同内容的分片(相同主分片的两个副本分片, 或者主分片和其某个副本分片)不会被放在同一个节点上, 所以如果节点数量不够的话, 有些replica-shard分片会处于未分配状态, 集群状态就不可能是green而是yellow; 比如索引 test 有 3个主分片, 每个主分片对应3个副本分片(该索引总共 3+3*3=12 个分片), 那么至少得4(number_of_replicas+1)个节点, 才能保证每个节点上都不会出现具有相同内容的分片, 即可以保证集群是green;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"02. ES 版本选择及简单安装","slug":"elasticsearch/2018-06-08-02","date":"2018-06-08T06:25:01.000Z","updated":"2018-11-09T03:45:09.000Z","comments":true,"path":"2018/06/08/elasticsearch/2018-06-08-02/","link":"","permalink":"http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-02/","excerpt":"","text":"版本选择 ES 的版本迭代比较快, 目前(06/2018)为止, 已经到6.X了, 可参考官网文档, 可能很多公司还在用2.X, 或者刚切到5.X; 此处之所以选用5.5.3来学习调研, 主要是因为公司选用的阿里云服务提供的是 ES 5.5.3版本 (所以你在选择版本时, 也可以根据 自建、购买云服务 来决定) 安装 安装Java, 推荐使用Java 8 : yum install java-1.8.0-openjdk* -y ES 下载 123456$ cd /usr/local/src$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.3.tar.gz$ tar -zxvf elasticsearch-5.5.3.tar.gz$ cd elasticsearch-5.5.3$ lsbin config lib LICENSE.txt modules NOTICE.txt plugins README.textile 启动 ES: es不能使用root权限启动, 所以需要创建新用户 123456$ adduser es$ passwd es$ chown -R es /usr/local/src/elasticsearch-5.5.3/$ cd /usr/local/src/elasticsearch-5.5.3/bin$ su es$ ./elasticsearch 验证es是否安装成功 可以在浏览器中打开 127.0.0.1:9200 (此处使用的是vagrant设定了虚拟主机的ip, 所以访问 http://192.168.3.200:9200/, 不过有些小坑下面会介绍 ) 或者可以 curl -X GET http://192.168.3.200:9200 启动坑点启动可能会报一些错(调研使用的是 centos7-minimal 版) 每个进程最大同时打开文件数太小 123456789101112131415[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]``` 解决方案: 切换到root, 可通过下面2个命令查看当前数量``` $ ulimit -Hn4096$ ulimit -Sn1024// 编辑如下文件vi /etc/security/limits.conf// 增加如下两行配置* soft nofile 65536* hard nofile 65536 elasticsearch用户拥有的内存权限太小, 至少需要262144 12ERROR: [1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案, 切换到root 123vi /etc/sysctl.conf 添加 vm.max_map_count=262144执行 sysctl -p 默认9200端口是给本机访问的, 因此es在成功启动后, 如果使用 192.168.3.200:9200 来访问, 可能失败, 因此需要在es配置文件elasticsearch.yml中增加 network.bind_host: 0.0.0.0, 重启后则可以正常访问 12345678910111213&#123; &quot;name&quot; : &quot;rjAFeY9&quot;, # node 节点名称 &quot;cluster_name&quot; : &quot;elasticsearch&quot;, # 节点默认的集群名称 (可以在es节点的配置文件elasticsearch.yml中进行配置) &quot;cluster_uuid&quot; : &quot;zaJApkNPRryFohhEMEVH5w&quot;, &quot;version&quot; : &#123; # es 版本号 &quot;number&quot; : &quot;5.5.3&quot;, &quot;build_hash&quot; : &quot;9305a5e&quot;, &quot;build_date&quot; : &quot;2017-09-07T15:56:59.599Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.6.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 上面未解释的信息暂时先不用了解 如果想启动多个结点, 还可能会报如下几个错 尝试启动第二个节点, 报错 123456OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000080000000, 174456832, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12)## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 174456832 bytes for committing reserved memory.# An error report file with more information is saved as:# /usr/local/src/elasticsearch-5.5.3/bin/hs_err_pid8651.log 解决方案: 其实这是因为我给虚拟机分配了2G的内存, 而elasticsearch5.X默认分配给jvm的空间大小就是2g, 所以jvm空间不够, 修改jvm空间分配 1234567vi /usr/local/src/elasticsearch-5.5.3/config/jvm.options将:-Xms2g-Xmx2g修改为:-Xms512m-Xmx512m 再次启动又报错 123...maybe these locations are not writable or multiple nodes were started without increasing [node.max_local_storage_nodes] (was [1])... 解决方案: 在 elasticsearch.yml 配置文件最后添加 node.max_local_storage_nodes: 256, 然后重新添加第二个节点 Elasticsearch Head 安装es 启动后, 访问 127.0.0.1:9200 可以查看版本和集群相关的信息, 但如果能有一个可视化的环境来操作它可能会更直观一些, 可以通过安装 Elasticsearch Head 这个插件来进行管理;Elasticsearch Head 是集群管理、数据可视化、增删改查、查询语句可视化工具, 在最新的ES5中安装方式和ES2以上的版本有很大的不同, 在ES2中可以直接在bin目录下执行 plugin install xxxx 来进行安装, 但是在ES5中这种安装方式变了, 要想在ES5中安装则必须要安装NodeJs, 然后通过NodeJS来启动Head, 具体过程如下: nodejs 安装 123// 更新node.js各版本yum源(Node.js v8.x)curl --silent --location https://rpm.nodesource.com/setup_8.x | bash -yum install -y nodejs github下载 Elasticsearch Head 源码 1234cd /usr/local/srcgit clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm install // (可能会有一些警告) 修改Elasticsearch配置文件, 编辑 elasticsearch-5.5.3/config/elasticsearch.yml, 加入以下内容: 12http.cors.enabled: true // 注意冒号后面要有空格http.cors.allow-origin: &quot;*&quot; 编辑elasticsearch-head-master文件下的Gruntfile.js, 修改服务器监听地址, 增加hostname属性, 将其值设置为 * : 123456789101112vi elasticsearch-head/Gruntfile.jsconnect: &#123; hostname: &quot;*&quot;, // 此处 server: &#123; options: &#123; port: 9100, base: &apos;.&apos;, keepalive: true &#125; &#125;&#125; 编辑elasticsearch-head-master/_site/app.js, 修改head连接es的地址，将localhost修改为es的IP地址 (注意:如果ES是在本地,就不要修改,默认就是localhost) 1this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://localhost:9200&quot;; 在启动elasticsearch-head之前要先启动elasticsearch, 然后在elasticsearch-head-master/目录下运行启动命令 1npm run start 最后验证 http://192.168.3.200:9100/ Kibana安装Kibana 是一个开源的分析和可视化平台, 属于 Elastic stack 技术栈中的一部分, Kibana 主要提供搜索、查看和与存储在 Elasticsearch 索引中的数据进行交互的功能, 开发者或运维人员可以轻松地执行高级数据分析, 并在各种图表、表格和地图中可视化数据;接下来主要就是使用Kibana的DevTools提供的控制台进行ES的学习 下载, 此处选择了5.5.3 12wget https://artifacts.elastic.co/downloads/kibana/kibana-5.5.3-linux-x86_64.tar.gztar -zxvf kibana-5.5.3-linux-x86_64.tar.gz 修改config/kibana.yml文件, 加入以下内容: 1234server.port: 5601 server.name: &quot;kibana&quot; server.host: &quot;0.0.0.0&quot; elasticsearch.url: &quot;http://127.0.0.1:9200&quot; 然后启动kibana服务: 12 cd /usr/local/src/kibana-5.5.3-linux-x86_64/bin./kibana 浏览器访问地址:http://192.168.3.200:5601/ DevTools 与 5.x之前版本的Sense Sense 是一个 Kibana 应用它提供交互式的控制台, 通过你的浏览器直接向 Elasticsearch 提交请求, 操作es中的数据 现在不用安装了, 可以直接使用Kibana提供的 DevTools 注意此时, 之前的es集群变成yellow状态了 (因为kibana有个副本分片并没有处于正常状态, 因为当前只有一个节点, 副本分片无法被分配到其他节点, 具体细节先不用着急, 后面会进行分析) 小结到此为止, 应该对ES有了最基础的了解, 且基本环境已经安装完毕, 对于后续的练习暂时就够了","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]},{"title":"01. 初识 Elasticsearch","slug":"elasticsearch/2018-06-08-01","date":"2018-06-08T06:24:25.000Z","updated":"2018-11-09T03:44:49.000Z","comments":true,"path":"2018/06/08/elasticsearch/2018-06-08-01/","link":"","permalink":"http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-01/","excerpt":"","text":"可以通过如下几个特点来认识ES: 开源 基于 Lucene, 提供比较简单的Restful APILucene 可以说是当下最先进、高性能、全功能的搜索引擎库, 由Apache软件基金会支持和提供(更多细节自行了解)但Lucene非常复杂, ES的目的是使全文检索变得简单, 通过隐藏 Lucene 的复杂性, 取而代之的提供一套简单一致的 RESTful API 高性能全文检索和分析引擎, 并可根据相关度对结果进行排序 可以快速且 近实时 地存储,检索(从文档被索引到可以被检索只有轻微延时, 约1s)以及分析 海量数据检索及分析: 可以扩展到上百台服务器, 处理PB级 结构化 或 非结构化 数据 面向文档型数据库, 存储的是整个对象或者文档, 它不但会存储它们, 还会为它们建立索引 应用场景 当你的应用数据量很大, 数据结构灵活多变, 数据之间的结构比较复杂, 如果用传统数据库, 可能不仅需要面对大量的表设计及数据库的性能问题, 此时可以考虑使用ES, 它不仅可以处理非结构化数据, 而且可以帮你快速进行扩容, 承载大量数据; 具体比如多数据源聚合大列表页: 微服务架构是目前很多公司都采用的架构, 所以经常会面对 多数据源聚合的 大列表页, 一个列表中的筛选字段,展示字段可能会来自多个服务, 同时涉及到分页, 所以传统方案可能比较吃力, 而且也得不到比较好的效果; (RRC这边目前是使用 ES 做 数据视图服务, 对这种大列表页所用到的数据源字段做统一配置和聚合) 日志数据分析, RRC 使用 ElasticStack 技术栈来很方便地对各服务的日志进行查询,分析,统计; 站内搜索(电商, 招聘, 门户 等等)都可以使用 ES 来做全文检索并根据相关性进行排名, 高亮展示关键词等; 版本选择 ES 的版本变更比较快, 目前(06/2018)为止, 已经到6.X了, 可参考官网文档, 可能很多公司还在用2.X, 或者刚切到5.X; 我之所以使用5.5.3来学习调研, 主要也是因为公司选用的阿里云服务提供的是 ES 5.5.3版本 (所以你在选择版本时, 也可以根据 自建、购买云服务 来决定) 安装 安装Java, 推荐使用Java 8 : yum install java-1.8.0-openjdk* -y ES 下载 123456$ cd /usr/local/src$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.3.tar.gz$ tar -zxvf elasticsearch-5.5.3.tar.gz$ cd elasticsearch-5.5.3$ lsbin config lib LICENSE.txt modules NOTICE.txt plugins README.textile 启动 ES: es不能使用root权限启动, 所以需要创建新用户 123456$ adduser es$ passwd es$ chown -R es /usr/local/src/elasticsearch-5.5.3/$ cd /usr/local/src/elasticsearch-5.5.3/bin$ su es$ ./elasticsearch 验证es是否安装成功 可以在浏览器中打开 127.0.0.1:9200 (此处使用的是vagrant设定了虚拟主机的ip, 所以访问 http://192.168.3.200:9200/, 不过有些小坑下面会介绍 ) 或者可以 curl -X GET http://192.168.3.200:9200 启动坑点启动可能会报一些错(调研使用的是 centos7-minimal 版) 每个进程最大同时打开文件数太小 123456789101112131415[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]``` 解决方案: 切换到root, 可通过下面2个命令查看当前数量``` $ ulimit -Hn4096$ ulimit -Sn1024// 编辑如下文件vi /etc/security/limits.conf// 增加如下两行配置* soft nofile 65536* hard nofile 65536 elasticsearch用户拥有的内存权限太小, 至少需要262144 12ERROR: [1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案, 切换到root 123vi /etc/sysctl.conf 添加 vm.max_map_count=262144执行 sysctl -p 默认9200端口是给本机访问的, 因此es在成功启动后, 如果使用 192.168.3.200:9200 来访问, 可能失败, 因此需要在es配置文件elasticsearch.yml中增加 network.bind_host: 0.0.0.0, 重启后则可以正常访问 12345678910111213&#123; &quot;name&quot; : &quot;rjAFeY9&quot;, # node 节点名称 &quot;cluster_name&quot; : &quot;elasticsearch&quot;, # 节点默认的集群名称 (可以在es节点的配置文件elasticsearch.yml中进行配置) &quot;cluster_uuid&quot; : &quot;zaJApkNPRryFohhEMEVH5w&quot;, &quot;version&quot; : &#123; # es 版本号 &quot;number&quot; : &quot;5.5.3&quot;, &quot;build_hash&quot; : &quot;9305a5e&quot;, &quot;build_date&quot; : &quot;2017-09-07T15:56:59.599Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.6.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 上面未解释的信息暂时先不用了解 如果想启动多个结点, 还可能会报如下几个错 尝试启动第二个节点, 报错 123456OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000080000000, 174456832, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12)## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 174456832 bytes for committing reserved memory.# An error report file with more information is saved as:# /usr/local/src/elasticsearch-5.5.3/bin/hs_err_pid8651.log 解决方案: 其实这是因为我给虚拟机分配了2G的内存, 而elasticsearch5.X默认分配给jvm的空间大小就是2g, 所以jvm空间不够, 修改jvm空间分配 1234567vi /usr/local/src/elasticsearch-5.5.3/config/jvm.options将:-Xms2g-Xmx2g修改为:-Xms512m-Xmx512m 再次启动又报错 123...maybe these locations are not writable or multiple nodes were started without increasing [node.max_local_storage_nodes] (was [1])... 解决方案: 在 elasticsearch.yml 配置文件最后添加 node.max_local_storage_nodes: 256, 然后重新添加第二个节点 Elasticsearch Head 安装es 启动后, 访问 127.0.0.1:9200 可以查看版本和集群相关的信息, 但如果能有一个可视化的环境来操作它可能会更直观一些, 可以通过安装 Elasticsearch Head 这个插件来进行管理;Elasticsearch Head 是集群管理、数据可视化、增删改查、查询语句可视化工具, 在最新的ES5中安装方式和ES2以上的版本有很大的不同, 在ES2中可以直接在bin目录下执行 plugin install xxxx 来进行安装, 但是在ES5中这种安装方式变了, 要想在ES5中安装则必须要安装NodeJs, 然后通过NodeJS来启动Head, 具体过程如下: nodejs 安装 123// 更新node.js各版本yum源(Node.js v8.x)curl --silent --location https://rpm.nodesource.com/setup_8.x | bash -yum install -y nodejs github下载 Elasticsearch Head 源码 1234cd /usr/local/srcgit clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm install // (可能会有一些警告) 修改Elasticsearch配置文件, 编辑 elasticsearch-5.5.3/config/elasticsearch.yml, 加入以下内容: 12http.cors.enabled: true // 注意冒号后面要有空格http.cors.allow-origin: &quot;*&quot; 编辑elasticsearch-head-master文件下的Gruntfile.js, 修改服务器监听地址, 增加hostname属性, 将其值设置为 * : 123456789101112vi elasticsearch-head/Gruntfile.jsconnect: &#123; hostname: &quot;*&quot;, // 此处 server: &#123; options: &#123; port: 9100, base: &apos;.&apos;, keepalive: true &#125; &#125;&#125; 编辑elasticsearch-head-master/_site/app.js, 修改head连接es的地址，将localhost修改为es的IP地址 (注意:如果ES是在本地,就不要修改,默认就是localhost) 1this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://localhost:9200&quot;; 在启动elasticsearch-head之前要先启动elasticsearch, 然后在elasticsearch-head-master/目录下运行启动命令 1npm run start 最后验证 http://192.168.3.200:9100/ Kibana安装Kibana 是一个开源的分析和可视化平台, 属于 Elastic stack 技术栈中的一部分, Kibana 主要提供搜索、查看和与存储在 Elasticsearch 索引中的数据进行交互的功能, 开发者或运维人员可以轻松地执行高级数据分析, 并在各种图表、表格和地图中可视化数据;接下来主要就是使用Kibana的DevTools提供的控制台进行ES的学习 下载, 此处选择了5.5.3 12wget https://artifacts.elastic.co/downloads/kibana/kibana-5.5.3-linux-x86_64.tar.gztar -zxvf kibana-5.5.3-linux-x86_64.tar.gz 修改config/kibana.yml文件, 加入以下内容: 1234server.port: 5601 server.name: &quot;kibana&quot; server.host: &quot;0.0.0.0&quot; elasticsearch.url: &quot;http://127.0.0.1:9200&quot; 然后启动kibana服务: 12 cd /usr/local/src/kibana-5.5.3-linux-x86_64/bin./kibana 浏览器访问地址:http://192.168.3.200:5601/ DevTools 与 5.x之前版本的Sense Sense 是一个 Kibana 应用它提供交互式的控制台, 通过你的浏览器直接向 Elasticsearch 提交请求, 操作es中的数据 现在不用安装了, 可以直接使用Kibana提供的 DevTools 注意此时, 之前的es集群变成yellow状态了 (因为kibana有个副本分片并没有处于正常状态, 因为当前只有一个节点, 副本分片无法被分配到其他节点, 具体细节先不用着急, 后面会进行分析) 小结到此为止, 应该对ES有了最基础的了解, 且基本环境已经安装完毕, 暂时就够","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch(一)","slug":"Elasticsearch-一","permalink":"http://blog.renyimin.com/tags/Elasticsearch-一/"}]}]}