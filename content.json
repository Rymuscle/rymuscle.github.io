{"meta":{"title":"Lant's Blog","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"32. 单机部署集群 -- 普通集群","slug":"RabbitMQ/2018-06-26-rabbitmq-32","date":"2018-06-26T07:28:16.000Z","updated":"2018-07-20T07:38:58.000Z","comments":true,"path":"2018/06/26/RabbitMQ/2018-06-26-rabbitmq-32/","link":"","permalink":"http://blog.renyimin.com/2018/06/26/RabbitMQ/2018-06-26-rabbitmq-32/","excerpt":"","text":"前言当你需要在生产环境中部署RabbitMQ时, 需要注意的是, 单实例在生产环境虽然部署起来很容易, 但是当你的rabbitmq服务器遇到内存崩溃或者断电的情况时, 这款高性能的产品就要成为你的耻辱了, 将会为你造成极大的问题!因此你需要将你的RabbitMQ变成高可用的才行; 内建集群简介 RabbitMQ最优秀的功能之一就是其内建集群, 这款消息队列中间件产品本身是基于Erlang编写, Erlang语言天生具备分布式特性(通过同步Erlang集群各节点的magic cookie来实现), 因此, RabbitMQ天然支持Clustering, 这使得RabbitMQ本身不需要像ActiveMQ、Kafka那样通过ZooKeeper分别来实现HA方案和保存集群的元数据。 RabbitMQ内建集群用来完成两个目标: 允许生产者和消费者在RabbitMQ节点崩溃的情况下继续运行;你可以失去一个RabbitMQ节点, 同时客户端可以重新连接到集群中的任何其他节点并继续生产或者消费消息, 就像什么都没有发生一样; 通过增加更多的节点来线性扩展消息吞吐量;如果RabbitMQ正疲于应对庞大的消息通信量的话, 那么线性地增加更多的节点则会增加更多性能; 集群的类型Rabbit集群模式大概分为两种: 普通模式、镜像模式; 本篇主要介绍普通模式 普通模式 普通模式(也就是默认的集群模式), 对于该集群模式, 当你将多个节点组合成集群后, 需要注意的是: 不是每一个节点都有所有队列的完全拷贝 在非集群的单一节点中, 所有关于队列的信息(元数据、状态、内容)都完全存储在该节点上; 但是如果在普通集群模式下创建队列的话, 集群只会在当前节点而不是所有节点上创建完整的队列信息(元数据、状态、内容); 而其他非所有者的节点, 只知道队列的元数据和指向该队列存在的哪个节点的指针; 因此当集群中队列所有者的节点崩溃时, 该节点的队列和关联的绑定就都消失了, 并且附加在这些队列上的消费者就会无法获取其订阅的信息, 并且生产者也无法将匹配该队列绑定信息的消息发送到队列中; 接下来需要了解的一个问题是: 为什么在默认的集群模式下, RabbitMQ不将队列内容和状态复制到所有的节点上? 其实有两个原因 存储空间: 如果每个集群节点都拥有所有Queue的完全数据拷贝, 那么每个节点的存储空间会非常大, 集群的消息积压能力会非常弱(无法通过集群节点的扩容提高消息积压能力); 性能: 消息的发布者需要将消息复制到每一个集群节点, 对于持久化消息来说, 网络和磁盘的负载都会明显增加, 最终只能保持集群性能平稳(甚至更糟); 所以, 通过设置集群中的唯一节点来负责特定队列, 只有该负责节点才会因队列消息而遭受磁盘活动的影响所有其他节点需要将接受到的该队列的消息传递给该队列的所有者节点, 因此, 往RabbitMQ集群添加更多的节点意味着你将拥有更多的节点来传播队列, 这些新增节点为你带来了性能的提升; 但是有人可能会想: 是否可以让消费者重新连接到集群上, 这样不就可以重新创建队列了? 但需要注意的是: 因为一般如果我们的队列设置的是持久化的, 而在该队列的主节点挂掉之后, 重新连接到队列时, 一般也不会修改队列的持久化属性; 这就需要注意一个问题, 仅当你之前创建的队列为非持久化时, 你才可以重新创建该队列为持久化, 因为这是为了保证你之前的持久化队列节点在重新被恢复启动后, 其中的消息还会被恢复, 而如果你创建一个新的持久化队列, 如果覆盖之前的持久化队列, 那消息不就丢了!!所以如果之前是持久化队列, 而且还是以持久化的方式创建该队列, 集群就会报错误, 后面会进行测试! 了解内部元数据RabbitMQ内部会始终同步四种类型的内部元数据: 队列元数据: 队列名称和它的属性 (是否可持久化, 是否自动删除); 交换器元数据: 交换器名称、类型和属性 (可持久化等); 绑定元数据: 一张简单的表格展示了如何将消息路由到队列; vhost元数据: 为vhost内的队列、交换器和绑定提供命名空间和安全属性; 内存or磁盘节点 每个Rabbitmq节点, 不管是单一节点系统或者是庞大集群的一部分, 要么是内存节点(RAM node), 要么是磁盘节点(disk node): 内存节点将所有的队列、交换器、绑定、用户、权限和vhost的元数据定义都仅存储在内存中; 而磁盘节点则将元数据存储在磁盘中; 非集群单一节点: 在单一节点的非集群环境中, RabbitMQ默认会将元数据都存放在内存中; 但是, 会将标记为可持久化的队列和交换器(以及它们的绑定)存储到硬盘上, 存储到硬盘上可以确保队列和交换器在重启Rabbitmq节点后重新被创建; 集群节点类型 当你引入Rabbitmq集群后, RabbitMQ需要追踪的元数据类型包括: 集群节点位置, 以及节点与已记录的其他类型的元数据的关系; 集群对元数据的存储提供了选择:将元数据存储到磁盘上 (集群中创建节点时的默认设置) 或者 存储到RAM内存中 注意, RabbitMQ要求在集群中至少要有一个磁盘节点, 所有其他节点可以是内存节点。当节点加入或者离开集群时, 它们必须要将变更至少通知到一个磁盘节点; 如果只有一个磁盘节点, 而不凑巧的是它有刚好崩溃, 那么集群虽然可以继续路由消息, 但是不能做一下操作: 创建队列 创建交换器 创建绑定 添加用户 更改权限 添加或删除集群节点 集群配置钱准备 在开始配置集群前, 首先要确保现存的Rabbitmq没有运行, 因此需要关闭节点 (本机为mac, 关闭操作如下) 123renyimindeMacBook-Pro:~ renyimin$ brew services stop rabbitmqStopping `rabbitmq`... (might take a while)==&gt; Successfully stopped `rabbitmq` (label: homebrew.mxcl.rabbitmq) 可以发现一个问题, 就是停止Rabbitmq服务之后, 貌似 RabbitMQ Management 的Web UI界面还是可以正常打开运行; 所以正确的关闭节点貌似是 rabbitmqctl stop 开始配置集群前需要注意: 通常来讲, 使用 rabbitmq-server 命令启动节点之后就大功告成了, 但是如果不用额外参数的话, 该命令会使用默认的节点名称 rabbit 和监听端口 5672;所以如果你想用该命令在一台机器上同时启动3个节点的话, 那么第2，3个节点都会因为节点名称和端口号冲突而导致启动失败; 因此, 为了在本机正常启动5个节点, 可以在每次调用 rabbitmq-server前, 通过设置环境变量 RABBITMQ_NODENAME, RABBITMQ_NODE_PORT 来明确指定唯一的节点名称和端口号!在此处做实验时, 将会采用 rabbit, rabbit_1,rabbit_2 命名节点名; 端口号为5612，5613, 5614 注意, 到目前为止, 虽然尚未谈论RabbitMQ的插件, 不过你有可能已经启用了一部分插件了; 如果确实如此的话, 你需要在启动集群节点前将插件禁用!这是因为像 RabbitMQ Management 这样的插件会监听专门的端口来提供服务(例如 Management 插件的 Web UI), 目前还没讲到如何设置插件监听不同的端口, 所以当第二个节点和之后的节点启动了它们的插件后, 就会和第一个启动节点的c插件相冲突, 然后节点就都崩溃了;可以先不禁用插件, 这样在启动多个节点时, 可以根据报错一个个关闭插件也可以; (rabbitmq-plugins disable 插件名) RabbitMQ集群的搭建 启动节点 注意: 启动的时候, 直接加上 -detached 参数的话, 可能会有些报错信息比如 error : cannot_delete_plugins_expand_dir, 这就是因为需要使用root权限才可以, 你可以使用 pa aux | grep rabbitmq 查看是否三个进程都成功启动了 注意: 启动时, 貌似不能像书上那样, RABBITMQ_NODENAME 只设置节点名, 最好设置上节点host 如下: 1234567renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detachedWarning: PID file not written; -detached was passed.renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit_1@localhost rabbitmq-server -detachedWarning: PID file not written; -detached was passed.renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit_2@localhost rabbitmq-server -detachedWarning: PID file not written; -detached was passed.renyimindeMacBook-Pro:~ renyimin$ 然后可以查看个节点状态 123renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost statusrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost statusrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost status 现在启动了三个节点 rabbit, rabbit_1, rabbit_2, 并且每个节点都会有系统的主机名在@后; 但是每个节点仍然是独立节点, 拥有自己的元数据, 并且不知道其他节点的存在; 集群中的第一个节点rabbit,将初始元数据带入集群, 并且无需被告知加入; 而第二个和之后的节点, 将加入第一个节点rabbit, 并获取rabbit节点的元数据; 要将rabbit_1和rabbit_2节点加入rabbit, 要停止该Erlang节点上运行的rabbitmq应用程序, 并重设它们的元数据, 这样它们才可以被加入rabbit节点并且获取rabbit节点的元数据; 可以使用 rabbitmqctl 来完成这些工作 停止rabbit_1节点上的应用程序 12renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost stop_appStopping rabbit application on node rabbit_1@renyimindeMacBook-Pro ... 重设rabbit_1节点的元数据和状态为清空状态 12renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost resetResetting node rabbit_1@renyimindeMacBook-Pro ... 这样你就准备好了一个 停止运行的并且清空了的 rabbit 应用, 现在可以准备好将其加入到集群中的第一个节点rabbit中:注意书上的 cluster 命令好像已经不用了, 换成了 join_cluster 123renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost join_cluster rabbit@localhostClustering node rabbit_1@localhost with rabbit@localhostrenyimindeMacBook-Pro:~ renyimin$ 最后, 可以重启第二个节点的应用程序 1234renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_appStarting node rabbit_1@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ 节点rabbit_2加入集群的步骤同上, 具体操作如下: 12345678910111213renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_appStarting node rabbit_1@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_appStopping rabbit application on node rabbit_2@localhost ...renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost resetResetting node rabbit_2@localhost ...renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost join_cluster rabbit@localhostClustering node rabbit_2@localhost with rabbit@localhostrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_appStarting node rabbit_2@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ 查看集群状态, 可以在任意一个节点通过 rabbitmqctl cluster_status 进行查看 123456789101112131415161718192021222324252627282930renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_statusCluster status of node rabbit@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_statusCluster status of node rabbit_1@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost cluster_statusCluster status of node rabbit_2@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit_2@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ 注意: 上面使用比较多的 rabbitmqctl 命令的关键参数是 -n, 这会告诉rabbitmqctl命令, 你想在指定节点而非默认节点rabbit@上执行命令; 记住, Erlang节点间通过Erlang cookie的方式来允许互相通信。因为rabbitmqctl使用Erlang OPT通信机制来和Rabbit节点通信, 运行rabbitmqctl的机器和所要连接的Rabbit节点必须使用相同的Erlang cookie, 否则你会得到一个错误;当然, 上面的集群是在本机做伪集群, Erlang cookie 自然也都是一致的! 将节点从集群中删除 forget_cluster_node 1234567renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_1@localhostRemoving node rabbit_1@localhost from the clusterrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_2@localhostRemoving node rabbit_2@localhost from the clusterrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_3@localhostRemoving node rabbit_3@localhost from the clusterrenyimindeMacBook-Pro:~ renyimin$ 集群节点类型设置与修改 可以在将节点加入集群时, 设定节点的类型 (参考) 比如 rabbitmqctl -n rabbit_3@localhost join_cluster --ram rabbit@localhost 之前已经通过 rabbitmqctl cluster_status 查看了集群的状态, 里面比较重要的是 nodes 部分 下面告诉你有三个节点加入了集群, 并且三个节点都是 disc 磁盘节点! 1234567[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit_2@localhost,[]&#125;]&#125;] running_nodes 部分告诉你集群中的哪些节点正在运行; 现在你可以连接到这三个running_nodes中的任何一个, 并且开始创建队列, 发布消息或者执行任何其他AMQP任务; 你也可以对节点类型进行修改, 如下将rabbit_2节点类型修改为内存节点 (注意: 修改节点类型, 需要先停止节点应用) 1234567891011121314151617181920renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_appStopping rabbit application on node rabbit_2@localhost ...renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost change_cluster_node_type ramTurning rabbit_2@localhost into a ram noderenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_appStarting node rabbit_2@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_statusCluster status of node rabbit_1@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost]&#125;, &#123;ram,[rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ 测试 运行生产者代码, 在集群中的rabbit节点中创建持久化队列 初始集群状态123456789renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_statusCluster status of node rabbit@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindemacbook-pro.rrcoa.com&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;]&#125;] - 运行生产者, 查看创建的队列(已经有一条msg放入队列中) 123456789101112131415161718192021renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ kill掉该持久化队列localClusterQueue所在的主节点rabbit 查看节点进程 12345renyimindeMacBook-Pro:~ renyimin$ ps aux | grep rabbitmqroot 2656 0.4 0.3 4150148 58156 ?? S 三01下午 5:09.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5672&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost&quot; -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 -noshell -noinputrenyimin 28537 0.0 0.0 2423384 232 s007 R+ 3:12下午 0:00.00 grep rabbitmqroot 72516 0.0 0.5 4143168 79400 ?? S 1:03下午 0:16.71 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_2@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5674&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost&quot; -kernel inet_dist_listen_min 25674 -kernel inet_dist_listen_max 25674 -noshell -noinputroot 71841 0.0 0.5 4138448 77104 ?? S 1:01下午 0:15.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_1@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5673&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost&quot; -kernel inet_dist_listen_min 25673 -kernel inet_dist_listen_max 25673 -noshell -noinput sudo kill 2656 将生产者改连 rabbit_1 节点, 重新运行生产者 报错: 挂掉的主节点中已存在该持久化队列, 如果在主节点挂掉后, 你能直接连接其他节点创建该队列的话, 此时创建的是个新队列, 要知道, 宕机的主节点中的持久化队列还在等待恢复呢, 它内部可能让然有很多msg需要恢复并被处理;所以Rabbit集群的这个问题是有原因的!! 可以重新启动该节点 sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detached 会发现之前的持久化队列会被恢复123456789101112131415161718renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 1prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 1prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 1prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$ 此时即使生产者连接着 rabbit_1 也可以创建该同名持久化队列了 重新运行刚才连接到 rabbit_1 的生产者, 不会报错了, 而是正确往队列发布了一条消息123456renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 2prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"20. 消费者预取 Consumer Prefetch","slug":"RabbitMQ/2018-06-13-rabbitmq-20","date":"2018-06-13T11:23:36.000Z","updated":"2018-07-19T02:06:14.000Z","comments":true,"path":"2018/06/13/RabbitMQ/2018-06-13-rabbitmq-20/","link":"","permalink":"http://blog.renyimin.com/2018/06/13/RabbitMQ/2018-06-13-rabbitmq-20/","excerpt":"","text":"Consumer Prefetch 作为限制 unacked 消息数量的更自然有效的方法; AMQP 0-9-1 指定了 basic.qos 方法, 以便你在消费者进行消费时, 可以限制channel(或connection)上未确认消息的数量; 但是值得注意的是: channel 并不是理想的设定范围, 因为单个channel可能从多个队列进行消费, channel和queue需要为每个发送的消息相互协调, 以确保它们不会超出限制, 这在单台机器上会慢, 而在整个集群中使用时会非常慢; 此外, 对于许多用途, 指定适用于每个消费者的预取计数更会简单一些; 因此, RabbitMQ在 basic.qos 方法中重新定义了全局标志的含义 (在php-amqplib中basic_qos()的第三个参数a_global): 请注意, 在大多数API中, 全局标志的默认值为false; (php-amqplib的basic_qos()方法的第三个参数a_global默认也为false) 简要分析 在使用RabbitMQ时, 如果完全不配置QoS, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是采用默认方式, 将队列中的所有消息按照网络和客户端允许的速度尽快轮发到与队列绑定的consumers端; 而consumers会在本地缓存所有投递过来的messages, 这样的话, 就可能会导致 如果某个消费者的业务逻辑处理比较复杂(将会在较长时间之后才会操作完成并进行ack), 这也就导致消费慢的Consumer将会在本地堆积很多消息, 从而导致内存不足或者对其他进程造成影响 (消费者可能被撑到假死); 而其他消费能力强的Consumers, 可能已经很快地消费完成处于闲置状态, 从而造成资源浪费; 同时, 新启的消费者也无法分担已经被之前消费者缓存到其本地的消息, 所以此时即便启动更多消费者, 也无力缓解大量的 unacked 消息积压, 让你产生疑惑; 而当你设置了Qos之后, RabbitMQ虽然也是将队列中的消息尽快轮发到Consumers中, 但是因为消费者具有的 prefetch_count 消息预取值上限, 所以RabbitMQ在轮发消息的时候, 如果发现消费者的 unacked 消息达到了 prefetch_count 的值, 即使rabbitmq中有很多ready的就绪消息, 也不会给该Consumer继续投递消息了(只有消费者的 unacked 消息小于prefetch_count的值时, 才会继续通过轮发方式给该consumer投递ready消息), 如果此时有新的消费者加入, 它也将会拿到未投递出去的ready消息! 可以通过启动 prefetchCountConsumer1，prefetchCountConsumer2 两个消费者(prefetch_count 均为10), 然后使用下面测试中的生产者发送100条消息, 前期观察会发现队列中消息的最大 unacked 为20, 并且你会发现队列中处于ready状态的消息会每次2个的递减, 这就预示着, 每次这两个消费者只要 unacked 的消息书小于prefetch_count(10), Rabbitmq才会给这两个consumer各自发送一条msg; 之后如果启动了 prefetchCountConsumer3(prefetch_count为20), 此时会发现队列中消息的最大 unacked 会为40, prefetchCountConsumer3的加入会使得队列中处于ready状态的消息直接骤减20个, 最后rabbitmq中的ready消息已经为0, 每个消费者还在继续消费各自未 unacked 的消息, 最终消费完成后, 整个队列中的 unacked 消息为0; Qos的设置只有在开启手动ack后才会生效 (即, prefetch_count 在 no_ask=false 的情况下生效) 测试 一般情况下, 同一队列绑定的多个消费者都是处理同一个业务, 而且如果在同一台机器启动, 消费能力应该都差不多, 但也难免出现如: 消费者资源分配不均 或者 两个消费者在处理业务时所请求的服务端机器配置有差异(假设SLB后又2台配置不均的机器), 这种情况还是应该考虑进来的! 本测试比较简单, 主要测试在默认不设置Qos的情况下, 两个消费能力不同的消费者在处理消息时存在的问题之一: 由于这种情况下, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是只顾自己轮发消息, 这样就会导致消息被轮发完成后, 消费能力高的消费者可能很快消费完消息并处于闲置状态, 而消费能力低的消费者却在很慢地进行消费, 这样就造成了资源的浪费; 准备 创建消费者1 ‘qosCustomer1’ (简单打印消息内容) , 代码参考, 启动消费者 php artisan qosConsumer1 创建消费者2 ‘qosCustomer2’ (sleep 5秒, 模拟处理能力比较差) , 代码参考, 启动消费者 php artisan qosConsumer2 创建生产者一次向队列 ‘qosQueue’ 中推送10条消息 , 代码参考, 请求一次生产者 http://www.rabbit.com/testQos 注意需要先启动消费者, 再请求生产者; (如果先请求了生产者, 可能在启动第一个消费者之后, 其会迅速消费完10条消息, 这样就无法模拟效果了) 测试发现 qosCustomer1 : 迅速打印出结果(1,3,5,7,9), 然后就处于闲置状态了 qosCustomer2 : 还在缓慢打印(2,4,6,8,10) 可以看到, 如果不设置Qos, Rabbitmq会尽快将消息从队列中轮发投递出去, 不会对消费者的消费能力进行任何评估! 所以: 为了避免这种浪费资源的情况, 你可能就需要根据上一篇讲解的 prefetch_count 来针对不同消费者进行设置; 问题答疑测试 根据上面的描述, 有个疑问: 在默认不设置Qos的情况下, 既然生产者发布的消息会尽可能全部推送给消费者进程, 队列中会尽可能将消息全部推出, 缓存在消费者本地, 那当消费者断开时, 消息是如何恢复到队列中的? 或者不会恢复到队列中? 为了答疑, 下面进行测试 准备测试代码 创建消费者1 ‘prefetchCountConsumer1’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), 代码参考 创建消费者2 ‘prefetchCountConsumer2’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), 代码参考 生产者一次向队列 ‘prefetchCountQueue’ 中推送100条消息 , 代码参考 测试: 在生产者请求一次之后(http://www.rabbit.com/prefetchCount), ready : 100, unacked: 0, total : 100, 表示队列中已经有100条消息已经就绪, 等待发出 运行第一个php artisan prefetchCountConsumer1之后, ready : 0, unacked : 100, total : 100 (也就是说, queue中已经没有 ready状态, 即准备好待发送的消息了, 消息都传递给消费者1了) 随着消费者的缓慢消费, ready : 0, unacked : 94, total : 94 () 如果模拟 挂掉第一个消费者之后, 会发现, ready : 83， unacked : 0, total : 83 (也就是说消费者意外宕掉之后, 队列中的消息会重新处于就绪状态, 等待着新的消费者来消费) 再次启动消费者2 php artisan testQosConsumerPrefetchCount2之后, ready : 0, unacked : 80, total : 80 (消息又会被全量发送给消费者2) 注意: 如果此时启动消费者1, 你会发现, 它是无法帮助消费者2进行消费的, 因为消息都在消费者2的本地, 所以队列中并没有 ready状态的就绪消息; 测试注意: 上述测试过程如果先启动两个消费者, 然后再发布消息进行测试, 你会发现, 由于两个消费者都设置了预取值, 而且相等, 所以消息仍然会快速轮发给这两个消费者; 如果将两个消费者的 prefetch_count 都设置为10, 那么你会发现, unacked 最多也就是两个消费者的prefetch_count和, 即20个 小结 消费者的 unacked 消息数量如果未达到Qos设置的 prefetch_count 量, Rabbit不会顾及消费者的消费能力, 会尽可能将queue中的消息全部推送出去给消费者; 因此, 当你发现消费者消费缓慢, 产生大量 unacked 消息时, 即便增加新的消费者, 也无法帮助之前的消费者分担消息(除非消费者1的 unacked 达到了 prefetch_count 限制), 只能分担队列中处于 ready 状态的消息; 除非你断开之前的消费者, 然后启动一个新的消费者, 消费者中积压的消息才会重新放入队列中 (因为之前的消费者挂掉之后, 其处理后的剩余消息在 queue中会恢复为 ready 状态) 但是注意: 新启动的这个消费者如果设置额prefetch_count不合理的话, 假设与之前消费者的 预取值 设置一样大, 它很快也会产生大量 unacked 消息 所以, 在新启消费者的时候, 需要设计好 prefetch_count 的大小, 然后可以启动多个消费者来共同进行消费; 扩展 rabbitmq对 basic.qos 信令的处理 首先, basic.qos 是针对 channel 进行设置的, 也就是说只有在channel建立之后才能发送basic.qos信令; RabbitMQ只支持通道级的预取计数, 而不是connection级的 或者 基于大小的预取;预取 在rabbitmq的实现中, 每个channel都对应会有一个rabbit_limiter进程, 当收到basic.qos信令后, 在rabbit_limiter进程中记录信令中prefetch_count的值, 同时记录的还有该channel未ack的消息个数; 在php-amqplib中, 可以使用 channel 的 basic_qos() 方法来进行控制, basic_qos() 有三个参数: prefetch_size : 限制预取的消息大小的参数, rabbitmq暂时没有实现 (如果prefetch_size字段不是默认值0, 则会通知客户端出错, 通知客户端RabbitMQ系统没有实现该参数的功能, 还可以参考此文)当你设置prefetch_size大于0的时候, 会出现如下报错 prefetch_count : 预取消息数量 global: 在3.3.0版本中对global这个参数的含义进行了重新定义, 即glotal=true时表示在当前channel上所有的consumer都生效(包括已有的), 否则只对设置了之后新建的consumer生效;","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"19. 消费者预取 Consumer Prefetch","slug":"RabbitMQ/2018-06-12-rabbitmq-19","date":"2018-06-12T03:26:55.000Z","updated":"2018-07-20T11:29:49.000Z","comments":true,"path":"2018/06/12/RabbitMQ/2018-06-12-rabbitmq-19/","link":"","permalink":"http://blog.renyimin.com/2018/06/12/RabbitMQ/2018-06-12-rabbitmq-19/","excerpt":"","text":"RabbitMQ关于吞吐量,延迟和带宽的一些理论 假设你在Rabbit中有一个队列, 并有一些客户端从这个队列中进行消费, 如果你根本没有设置QoS, 那么Rabbit将尽可能快地按照网络和客户端允许的速度将所有队列的消息推送到客户端; 因此, 消费者所占用的内存将会激增, 因为它们将所有消息都缓存在自己的RAM中; 同时, 值得注意的是: 此时如果你询问Rabbit, 队列可能会显示为空, 但是会有大量的 unacked 消息; 并且此时如果你添加新的消费者, 由于消息已经在现有的客户端中缓存, 队列中并没有 ready状态的 消息, 所以即使增加更多新的消费者, 也无法缓解队列中 unacked 消息数量, 这是相当次优的! 所以，默认的QoS预取给客户端(consumer)设置了无限的缓冲区, 这可能导致不良的行为和性能; 那么, 应该将QoS预取缓冲区大小设置为多少呢? 目标是让消费者保持工作饱和状态, 但要尽量减少客户端的缓冲区大小, 以便让更多的消息保留在Rabbit的队列中, 这样就可以供新消费者来消费; 比方说, Rabbit从这个队列中拿出一条消息, 把它投递给消费者, 需要50ms, 而Consumer处理消息需要4ms; 一旦消费者处理了消息, 它就会发送一个ack给Rabbit, 这将再次花费50ms发送给Rabbit并被Rabbit进行处理; 所以 消费完成并进行一次ack的时间 + 一次消息从队列到Consumer的投递时间 总共会花费104ms的往返时间。 如果我们消息设置了QoS预取值为1, 那么直到这个往返行程完成之前, Rabbit是不会发送下一个消息给客户端的;因此, 每次往返的104ms中, Consumer只有4ms, 或者说只有3.8％的时间忙碌, 而我们希望Consumer百分之百的时间都在忙碌中; 如果我们在每个消息的客户端上执行 总的往返时间/处理时间, 会得到 104/4 = 26如果我们设置消息的QoS预取值为26, 那就解决了我们的问题: 如果每条消息需要4ms的处理来处理, 那么总共需要 26×4 = 104ms 来处理整个缓冲区(中的消息);第一个4ms是第一个消息的处理时间, 处理完成后, 客户端然后发出一个确认(这需要50ms才能到达代理), 然后继续处理缓冲区中的下一条消息, 一次ack时间 + 新一轮消息的投递时间 = 100s, Consumer正好完成缓冲区剩下的25条消息, 然后新的26条消息也已经到达, 并准备好等待客户端来处理它;因此, 客户端始终处于忙碌状态: 具有较大的QoS预取值也不会使其更快了, 但是我们最大限度地减少了缓冲区的大小, 并且减少了客户端消息的延迟;客户端能够在下一条消息到达之前完全排空缓冲区, 因此缓冲区实际上保持为空; 如果处理时间和网络行为保持不变, 此解决方案绝对没问题 但考虑一下如果网络突然间速度减半会发生什么情况? 显然, 网络传输时间就加长了, 此时你的预取缓冲区(也就是你设置的prefetch预取值)就不够大了, 现在Consumer会就会稍有闲置, 等待新消息到达, 因为客户端能够处理消息的速度比Rabbit能够提供新消息的速度要快; 为了解决这个问题, 我们可能会决定将QoS预取大小加倍(或接近两倍), 如果我们从26开始将它推到51, 那么如果客户端处理保持在每个消息4ms, 我们现在在缓冲区中会有51 * 4 = 204ms的消息处理时间, 其中4ms将用于处理消息, 而200ms用于发送消息回复rabbit并收到下一条消息, 因此, 我们现在可以应对网络速度的减半; 再次分析: 如果网络又恢复正常运行, 现在将QoS预取加倍, 意味着每个消息都会驻留在客户端缓冲区中一段时间​​, 而不是在到达客户端时立即处理; 从现在51条消息的完整缓冲区开始, 我们知道新消息将在客户端完成处理第一条消息之后的100ms处开始出现在客户端, 但在这100毫秒内, 客户只能处理100/4 = 25个消息, 这意味着当新消息到达客户端时, 它会在客户端从缓冲区头部移除时被添加到缓冲区的末尾; 而缓冲区将始终保持(50 - 25 = 25)个消息长度, 因此每个消息将在缓冲区中保持 25 * 4 = 100ms; 因此, 增加预取缓冲区大小, 可以使consumer应对恶化的网络性能, 同时保持客户端繁忙; 同样, 如果不是网络性能的恶化, 而是客户端开始花费40ms来处理每条消息而不是之前的4ms, 会发生什么情况? 假设原始的预取缓冲区大小设置的是26条消息, 客户端现在需要花40ms处理第一条消息, 然后将确认消息发送回Rabbit并移至下一条消息;ack仍然需要50ms才能到达Rabbit, 而Rabbit发出一条新的消息需要50ms, 但在100ms内, 客户端只处理了 100/40 = 2.5 条消息, 而不是剩余的25条消息;因此当新消息到来时, 缓冲区在这一点上仍然是有 25 - 3 = 22 个消息, 这样的话, 来自Rabbit的新消息就不会被立即处理, 而是位于第23位, 落后于其他22条仍在等待处理的消息;客户端(Consumer)将会有 22 * 40 = 880ms 的时间都不会触及到那个新到的消息, 鉴于从Rabbit到客户端的网络延迟仅为50ms, 这个额外的880ms延迟现在为延迟的95％ (880 / (880 + 50) = 0.946); 当你决定尝试通过添加更多消费者来处理这种增长的积压时, 需要注意, 现在有消息正在被现有客户端缓冲, 并不是说你增加消费者就能缓解这部分的压力! 更糟糕的是, 如果我们将缓冲区大小设置为可以预取51条消息以应对网络性能下降,会发生什么?处理第一条消息后, 将在客户端缓冲另外50条消息, 100ms后(假设网络运行正常), 一条新消息将从Rabbit到达客户端, consumer在100ms中只能处理这50条消息中的两条消息(缓冲区现在为47条消息长),因此新消息将会在缓冲区中是第48位, 这样的话, 知道 47 40 = 1880ms 之后, 消费者才会开始处理新来的消息, 同样, 考虑到向客户端发送消息的网络延迟仅为50ms, 现在这个1880ms的延迟意味着客户端缓冲占延迟的97％(1880/(1880 + 50)= 0.974);这可能是不可接受的: 数据只能在客户端收到后2秒内立即处理, 才能有效且有用！*如果其他消费客户端空闲, 他们无能为力: 一旦Rabbit向客户端发送消息, 消息就是客户端的责任, 直到他们拒绝或拒绝消息; 消息发送到客户端后，客户端不能窃取彼此的消息;您希望客户端保持繁忙状态, 但客户端尽可能少地缓存消息, 以便客户端缓冲区不会延迟消息, 因此新消费客户端可以快速接收来自Rabbit队列的消息; 因此, 如果网络变慢, 缓冲区太小会导致客户端空闲; 但如果网络正常运行, 缓冲区太大会导致大量额外的延迟;如果客户端突然开始花费更长时间来处理每个缓冲区, 则会导致大量额外的延迟;很明显, 你真正想要的是可以变化的缓冲区大小, 这些问题在网络设备中很常见, 并且一直是很多研究的主题;主动队列管理算法试图尝试放弃或拒绝消息，以避免消息长时间处于缓冲区。当缓冲区保持空闲时（每条消息只遭受网络延迟，并且根本不在缓冲区中），缓冲区在那里吸收峰值，从而实现最低延迟。从网络路由器的角度来看，Jim Gettys一直在研究这个问题：局域网和广域网性能之间的差异会遇到完全相同的问题。实际上，无论何时，在生产者（在我们的例子中为Rabbit）和消费者（客户端应用程序逻辑）之间都有一个缓冲区，双方的性能可以动态变化，您将会遇到这些问题。最近发布了一种名为Controlled Delay的新算法，该算法似乎在解决这些问题方面效果很好。 小结 针对Qos的提前预习 信道预取设置(QoS)由于消息是异步发送(推送)给客户端的, 因此在任何给定时刻通常都有不止一条消息在信道上运行; 此外, 客户的手动确认本质上也是异步的, 所以有一个 未确认的交付标签的滑动窗口, 开发人员通常会倾向于限制此窗口的大小, 以避免消费者端无限制的缓冲区问题。这是通过使用 basic.qos 方法设置 预取计数 值完成的, 该值定义了channel上允许的最大未确认递送数量, 一旦数字达到配置的计数, RabbitMQ将停止在通道上传送更多消息, 除非至少有一个未确认的消息被确认;例如, 假设在通道 “Ch” 上有未确认的交付标签5,6,7和8, 并且通道 “Ch” 的预取计数(后面会学到是prefetch_count)设置为4, 则RabbitMQ将不会在 “Ch” 上推送更多交付, 除非至少有一个未完成的交付被确认(当确认帧在 delivery_tag=8 的频道上到达时, RabbitMQ将会注意到并再发送一条消息) QoS预取设置对使用 basic.get(pull API) 获取的消息没有影响, 即使在手动确认模式下也是如此; 消费者确认模式, 预取和吞吐量 确认模式 和 QoS预取值 对消费者吞吐量有显着影响, 一般来说, 增加预取值将提高向消费者传递消息的速度, 当然, 自动确认模式可以产生最佳的传送速率 但是, 在上面两种情况下, 尚未完成交付处理的消息(unacked)数量也会增加, 从而增加消费者RAM消耗; 自动确认模式或带无限预取的手动确认模式应谨慎使用, 消费者在没有确认的情况下消耗大量消息将导致其所连接的节点上的内存消耗增长; 预取值1是最保守的, 但这将显着降低吞吐量, 特别是在消费者连接延迟较高的环境中, 对于许多应用来说, 更高的价值是合适和最佳的; 100到300范围内的Qos(prefetch_count)预取值通常提供最佳的吞吐量, 并且不会面临压垮consumer的重大风险, 而更高的值往往会遇到效率递减的规律;","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"08. 事务 VS Publisher Confirms(发布者确认机制)","slug":"RabbitMQ/2018-06-05-rabbitmq-08","date":"2018-06-05T11:20:56.000Z","updated":"2018-07-20T11:29:01.000Z","comments":true,"path":"2018/06/05/RabbitMQ/2018-06-05-rabbitmq-08/","link":"","permalink":"http://blog.renyimin.com/2018/06/05/RabbitMQ/2018-06-05-rabbitmq-08/","excerpt":"","text":"问题的出现 和消息持久化相关的一个概念是 AMQP 的事务(transaction)机制; 到目前为止, 我们讨论的是将 消息, 队列 和 交换器 设置为持久化; 这一切都工作的很好, 并且RabbitMQ也负责保证消息的安全, 但是由于 发布消息的操作并不会反回任何信息给生产者, 所以你也无法得知是否消息已经到达了服务器并且服务器是否已经将消息持久化到了硬盘; 服务器可能会在把消息写入到硬盘前就宕机了, 或者消息压根就还没有发送到服务器, 服务器就宕机了, 消息会因此而丢失, 而你却不知道; 另外, 你可能是发送多条消息, 如果部分发送成功, 部分失败呢? 这你也无法得知; 事务机制 为了确保消息能够被安全发布到Broker, 如果使用标准的AMQP 0-9-1, 保证消息不会丢失的唯一方法是使用 事务机制 (将channel事务化) php-amqplib 中与事务机制有关的方法有三个, 分别是Channel里面的 txSelect(), txCommit() 以及 txRollback(); txSelect(): 用于将当前Channel设置成是transaction模式 txCommit(): 用于提交事务 txRollback(): 用于回滚事务 但是值得注意的是事务存在的问题: AMQP 0-9-1 中的事务几乎吸干了RabbitMQ的性能, 会导致事务吞吐量严重下降; 事务会使得生产者应用程序变成同步的, 而你使用消息通信就是为了避免同步; 鉴于上面的问题, 你可能不会在生产中使用事务机制, 此处只做了个简单的事务测试, 测试代码 Publisher Confirms 既然事务存在的问题让你拒绝使用它, 但是确保消息被成功投递到服务器这个问题仍需要解决; 为了避免事务机制在解决问题时导致的新问题, RabbitMQ团队拿出了更好的方案来保证消息的投递: 发送方确认模式 它模仿协议中已经存在的 消费者确认机制 要启用这个确认机制，客户端可以通过使用 channel 的 confirm.select 方法 如果设置了 confirm.select 方法的 no-wait, 代理会用 confirm.select-ok 进行响应, 不过这点你貌似也只能通过抓包来观察: 这里说的 confirm.select-ok 是代理对发布者的响应信息 (和 php-amqplib包中的 confirm_select_ok() 方法可不是一个意思, 而且php-amqplib也没对confirm_select_ok做实现) 上面也提到了, 该确认机制是模仿已经存在的 消费者确认机制, 所以, Broker也会使用类似 ack, nack 来响应Publisher: 可以通过为 set_ack_handler , set_nack_handler 设置回调, 来监测消息是否成功到达服务器, 成功则会触发 set_ack_handler, 失败则会触发 set_nack_handler 只有在负责队列的Erlang进程中发生内部错误时才会回应nack, 所以这个在测试中也一直没有使用 set_nack_handler 捕获到错误 (是对于nack的消息, 可以设置进行重发); 注意: 这两监听函数是监听服务器对 publisher 的应答的, 可不是监听 consumer 对服务器的应答的; 一旦在channel上使用 confirm.select 方法, 就说 channel 处于 确认模式, 一旦通道处于确认模式, 就不能进行事务处理; 也就是说 事务 和 Publisher Confirm 不能同时使用; 一旦通道处于确认模式, 代理和客户端都会对消息进行计数(在第一次confirm.select时从1开始计数), 然后, broker通过在相同channel上发送 basic.ack 来处理它们, 从而确认消息; delivery-tag 字段包含确认消息的序列号;最大 Delivery Tag, 递送标签是一个64位长的值，因此其最大值为9223372036854775807.由于递送标签的范围是按每个通道划分的，因此发布商或消费者在实践中不太可能运行该值 Publisher Confirms 的顺序考虑 在大多数情况下, RabbitMQ将按发布顺序向publisher确认消息(这适用于在单个频道上发布的消息); 但是, 发布者确认是异步发出的, 并且可以确认一条消息或一组消息;由于消息确认可以以不同的顺序到达, 所以, 应用程序应尽可能不取决于确认的顺序; 发布者确认存在的问题 mandatory 属性问题 测试代码publisher confirm 不需要消费者参与, 代码参考","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"06. 持久化策略","slug":"RabbitMQ/2018-05-28-rabbitmq-06","date":"2018-05-28T09:32:11.000Z","updated":"2018-07-20T09:43:29.000Z","comments":true,"path":"2018/05/28/RabbitMQ/2018-05-28-rabbitmq-06/","link":"","permalink":"http://blog.renyimin.com/2018/05/28/RabbitMQ/2018-05-28-rabbitmq-06/","excerpt":"","text":"持久化原理 RabbitMQ 默认情况下, Exchange, 队列, 消息 都是非持久的, 这意味着一旦消息服务器重启, 所有已声明的 Exchange, 队列, 以及 队列中的消息 都会丢失; RabbitMQ确保持久化的消息能在服务器重启之后恢复的方式是, 将它们写入磁盘上的一个持久化日志文件。当发布一条持久性消息到一个持久交换机上时, Rabbit会在消息提交到日志文件中之后才发送响应; 还需要注意的是, 如果之后这条消息被路由到一个非持久化队列, 则消息又会从上面的日志文件中删除, 并且无法从服务器重启中恢复; 一旦你从持久化队列中消费了一条持久性消息(并且进行了确认), RabbitMQ会在持久化日志中把这条消息标记为等待垃圾收集; 持久化方案 要做到消息持久化, 必须保证如下三点设置正确: exchange交换器: durable属性为true; queue队列: durable属性为true; 除了上述两点之外, 还需要在投递消息时候, 设置message的 delivery_mode 模式为2来标识消息为持久化消息; 另外: 一个包含持久化消息的非持久化队列, 在Rabbit Server重启之后, 该队列将会不复存在, 消息就会变成孤儿; 具体代码 持久化的问题 持久化由于会写磁盘, 所以会极大降低RabbitMQ每秒处理的消息总数, 降低吞吐量; 持久化在Rabbit内建集群环境下工作的并不好, 虽然RabbitMQ集群允许你和集群中的任何节点的任一队列进行通信, 但是如果队列所在的节点崩溃后, 如果队列是持久化的, 那么直到这个节点恢复之前, 这个队列都不会在整个集群中被创建出来; 后面在学习集群时, 会给出相应的解决方案;","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"03. HTTP状态码详解","slug":"HTTP/2017-11-30-HTTP-03","date":"2017-11-30T06:30:12.000Z","updated":"2018-07-20T13:42:17.000Z","comments":true,"path":"2017/11/30/HTTP/2017-11-30-HTTP-03/","link":"","permalink":"http://blog.renyimin.com/2017/11/30/HTTP/2017-11-30-HTTP-03/","excerpt":"","text":"1xx 101: 参考博文WebSocket简单示例分析 (做协议升级, 还会响应: Connection: Upgrade) 2xx Web API的设计与开发 P109 200 OK : 200码非常出名, 似乎没有对它进一步说明的必要; 201 Created : 当在服务器端创建数据成功时, 会返回201状态码; 也就是使用 POST 请求方法的场景 (如:用户登录后添加了新用户, 上传了图片等新创建数据的场景) 202 Accepted : 在异步处理客户端请求时, 它用来表示服务器端已经接受了来自客户端的请求, 但处理尚未结束; 在文件格式转换, 处理远程通知(Apple Push Notification等)这类很耗时的场景中, 如果等到所有处理都结束后才向客户端返回响应消息, 就会花费相当长的时间, 造成应用可用性不高; 这时采用的方法是服务器向客户端返回一次响应消息, 然后立刻开始异步处理。 202状态码就被用于告知客户端服务器端已经开始处理请求, 但整个处理过程尚未结束; 比如: 以LinkedIn的参与讨论的API为例如果成功参与讨论并发表意见, 服务器端通常会返回201状态码;但如果需要得到群主的确认, 那么所发表的意见就无法立即在页面显示出来, 这时服务器端就需要返回202状态码; 从广义上来看, 该场景也属于异步处理, 但和程序设计里的异步执行当然不同; 204 No Content : 正如其字面意思, 当响应消息为空时会返回该状态码。 其实就是告诉浏览器, 服务端执行成功了, 但是没什么数据返回给你, 所以你不用刷新页面, 也不用导向新的页面; 在用 DELETE 方法删除数据时, 服务器端通常会返回204状态码(阮一峰博文也提到过, 对DELETE适用); 除此之外, 也有人认为在使用 PUT或PATCH 方法更新数据时, 因为只是更新已有数据, 所以返回204状态码更加自然;书中建议 DELETE 返回204; PUT或PATCH返回200并返回该方法所操作的数据; 关于204状态码的讨论可以参考 p111; 205 Reset Content : 告诉浏览器, 页面表单需要被重置; 205的意思是服务端在接收了浏览器POST请求以后, 处理成功以后, 告诉浏览器, 执行成功了, 请清空用户填写的Form表单, 方便用户再次填写; 206 Partial Content : 成功执行了一个部分或Range(范围)的请求; 206响应中, 必须包含 Content-Range, Date 以及 ETag或Content-Location首部; 3xx300 Multiple Choices : 客户端驱动方式进行内容协商时, 服务器可能返回多个连接供客户端进行选择 (比如多语言网站可能会出现); 301 Moved Permanently : 在请求的URL已经被移除时使用, 响应的Location首部中应该包含资源现在所处的URL; (比较适合永久重定向) 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是301; 则即便稍后取消了location.php中的跳转(或者修改了跳转地址), 由于浏览器还是会认为你之前的跳转是永久性的, 再次访问www.test.com/location.php仍然会跳转到之前的跳转链接(除非清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 302 Found: 与301类似, 但是客户端应该使用Location首部给出的URL来进行临时定位资源, 将来的请求仍应该使用老的URL; 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是302; 如果稍后取消了location.php中的跳转, 再次访问www.test.com/location.php, 会发现不会进行跳转, 而是访问到 location.php 修改后的代码 (不用清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 303 See Other : HTTP/1.1使用303来实现和302一样的临时重定向; 307 Temporary Redirect HTTP/1.1规范要求用307来取代302进行临时重定向; (302临时重定向留给HTTP/1.0) 所以他也具备302临时重定向的特点; 但是, 与 302, 303 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 308 Permanent Redirect 貌似不是rfc2616的标准 具备和301永久重定向的特点, 需要清除浏览器缓存才行; 但是, 与 301 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 304 Not Modified : 参考博文缓存相关 4xx Web API的设计与开发 P1134字头状态码主要用于描述因客户端请求的问题而引发的错误。也就是说, 服务器端不存在问题, 但服务器端无法理解客户端发送的请求, 或虽然服务器端能够理解但请求却没有被执行, 当遇到这些情况引发的错误时, 服务器端便会向客户端返回这一类别的状态码。因此, 当服务器端返回4字头的状态码时, 就表示客户端的访问方式发生了问题, 用户需要检查一下客户端的访问方式或访问的目标资源等。 400 Bad Request : 表示其他错误的意思, 即其他4字头状态码都无法描述的错误类型; 401 Unauthorized : 表示认证(Authentication)类型的错误 比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 403 Forbidden : 和401状态码比较相似, 所以也经常被混淆; 其实403表示的是授权(Authotization)类型的错误, 授权和认证的不同之处是: 认证表示”识别前来访问的是谁”, 而授权则表示”赋予特定用户执行特定操作的权限” 通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限” 404 Not Found : 表示访问的数据不存在, 但是 例如当客户端湿度获取不存在的用户信息时, 或者试图访问原本就不存在的端点时, 服务器就会返回404状态码; 所以, 如果客户端想要获取用户信息, 却得到服务器端返回的404状态码, 客户端仅凭”404 Not Found”将难以区分究竟是用户不存在, 还是端点URI错误导致访问了原本不存在的URI; 405 Method Not Allowed : 表示虽然访问的端点存在, 但客户端使用的HTTP方法不被服务器端允许; 比如客户端使用了POST方法来访问只支持GET方法的信息检索专用的API; 又比如客户端用了GET方法来访问更新数据专用的API等; 406 Not Acceptable : 服务器端API不支持客户端指定的数据格式时, 服务器端所返回的状态码; 比如, 服务器端只支持JSON和XML输出的API被客户端指定返回YAML的数据格式时, 服务器端就会返回406状态码; 408 Request Timeout : 当客户端发送请求至服务器端所需的时间过长时, 就会触发服务器端的超时处理, 从而使服务器端返回该状态码; 409 Conflict: 用于表示资源发生冲突时的错误 (est中就会有该错误码) 比如通过指定ID等唯一键值信息来调用注册功能的API时, 倘若已有相同ID的数据存在, 就会导致服务器端返回409状态码; 在使用邮箱地址及Facebook ID等信息进行新用户注册时, 如果该邮箱地址或者ID已经被其他用户注册, 就会引起冲突, 这时服务器端就会返回409状态码告知客户端该邮箱地址或ID已被使用; 410 Gone : 和 404状态码 相同, 都表示访问资源不存在, 只是410状态码不单表示资源不存在, 还进一步告知资源曾经存在, 只是目前已经消失了; 因此服务器端常在访问被删除的数据时返回该状态码, 但是为了返回该状态码, 服务器必须保存该数据已被删除的信息, 而且客户端也应该知晓服务器端保存了这样的信息; 但是在通过邮箱地址搜索用户信息的API中, 从保护个人信息的角度来说, 返回410状态码的做法也会受到质疑; (所以在此种资源不存在的情况下, 为了稍微安全一些, 返回410状态码需要慎重) 413 Request Entity Too Large : 413也是比较容易出现的一种状态码, 表示请求实体过大而引发的错误 请求消息体过长是指, 比如在上传文件这样的API中, 如果发送的数据超过了所允许的最大值, 就会引发这样的错误; 414 Request-URI Too Large : 414是表示请求首部过长而引发的错误 如果在进行GET请求时, 查询参数被指定了过长的数据, 就会导致服务器端返回414状态码 415 Unsupported Media Type : 和406比较相似 406我们知道是表示服务器端不支持客户端想要接收的数据格式 而415表示的是服务器端不支持客户端请求首部 Content-Type 里指定的数据格式, 也就是说, 当客户端通过POST,PUT,PATCH等方法发送的请求消息体的数据格式不被服务器支持时, 服务器端就会返回415状态码; 例如在只接收JSON格式的API里, 如果客户端请求时发送的是XML格式的数据去请求服务器端, 或者在 Content-Type 首部指定 application/xml, 都会导致该类型错误; 429 Too Many Requests : 是2012年RFC6585文档中新定义的状态码, 表示访问次数超过了所允许的范围; 例如某API存在一小时内只允许访问100次的访问限制, 这种情况下入股哦客户端视图进行第101次访问, 服务器便会返回该状态码; 表示在一定的时间内用户发送了太多的请求, 即超出了”频次限制”, 在响应中，可以提供一个 Retry-After 首部来提示用户需要等待多长时间之后再发送新的请求; 5xx 5字头状态码表示错误不发生在客户端, 而是由服务器自身问题引发的。 500 Internal Server Error : 是web应用程序开发里非常常见的错误, 当服务器代码里存在bug, 输出错误信息并停止运行等情况下, 就会返回该类型的错误; 因此, 不仅限于API, 对于5字头状态码的错误, 都要认真监视错误日志, 使系统在出错时及时告知管理员, 以便在错误发生时做好应对措施, 防止再次发生。 501 Not Implemented : ??? 502 Bad GateWay : ??? 503 Service Unavaliable : 用来表示服务器当前处于暂不可用状态 可以回送:响应首部 Retry-After 表示多久恢复; 不同的客户端与服务器端应用对于 Retry-After 首部的支持依然不太一致; 不过，一些爬虫程序，比如谷歌的爬虫程序Googlebot, 会遵循Retry-After响应首部的规则, 将其与503(Service Unavailable,当前服务不存在)响应一起发送有助于互联网引擎做出判断,在宕机结束之后继续对网站构建索引。 参考:https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Retry-After 504 Gateway Time-out: 复现这个错误码比较简单, 让你的php程序模拟耗时请求, 如下代码 123&lt;?phpsleep(70);//模拟耗时，睡70秒echo &quot;睡醒了&quot;; 就会返回 ``` 504 Gateway Time-out nginx/1.11.4 ``` 505 HTTP Version Not Supported: 服务器收到的请求, 使用的是它无法支持的HTTP协议版本; 参考:《HTTP权威指南》、《Web API的设计与开发》","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/tags/HTTP/"}]},{"title":"02. HTTP请求方法","slug":"HTTP/2017-11-30-HTTP-02","date":"2017-11-30T03:29:12.000Z","updated":"2018-07-20T13:20:39.000Z","comments":true,"path":"2017/11/30/HTTP/2017-11-30-HTTP-02/","link":"","permalink":"http://blog.renyimin.com/2017/11/30/HTTP/2017-11-30-HTTP-02/","excerpt":"","text":"前言 HTTP/1.1 中实现的method, 参考RFC2616, 可以看到有: OPTIONS, HEAD, GET, POST, PUT, DELETE, TRACE, CONNECT RFC2616中提到: PATCH, LINK, UNLINK方法被定义, 但并不常见; (《图解http协议》中也提到 LINK, UNLINK 已经被http1.1废弃); 不同应用各自的实现不同, 有些应用会完整实现, 有些还会扩展, 有些可能只会实现一部分; PUT PUT: 替换资源; PUT 和 POST的区别: 在HTTP中, PUT被定义为 idempotent(幂等性) 的方法, POST则不是, 这是一个很重要的区别 应该用 PUT 还是 POST? 取决于这个REST服务的行为是否是idempotent(幂等)的假如发送两个请求, 希望服务器端是产生两个新数据，那就说明这个服务不是idempotent的, 因为多次使用产生了副作用了, 那就应该使用 POST 方法;但如果是希望后一个请求把第一个请求覆盖掉(这不正是修改么), 那这个服务就是idempotent的, 那就应该使用 PUT 方法; 虽然 POST 和 PUT 差别不大, 用错了也没关系, 但是你的服务一放到internet上，如果不遵从HTTP协议的规范，就可能给自己带来麻烦; POST POST: 上面已经提过了, POST是非幂等的; POST 和 PUT 都可以上传文件或者创建新信息, 但主要看你的REST服务行为是否是幂等的; PATCHPATCH不是HTTP标准方法的，服务端需要考虑客户端是否能够支持的问题; 对已有资源的操作: 用于对资源的 部分内容 进行更新 (例如更新某一个字段, 具体比如说只更新用户信息的电话号码字段); 而 PUT 则用于更新某个资源较完整的内容, 比如说用户要重填完整表单更新所有信息, 后台处理更新时可能只是保留内部记录ID不变; HEAD HEAD和 GET 本质是一样的, 区别在于如果使用HEAD, 响应体将不会被返回, 而仅仅返回HTTP头信息; 比如: 欲判断某个资源是否存在, 我们通常使用GET, 但这里用HEAD则意义更加明确; GET比较简单, 直接获取资源; OPTIONS这个方法使用比较少, 它用于获取当前URL所支持的方法;若请求成功, 则它会在HTTP头中包含一个名为 Allow 的头, 值是服务器所支持的方法, 如 GET, POST;之前跨域相关博文 CORS方案 not-so-simple request 中的”预检”请求用的请求方法就是 OPTIONS; CONNECT要求用隧道协议连接代理, 如使用SSL TRACE~~未完待续 DELETE参考 PURGE非规范中定义的方法","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/tags/HTTP/"}]},{"title":"20. MySQL -- 事务","slug":"MySQL/2017-09-16-mysql-20","date":"2017-09-16T03:06:07.000Z","updated":"2018-07-20T15:41:54.000Z","comments":true,"path":"2017/09/16/MySQL/2017-09-16-mysql-20/","link":"","permalink":"http://blog.renyimin.com/2017/09/16/MySQL/2017-09-16-mysql-20/","excerpt":"","text":"事务的概念 事务：可以理解为一个 独立的 工作单元, 在这个 独立的 工作单元中, 可以有 一组 操作; 放在这个独立工作单元中的一组操作, 要么全部执行成功, 要么全部执行失败。 仍然通过最经典的银行转账应用来解释一下: 假设有两个角色 ‘Iron Man’(余额500), ‘Wolverine’(余额15), 现在 ‘Iron Man’ 通过该银行应用给 ‘Wolverine’ 转账100元, 那么本次转账操作至少需要三个步骤 123检查`Iron Man`余额`&gt;=100`元从`Iron Man`余额中`-100`元给`Wolverine`余额`+100`元 注意: 上面的三个步操作，其实就需要打包在一个事务中, 这样就可以保证一组操作可以作为一个 独立的工作单元 来执行。并且在 独立工作单元(即事务) 中的这三个操作, 只要有任何一个操作失败, 则事务整体就应该是失败的, 那就必须回滚所有已经执行了的步骤。 假设第二步操作成功, 但是第三步操作失败, 那么整个事务就应该是失败的, 就必须将第二步的操作回滚。(其实这里也体现了事务最基本的一个特性: 保证数据的一致性) 事务的ACID特性一个运行良好的事务处理系统必须具备下面这些标准特性(高并发场景离不开事务的这几个标准特性) Atomicity 原子性一个事务必须被视为一个不可分割的最小工作单元, 整个事务中的所有操作要么全部提交成功, 要么全部失败回滚。对于一个事务来说, 不能只成功执行其中的一部分操作, 这就是事务的原子性。 Consistency 一致性你大概可以这样来理解: 虽然数据表中的数据可能一直在变化, 但是事务的一致性特性总是能够保证 数据库总是从一个数据一致性的状态 转换到 另一个数据一致性的状态; 比如之前转账的例子:转账前的数据一致性状态是: ‘Iron Man’(余额500), ‘Wolverine’(余额15)转账成功后的数据一致性状态是: ‘Iron Man’(余额400), ‘Wolverine’(余额115)转账如果失败的话, 数据的一致性的状态应该回滚到转账前的状态: ‘Iron Man’(余额500), ‘Wolverine’(余额15) Isolation 隔离性 通常来说, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的;比如在之前的转账例子中, 在执行完成最后一步(第三步), 事务还没来得及最终提交之前, 此时有另一个程序去读取A账户的余额, 那么这个程序读到的应该是没有被减100的余额才对 上面为什么说 通常来说, 难道还有其他情况 ?后面会详细讨论事务隔离性 的四个 隔离级别, 到时候就知道这里为什么说通常来说对其他事务是不可见的; (但确实也还有特例, 比如最低隔离级别 READ UNCOMMITTED, 对其他事务的可见就造成了 脏读问题 的出现) 事务有四种隔离级别(从低到高) READ UNCOMMITTED (未提交读) READ COMMITTED (提交读) REPEATABLE READ (可重复读) SERIALIZABLE (可串行化) 注意: 它仍然无法解决更新丢失的问题(可以参考) Durability 持久性一旦事务被最终提交后, 在这个独立单元中的所有操作所做的修改将会 永久 保存到数据库中; (所谓永久可以理解为被事务修改的数据是真正存放到了表中, 而不是存放在了诸如临时表之类的地方);","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]}]}