{"meta":{"title":"Lant's Blog","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"mysql(InnoDB)事务隔离级别(REPEATABLE READ) 与 锁,MVCC","slug":"2017-12-31-mysql_transaction-05","date":"2017-12-31T08:30:11.000Z","updated":"2018-01-19T01:43:29.000Z","comments":true,"path":"2017/12/31/2017-12-31-mysql_transaction-05/","link":"","permalink":"http://blog.renyimin.com/2017/12/31/2017-12-31-mysql_transaction-05/","excerpt":"","text":"REPEATABLE READ(可重复读) 之前已经了解到, 该隔离级别可以解决不可重复读问题 (当然, 也能解决脏读问题), 那么如果单纯用锁来实现, 可能会是如下这样子: 既然REPEATABLE READ 隔离级别可以解决脏读, 不可重复读的问题, 也就是它既可以让事务只能读其他事务已提交的的记录, 又能在同一事务中保证多次读取的数据即使被其他事务修改, 也是一致的。 解决脏读问题: 试想一下, 当在事务A中读取数据D的时候, 假设D之前已经在事务B中了, 并且事务B中对数据D做了修改, 但是事务B还没有完成(commit/rollback), 那如何让事务A无法读取数据D呢? 当事务B在对数据D做写操作的时候, 假设给数据D加上了行级的排他锁(X lock), 那事务A自然只能阻塞等事务A完成后才能读取数据D了, 这样就解决了脏读问题。 解决 不可重复读问题: 试想一下, 当在事务A中第一次读取了数据D之后, 直接给该数据D加S共享锁, 那其他事务自然只能阻塞等事务A完成后才能对数据D做修改操作了, 这样就解决了不可重复读, 在事务A中多次读取数据D, 都是一样的。 上面使用S锁+X锁确实可以实现 READ COMMITTED 隔离级别的效果, 也就避免了脏读问题和不可重复读问题, 当然, 这里的问题仍然是低效！！！！ 因为 MySQL 在事务隔离级别Read committed 、Repeatable Read下，InnoDB 存储引擎采用非锁定的一致性读－－即读取数据不用加锁，即采用的是MVCC中一致性非锁定读模式, 所以, InnoDB的做法是: 读不影响写，写不影响读。 读不影响写: 当数据正在执行读操作时，其他事务的写操作不会因此去等待当前事务行上S锁的释放，而是会去读取行的一个快照数据。 写不影响读：当数据正在执行写操作时，其他事务的读操作不会因此去等待当前事务行上X锁的释放，而是会去读取行的一个快照数据。 所以总结来看, READ UNCOMMITTED 和 REPEATABLE READ 这两个隔离级别都是使用 写用排他锁 + 读用MVCC, 区别可以参考 MySQL-InnoDB-MVCC多版本并发控制 MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"mysql(InnoDB)事务隔离级别(READ COMMITTED) 与 锁,MVCC","slug":"2017-12-31-mysql_transaction-04","date":"2017-12-31T02:01:47.000Z","updated":"2018-01-02T01:33:33.000Z","comments":true,"path":"2017/12/31/2017-12-31-mysql_transaction-04/","link":"","permalink":"http://blog.renyimin.com/2017/12/31/2017-12-31-mysql_transaction-04/","excerpt":"","text":"READ COMMITTED(提交读) 了解了之前 READ UNCOMMITTED 隔离级别是如何加锁的, 并且在文章中, 已经知道 READ COMMITTED 隔离级别可以解决脏读的问题, 那接下来, 对于 READ COMMITTED 隔离级别, 试想一下如果让你用锁来设计, 你会怎么做? 既然READ COMMITTED 隔离级别可以解决脏读的问题, 也就是他可以让事务只能读其他事务已提交的的记录。 如果用锁机制来实现该隔离级别: 试想一下, 当在事务A中读取数据D的时候, 假设D之前已经在事务B中了, 并且事务B中对数据D做了修改, 但是事务B还没有完成(commit/rollback), 那如何让事务A无法读取数据D呢? 当事务B在对数据D做写操作的时候, 假设给数据D加上了行级的排他锁(X lock), 那事务A自然只能阻塞等事务A完成后才能读取数据D了! 数据库这样做的话确实实现了READ COMMITTED隔离级别的效果, 也就避免了脏读, 但问题是这是一种很低效的做法, 因为对于大部分应用来说, 读操作是多于写操作的, 当写操作加锁时, 那么读操作全部被阻塞, 这样在大用户量高并发的情况下, 会直接降低数据库的读效率。 那么, 既然用锁机制实现该隔离级别是低效的做法, 数据库是如何做的? 之前在相关MVCC的文章中可以得到答案: 数据库是使用了 排他锁+MVCC 的机制来实现该隔离级别的, 而不是单纯的使用锁或者单纯的使用MVCC READ COMMITTED与锁 测试 数据表结构如下: 1234567891011mysql&gt; select * from test_transaction;+----+---------------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+---------------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 2 | 我有一双铁爪 || 2 | 钢铁侠-rym | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+---------------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 重新设置客户端1事务隔离级别为read committed: SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED; 1234567891011121314151617181920mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.00 sec) mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-COMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; 再重新打开一个客户端2并设置事务隔离级别为read committed; 在客户端1中打开事务, 然后更改数据, 先不提交; 然后在客户端2中打开事务, 读取客户端1中尚未提交的那条被修改数据 结果发现在客户端2中可以正常读取到那条数据, 只不过, 那条数据并不是被客户端1事务中修改后的数据, 而是最初的稳定数据, 这就避免了脏读!! 对于该隔离级别修改数据时使用的锁类型, 其分析方法, 和之前一篇MySQL(INNODB引擎)事务READ UNCOMMITTED隔离级别和锁的关系 是一样的： 可以在客户端1的事务在修改数据并且未提交时, 在客户端2中对同一数据进行修改, 然后在客户端2阻塞阶段通过查看表的加锁情况: select * from information_schema.INNODB_LOCKS;,事务状态: select * from information_schema.INNODB_TRX;,进行分析, 结果就不展示了, 可以自行测试一下, 该隔离级别修改数据时使用的也是排他锁, 并且客户端2的修改语句会锁等待~(和之前分析READ UNCOMMITTED隔离级别一样, 既然使用了排他锁, 竟然别的事务还能读取, 这特么不就又违反了排他锁的特性么? 还是那句话, 另一个事务在读取的时候并不会加锁, 而是用的MVCC机制读取的镜像) 小结: InnoDB在该隔离级别(READ COMMITTED)写数据是使用排他锁, 读取数据不加锁而是使用了MVCC机制, 这样就可以大大提高并发读写效率, 写不影响读, 因为读并未加锁, 读的是记录的镜像版本!! MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"mysql(InnoDB)事务隔离级别(READ UNCOMMITTED) 与 锁","slug":"2017-12-29-mysql_transaction-02","date":"2017-12-29T11:12:11.000Z","updated":"2018-01-04T01:56:07.000Z","comments":true,"path":"2017/12/29/2017-12-29-mysql_transaction-02/","link":"","permalink":"http://blog.renyimin.com/2017/12/29/2017-12-29-mysql_transaction-02/","excerpt":"","text":"前言先针对自己以前错误的思维做个记录, 可以直接跳过 由于以前看到很多资料在谈到并发控制的时候, 都会提到用锁来控制并发, MySQL也不例外, 也有很多和锁相关的概念(留到后面会单独整理一篇笔记出来), 所以一提到高并发产生的问题, 我会不自觉地提出一个疑问: 现在并发出问题了, 那怎么用锁的相关知识来解决?; 而且近期一段时间也一直在看很多有关MySQL锁相关的资料,书籍, 于是乎 死锁, 锁冲突, 行锁,表锁, 读锁, 写锁, 乐观锁, 悲观锁 ……等等 N多锁相关的名词(后面的笔记会把所有自己遇到的, 全部整理并进行分析), 大量的篇幅, 高深晦涩的描述, 直接导致我意识里认为嗯, 锁真tm高大上, 真tm高端, 肯定tm就是它了; 于是就进入了思想误区, 认为在解决脏读,不可重复读,幻读的资料中, 应该大篇幅的描述如何用锁相关的知识来解决这些问题, 然而略失落了, 资料倒是提了点儿锁的知识, 但更多的是用事务的哪个隔离级别来解决这些问题, 锁哪儿去了? 尤其是在分析脏读,不可重复读,幻读这几个问题的时候, 一上去就全乱了, 比如 脏读, 如果总是以MySQL锁的相关知识作为前提来分析, 就会陷入误区 ‘事务A读取数据的时候肯定会加S锁的, 事务B自然是无法对未完成的事务A中的数据进行修改的, 我Ca, 这种脏读的场景根本就不成立嘛!‘, 那为什么不提锁, 而是用隔离级别来解决。 ………… 晕了几天之后,终于稍微醒了点…… 参考美团技术博客 显然, 事务隔离级别的核心就是锁, 各隔离级别使用了不同的加锁策略，在分析之前的几个高并发事务问题的时候, 隔离级别(锁)自然是不能作为前置知识点的, 而是最终问题的解决方案! “READ UNCOMMITTED与锁”的困惑(未提交读) 在READ UNCOMMITTED级别, 事务中的修改, 即使还没有提交, 对其他事务也都是可见的; 也就是说事务可以读取未提交的数据, 这也就造成了 脏读(Dirty Read) 的出现。 这个级别会导致很多问题, 而且从性能上来说, READ COMMITTED 并不会比其他的级别好太多, 却缺乏其他级别的很多好处, 在实际应用中一般很少使用。 虽然很少使用, 但还是有必要了解一下, 它这个隔离级别究竟是怎么隔离的, 竟然还能容许很多问题的存在？ (老兄亏你还算个隔离级别, 怎么办事儿的…) 网上相关资料五花八门, 下面列几个出来(希望你看完不要激动): 美团技术博客: segmentfault一篇文章 CSDN一篇文章 CSDN一篇文章 说实话, 资料查到这份儿上, 我已经快崩溃了, 就READ UNCOMMITTED这个隔离级别: 有说读写都不加锁的 有说’修改完数据立即加S锁的, 修改时撤掉S锁’ 有说’写加S锁,事务结束释放’的 有说’写加X锁,事务结束释放’的 行啦, 不查了, 再查就崩溃了, 自己去测一下吧!!! 本次测试是使用MAMP PRO中mysql5.6版本 先准备一张测试表test_transaction: 1234567891011121314DROP TABLE IF EXISTS `test_transaction`;CREATE TABLE `test_transaction` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `user_name` char(20) NOT NULL COMMENT &apos;姓名&apos;, `age` tinyint(3) NOT NULL COMMENT &apos;年龄&apos;, `gender` tinyint(1) NOT NULL COMMENT &apos;1:男, 2:女&apos;, `desctiption` text NOT NULL COMMENT &apos;简介&apos;, PRIMARY KEY (`id`), KEY `name_age_gender_index` (`user_name`,`age`,`gender`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;INSERT INTO `test_transaction` VALUES (1, &apos;金刚狼&apos;, 127, 1, &apos;我有一双铁爪&apos;);INSERT INTO `test_transaction` VALUES (2, &apos;钢铁侠&apos;, 120, 1, &apos;我有一身铁甲&apos;);INSERT INTO `test_transaction` VALUES (3, &apos;绿巨人&apos;, 0, 2, &apos;我有一身肉&apos;); 如下: 123456789mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 2 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) READ UNCOMMITTED与锁 测试演示该隔离级别脏读效果 先查看当前会话(当前客户端)事务的隔离级别: SELECT @@SESSION.tx_isolation; 可以看到: REPEATABLE READ 是InnoDB存储引擎的默认事务隔离级别 123456789mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; 重新设置当前客户端事务隔离级别为read uncommitted: SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; 注意, 此时只是当前会话端的隔离级别被改, 其余客户端连接自然还是默认的REPEATABLE READ隔离级别 接下来将客户端2的事务隔离级别也设置为read uncommitted; 客户端1开启事务,并执行一个查询’读取数据’: 1234567891011121314151617181920mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction where id=2;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 |+----+-----------+-----+--------+--------------------+1 row in set (0.00 sec) mysql&gt; 注意, 客户端1此时的事务并未提交 客户端2开启事务, 并修改客户端1查询的数据 123456789101112131415mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-托尼&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 此时发现, 客户端2可以对客户端1正在读取的记录进行修改, 而根据锁相关知识, 如果说客户端1在读取记录的时候加了S锁, 那么客户端2是不能加X锁对该记录进行更改的, 所以可以得出结论: 要么是客户端1读取记录的时候没有加S锁, 要么是客户端2更改该记录的时候没有加X锁(这样即使客户端1加了S锁,对它这个不加锁的事务也无可奈何), 那么究竟是哪种情况导致的? 下面继续进行分析… 注意, 客户端2此时的事务也并未提交 切换到客户端1, 再次查询数据, 发现数据已经变成了’钢铁侠-托尼’; 然后客户端2 rollback 事务, 再到客户端1中查询,发现user_name又变成了’钢铁侠’, 那之前独到’钢铁侠-托尼’就是脏数据了, 这就是一次 脏读 测试,分析该隔离级别如何加锁 重新构造测试条件 客户端1开启事务, 然后对数据做修改 1234567mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rymuscle&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 注意, 客户端1此时的事务并未提交 客户端2开启事务, 对相同的数据行做修改 12345mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rym&apos; where id=2;....阻塞等待了 最终会如下: 注意: 在上面的过程, 在客户端2阻塞阶段, 你可以通过一个新的客户端来分析, 客户端2在锁等待的情况下的 加锁情况 和 事务状态: 查看表的加锁情况: select * from information_schema.INNODB_LOCKS; 事务状态 select * from information_schema.INNODB_TRX; 所以, READ UNCOMMITTED 隔离级别下, 写操作是会加锁的, 而且是X排他锁, 直到客户端1事务完成, 锁才释放, 客户端2才能进行写操作 接下来你肯定会纳闷 “既然该隔离级别下事务在修改数据的时候加的是x锁, 并且是事务完成后才释放, 那之前的测试客户端2在事务中修改完数据之后, 为什么事务还没完成, 也就是x锁还在, 结果客户端1却能读取到客户端2修改的数据”？这完全不符合排他锁的特性啊(要知道,排他锁会阻塞除当前事务之外的其他事务的读,写操作) 其实网上已经有人在sqlserver的官网上找到了相关资料: 12345ansactions running at the READ UNCOMMITTED level do not issue shared locks to prevent other transactions from modifying data read by the current transaction. READ UNCOMMITTED transactions are also not blocked by exclusive locks that would prevent the current transaction from reading rows that have been modified but not committed by other transactions. When this option is set, it is possible to read uncommitted modifications, which are called dirty reads. Values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. This option has the same effect as setting NOLOCK on all tables in all SELECT statements in a transaction. This is the least restrictive of the isolation levels. 翻译翻译, 在思考思考, 其实说的是在 READ UNCOMMITTED 级别运行的事务不会发出共享锁来防止其他事务修改当前事务读取的数据, 既然不加共享锁了, 那么当前事务所读取的数据自然就可以被其他事务来修改。而且当前事务要读取其他事务未提交的修改, 也不会被排他锁阻止, 因为排他锁会阻止其他事务再对其锁定的数据加读写锁, 但是可笑的是, 事务在该隔离级别下去读数据的话根本什么锁都不加, 这就让排他锁无法排它了, 因为它连锁都没有。这就导致了事务可以读取未提交的修改, 称为脏读。 所以可以得出: READ UNCOMMITTED隔离级别下, 读不会加任何锁。而写会加排他锁，并到事务结束之后释放。 参考资料:-《高性能MySQL》 MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"MySQL-InnoDB-MVCC多版本并发控制","slug":"2017-12-28-mysql_mvcc","date":"2017-12-28T13:07:12.000Z","updated":"2018-01-18T13:22:11.000Z","comments":true,"path":"2017/12/28/2017-12-28-mysql_mvcc/","link":"","permalink":"http://blog.renyimin.com/2017/12/28/2017-12-28-mysql_mvcc/","excerpt":"","text":"(Multiversion Concurrency Control) 前言最近正在啃《高性能MySQL》这本书, 当看到事务相关知识时, 决定对该知识点稍微深入一下, 这里主要先说一下本人在啃相关知识点时的曲折之路:1.首先是事务相关ACID特性, 之前已经有相关笔记进行过介绍, 这里不再重复; 2.接下来是高并发事务相关的问题, 像是 脏读, 不可重复读, 幻读, 更新丢失等问题之前也有介绍; 3.再下来就是MySQL应对高并发事务的诸多问题是如何给出解决方案的(其中包含各个隔离级别的简介); 4.然后就是各个隔离级别的具体介绍及与锁的关系, 也就是在这部分知识点, 发现了之前并没有过多关心的知识点 MVCC多版本并发控制, 然后一发不可收拾了… 相关资料 阿里数据库内核’2017/12’月报中对MVCC的解释是: 多版本控制: 指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。在内部实现中，与Postgres在数据行上实现多版本不同，InnoDB是在undolog中实现的，通过undolog可以找回数据的历史版本。找回的数据历史版本可以提供给用户读(按照隔离级别的定义，有些读请求只能看到比较老的数据版本)，也可以在回滚的时候覆盖数据页上的数据。在InnoDB内部中，会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性。 &lt;高性能MySQL&gt;中对MVCC的部分介绍 MySQL的大多数事务型存储引擎实现的其实都不是简单的行级锁。基于提升并发性能的考虑, 它们一般都同时实现了多版本并发控制(MVCC)。不仅是MySQL, 包括Oracle,PostgreSQL等其他数据库系统也都实现了MVCC, 但各自的实现机制不尽相同, 因为MVCC没有一个统一的实现标准。可以认为MVCC是行级锁的一个变种, 但是它在很多情况下避免了加锁操作, 因此开销更低。虽然实现机制有所不同, 但大都实现了非阻塞的读操作，写操作也只锁定必要的行。MVCC的实现方式有多种, 典型的有乐观(optimistic)并发控制 和 悲观(pessimistic)并发控制。MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作。其他两个隔离级别够和MVCC不兼容, 因为 READ UNCOMMITTED 总是读取最新的数据行, 而不是符合当前事务版本的数据行。而 SERIALIZABLE 则会对所有读取的行都加锁。 从书中可以了解到: MVCC是被Mysql中 事务型存储引擎InnoDB 所支持的; 应对高并发事务, MVCC比单纯的行锁更高效; MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作; MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现; 各数据库中MVCC实现并不统一 但是书中提到 “InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的”(网上也有很多此类观点), 但其实并不准确, 可以参考MySQL官方文档, 可以看到, InnoDB存储引擎在数据库每行数据的后面添加了三个字段, 不是两个!! 相关概念read view, 快照snapshot1.淘宝数据库内核月报/2017/10/01/此文虽然是以PostgreSQL进行的说明, 但并不影响理解, 在”事务快照的实现”该部分有细节需要注意: - **事务快照是用来存储数据库的事务运行情况。** - 一个事务快照的创建过程可以概括为： 查看当前所有的未提交并活跃的事务，存储在数组中 选取未提交并活跃的事务中最小的XID，记录在快照的xmin中 选取所有已提交事务中最大的XID，**加1**后记录在xmax中 2.注意: 上文中在PostgreSQL中snapshot的概念, 对应MySQL中, 其实就是你在网上看到的read view,快照这些概念; 比如何登成就有关于Read view的介绍; 而 此文 却仍是使用快照来介绍; 3.read view 主要是用来做可见性判断的, 比较普遍的解释便是”本事务不可见的当前其他活跃事务”, 但正是该解释, 可能会造成一节理解上的误区, 所以此处提供两个参考, 供给大家避开理解误区: - read view中的`高水位low_limit_id`可以参考 &quot;https://github.com/zhangyachen/zhangyachen.github.io/issues/68&quot;, &quot;https://www.zhihu.com/question/66320138(呵呵一笑百媚生)&quot; - 如果单纯按照&apos;https://www.jianshu.com/p/fd51cb8dc03b&apos;中的read view介绍来理解, 在rc级别下做演示, 就会发现使用该算法会出错! - 其实上面第1点中加粗部分也是相关高水位的介绍( 注意进行了+1 ) 4.另外, 对于read view快照的生成时机, 也非常关键, 也正是因为生成时机的不同, 造成了RC,RR两种隔离级别的不同可见性, 可以参考 http://www.sohu.com/a/194511597_610509, https://www.cnblogs.com/digdeep/p/4947694.html 两篇文章; - 在innodb中(默认repeatable read级别), 事务在begin/start transaction之后的第一条select读操作后, 会创建一个快照(read view), 将当前系统中活跃的其他事务记录记录起来; - 在innodb中(默认repeatable committed级别), 事务中每条select语句都会创建一个快照(read view); - [参考](https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_consistent_read) 1234With REPEATABLE READ isolation level, the snapshot is based on the time when the first read operation is performed. 使用REPEATABLE READ隔离级别，快照是基于执行第一个读操作的时间。With READ COMMITTED isolation level, the snapshot is reset to the time of each consistent read operation.使用READ COMMITTED隔离级别，快照被重置为每个一致的读取操作的时间。 5.undo-log 可以参考数据库内核月报2015/04/01 前言 Undo log是InnoDB MVCC事务特性的重要组成部分。当我们对记录做了变更操作时就会产生undo记录，Undo记录默认被记录到系统表空间(ibdata)中，但从5.6开始，也可以使用独立的Undo 表空间。 Undo记录中存储的是老版本数据，当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着undo链找到满足其可见性的记录。当版本链很长时，通常可以认为这是个比较耗时的操作（例如bug#69812）。 大多数对数据的变更操作包括INSERT/DELETE/UPDATE，其中INSERT操作在事务提交前只对当前事务可见，因此产生的Undo日志可以在事务提交后直接删除（谁会对刚插入的数据有可见性需求呢！！），而对于UPDATE/DELETE则需要维护多版本信息，在InnoDB里，UPDATE和DELETE操作产生的Undo日志被归成一类，即update_undo 另外, 在回滚段中的undo logs分为: insert undo log 和 update undo log insert undo log : 事务对insert新记录时产生的undolog, 只在事务回滚时需要, 并且在事务提交后就可以立即丢弃。 update undo log : 事务对记录进行delete和update操作时产生的undo log, 不仅在事务回滚时需要, 一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被purge线程删除。 6.InnoDB存储引擎在数据库每行数据的后面添加了三个字段 6字节的事务ID(DB_TRX_ID)字段: 用来标识最近一次对本行记录做修改(insert|update)的事务的标识符, 即最后一次修改(insert|update)本行记录的事务id。 至于delete操作，在innodb看来也不过是一次update操作，更新行中的一个特殊位将行表示为deleted, 并非真正删除。 7字节的回滚指针(DB_ROLL_PTR)字段: 指写入回滚段(rollback segment)的 undo log record (撤销日志记录记录)。 如果一行记录被更新, 则 undo log record 包含 ‘重建该行记录被更新之前内容’ 所必须的信息。 6字节的DB_ROW_ID字段: 包含一个随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。 结合聚簇索引的相关知识点, 我的理解是, 如果我们的表中没有主键或合适的唯一索引, 也就是无法生成聚簇索引的时候, InnoDB会帮我们自动生成聚集索引, 但聚簇索引会使用DB_ROW_ID的值来作为主键; 如果我们有自己的主键或者合适的唯一索引, 那么聚簇索引中也就不会包含 DB_ROW_ID 了 。 关于聚簇索引, 《高性能MySQL》中的篇幅对我来说已经够用了, 稍后会整理一下以前的学习笔记, 然后更新上来。 7.可见性比较算法（这里每个比较算法后面的描述是建立在rr级别下，rc级别也是使用该比较算法,此处未做描述）设要读取的行的最后提交事务id(即当前数据行的稳定事务id)为 trx_id_current当前新开事务id为 new_id当前新开事务创建的快照read view 中最早的事务id为up_limit_id, 最迟的事务id为low_limit_id(注意这个low_limit_id=未开启的事务id=当前最大事务id+1)比较: 1.trx_id_current &lt; up_limit_id, 这种情况比较好理解, 表示, 新事务在读取该行记录时, 该行记录的稳定事务ID是小于, 系统当前所有活跃的事务, 所以当前行稳定数据对新事务可见, 跳到步骤5. 2.trx_id_current &gt;= trx_id_last, 这种情况也比较好理解, 表示, 该行记录的稳定事务id是在本次新事务创建之后才开启的, 但是却在本次新事务执行第二个select前就commit了，所以该行记录的当前值不可见, 跳到步骤4。 3.trx_id_current &lt;= trx_id_current &lt;= trx_id_last, 表示: 该行记录所在事务在本次新事务创建的时候处于活动状态，从up_limit_id到low_limit_id进行遍历，如果trx_id_current等于他们之中的某个事务id的话，那么不可见, 调到步骤4,否则表示可见。 4.从该行记录的 DB_ROLL_PTR 指针所指向的回滚段中取出最新的undo-log的版本号, 将它赋值该 trx_id_current，然后跳到步骤1重新开始判断。 5.将该可见行的值返回。 案例分析1.下面是一个非常简版的演示事务对某行记录的更新过程, 当然, InnoDB引擎在内部要做的工作非常多: 2.下面是一套比较算法的应用过程也可参考https://github.com/zhangyachen/zhangyachen.github.io/issues/68中的案例 当前读和快照读1.MySQL的InnoDB存储引擎默认事务隔离级别是RR(可重复读), 是通过 “行排他锁+MVCC” 一起实现的, 不仅可以保证可重复读, 还可以部分防止幻读; 2.为什么是部分防止幻读, 而不是完全防止? 效果: 在如果事务B在事务A执行中, insert了一条数据并提交, 事务A再次查询, 虽然读取的是undo中的旧版本数据(防止了部分幻读), 但是事务A中执行update或者delete都是可以成功的!! 因为在innodb中的操作可以分为当前读(current read)和快照读(snapshot read): 3.快照读(snapshot read) 简单的select操作(当然不包括 select … lock in share mode, select … for update) 4.当前读(current read) 官网文档 Locking Reads select … lock in share mode select … for update insert update delete在RR级别下，快照读是通过MVVC(多版本控制)和undo log来实现的，当前读是通过加record lock(记录锁)和gap lock(间隙锁)来实现的。innodb在快照读的情况下并没有真正的避免幻读, 但是在当前读的情况下避免了不可重复读和幻读!!! 小结 一般我们认为MVCC有下面几个特点： 每行数据都存在一个版本，每次数据更新时都更新该版本 修改时Copy出当前版本, 然后随意修改，各个事务之间无干扰 保存时比较版本号，如果成功(commit)，则覆盖原记录, 失败则放弃copy(rollback) 就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道, 因为这看起来正是，在提交的时候才能知道到底能否提交成功 而InnoDB实现MVCC的方式是: 事务以排他锁的形式修改原始数据 把修改前的数据存放于undo log，通过回滚指针与主数据关联 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） 二者最本质的区别是: 当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ Innodb的实现真算不上MVCC, 因为并没有实现核心的多版本共存, undo log 中的内容只是串行化的结果, 记录了多个事务的过程, 不属于多版本共存。但理想的MVCC是难以实现的, 当事务仅修改一行记录使用理想的MVCC模式是没有问题的, 可以通过比较版本号进行回滚, 但当事务影响到多行数据时, 理想的MVCC就无能为力了。 比如, 如果事务A执行理想的MVCC, 修改Row1成功, 而修改Row2失败, 此时需要回滚Row1, 但因为Row1没有被锁定, 其数据可能又被事务B所修改, 如果此时回滚Row1的内容，则会破坏事务B的修改结果，导致事务B违反ACID。 这也正是所谓的 第一类更新丢失 的情况。 也正是因为InnoDB使用的MVCC中结合了排他锁, 不是纯的MVCC, 所以第一类更新丢失是不会出现了, 一般说更新丢失都是指第二类丢失更新。 参考 最初读的一篇文章 关于read view创建时机: http://www.sohu.com/a/194511597_610509 https://www.cnblogs.com/digdeep/p/4947694.html https://www.zhihu.com/question/265280455/answer/292022808 关于比较算法 low_limit_id 高水位事务: https://github.com/zhangyachen/zhangyachen.github.io/issues/68 https://www.zhihu.com/question/66320138 https://www.zhihu.com/question/265280455/answer/292022808 大咖问答:https://www.zhihu.com/inbox/4577674200 更多可以参考数据库内核月报: https://yq.aliyun.com/articles/303200?spm=5176.100240.searchblog.9.271fd153pQ9FgV 官方文档","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"}]},{"title":"MySQL(INNODB引擎)高并发事务问题及解决方案","slug":"2017-12-27-mysql_transaction-01","date":"2017-12-27T13:01:07.000Z","updated":"2018-01-18T12:39:51.000Z","comments":true,"path":"2017/12/27/2017-12-27-mysql_transaction-01/","link":"","permalink":"http://blog.renyimin.com/2017/12/27/2017-12-27-mysql_transaction-01/","excerpt":"","text":"事务的概念 事务：可以理解为一个 独立的 工作单元, 在这个独立的工作单元中, 可以有一组操作; 放在这个独立工作单元中的一组操作, 要么全部执行成功, 要么全部执行失败。 仍然通过最经典的银行转账应用来解释一下: 假设有两个角色 ‘Iron Man’(余额500), ‘Wolverine’(余额15), 现在 ‘Iron Man’ 通过该银行应用给 ‘Wolverine’ 转账100元, 那么本次转账操作至少需要三个步骤 123检查`Iron Man`余额`&gt;=100`元从`Iron Man`余额中`-100`元给`Wolverine`余额`+100`元 注意: 上面的三个步操作，其实就需要打包在一个事务中, 这样就可以保证一组操作可以作为一个 独立的工作单元 来执行。并且在 独立工作单元(即事务) 中的这三个操作, 只要有任何一个操作失败, 则事务就整体就是失败的, 那就必须回滚所有已经执行的步骤。 假设第二步操作成功, 但是第三步操作失败, 那么整个事务也就应该是失败的, 那就必须将第二步的操作也回滚。(其实这里也体现了事务最基本的一个特性: 保证数据的一致性) 当然, 在真实高并发场景下, 事务需要做的事情其实还很多, 因为高并发会出现很多意想不到的问题, 后面会简要分析一下可能会出现的一些问题。 事务的ACID特性在分析高并发事务的问题前, 我们要先熟悉一下事务的几个标准特性, 因为一个运行良好的事务处理系统必须具备这些标准特性, 而且这些高并发问题的解决也离不开事务的这几个标准特性!!! Atomicity 原子性 一个事务必须被视为一个不可分割的最小工作单元, 整个事务中的所有操作要么全部提交成功, 要么全部失败回滚。 对于一个事务来说, 不能只成功执行其中的一部分操作, 这就是事务的原子性。 Consistency 一致性 你大概可以这样来理解: 虽然数据表中的数据可能一直在变化, 但是事务的一致性特性总是能够保证 数据库总是从一个一致性的状态 转换到 另一个一致性的状态; 比如在之前的转账例子: 123转账前的一致性状态是: &apos;Iron Man&apos;(余额500), &apos;Wolverine&apos;(余额15)转账成功后的一致性状态是: &apos;Iron Man&apos;(余额400), &apos;Wolverine&apos;(余额115)转账如果失败的话, 一致性的状态应该回滚到转账前的状态: &apos;Iron Man&apos;(余额500), &apos;Wolverine&apos;(余额15) Isolation 隔离性 通常来说, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的;比如在之前的转账例子中, 在执行完成第二步, 但是第三步还没开始的时候, 此时有另一个账户汇总的程序开始运行, 那么这个程序所拿到的A账户余额应该是没有被减100的余额才对 后面我们还会详细讨论事务隔离性的 隔离级别, 到时候就知道这里为什么说通常来说对其他事务是不可见的; (也就是还有特例, 比如最低隔离级别 READ UNCOMMITTED, 对其他事务的可见就造成了脏读问题的出现) 事务有四种隔离级别(从低到高: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE) Durability 持久性 一旦事务被最终提交, 则在事务这个独立单元中的所有操作所做的修改将会 永久保存到数据库中; (这里所说的永久可以理解为 被事务修改的数据 是真正存放到了表中, 而不是存放在了诸如临时表之类的地方。) 高并发事务的问题在并发量比较大的时候, 很容易出现 多个事务同时进行 的情况。假设有两个事务正在同时进行, 值得注意的是: 它们两者之间是互相不知道对方的存在的, 各自都对自身所处的环境过分乐观, 从而并没有对自己所操作的数据做一定的保护处理, 所以最终导致了一些问题的出现; 接下来, 在分析高并发事务的问题时, 你可能已经了解过一些关于锁的概念, 但是接下来分析这些高并发问题时, 暂时不会带入锁的概念, 只会列出问题, 并直接告诉你各个问题是使用事务隔离性的哪个隔离级别来解决掉的; 脏读 如果mysql中一个事务A读取了另一个并行事务B未最终提交的写数据, 那事务A的这次读取就是脏读。(因为事务A读取的是’脏数据’, 是’非持久性’的数据) 之所以说是’非持久性数据’, ‘脏数据’, 是因为事务B最终可能会因为内部其他后续操作的失败或者系统后续突然崩溃等原因, 导致事务最终整体提交失败, 那么事务A此时读取到的数据在表中其实会被回滚, 那事务A拿到的自然就是脏的数据了。 图示: 事务A在T4阶段读取库存为20, 这个库存其实就属于脏数据, 因为事务B最终会回滚这个数据, 所以如果事务A使用库存20进行后续的操作, 就会引发问题, 因为事务A拿到的数据已经和表中的真实数据不一致了。 那么这个问题如何解决呢? 在MySQL中, 其实事务已经用自身特性(隔离性的 – READ COMMITED或以上隔离级别)解决了这个问题; READ COMMITED级别保证了, 只要是当前语句执行前已经提交的数据都是可见的。 不可重复读 假设现在上面的 脏读问题 已经被完全解决了, 那就意味着事务中每次读取到的数据都是 持久性 的数据(被别的事务最终 提交/回滚 完成后的数据)。 但是你需要知道的是: 解决了脏读问题, 只是能保证你在事务中每次读到的数据都是持久性的数据而已!!!! 如果在一个事务中多次读取同一个数据, 正好在两次读取之间, 另外一个事务确实已经完成了对该数据的修改并提交, 那问题就来了: 可能会出现多次读取结果不一致的现象。 那么这个问题如何解决呢? 在MySQL中, 事务已经用自身特性(隔离性的 – REPEATABLE READ或以上隔离级别)解决了这个问题; REPEATABLE READ级别保证了, 只要是当前事务执行前已经提交的数据都是可见的。 幻读 由于很多人(当然也包括本人), 容易搞混 不可重复读 和 幻读, 这两者确实非常相似。 但 不可重复读 主要是说多次读取一条记录, 发现该记录中某些列值被修改过。 而 幻读 主要是说多次读取一个范围内的记录(包括直接查询所有记录结果或者做聚合统计), 发现结果不一致(比如发现增加/减少了一条记录)。(可以参考MySQL官方文档对 Phantom Rows 的介绍) 其实对于 幻读, MySQL的InnoDB引擎默认的RR级别已经通过MVCC自动帮我们解决了(并非完全解决), 所以该级别下, 你也模拟不出幻读的场景; 退回到 RC 隔离级别的话, 你又容易把幻读和不可重复读搞混淆, 所以这可能就是比较头痛的点吧! 另外可以参考《高性能MySQL》对 RR 隔离级别的描述 理论上RR级别是无法解决幻读的问题, 但是由于InnoDB引擎的RR级别还使用了MVCC, 所以也就避免了幻读的出现! 幻读的延伸MVCC虽然解决了幻读问题, 但严格来说, MVCC只是部分解决幻读问题, 接下来进行演示: 打开客户端1查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 打开客户端2查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端2中开启事务, 然后查询数据 1234567891011121314mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端1中插入一条id为4的新数据 (直接自动提交) 1234567891011121314mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 || 4 | 死侍 | 18 | 0 | A bad boy |+----+-----------+-----+--------+--------------------+4 rows in set (0.00 sec) mysql&gt; 在客户端2事务中再次查询数据, 发现数据没有变化(表示可以重复读, 并且克服了幻读)!! 但是在客户端2事务中插入一条id为4的新数据, 发现提示数据已经存在!!! 12345678910111213141516171819202122232425262728mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);1062 - Duplicate entry &apos;4&apos; for key &apos;PRIMARY&apos; //( 后面会看到: 其实是因为insert是当前读)mysql&gt; //并且, 此时`update/delete`也是可以操作这条在事务中看不到的记录的! //( 后面会看到: update，delete也都是当前读) 那么这是什么问题呢? 可以参考MySQL官方文档 – 一致性非阻塞读 The snapshot of the database state applies to SELECT statements within a transaction, not necessarily to DML statements. If you insert or modify some rows and then commit that transaction, a DELETE or UPDATE statement issued from another concurrent REPEATABLE READ transaction could affect those just-committed rows, even though the session could not query them. If a transaction does update or delete rows committed by a different transaction, those changes do become visible to the current transaction.个人认为应该翻译为: 数据库状态的快照适用于事务中的SELECT语句, 而不一定适用于所有DML语句。 如果您插入或修改某些行, 然后提交该事务, 则从另一个并发REPEATABLE READ事务发出的DELETE或UPDATE语句就可能会影响那些刚刚提交的行, 即使该事务无法查询它们。 如果事务更新或删除由不同事务提交的行, 则这些更改对当前事务变得可见。 其实, MVCC并发控制中的读操作分为两类: 快照读 (snapshot read) 与 当前读 (current read) 参考 在RR级别下, 快照读是通过MVVC(多版本控制)和undo log来实现的, 而当前读是通过加record lock(记录锁)和gap lock(间隙锁)来实现的。如果需要实时显示数据，还是需要通过加锁来实现。这个时候会使用next-key技术来实现。 快照读, 读取专门的快照 (对于RC，快照（ReadView）会在每个语句中创建。对于RR，快照是在事务启动时创建的), 快照读的操作如下: 1简单的select操作 (不包括: select ... lock in share mode, select ... for update) 当前读, 读取最新版本的记录, 没有快照。 在InnoDB中，当前读取根本不会创建任何快照。当前读的操作如下: 12345select ... lock in share modeselect ... for updateinsertupdatedelete 当然, 使用隔离性的最高隔离级别SERIALIZABLE也可以解决幻读, 但该隔离级别在实际中很少使用! 更新丢失 最后聊一下高并发事务的另一个问题 – 丢失更新问题, 该问题和之前几个问题需要区分开, 因为解决方案不是一类! 第一类丢失更新: A事务撤销时, 把已经提交的B事务的更新数据覆盖了。 不过, 通过后面MVCC相关文章最后的小结你会了解到, 这类更新丢失问题是不会出现的, 因为InnoDB存储引擎的隔离级别都使用了排他锁, 即使是 MVCC也不是纯MVCC, 也用到了排他锁! 这样的话事务A在未完成的时候, 其他事务是无法对事务A涉及到的数据做修改并提交的。 第二类丢失更新: A事务覆盖B事务已经提交的数据，造成B事务所做操作丢失。 此类更新丢失问题, 无法依靠前三种隔离级别来解决, 只能用最高隔离级别 Serializable 或者手动使用乐观锁, 悲观锁来解决。 当然, 更新操作不是在所有情况下都会导致丢失更新问题, 如果你更改的最终状态是确定的, 而不是类似递减或者递增, 那是不会造成丢失更新问题的!! 最高隔离级别Serializable在实际应用场景中并不被采用, 对于手动使用乐观锁, 悲观锁的方案, 将会在以后关于锁的文章中一并给出! 参考资料: 淘宝数据库内核6月报 《高性能MySQL》 美团技术博客 MySQL官方文档","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"HTTP - 缓存","slug":"2017-12-10-HTTP-04-cache","date":"2017-12-10T09:13:21.000Z","updated":"2018-02-04T03:36:14.000Z","comments":true,"path":"2017/12/10/2017-12-10-HTTP-04-cache/","link":"","permalink":"http://blog.renyimin.com/2017/12/10/2017-12-10-HTTP-04-cache/","excerpt":"","text":"Web缓存简介 Web缓存是指可以自动保存常见文档副本的HTTP设备。当Web请求抵达缓存设备时, 如果缓存设备本地有”已缓存的”副本, 就可以从本地设备而不是原始服务器中提取这个文档。 使用缓存的优点: 减少了冗余的数据传输, 节省了你的网络费用 有很多客户端访问一个流行的原始服务器页面时, 服务器会多次传输同一份文档, 每次传送给一个客户端。这样就会导致一些相同的字节在网络中一遍遍地传输, 这些冗余的数据传输会耗尽昂贵的网络带宽, 降低传输速度, 加重Web服务器的负载。有了缓存, 就可以保留第一条服务器响应的副本, 后继请求就可以由缓存的副本来应对了, 这样可以减少那些流入/流出原始服务器而被浪费掉了的重复流量。 缓解了网络本身的瓶颈问题, 不需要更多的带宽就能够更快地加载页面 很多网络为本地网络客户端提供的带宽比为远程度服务器提供的带宽要宽。(这个大家应该有深有体会, 局域网内传输是很快的!!!)如果客户端能够从一个快速局域网的缓存中得到一份副本, 那么缓存就可以提高性能—尤其是要传输比较大的文件时。 降低了对原始服务器的要求, 服务器可以更快地响应, 避免过载的出现 瞬间拥塞: 突发事件(爆发性新闻, 抢购等)使很多人几乎同时去访问一个Web文档时, 就会出现瞬间拥塞, 由此造成的过多流量峰值可能会使网络和Web服务器产生灾难性的崩溃。而缓存在应对瞬间拥塞时就显得非常重要。 降低了距离时延, 因为从较远的地方加载页面会更慢一些即使带宽不是问题, 距离也可能成为问题。每台网络路由器都会增加因特网流量的时延。即使客户端和服务器之间没有太多的路由器, 光速自身也会造成显著的时延。 比如波士顿到旧金山的直线距离大约为2700英里, 在最好的情况下, 以光速传输(186000英里/秒)的信号可以在大约15毫秒从波士顿传送到旧金山, 并在30毫秒内完成一个往返。假设某个Web页面包含了20个小图片, 都在旧金山的一台服务器上, 如果波士顿的一个客户端打开了4条到服务器的并行连接, 而且保持着连接的活跃状态, 光速自身就要消耗大约1/4秒(240毫秒)的下载时间。如果服务器位于(距离旧金山6700英里)的东京, 时延就会变成600毫秒。中等复杂的web页面会带来几秒钟的光速时延。况且实际应用中, 信号的传输速度会比光速低一些, 因此距离时延会更加严重。 而将缓存放在附近的机房里可以将文件传输距离从数千英里缩短为数十米。 ‘缓存命中’、’未命中’ 的概念 如果一些请求到达缓存设备时, 缓存设备可以用本地已有的副本为这些请求提供服务, 就被称为缓存命中。 如果一些请求到达缓存设备时, 缓存设备本地没有副本提供给这些请求, 而将请求转发给原始服务器, 这就被称为缓存未命中。 后面还有 再验证命中 和 再验证未命中 的概念; 引出文档过期 和 服务器再验证 已缓存的数据要与服务器数据保持一致: 缓存设备本地的副本 并不是时刻都与原始服务器上的文档一样, 毕竟服务器中的这些文档会随着时间发生变化(比如有些报告可能每个月都会变化, 而在线报纸每天都会变化, 财经数据可能每过几秒就会发生变化)。 所以, 如果缓存提供的总是老的数据, 就会变得毫无用处。 HTTP通过一些简单的机制, 可以做到: 在不要求服务器记住有哪些缓存设备拥有其文档副本的情况下, 保持已缓存数据与服务器数据之间的充分一致。 HTTP将这些简单的机制称为 文档过期(document expiration)(也就是缓存副本的过期时间) 和 服务器再验证(server revalidation)。 缓存副本的过期时间 原始服务器通过 老式的HTTP/1.0+的实体首部字段Expires 或 新式的HTTP/1.1的通用首部字段Cache-Control:max-age 可以向每个文档附加一个过期日期。 Expires 和 Cache-Control:max-age 所做的事情本质上是一直的, 但由于 Cache-Control 首部使用的是相对时间而不是绝对时间, 所以我们更倾向与使用比较新的 Cache-Control 首部。 Expires 绝对日期依赖于计算机时钟的正确设置 如下图: 在缓存文档过期之前, 缓存设备可以随意使用这些副本, 而且无需与服务器做任何联系!! 当然, 除非 客户端请求中包含 “阻止提供缓存” 的首部 Cache-Control:no-store; 或者客户端请求中包含”只有经过验证才能返回缓存副本”的首部Cache-Control:no-cache*), 但是一旦已缓存文档过期, 缓存设备就必须与服务器进行核对(当然, 除非你设置了Cache-Control:only-if-cached要求只使用缓存), 询问文档是否被修改过, 如果被修改过, 就要获取一份新鲜(带有新的过期日期)的副本。 注意: 不推荐使用Expires首部, 它指定的是实际的过期日期而不是秒数。HTTP设计者后来认为, 由于很多服务器的时钟都不同步, 或者不正确, 所以最好还是用剩余秒数, 而不是绝对时间来表示过期时间。 有些服务器还会回送一个Expires:0响应头,视图将文档置于永远过期的状态, 但这种语法是非法的, 可能给某个软件带来问题, 应该试着支持这种结构的输入, 但是不应该产生这种结构的输出。 而 Cache-Control 的 max-age 则可以设置 Cache-Control: max-age=0 另外, 注意 no-cache 和 must-revalidate 的区别 no-cache: 告诉浏览器、缓存服务器，不管本地副本是否过期，使用资源副本前，一定要到源服务器进行副本有效性校验。 must-revalidate：告诉浏览器、缓存服务器，本地副本过期前，可以使用本地副本；本地副本一旦过期，必须去源服务器进行有效性校验。(这应该是缓存系统的默认行为, 但must-revalidate指令使得这个要求是明确的参考) 可参考 副本过期算法测试 FireFox测试过期时间算法( Date + Expire/max-age - Age) 123456789101112131415161718192021222324&lt;?php/** * 主要测试浏览器确实是根据 expirationTime = responseTime(Date头) + freshnessLifetime(max-age/Exprie值) - currentAge(Age头) * 来计算失效时间的 * chrome好像不太正常(会交替显示 123 和 456789) * firefox 进行回车测试, 结果发现完全正常 */if(!isset($_SERVER['HTTP_IF_MODIFIED_SINCE'])) &#123; header(\"HTTP/1.1 200\"); header('Cache-Control: max-age=30'); // 放到下一行就不生效了(响应头还特么还有顺序?) header('Age:10'); // 发现浏览器确实拿着这个日期去判断有没有过期 header('Date:'. date('D, d M Y H:i:s', time()-10).' GMT'); header('Last-Modified:'. date('D, d M Y H:i:s', time()-20000).' GMT'); echo 123; exit;&#125;//算法: expirationTime = responseTime(Date头) + freshnessLifetime(max-age/Exprie值) - currentAge(Age头)// 此处浏览器判断 date + 30 - 10 , 由于date是当前时间, 所以差不多有20秒的过期时间// 如果是Age:0的话, date + 30 -0, 由于date是当前时间, 所以差不多有30秒的过期时间// 如果是Date-10, Age:0的话, date-10 + 30 -10, 所以差不多有10秒的过期时间 (不太好抓, 不过肯定是10秒过期)//发现只有超时之后, 才会显示出下面的信息 (firefox准确无误地实现,在未过期之前, 是不会带If-Modified-Since头去请求的)echo 456789;die; 缓存副本过期后的”再验证” 原始服务器上的内容可能会发生变化, 缓存要不时地对其进行检测, 看看自己保存的副本是否仍是服务器上最新的副本。这种”新鲜度检测”就被称为HTTP再验证(revalidation)。 虽然缓存可以在任意时刻, 以任意的频率从对副本进行再验证, 但是由于缓存中通常会包含数百万的文档, 而且网络带宽是很珍贵的, 所以大部分缓存只有在客户端发起请求,并且副本旧的足以需要再次检测的时候, 才会对副本进行再验证。 副本旧的足以需要再次检测的时候? 也就是缓存副本的过期时间已到!! 但是仅仅是已缓存文档过期了, 还不能说明该过期文档和原始服务器上的文档有实际的区别, 这只是意味着到时间进行再验证了！ 再验证命中(缓慢命中) 缓存对副本进行再验证时, 会向原始服务器发送一个小的再验证请求。如果发现内容没有变化, 服务器会以一个小的 304 Not Modified 进行响应。 只要缓存知道副本仍然有效, 就会再次将副本标识为暂时新鲜的, 并将副本提供给客户端, 这被称为再验证命中(revalidate hit) 或 缓慢命中(slow hit)。 当然, 这种方式确实还是需要与原始服务器进行核对, 所以会比单纯的缓存命中要慢, 但是它并没有从服务器中获取对象数据, 所以要比缓存未命中要快一些。 再验证未命中 缓存对副本进行再验证时, 会向原始服务器发送一个小的再验证请求。如果缓存发现服务器对象与已缓存副本不同, 则服务器会向客户端发送一条普通的, 带有完整内容的 HTTP 200 OK 响应; 当然, 这种方式确实不仅需要与原始服务器进行核对, 而且会从服务器中获取对象数据, 所以理论上貌似要比缓存未命中要慢一些, 但其实差不多 再验证 – 服务器对象被删除如果再验证发现服务器对象已经被删除, 服务器就回送一个 404 Not Found 响应, 缓存也会将其副本删除。 小结成功的再验证 比 缓存未命中 要快失败的再验证 几乎和 缓存未命中 速度一样 再验证依靠 – 条件方法 为了有效地进行再验证, HTTP定义了一些特殊的请求, 不用从服务器上获取整个对象, 就可以快速检测出内容是否是最新的。 HTTP的条件方法可以高效地实现再验证。 HTTP允许缓存向原始服务器发送一个 “条件GET”, 请求只有在服务器文档与缓存中现有的副本不同时, web服务器才会回送对象主体; 通过这种方式, 将新鲜度检测和对象获取结合成了单个条件GET。 向GET请求报文中添加一些特殊的条件首部, 就可以发起条件GET。 HTTP定义了5个条件请求首部, 对 缓存再验证 来说有用的2个首部是 If-Mofified-Since 和 If-None-Match, 所有的条件首部都以前缀If-开头。 If-Modified-Since:Date 再验证 最常见的缓存再验证首部是 请求首部字段 If-Modified-Since, If-Modified-Since再验证请求通常被称为IMS请求。 如果自If-Modified-Since指定日期之后, 文档被修改了, If-Modified-Since 条件就为真, 通常GET就会成功执行, 携带新首部的新文档会被返回给缓存, 新首部除了其他信息之外, 还包含了一个新的过期日期; 如果自If-Modified-Since指定日期之后, 文档没被修改, If-Modified-Since 条件就为假, 会向客户端返回一个小的 304 Not Modified响应报文, 为了提高有效性, 不会返回文档主体。这些首部是放在响应中返回的, 但是只会返回哪些需要在源端更新的首部, 比如, Content-Type首部通常不会被修改, 所以通常不需要发送。一般会发送一个新的过期日期。 请求首部字段If-Modified-Since 和 实体首部字段Last-Modified 配合工作。 原始服务器会将最后的修改日期附加到所提供的文档上去, 当缓存要对已缓存文档进行再验证时, 就会包含一个If-Modified-Since首部, 其中携带有最后修改已缓存副本的日期: If-Modified-Since:&lt;cached last-modified date&gt; 如果在此期间原始服务器文档被修改了, 最后的修改日期就会不同了, 这样If-Modified-Since条件就为真, 原始服务器就会回送新的文档； 否则, 服务器会注意到缓存的最后修改日期与服务器文档当前的最后修改日期相符合, 则会返回一个 304 Not Modified 响应。 小结: 如果在验证发现原始服务器内容未发生变化, If-Modified-Since在验证会返回304响应, 如果发生了变化, 就返回带有新主体的200响应。 If-None-Match 实体标签再验证实体标签 有些情况下使用最后修改日期进行再验证是不够的: 有些文档可能会被周期性地重写, 但实际包含的数据常常却是一样的。尽管内容没有发生变化, 但是修改日期会发生变化。 有些文档可能内容被修改了, 但是所做的修改并不重要, 不需要让世界范围内的缓存都重装数据(比如对拼写或注释的修改)。 涉及到弱验证器 有些服务器无法准确地判定其页面的最后修改日期。 有些服务器提供的文档会在亚秒间隙发生变化(比如,实时监视器), 对这些服务器来说, 以秒为粒度的修改日期可能就不够用了。 为了解决上述问题, HTTP有一个被称为 实体标签(ETag) 的 版本标识符, 这个实体标签是附加到文档上的任意标签, 标签可能可能包含了文档序列号或版本名, 或是文档内容的校验及其他指纹信息。 当对文档进行修改时, 可以修改文档的实体标签来说明这个新的版本。这样, 如果实体标签被修改了, 缓存就可以用 If-None-Match 条件首部来GET文档的新副本了。 假设缓存中有一个文档已经过(Expires:, Cache-Control:max-age)期, 或者其他配置导致需要再次验证, 如果缓存中有一个实体标签为v2.6, 则它会与原始服务器进行再验证: 如果服务器上的实体标签已经发生了变化(可能变成了v3.0, 和v2.6不再匹配), 服务器则会在一个 200 OK 响应中返回新的内容以及新的Etag标签 ; 如果标签仍然与原始服务器标签匹配, 则会返回一条304 Not Modified响应; 弱验证器 只要原始服务器内容发生变化, 则实体标签就会变化, 正常情况下, 强验证器就会对比失败, 导致服务器会在一个 200 OK 响应中返回新的内容以及新的Etag标签; 有时, 服务器希望对文档进行一些不重要的修改, 并且不需要使所有已缓存副本都失效HTTP1.1支持的”弱验证器”, 就允许对一些内容做修改, 此时服务器会用前缀 W/ 来标识弱验证器。 不管相关的实体值以何种方式发生了变化, 强实体标签都要发生变化, 而相关实体在语义上发生了比较重要的变化时, 弱实体标签页应该发生变化。 实体标签 和 最近修改日期 如果服务器回送了一个实体标签, HTTP/1.1客户端就必须使用实体标签验证器。如果服务器只回送了一个Last-Modified值, 客户端就可以使用 If-Modified-Since 验证。如果实体标签和最后修改日期都提供了, 客户端就应该使用这两种再验证方案, 这样HTTP1.0和HTTP1.1换成你都可以正确响应了。 除非HTTP/1.1原始服务器无法生成实体标签验证器, 否则就应该发送一个出去, 如果使用弱实体标签有优势的话, 发送的可能就是个弱实体标签, 而不是强实体标签。而且最好同时发送一个最近修改值。如果HTTP/1.1缓存或服务器受到的请求既带有 If-Modified-Since, 又带有实体标签条件首部, 那么只有这两个条件都满足时, 才能返回 304 Not Modified 响应(也就是两个都做验证)。 缓存状态码 200 和 304参考P176: HTTP没有为用户提供一种手段来区分响应是缓存命中的, 还是访问原始服务器得到的。在这两种情况下, 响应状态码都是200OK, 说明响应有主体部分。 你从public公共缓存中可能直接得到未过期的资源, 此时会返回 200 ok; 你也可能到公共缓存后发现要再验证, 此时发现文本已变更, 服务器也会返回 200 ok; 缓存命中(这里指的是公共的代理缓存命中) 返回 200 ok 客户端第一次访问资源, 浏览器和服务器之间有代理服务器, 这样的话, 由于这个代理服务器是个公共代理, 所以里面可能已经有了服务器响应的资源副本, 所以代理服务器会直接响应 资源副本和200 ok给客户端; 访问原始服务器, 返回 200 ok 浏览器和服务器之间没有代理服务器, 这样的话, 客户端第一次请求资源, 则服务器直接 响应 200 ok 和 资源对象 给客户端; 客户端多次访问资源, 浏览器和服务器之间有代理服务器, 但是由于种种原因, 缓存需要再验证, 并且结果发现再验证未命中, 则服务器会响应资源对象和200 ok给代理缓存, 然后代理再响应”服务器响应的资源和200 ok副本”给客户端; 浏览器直接取的自己的本地缓存, 返回 200 ok (from disk/memory cache) 此处由于浏览器之前缓存了 代理缓存服务器cdn 上的缓存副本, 所以浏览器缓存的副本和上面cdn代理缓存的副本一样(age缓存时间都没变), 只不过会标注”已缓存”来表示没有响应主体部分 304 Not Modified 是缓存和服务器多确认了一次缓存有效性检测后, 发现缓存再验证命中, 但是用的还是缓存。 小结: 304 Not Modified 比 再验证未命中返回200 OK 快, 但是比 private缓存命中返回 200 ok from disk/memory cache 慢; 参考 http权威指南176页 公有和私有缓存 通用首部字段(general header fields)Cache-Control有两个缓存响应指令: public 和 private 缓存可以是单个用户专用的, 也可以是数千名用户共享的 ; 专用缓存被称为私有缓存(private cache), 私有缓存是个人的缓存, 包含了单个用户最常用的页面 ; 共享缓存被称为公有缓存(public cache), 公有缓存包含了某个用户团体常用页面 ; 私有缓存私有缓存不需要很大的动力或存储空间, 这样就可以将其做的很小, 很便宜。Web浏览器中就有内建的私有缓存—大多数浏览器都会将常用文档缓存在你个人电脑的磁盘和内存中, 并且允许用户去配置缓存的大小和各种设置; 公有缓存 公有缓存是特殊的共享代理服务器, 被称为缓存代理服务器(caching proxy server), 或者更常见地被称为代理缓存(proxy cache)。 代理缓存会从自己本地缓存中给用户提供缓存资源, 或者代表用户与服务器进行联系。公有缓存会接受来自多个用户的访问, 所以通过它可以更好地减少冗余流量。 如下图: 每个客户端都会重复地访问一个(还不在私有缓存中的)新的”热门”文档。每个私有缓存都要获取同一份文档, 这样它就会多次穿过网络。 而使用共享的公有缓存时, 对于这个流行的对象, 缓存只要取一次就行了, 它会用共享的副本为所有的请求服务, 以降低网络流量。 缓存控制 客户端可以用 Cache-Control 请求首部来 强化 或 放松 对过期时间的限制。 有些应用程序对文档的新鲜度要求很高, 对于这些应用程序, 客户端可以用 Cache-Control 首部使过期时间更严格; 另一方面, 为了提高性能, 可靠性或开支的一种折中方式, 客户端可能会放松新鲜度要求; 如下对 Cache-Control 的请求指令进行了小结:HTTP Cache-Control: max-age和max-stale=s的区别 Pagma:no-cache 和 Cache-Control:no-cache 一样, 不过是为了兼容HTTP/1.0; 参考:HTTP权威指南 – 第七章 缓存《图解HTTP协议》https://developer.mozilla.org/en-US/docs/Web/HTTPRFC 2616MDN Web docs","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/tags/HTTP/"}]},{"title":"HTTP - 请求Method","slug":"2017-12-10-HTTP-03-Method","date":"2017-12-10T03:25:12.000Z","updated":"2018-02-04T03:34:46.000Z","comments":true,"path":"2017/12/10/2017-12-10-HTTP-03-Method/","link":"","permalink":"http://blog.renyimin.com/2017/12/10/2017-12-10-HTTP-03-Method/","excerpt":"","text":"前言 HTTP/1.1 中实现的 method，见RFC2616, 有: OPTIONS, GET, HEAD, POST, PUT, DELETE, TRACE, CONNECT RFC2616中提到: PATCH，LINK，UNLINK方法被定义，但并不常见, 在RFC 2068中实现; 《图解http协议》中LINK,UNLINK已经被http1.1废弃; 规范中虽然是上面那样定义的, 但具体还要看不同应用各自是如何去实现的, 有些应用会完整实现, 有些还会扩展, 有些可能会实现一部分 参考symfony中的 symfony/src/Symfony/Component/HttpFoundation/Request.php 12345678910const METHOD_HEAD = 'HEAD';const METHOD_GET = 'GET';const METHOD_POST = 'POST';const METHOD_PUT = 'PUT';const METHOD_PATCH = 'PATCH';const METHOD_DELETE = 'DELETE';const METHOD_PURGE = 'PURGE';const METHOD_OPTIONS = 'OPTIONS';const METHOD_TRACE = 'TRACE';const METHOD_CONNECT = 'CONNECT'; 而像postman这种工具, 实现的就比较多: 简要分析 PUT: 对已有资源进行更新操作, 所以是 update 操作; put和post有什么区别呢?在HTTP中, PUT被定义为idempotent(幂等性)的方法，POST则不是，这是一个很重要的区别。 一个简单例子: 假设一个博客系统提供一个Web API(http://superblogging/blogs/post/{blog-name}), 可以使用PUT或者POST进行请求, HTTP的body部分就是博文内容，这是一个很简单的REST API例子。 我们应该用PUT还是POST？取决于这个REST服务的行为是否是idempotent(幂等)的, 假如发送两个请求, 希望服务器端是产生两个博客帖子，那就说明这个服务不是idempotent的, 因为多次使用产生了副作用了, 那就应该使用POST方法。但如果是希望后一个请求把第一个请求覆盖掉(这不正是修改么), 那这个服务就是idempotent的。 虽然POST和PUT差别不大, 用错了也没关系, 但是你的服务一放到internet上，如果不遵从HTTP协议的规范，就可能给自己带来麻烦 POST: 上面已经提过了, 所以POST是非幂等的; POST和PUT都可以上传文件或者创建新信息, 但主要看你的REST服务行为是否是幂等的12再比如, 在我们的支付系统中，一个api的功能是创建收款金额二维码，它和金额相关，每个用户可以有多个二维码，如果连续调用则会创建新的二维码，这个时候就用POST还是那个例子，用户的账户二维码只和用户关联，而且是一一对应的关系，此时这个api就可以用PUT，因为每次调用它，都将刷新用户账户二维码 PATCH 对已有资源的操作:用于资源的部分内容的更新, 例如更新某一个字段。具体比如说只更新用户信息的电话号码字段, 而PUT用于更新某个资源较完整的内容, 比如说用户要重填完整表单更新所有信息, 后台处理更新时可能只是保留内部记录ID不变。 当资源不存在时: PATCH 可能会去创建一个新的资源, 这个意义上像是 saveOrUpdate 操作。 参考: https://segmentfault.com/q/1010000005685904/ https://unmi.cc/restful-http-patch-method/ http://restcookbook.com/HTTP%20Methods/patch/ https://tools.ietf.org/html/rfc5789 HEAD: HEAD和 GET 本质是一样的, 区别在于如果使用HEAD, 响应体将不会被返回，而仅仅返回HTTP头信息。有的人可能觉得这个方法没什么用，其实不是这样的。想象一个业务情景: 欲判断某个资源是否存在, 我们通常使用GET, 但这里用HEAD则意义更加明确。 GET: 比较简单, 直接获取资源; OPTIONS: 这个方法很有趣, 但极少使用。它用于获取当前URL所支持的方法。若请求成功, 则它会在HTTP头中包含一个名为”Allow”的头, 值是所支持的方法, 如”GET, POST”。 之前[介绍跨域]时, CORS方案 -- (not-so-simple request)中的”预检”请求用的请求方法就是 OPTIONS CONNECT : 要求用隧道协议连接代理, 如使用SSL TRACE : 书中谁比较少用 TRACE_Method是HTTP（超文本传输）协议定义的一种协议调试方法，该方法会使服务器原样返回任意客户端请求的任何内容。TRACE和TRACK是用来调试web服务器连接的HTTP方式。支持该方式的服务器存在跨站脚本漏洞，通常在描述各种浏览器缺陷的时候，把”Cross-Site-Tracing”简称为XST。攻击者可以利用此漏洞欺骗合法用户并得到他们的私人信息。（这个命令好怕怕，无知好吓人啊）如何关闭Apache的TRACE请求虚拟主机用户可以在.htaccess文件中添加如下代码过滤TRACE请求:RewriteEngine onRewriteCond %{REQUEST_METHOD} ^(TRACE|TRACK)RewriteRule .* - [F]服务器用户在httpd.conf尾部添加如下指令后重启apache即可:TraceEnable off DELETE : 参考 PURGE : 非规范中定义的方法","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/tags/HTTP/"}]},{"title":"08.","slug":"2017-09-22-composer-08","date":"2017-09-22T13:20:17.000Z","updated":"2018-02-03T07:34:43.000Z","comments":true,"path":"2017/09/22/2017-09-22-composer-08/","link":"","permalink":"http://blog.renyimin.com/2017/09/22/2017-09-22-composer-08/","excerpt":"","text":"","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"07. autoload之psr-4, psr-0, classmap, files","slug":"2017-09-22-composer-07","date":"2017-09-22T05:10:30.000Z","updated":"2018-02-03T09:52:47.000Z","comments":true,"path":"2017/09/22/2017-09-22-composer-07/","link":"","permalink":"http://blog.renyimin.com/2017/09/22/2017-09-22-composer-07/","excerpt":"","text":"自动加载 vendor/ 库 对于composer安装到vendor/目录下的库 如何在项目中自动加载到? composer安装完库之后, 会生成一个 vendor/autoload.php 文件, 你可以在项目中简单的引入这个文件, 这样就可以自动加载composer管理的vendor/下的这些库; require ‘vendor/autoload.php’; 当然, 你自己发布的packagist包一定要注意其中也需要设置自动加载规则(命名空间和目录对应关系) composer 自动加载类型psr-4 如果你的项目中还没有准备好自动加载功能(来实现对你项目各个目录中类的自动加载),现在你已经不需要自己去准备了, 因为一旦你引入了composer, 它就已经为你准备好了这一功能!!(当然, 引入composer很简单, 无论你是自己 comoser init初始化composer.json文件还是通过composer require安装一个包来生成 composer.json文件都可以) 它不仅能像上面说的那样帮你实现自动加载composer帮你管理的包, 也可以帮你在项目中创建自己的自动加载!! 你可以在 composer.json 的 autoload 字段中增加自己的 autoloader 12345&#123; &quot;autoload&quot;: &#123; &quot;psr-4&quot;: &#123;&quot;Acme\\\\&quot;: &quot;src/&quot;&#125; &#125;&#125; 像上面那样, 你就定义一个从 命名空间 到 目录 的映射关系, 此时 src 应该和vendor目录同级, 都在你项目的根目录下; 最后, 你在src目录下写的类就应该是Acme命名空间; 如果指定的 Acme 是个顶级命名空间, 那src下不管目录多深, 都可以从这个顶级开始找到, 不用在一一配置对应关系了; 如果 Acme 不是个顶级命名空间, 那么和src同级的目录也得配置其命名空间和对应关系 像上面那样配置好之后, composer 将注册一个 PSR-4 autoloader 到 Acme 命名空间 添加完 autoload 字段后，你应该再次运行 install 命令来生成 vendor/autoload.php 文件 注意: 此时虽然修改了 composer.json 文件, 但是由于并没有涉及到包信息(比如版本信息)的修改, 所以install和update都一样; 引用这个文件也将返回 autoloader 的实例，你可以将包含调用的返回值存储在变量中，并添加更多的命名空间。这对于在一个测试套件中自动加载类文件是非常有用的。 可参考: http://docs.phpcomposer.com/01-basic-usage.html#Autoloading psr-0不推荐…. 这里就不扯了 classmap classmap 需要写在autoload内; classmap 所配置的目录下的所有 .php 和 .inc 文件里的类, 都会在 install/update 过程中存储到 vendor/composer/autoload_classmap.php 文件中的map数组中; vendor/composer/autoload_classmap.php文件中的映射关系, key是扫描到的类的namespace\\类名 或者 类名(没有命名空间的), value是类文件的路径 格式 12345&#123; &quot;autoload&quot;: &#123; &quot;classmap&quot;: [&quot;src/&quot;, &quot;lib/&quot;, &quot;test/Something.php&quot;] // 可以看到不仅可以指定目录, 也可以指定文件 &#125;&#125; files 也需要写在autoload内; Files方式就是手动指定供直接加载的文件, 比如说我们有一系列全局的helper functions，可以放到一个helper文件里然后直接进行加载;&quot;autoload&quot;: { &quot;psr-4&quot;: { //一些自己写的类库 &quot;Test\\\\&quot;: &quot;src/&quot;, &quot;Test1\\\\&quot;: &quot;src1/&quot;, &quot;Test2\\\\&quot;: &quot;src2/&quot; }, &quot;classmap&quot;: [&quot;src/&quot;, &quot;src1/hehe.php&quot;], // 一些类 &quot;files&quot;: [&quot;common/functions.php&quot;] // 一些公共函数 }","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"06. 发布自己的包","slug":"2017-09-20-composer-06","date":"2017-09-20T10:40:17.000Z","updated":"2018-02-03T09:18:53.000Z","comments":true,"path":"2017/09/20/2017-09-20-composer-06/","link":"","permalink":"http://blog.renyimin.com/2017/09/20/2017-09-20-composer-06/","excerpt":"","text":"前言 GitHub官方提供了和Packagist相关的钩子服务; Packagist主要提供Composer包发布和索引, 默认Composer从Packagist获取资源。(可以使用你的GitHub帐号登录Packagist) 也可以理解为你真正的项目代码是在Gihub仓库中, 而相关介绍及索引信息是在Packagist平台 发布步骤github仓库部分 github创建仓库 将本地目录与github中仓库关联 在本地项目中初始化 composer.json 文件 composer init(使用composer自带的初始化命令，创建一个composer.json描述文件)。 如果想手动编辑，可以去composer官网阅读相关文档获得帮助。 在本地开发一个功能包, 并上传到github仓库中 开发功能包的注意事项: 需要在composer.json文件中配置好你当前包的自动加载规则, 比如: 12345\"autoload\": &#123; \"psr-4\": &#123; \"Lant\\\\\": \"./\" &#125; &#125; 否则, 即使你下载下来你的包, 并且你引入了 vendor/autoload.php 文件, 也无法正常自动加载到你的包代码 如果你的包composer.json文件中指定了 顶级命名空间名 与 目录 的关系, 子命名空间和目录就不用设置了 只用在子目录的类文件中声明 namespace 顶级命名空间/本命名空间 即可! 如果你包中的是几个同级目录, 那你可能就需要为每个目录设置 命名空间 和 目录的对应关系! Packagist部分 访问Packagist主页，确认自己已经登录，然后点击右上角大大的Submit Package，然后填入我们创建的仓库的地址，点击Check，然后没问题，再点击Submit。 为了让Packagist平台可以自动更新github仓库中的信息, 需要我们配置Github仓库的钩子服务 进入仓库, 点击 “setting” 点击左侧 “Integrations &amp; services” 然后 “Add service” - 选择 “Packagist” 然后填写表单, username为你的packagist账户名(如果使用github账户登录, 则为github账户名), Token是packagist中的Token; 注意有时候你的包修改完之后, 发现github仓库中有了, packagist中的同步时间也有了, 那你得看一下中国全量镜像站点的同步时间是否正确 (说好的一分钟同步一次, 但..不尽然, 被坑过); 参考http://note.youdao.com/noteshare?id=8265aa9789dba4451ada428a95048f33","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"05. require 和 create-project","slug":"2017-09-20-composer-05","date":"2017-09-20T10:21:46.000Z","updated":"2018-02-03T07:27:07.000Z","comments":true,"path":"2017/09/20/2017-09-20-composer-05/","link":"","permalink":"http://blog.renyimin.com/2017/09/20/2017-09-20-composer-05/","excerpt":"","text":"require是在当前项目目录下进行包安装, 一般安装到vendor/下; create-project 是指把包当成一个项目来安装, 也就是如果你创建的这个包是一个完整的项目, 你就可以来直接把这个包当成项目来创建 composer create-project lant/packagist_test 项目在本地的目录名 项目版本(如:dev-master)","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"04.更新包的方式(require, install, update对比)","slug":"2017-09-18-composer-04","date":"2017-09-18T14:23:17.000Z","updated":"2018-02-03T07:24:33.000Z","comments":true,"path":"2017/09/18/2017-09-18-composer-04/","link":"","permalink":"http://blog.renyimin.com/2017/09/18/2017-09-18-composer-04/","excerpt":"","text":"require虽然是安装, 但也可以用来更新包的版本, 并同时更新composer.json和composer.lock文件, 如果没有则会创建! composer require 包名 新版本 当你手动修改了composer.json文件中包的版本之后, 可以执行 composer update 来重新安装该包, 并更新composer.lock文件, 如果没有则会创建! 当然, 你可以指定你需要更新的包 composer update 包名, 包名... 另外, 还应该注意一下 install 和 update 的一个小细节:当你修改了composer.json文件, 如果不是对包做增删改(比如增加一个包, 删除一个包, 或者修改包的版本信息), 而是增删改其他信息(比如配置自动加载之类的信息), 那么你使用 install 和 update 是没有区别的! 小结 install, require, update都可以做包安装 require 和 update 都可以做包更新 (install不能做包版本的更新 或 新增/删除包) install 和 update 都除了做包安装, 还可以对诸如自动加载的信息进行重新更新!! 另外: install:主要是在部署阶段使用，以便在生产环境和开发环境使用的都是composer.lock文件中相同的依赖项，保证线上部署环境与本地开发环境的一致性。 update: 主要是在开发阶段使用，根据我们在composer.json文件中指定的内容升级项目的依赖包。 此更新非彼更新比如packagist中的包现在是v2.0, 你本地的是v1.0, 你直接执行 composer update, 不要指望composer会自动帮你更新到v2.0, 要更新你得在composer.json中指明版本号, 然后composer update才会根据composer.json文件去更新!这样, 至于你的更新是升级还是降级就看你在composer.json文件中如何指定的了!","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"03.安装包的方式(require, install, update对比)","slug":"2017-09-18-composer-03","date":"2017-09-18T13:20:31.000Z","updated":"2018-02-03T07:10:23.000Z","comments":true,"path":"2017/09/18/2017-09-18-composer-03/","link":"","permalink":"http://blog.renyimin.com/2017/09/18/2017-09-18-composer-03/","excerpt":"","text":"初次做包安装 如果你的项目刚引入composer, 现在是第一次进行包的安装, 也就是只有composer.json文件, 并没有composer.lock文件, 可以, 直接执行 composer require 包名 包版本 该命令会帮你安装好包到 vendor/ 目录下 会生成 composer.json 文件, 并将依赖信息写入文件中 会生成 composer.lock 文件composer将会通过composer.json来读取需要的包和相对的版本, 然后创建composer.lock文件所以… 对于除了包版本之外的其他配置, 如自动加载…等, composer.lock 文件不会包含! (所以当改变这些信息之后, install 和 update的效果一样) 非初次安装 如果你的项目已经安装过一些包了, 即已经有 composer.json, composer.lock 文件; 此时, 你有两种方式: 和初次安装一样, 使用 composer require 包名 包版本 进行安装 手动在composer.json文件中进行配置, 然后运行 composer update注意, 此时不能使用 composer install, 因为该命令是依据 composer.lock 文件来进行安装的, 而composer.lock文件又是依据composer.json文件中的包及包版本信息生成的,而此时你改变了 composer.json 文件, 并且是新增了一个包(及版本对应关系), 所以你需要更新 composer.lock 文件! 如果你执行的是 composer install, 则会警告: Warning: The lock file is not up to date with the latest changes in composer.json. You may be getting outdated dependencies. Run update to update them. 当然, 你也可以删除 composer.lock 文件, 然后手动在composer.json文件中进行配置, 最后执行 composer install install, require, update都可以做包安装","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"02. 设置中国全量镜像","slug":"2017-09-18-composer-02","date":"2017-09-18T09:40:11.000Z","updated":"2018-02-03T07:10:11.000Z","comments":true,"path":"2017/09/18/2017-09-18-composer-02/","link":"","permalink":"http://blog.renyimin.com/2017/09/18/2017-09-18-composer-02/","excerpt":"","text":"前言 一般情况下,安装包的数据(主要是 zip 文件) 一般是从 github.com 上下载的, 安装包的元数据是从 packagist.org 上下载的。然而，由于众所周知的原因，国外的网站连接速度很慢，并且随时可能被“墙”甚至“不存在”。“Packagist 中国全量镜像”所做的就是缓存所有安装包和元数据到国内的机房并通过国内的 CDN 进行加速，这样就不必再去向国外的网站发起请求, 从而达到加速 composer install以及 composer update 的过程, 并且更加快速、稳定。因此, 即使 packagist.org、github.com 发生故障(主要是连接速度太慢和被墙), 你仍然可以下载、更新安装包。 原理图下面是一张从网上找的图 配置方法 修改 composer 的全局配置文件 打开命令行窗口（windows用户）或控制台（Linux、Mac 用户）并执行命令: composer config -g repo.packagist composer https://packagist.phpcomposer.com 修改当前项目的 composer.json 配置文件 打开命令行窗口（windows用户）或控制台（Linux、Mac 用户）, 进入你的项目的根目录（也就是 composer.json 文件所在目录），执行命令: composer config repo.packagist composer https://packagist.phpcomposer.com 命令将会在当前项目中的 composer.json 文件的末尾自动添加镜像的配置信息（你也可以自己手工添加）： 123456\"repositories\": &#123; \"packagist\": &#123; \"type\": \"composer\", \"url\": \"https://packagist.phpcomposer.com\" &#125; &#125; 参考: https://pkg.phpcomposer.com/","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"01.安装","slug":"2017-09-18-composer-01","date":"2017-09-18T09:10:11.000Z","updated":"2018-02-04T03:33:08.000Z","comments":true,"path":"2017/09/18/2017-09-18-composer-01/","link":"","permalink":"http://blog.renyimin.com/2017/09/18/2017-09-18-composer-01/","excerpt":"","text":"composer.phar文件下载先下载composer.phar文件, 3种方式: curl -sS https://getcomposer.org/installer | php php -r &quot;readfile(&#39;https://getcomposer.org/installer&#39;);&quot; | php 手动下载Composer, 地址 Linux/Unix/OS 全局安装 : mv composer.phar /usr/local/bin/composer 局部安装 : mv composer.phar /局部目录/composer windows 全局安装 : 配置composer.phar文件路径(D:\\WWW\\composer)到环境变量中 ; 接下来需要在composer.phar同级目录下新建文件composer.bat : echo @php &quot;%~dp0composer.phar&quot; %*&gt;composer.bat 这就安装好了 局部安装 : 直接把下载的composer.phar文件放到项目根目录下; 运行命令 : php composer.phar install 然后就安装成功了(每个局部目录都需要这么安装, 比较麻烦) 推荐全局安装即可. Composer是PHP中的一个依赖管理工具, 它可以让你声明自己项目所依赖的库，然后它将会在项目中为你安装这些库。安装步骤可以到官网阅读Getting Started。在继续阅读之前，请确认composer已经安装并且可以使用。命令别名是composer，所以后续的所有如composer xxx均代表是执行composer命令。","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.renyimin.com/tags/Composer/"}]},{"title":"HTTP - 并行连接, 持久连接","slug":"2017-04-21-HTTP-Connection-Keep-Alive","date":"2017-04-21T12:10:11.000Z","updated":"2018-01-25T05:57:37.000Z","comments":true,"path":"2017/04/21/2017-04-21-HTTP-Connection-Keep-Alive/","link":"","permalink":"http://blog.renyimin.com/2017/04/21/2017-04-21-HTTP-Connection-Keep-Alive/","excerpt":"","text":"常被误解的Connection首部 HTTP允许在客户端和最终的源端服务器之间存在一串HTTP中间实体(代理, 高速缓存等)。可以从客户端开始, 逐跳地将HTTP报文经过这些中间设备, 转发到源端服务器上去(或者进行反向传递)。 HTTP的Connection首部字段中有一个由,分隔的 连接标签 列表; Connection首部可以承载3种不同类型的标签, 因此非常令人费解: HTTP首部字段名, 列出了只与此链接有关的首部; 任意标签值, 用于描述此链接的非标准选项; close, 说空操作完成之后需要关闭这条持久连接; 如果连接标签中包含了一个HTTP首部字段的名称, 那么这个首部字段就包含了一些连接有关的信息, 不能将其转发出去, 在将报文转发出去之前, 必须删除Connection首部列出的所有首部字段。 由于Connection搜捕可以防止无意中对本地首部的转发, 因此将逐跳字首部名放入Connection首部被称为”对首部的保护”。 (Connection首部是个逐跳首部, 只适用于单条传输链路, 不应该沿着传输链路向下传输 (参考P101)) 并行连接 在串行请求时, 浏览器可以先完整地请求原始的HTML页面, 然后请求第一个嵌入对象, 然后请求第二个嵌入对象等, 以这种简单的方式对每个嵌入式对象进行串行处理, 很明显这样处理很慢!! HTTP允许客户端打开多条连接, 并行地执行多个HTTP事务, 如下图, 并行加载了四幅嵌入式图片, 每个事务都有自己的TCP连接: 并行连接可能会提高页面的加载速度 包含嵌入对象的组合页面如果能通过并行连接克服单条连接的空载时间和带宽限制, 加载速度也会有所提高。时延可以重叠起来, 而且如果单条连接没有充分利用客户端的因特网带宽, 可以将为用带宽分配来装载其他对象。 如下图, 串行和并行的对比, 并行情况下, 先装载的是封闭的HTML页面, 然后并行处理其余3个事务, 每个事务都有自己的连接。(图片的装载是并行的, 连接的时延也是重叠的) 由于软件开销的存在, 每个连接请求之间总会有一些小的时延, 但连接请求和传输时间基本上都是重叠起来的! 并行连接不一定更快 即使并行连接的速度可能会更快, 但是并不一定总是更快。 因为在客户端的网络带宽如果不足时, 大部分的时间可能都是用来传送数据的。在这种情况下, 一个连接到速度较快服务器上的HTTP事务就会很容易耗尽所有可用的Modem带宽。 如果并行加载多个对象, 每个对象都会去竞争这有限的带宽, 每个对象都会以较慢的速度按比例加载, 这样带来的性能提升就很小, 甚至没什么提升。 而且打开大量连接会消耗很多内存资源, 从而引发自身性能问题。 复杂的Web有可能会有数十或数百个内嵌对象, 客户端可能可以打开数百个连接, 但Web服务器通常要同时处理很多其他用户的请求, 所以很少有Web服务器希望出现这样的情况。 一百个用户同时发出申请, 每个用户打开100个连接, 服务器就要负责处理1W个连接, 这会造成服务器性能的严重下降。对高负荷的代理来说也同样如此。 实际上, 浏览器确实使用了并行连接, 但它们会将并行连接的总数限制为一个较小的值(通常是四个)。服务器可以随意关闭来自特定客户端的超量连接。 并行连接可能让人”感觉”更快一些通过上面的介绍, 我们知道并行连接并不总是能使页面加载更快, 但即使实际上没有加快页面的传输速度, 并行连接通常也会让用户觉得页面加载的更快了,因为多个组件对象同时出现屏幕上时, 用户能够看到加载的进展。如果整个屏幕上有很多动作在进行, 即使实际上整个页面的下载时间更长, 用户也会认为Web页面加载得更快一些。 持久连接 HTTP/1.1(以及HTTP/1.0的各种增强版本)允许HTTP设备在事务处理结束之后将TCP连接保持在打开状态, 以便未来的HTTP请求能够重用现存的连接。在事务处理结束之后仍然保持在打开状态的TCP连接被称为持久连接。 非持久连接会在每个事务结束之后关闭, 持久连接会在不同事务之间保持打开状态, 直到客户端或服务器其决定将其关闭为止。 重用已对目标服务器打开的空闲持久连接, 就可以避开缓慢的连接建立阶段。而且已经打开的连接还可以避免慢启动的拥塞使用阶段, 以便更快速地进行数据的传输。 持久连接和并行连接 之前已经了解过”并行连接可以提高复合页面的传输速度, 但并行连接也有一些缺点”;而持久连接有一些比并行连接更好的地方,持久连接降低了时延和连接建立的开销, 将连接保持在已调谐状态, 而且减少了打开连接的潜在数量。但是, 管理持久连接时要特别小心, 不然就会积累大量的空闲连接, 耗费本地以及远程客户端和服务器上的资源。 持久连接与并行连接配合使用可能是更高效的方式。现在, 很多Web应用程序都会打开少量的并行连接, 其中的每一个都是持久连接。 持久连接有两种类型: 比较老的 HTTP/1.0+&quot;keep-alive&quot; 连接, 以及现代的 HTTP/1.1 &quot;persistent&quot; 连接。 HTTP/1.0+keep-alive连接 前言:大约从1996年开始, 很多HTTP/1.0浏览器和服务器都进行了扩展, 以支持一种被称为keep-alive连接的早期实验型持久连接。这些早期的持久连接收到了一些互操作性设计方面问题的困扰, 这些问题在后期的HTTP/1.1版本中都得到了修正, 但很多客户端和服务器仍然在使用这些早期的keep-alive连接。 下图在”串行连接上实现了4个HTTP事务的时间线” 与 “在一条持久连接上实现同样事务” 所需的时间线进行了比较, 显示了keep-alive连接的一些性能优点 由于去除了创建连接和关闭连接的开销, 所以时间线有所缩减 Keep-Alive操作客户端和服务器要配合 keep-alive已经不再使用了, 而且在当前的HTTP/1.1规范中也已经没有了对它的说明了。但浏览器和服务器对keep-alive握手的使用仍然相当广泛, 因此HTTP的实现者应该做好与之进行交互操作的准备. 实现HTTP/1.0 keep alive连接的客户端可以通过包含Connection: Keep-Alive首部请求将一条连接保持在打开状态。 如果服务器愿意为下一条请求将连接保持在打开状态, 就在响应中包含相同的首部。如果响应中没有Connection: Keep-Alive首部, 客户端就认为服务器不支持keep-alive, 会在发回响应报文之后关闭连接。 还有keep-alive首部 注意, keep-Alive首部只是请求将连接保持在活跃状态。发出keep-alive请求之后, 客户端和服务器并不一定会同意进行keep-alive会话。 它们可以在任意时刻关闭空闲的keep-alive连接, 并可随意限制keep-alive连接所处理事务的数量。 可以用Keep-Alive通用首部字段中指定的, 有逗号分隔的选项来调节keep-alive的行为: 参数timeout: 是在Keep-Alive响应首部发送的, 它估计了服务器希望将连接保持在活跃状态的时间。这并不是一个承诺值。 参数max: 是在Keep-Alive响应首部发送的, 它估计了服务器还希望为多少个事务保持次连接的活跃状态。这并不是一个承诺值。 Keep-Alive首部还可以支持任意未经处理的属性, 这些属性主要用于诊断和调试。语法为 name [=value]。 Keep-Alive首部完全是可选的, 但只有在提供了 Connection:Keep-Alive 时才能使用它。 下面这个例子说明服务器最多还会为另外5个事务保持连接的打开状态, 或者将打开状态保持到连接空闲了2分钟之后。 12Connection: Keep-AliveKeep-Alive: max=5, timeout=120 keep-alive连接的限制和规则 在HTTP/1.0中, keep-alive并不是默认使用的。客户端必须发送一个 Connection: Keep-Alive 请求首部来激活keep-alive连接。 Connection: Keep-Alive 首部必须随所有希望保持持久连接的报文一起发送。 如果客户端没有发送Connection: Keep-Alive首部, 服务器就会在那条请求之后关闭连接。 客户端如果探明响应中没有Connection: Keep-Alive响应首部, 就可以知道服务器发出响应之后是否会关闭连接了。 一般都是在检测到连接关闭之后, 就可以确定报文实体主体部分的长度。如果想”无需检测到连接关闭 就能确定报文实体主体部分的长度”, 那你的响应报文的实体主体部分必须有正确的Connect-Length, 有多部件媒体类型, 或者用分块传输编码的方式进行了编码。 在一条keep-alive信道中回送错误的 Connection-Length 是很糟糕的事, 这样的话, 事务处理的另一端就无法精确地检测出一条报文的结束和另一条报文的开始了。 代理和网关必须执行Connection首部的规则, 代理或网关必须在将报文转发出去或将其高速缓存之前, 删除在Connection首部中命名的所有首部字段以及Connection首部本身。 严格来说, 不应该与无法确定是否支持Connection首部的代理服务器建立keep-alive连接, 以防止出现下面要介绍的哑代理问题, 在实际应用中不是总能做到这一点的。 从技术上来讲, 应该忽略所有来自HTTP/1.0设备的Connection首部字段(包括Connection:Keep-Alive), 因为他们可能是由比较老的代理服务器误转发的。但是实际上, 尽管可能会有在老代理上挂起的危险, 有些客户端和服务器还是会违反这条规则。 除非重复发送请求会产生其他副作用, 否则 “如果在客户端受到完整响应之前连接就关闭了, 那么客户端一定要做好重试请求的准备”。 Keep-Alive和哑代理 正常情况下, 如果客户端与一台服务器对话, 客户端可以发送一个 Connection:Keep-Alive 首部来告知服务器它希望保持连接的活跃状态, 如果服务器支持keep-alive, 就回送一个 Connection:Keep-Alive 首部, 否则就不回送。 问题是出在代理上 — 尤其是那些不理解Connection首部, 而且不知道在沿着转发链路将报文转发出去之前应该将Connection首部删除的代理。 很多老式或简单的代理都是盲中继(blind relay), 他们只是将字节从一个连接转发到两一个连接中去, 不对Connection首部进行特殊处理。 下图就是一个Web客户端通过一个作为盲中继使用的哑代理与Web服务器进行对话的例子: 更多参考: P101 盲中继的更多问题参考 4.5.7 (??) 为了防止此类代理通信问题的发生, 现在的代理都决不能转发Connection首部和所有名字出现在Connection值中的首部。 另外还有几个不能作为Connection首部的值, 并且也不能被代理转发或作为缓存响应使用的首部: Proxy-Authenticate, Proxy-Connection, Transfer-Encoding 和 Upgrade; HTTP/1.1 persistent连接 HTTP/1.1主键停止了对keep-alive连接的支持, 用一种名为持久连接(persistent connection)的改进型设计取代了它。 持久连接的目的与keep-alive连接的目的相同, 但机制更优一些。 与HTTP/1.0的keep-alive连接不同, HTTP/1.1持久连接在默认情况下是激活的。除非特别指明, 否则HTTP/1.1假定所有连接都是持久的。 要在事务处理结束之后将连接关闭, HTTP/1.1应用程序必须向报文中显示地添加一个Connection:close首部。 这是与以前的HTTP协议很重要的区别, 在以前的版本中, keep-alive连接要么是可选的, 要么根本就不支持。 HTTP/1.1客户端假定在收到响应后, 除非响应中包含了 Connection:close首部, 不然HTTP/1.1连接就仍维持在打开状态。 但是, 客户端和服务器仍然可以随时关闭空闲的连接。 不发送 Connection:close 并不以为这服务器承诺永远将连接保持在打开状态。 persistent连接的限制和规则 (??) 发送了 Connection:close 请求首部之后, 客户端就无法在那条连接上发送更多的请求了。 如果客户端不想在连接上发送其他请求了, 就应该在最后一条请求中发送一个 Connection:close 请求首部。 只有当连接上所有的报文都有正确的, 自定义报文长度时 – 也就是, 实体主体部分的长度都和响应 Connect-Length 一致, 或者是用分块传输编码方式编码的 — 连接才能持久保持。 HTTP/1.1的代理必须能够分别管理与客户端和服务器的持久连接 — 每个持久连接都值适用于一跳传输。 (由于较老的代理会转发Connection首部, 所以)HTTP/1.1的代理服务器不应该与HTTP/1.0客户端建立持久连接, 除非他们了解客户端的处理能力。 实际上, 这一点是很难做到的, 很多厂商都违背了这一原则。 尽管服务器不应该试图在传输报文的过程中关闭连接, 而且在关闭连接之前至少应该响应一条请求, 但不管Connection首部取了什么值, HTTP/1.1设备都可以在任意时刻关闭连接。 HTTP/1.1应用程序必须能够从异步的关闭中恢复出来, 只要不存在可能会累积起来的副作用, 客户端都应该重试这条请求。(??) 除非重复发送请求会产生其他副作用, 否则 “如果在客户端收到完整响应之前连接就关闭了, 那么客户端必须要重新发送请求” 一个用户客户端对任何服务器或代理, 最多只能维护两条持久连接, 以防服务器过载。 代理可能需要更多到服务器的连接来支持并发用户的通信, 所以如果有N个用户试图访问服务器的话, 代理最多要维持2N条到任意服务器或父代理的连接。 管道化连接 HTTP/1.1允许在持久连接上可选地会用请求管道。这是在keep-alive连接上的进一步性能优化。在相应到达之前, 可以将多条请求放入队列。 当第一条请求通过网络流向地球另一端的服务器时, 第二条和第三条也可以开始发送了。 在高时延网络条件下, 这样做可以降低网络的回环时间, 提高性能。 如下图: 对管道化连接的限制 如果HTTP客户端无法确认连接是持久的, 就不应该使用管道。 必须按照与请求相同的顺序回送HTTP响应。HTTP报文中没有序列号标签, 因此如果收到的响应失序了, 就没办法将其与请求匹配起来了。 HTTP客户端必须做好连接会在任意时刻关闭的准备, 还要准备好重发所有未完成的管道化请求。 如果客户端打开了一条持久连接, 并立即发出了10条请求, 服务器可能在只处理了5条请求后关闭了连接, 剩下的5条请求会失败, 客户端必须能够应对这些过早关闭连接的情况, 重新发出这些请求。 HTTP客户端不应该用管道化的方式发送回产生副作用的请求(比如POST)。 总之, 出错的时候, 管道化方式会阻塞客户端了解服务器执行的是一系列管道化请求中的哪一些。由于无法安全地重试POST这样的非幂等请求, 所以出错时, 就存在某些方法永远不会被执行的风险。 关闭连接“任意”解除连接所有HTTP客户端, 服务器或代理都可以在任意时刻关闭一条TCP传输连接, 通常会在一条报文结束时关闭连接, 但出错的时候, 也可能在首部行中间, 或其他奇怪的地方关闭连接。对管道化持久连接来说, 这种情形是很常见的。HTTP应用程序可以在经过任意一段时间之后，关闭持久连接。比如，在持久连接空闲一段时间之后，服务器可能会决定将其关闭。但是，服务器永远都无法确定在它关闭”空闲”连接的那一刻，在线路的那一头的客户端有没有数据要发送。如果出现这种情况，客户端就会在写入半截请求报文时发现出现了连接错误。 Conetent-Length 及 截尾操作每条HTTP响应都应该有精确的Content-Length首部，用来描述响应主体的尺寸。如果老的HTTP服务器省略了Content-Length或者包含错误的长度指示，这样就要一来服务器发出连接关闭来说明数据的真是末尾。 连接关闭容限,重试及幂等性即使在非错误情况下,连接也可以在任意时刻关闭。HTTP应用程序要做好正确处理非预期关闭的准备。如果在客户端执行事务的过程中, 传输连接关闭了, 那么, 除非事务处理会带来一些副作用, 否则客户端就应该重新打开连接, 并重试一次。对管道化连接来说, 这种情况更加严重一些。客户端可以将大量请求放入队列中排队, 但源端服务器可以关闭连接, 这样就会留下大量未处理的请求, 需要重新调度。 副作用是很重要的问题, 如果在发送出一些请求数据之后, 收到返回结果之前, 连接关闭了, 客户端就无法百分之百地确定服务器端实际激活了多少事务。有些事务, 比如GET一个静态的HTML页面, 可以反复执行多次, 也不会有什么变化。而其他一些事务, 比如向一个在线书店POST一张订单, 就不能重复执行, 不然会有下多张订单的危险。 如果一个事务， 不管是执行一次还是很多次，得到的结果都相同, 这个事务就是幂等的。实现者们可以认为GET、HEAD、PUT、DELETE、TRACE和OPTIONS方法都共享这一特性。客户端不应该以管道化方式传送非幂等请求(比如POST)。否则，传输连接的过早终止就会造成一些不确定的后果。要发送一条非幂等请求，就需要等待来自前一条清求的响应状态。 尽管用户Agent代理可能会让操作员来选择是否对请求进行重试，但一定不能自动重试非幂等方法或序列。比如，大多数浏览器都会在重载一个缓存的POST响应时提供一个对话框，询问用户是否希望再次发起事务处理。 正常关闭连接 正常关闭连接TCP连接是双向的。TCP连接的每一端都有一个输入队列和一个输出队列, 用于数据的读或写。放入一端输出队列中的数据最终会出现在另一端的输入队列中。 完全关闭与半关闭应用程序可以关闭TCP输入和输出信道中的任意一个, 或者将两者都关闭了。套接字调用close()会将TCP连接的输入和输出信道都关闭了, 这被称作 “完全关闭”。还可以用套接字调用shutdown()单独关闭输入或输出信道。这被称为”半关闭”。 TCP关闭及重置错误…. 参考《HTTP权威指南》– 第四章《图解HTTP协议》https://developer.mozilla.org/en-US/docs/Web/HTTPhttps://tools.ietf.org/html/rfc2616","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/tags/HTTP/"}]},{"title":"OOP - Proxy","slug":"2016-08-07-OOP-Proxy","date":"2016-08-07T13:05:36.000Z","updated":"2018-01-22T03:06:30.000Z","comments":true,"path":"2016/08/07/2016-08-07-OOP-Proxy/","link":"","permalink":"http://blog.renyimin.com/2016/08/07/2016-08-07-OOP-Proxy/","excerpt":"","text":"前言代理模式是常用的结构型设计模式之一, 当无法直接访问某个对象或访问某个对象存在困难时可以通过一个代理对象来间接访问, 为了保证客户端使用的透明性, 所访问的真实对象与代理对象需要实现相同的接口。根据代理模式的使用目的不同, 代理模式又可以分为多种类型, 例如 保护代理、远程代理、虚拟代理、缓冲代理等, 它们应用于不同的场合, 满足用户的不同需求。 代理模式是一种对象结构型模式。在代理模式中通过引入了一个新的代理对象, 代理对象在客户端对象和目标对象之间起到中介的作用, 它去掉客户不能看到的内容和服务或者增添客户需要的额外的新服务。 代理模式 代理模式的结构比较简单, 其核心是代理类, 为了让客户端能够一致性地对待真实对象 和 代理对象, 在代理模式中引入了抽象层, 代理模式结构如下: 代理模式包含如下三个角色: Subject(抽象主题角色): 它声明了真实主题和代理主题的共同接口, 这样一来在任何使用真实主题的地方都可以使用代理主题, 客户端通常需要针对抽象主题角色进行编程。 Proxy(代理主题角色): 它包含了对真实主题的引用, 从而可以在任何时候操作真实主题对象; 在代理主题角色中提供一个与真实主题角色相同的接口, 以便在任何时候都可以替代真实主题; 代理主题角色还可以控制对真实主题的使用, 负责在需要的时候创建和删除真实主题对象, 并对真实主题对象的使用加以约束。 通常, 在代理主题角色中, 客户端在调用所引用的真实主题操作之前或之后还需要执行其他操作, 而不仅仅是单纯调用真实主题对象中的操作。 RealSubject(真实主题角色): 它定义了代理角色所代表的真实对象, 在真实主题角色中实现了真实的业务操作, 客户端可以通过代理主题角色间接调用真实主题角色中定义的操作。 代码实现: 代理模式的结构图比较简单, 但是在真实的使用和实现过程中要复杂很多, 特别是代理类的设计和实现。 抽象主题类可以是接口、抽象类或具体类, 它声明了真实主题类和代理类的公共方法, 客户端针对抽象主题类编程, 一致性地对待真实主题和代理主题, 典型的抽象主题类代码如下: 1234abstract class Subject &#123; public function Request(); &#125; 真实主题类继承了抽象主题类, 提供了业务方法的具体实现, 其典型代码如下: 1234567class RealSubject implements Subject &#123; public function Request() &#123; //业务方法具体实现代码 &#125; &#125; 代理类也是抽象主题类的子类，它维持一个对真实主题对象的引用，调用在真实主题中实现的业务方法，在调用时可以在原有业务方法的基础上附加一些新的方法来对功能进行扩充或约束，最简单的代理类实现代码如下： 123456789101112131415161718192021class Proxy implements Subject &#123; private $realSubject = new RealSubject(); //维持一个对真实主题对象的引用 public function PreRequest() &#123; // &#125; public function Request() &#123; PreRequest(); $realSubject-&gt;Request(); //调用真实主题对象的方法 PostRequest(); &#125; public function PostRequest() &#123; // &#125; &#125; 但是, 在实际开发过程中, 代理类的实现比上述代码要复杂很多, 代理模式根据其目的和实现方式不同可分为很多种类, 其中常用的几种代理模式简要说明如下: 远程代理(Remote Proxy): 为一个位于不同的地址空间的对象提供一个本地的代理对象, 这个不同的地址空间可以是在同一台主机中, 也可是在另一台主机中, 远程代理又称为大使(Ambassador)。 虚拟代理(Virtual Proxy): 如果需要创建一个资源消耗较大的对象, 先创建一个消耗相对较小的对象来表示, 真实对象只在需要时才会被真正创建。 保护代理(Protect Proxy): 控制对一个对象的访问, 可以给不同的用户提供不同级别的使用权限。 缓冲代理(Cache Proxy): 为某一个目标操作的结果提供临时的存储空间, 以便多个客户端可以共享这些结果。 智能引用代理(Smart Reference Proxy): 当一个对象被引用时, 提供一些额外的操作, 例如将对象被调用的次数记录下来等。 在这些常用的代理模式中, 有些代理类的设计非常复杂, 例如远程代理类, 它封装了底层网络通信和对远程对象的调用, 其实现较为复杂。 应用实例 实例说明: 某软件公司承接了某信息咨询公司的收费商务信息查询系统的开发任务, 该系统的基本需求如下:(1)在进行商务信息查询之前用户需要通过身份验证, 只有合法用户才能够使用该查询系统;(2)在进行商务信息查询时系统需要记录查询日志, 以便根据查询次数收取查询费用。该软件公司开发人员已完成了商务信息查询模块的开发任务, 现希望能够以一种松耦合的方式向原有系统增加身份验证和日志记录功能, 客户端代码可以无区别地对待原始的商务信息查询模块和增加新功能之后的商务信息查询模块, 而且可能在将来还要在该信息查询模块中增加一些新的功能。试使用代理模式设计并实现该收费商务信息查询系统。 实例分析及类图通过分析, 可以采用一种间接访问的方式来实现该商务信息查询系统的设计, 在客户端对象和信息查询对象之间增加一个代理对象, 让代理对象来实现身份验证和日志记录等功能, 而无须直接对原有的商务信息查询对象进行修改, 如下图:在上图中, 客户端对象通过代理对象间接访问具有商务信息查询功能的真实对象, 在代理对象中除了调用真实对象的商务信息查询功能外, 还增加了身份验证和日志记录等功能。使用代理模式设计该商务信息查询系统, 结构图如下:图中: 业务类AccessValidator用于验证用户身份; 它提供方法Validate()来实现身份验证; 业务类Logger用于记录用户查询日志; 它提供方法Log()来保存日志; Searcher充当抽象主题角色; RealSearcher充当真实主题角色; ProxySearcher充当代理主题角色; 维持了对RealSearcher对象、AccessValidator对象和Logger对象的引用。 代码: 本实例是 保护代理 和 智能引用代理 的应用实例, 在代理类ProxySearcher中实现对真实主题类的权限控制和引用计数, 如果需要在访问真实主题时增加新的访问控制机制和新功能, 只需增加一个新的代理类, 再修改配置文件, 在客户端代码中使用新增代理类即可, 源代码无须修改, 符合开闭原则。 各种代理参考代理模式效果代理模式是常用的结构型设计模式之一, 它为对象的间接访问提供了一个解决方案, 可以对对象的访问进行控制。代理模式类型较多, 其中远程代理、虚拟代理、保护代理等在软件开发中应用非常广泛。 代理模式的共同优点如下： 能够协调调用者和被调用者, 在一定程度上降低了系统的耦合度; 客户端可以针对抽象主题角色进行编程, 增加和更换代理类无须修改源代码, 符合开闭原则, 系统具有较好的灵活性和可扩展性; 此外, 不同类型的代理模式也具有独特的优点, 例如: 远程代理为位于两个不同地址空间对象的访问提供了一种实现机制, 可以将一些消耗资源较多的对象和操作移至性能更好的计算机上, 提高系统的整体运行效率; 虚拟代理通过一个消耗资源较少的对象来代表一个消耗资源较多的对象, 可以在一定程度上节省系统的运行开销; 缓冲代理为某一个操作的结果提供临时的缓存存储空间, 以便在后续使用中能够共享这些结果, 优化系统性能, 缩短执行时间; 保护代理可以控制对一个对象的访问权限, 为不同用户提供不同级别的使用权限; 代理模式的主要缺点如下: 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢，例如保护代理。 实现代理模式需要额外的工作，而且有些代理模式的实现过程较为复杂，例如远程代理。 模式适用场景代理模式的类型较多, 不同类型的代理模式有不同的优缺点, 它们应用于不同的场合: 当客户端对象需要访问远程主机中的对象时可以使用远程代理。 当需要用一个消耗资源较少的对象来代表一个消耗资源较多的对象，从而降低系统开销、缩短运行时间时可以使用虚拟代理，例如一个对象需要很长时间才能完成加载时。 当需要为某一个被频繁访问的操作结果提供一个临时存储空间，以供多个客户端共享访问这些结果时可以使用缓冲代理。通过使用缓冲代理，系统无须在客户端每一次访问时都重新执行操作，只需直接从临时缓冲区获取操作结果即可。 当需要控制对一个对象的访问，为不同用户提供不同级别的访问权限时可以使用保护代理。 当需要为一个对象的访问（引用）提供一些额外的操作时可以使用智能引用代理。 参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"},{"name":"对象结构型","slug":"对象结构型","permalink":"http://blog.renyimin.com/tags/对象结构型/"}]},{"title":"OOP - Iterator","slug":"2016-07-28-OOP-Iterator","date":"2016-07-28T13:07:31.000Z","updated":"2018-01-18T03:53:51.000Z","comments":true,"path":"2016/07/28/2016-07-28-OOP-Iterator/","link":"","permalink":"http://blog.renyimin.com/2016/07/28/2016-07-28-OOP-Iterator/","excerpt":"","text":"前言我们可以将电视机看成一个存储电视频道的集合对象, 通过遥控器可以对电视机中的电视频道集合进行操作, 如返回上一个频道、跳转到下一个频道或者跳转至指定的频道。遥控器为我们操作电视频道带来很大的方便, 用户并不需要知道这些频道到底如何存储在电视机中。 而在软件开发中, 也存在大量类似电视机一样的类, 它们可以存储多个成员对象(元素), 这些类通常称为聚合类(Aggregate Classes), 对应的对象称为聚合对象。 为了更加方便地操作这些聚合对象, 同时可以很灵活地为聚合对象增加不同的遍历方法, 我们也需要类似电视机遥控器一样的角色, 可以访问一个聚合对象中的元素但又不需要暴露它的内部结构。 本篇将要学习的迭代器模式将为聚合对象提供一个遥控器, 通过引入迭代器, 客户端无须了解聚合对象的内部结构即可实现对聚合对象中成员的遍历, 还可以根据需要很方便地增加新的遍历方式。 引用”销售管理系统中数据的遍历” 初始方案: Sunny软件公司为某商场开发了一套销售管理系统, 在对该系统进行分析和设计时, Sunny软件公司开发人员发现经常需要对系统中的商品数据、客户数据等进行遍历, 为了复用这些遍历代码, Sunny公司开发人员设计了一个抽象的数据集合类AbstractObjectList, 而将存储商品和客户等数据的类作为其子类, AbstractObjectList类结构如下图所示： 问题: 违反 单一职责, 接口隔离 Sunny软件公司开发人员通过对AbstractObjectList类结构进行分析, 发现该设计方案存在如下几个问题： 在类图中, addObject()、removeObject() 等方法用于管理数据, 而next()、isLast()、previous()、isFirst()等方法用于遍历数据。这将导致聚合类的职责过重, 它既负责存储和管理数据, 又负责遍历数据, 违反了 “单一职责原则”, 由于聚合类非常庞大, 实现代码过长, 还将给测试和维护增加难度。 如果将抽象聚合类声明为一个接口, 则在这个接口中充斥着大量方法, 不利于子类实现, 违反了 “接口隔离原则”。 如果将所有的遍历操作都交给子类来实现, 将导致子类代码庞大, 而且必须暴露AbstractObjectList的内部存储细节, 向子类公开自己的私有属性, 否则子类无法实施对数据的遍历，这将破坏AbstractObjectList类的封装性。 如何解决上述问题? 解决方案之一就是将聚合类中负责遍历数据的方法提取出来, 封装到专门的类中, 实现数据存储和数据遍历分离, 无须暴露聚合类的内部属性即可对其进行操作, 而这正是迭代器模式的意图所在。 迭代器模式 在软件开发中, 我们经常需要使用聚合对象来存储一系列数据。聚合对象拥有两个职责: 一是存储数据, 二是遍历数据。 从依赖性来看，前者是聚合对象的基本职责； 而后者既是可变化的，又是可分离的。 因此，可以将遍历数据的行为从聚合对象中分离出来，封装在一个被称之为 “迭代器” 的对象中，由迭代器来提供遍历聚合对象内部数据的行为，这将简化聚合对象的设计，更符合 “单一职责原则” 的要求。 迭代器模式(Iterator Pattern)定义：提供一种方法来访问聚合对象, 而不用暴露这个对象的内部表示, 其别名为游标(Cursor)模式。迭代器模式是一种对象行为型模式。 在迭代器模式结构中包含聚合和迭代器两个层次结构, 考虑到系统的灵活性和可扩展性, 在迭代器模式中应用了工厂方法模式, 其模式结构如下所示: 在迭代器模式结构图中包含如下几个角色: Iterator(抽象迭代器): 它定义了访问和遍历元素的接口, 声明了用于遍历数据元素的方法, 例如: 用于获取第一个元素的first()方法，用于访问下一个元素的next()方法，用于判断是否还有下一个元素的hasNext()方法，用于获取当前元素的currentItem()方法等，在具体迭代器中将实现这些方法。 ConcreteIterator(具体迭代器): 它实现了抽象迭代器接口，完成对聚合对象的遍历，同时在具体迭代器中通过游标来记录在聚合对象中所处的当前位置，在具体实现时，游标通常是一个表示位置的非负整数。 Aggregate(抽象聚合类):它用于存储和管理元素对象, 声明一个createIterator()方法用于创建一个迭代器对象, 充当抽象迭代器工厂角色。 ConcreteAggregate(具体聚合类): 它实现了在抽象聚合类中声明的createIterator()方法，该方法返回一个与该具体聚合类对应的具体迭代器ConcreteIterator实例。 在迭代器模式中, 提供了一个外部的迭代器来对聚合对象进行访问和遍历, 迭代器定义了一个访问该聚合元素的接口, 并且可以跟踪当前遍历的元素, 了解哪些元素已经遍历过而哪些没有。迭代器的引入, 将使得对一个复杂聚合对象的操作变得简单。 下面我们结合代码来对迭代器模式的结构进行进一步分析, 在迭代器模式中应用了工厂方法模式, 抽象迭代器对应于抽象产品角色, 具体迭代器对应于具体产品角色, 抽象聚合类对应于抽象工厂角色, 具体聚合类对应于具体工厂角色 在抽象迭代器中声明了用于遍历聚合对象中所存储元素的方法，典型代码如下所示： 123456interface Iterator &#123; public void first(); //将游标指向第一个元素 public void next(); //将游标指向下一个元素 public boolean hasNext(); //判断是否存在下一个元素 public Object currentItem(); //获取游标指向的当前元素 &#125; 在具体迭代器中将实现抽象迭代器声明的遍历数据的方法，如下代码所示： 123456789101112131415161718class ConcreteIterator implements Iterator &#123; private ConcreteAggregate objects; //维持一个对具体聚合对象的引用，以便于访问存储在聚合对象中的数据 private int cursor; //定义一个游标，用于记录当前访问位置 public ConcreteIterator(ConcreteAggregate objects) &#123; this.objects=objects; &#125; public void first() &#123; ...... &#125; public void next() &#123; ...... &#125; public boolean hasNext() &#123; ...... &#125; public Object currentItem() &#123; ...... &#125; &#125; 需要注意的是抽象迭代器接口的设计非常重要: 一方面需要充分满足各种遍历操作的要求, 尽量为各种遍历方法都提供声明; 另一方面又不能包含太多方法, 因为接口中方法太多将给子类的实现带来麻烦; 另外, 如果需要在具体迭代器中为聚合对象增加全新的遍历操作, 则必须修改抽象迭代器和具体迭代器的源代码，这将 违反“开闭原则”, 因此在设计时要考虑全面,避免之后修改接口。 聚合类用于存储数据并负责创建迭代器对象, 最简单的抽象聚合类代码如下所示: 123interface Aggregate &#123; Iterator createIterator(); &#125; 具体聚合类作为抽象聚合类的子类，一方面负责存储数据，另一方面实现了在抽象聚合类中声明的工厂方法createIterator()，用于返回一个与该具体聚合类对应的具体迭代器对象，代码如下所示： 1234567class ConcreteAggregate implements Aggregate &#123; ...... public Iterator createIterator() &#123; return new ConcreteIterator(this); &#125; ...... &#125; 理解迭代器模式中 具体聚合类 与 具体迭代器类 之间存在的依赖关系和关联关系。 迭代器模式中应用了工厂方法模式(每个具体的聚合对象都对应一个具体的迭代器); 销售管理系统的解决方案代码 参考 如果需要增加一个新的具体聚合类, 如客户数据集合类, 并且需要为客户数据集合类提供不同于商品数据集合类的正向遍历和逆向遍历操作, 那么只需增加一个新的聚合子类和一个新的具体迭代器类即可;原有类库代码无须修改, 符合“开闭原则”; 如果需要为ProductList类更换一个迭代器, 只需要增加一个新的具体迭代器类作为抽象迭代器类的子类, 重新实现遍历方法, 原有迭代器代码无须修改, 也符合“开闭原则”; 但是如果要在迭代器中增加新的方法, 则需要修改抽象迭代器源代码, 这将违背“开闭原则”。 PHP迭代器 PHP SPL 中已经提供了迭代器接口Iterator和容器接口IteatorAggragate 并且PHP SPL已经提供了很多具体的迭代器对象 当然, 如果SPL准备的迭代器还不够, 你可以为你的聚合类创建自定义的迭代器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&lt;?php// 实现自己的具体迭代器class ConcreteIterator implements Iterator&#123; private $position = 0; private $array = array(); public function __construct($array) &#123; $this-&gt;array = $array; $this-&gt;position = 0; &#125; function rewind() &#123; $this-&gt;position = 0; &#125; function current() &#123; return $this-&gt;array[$this-&gt;position]; &#125; function key() &#123; return $this-&gt;position; &#125; function next() &#123; ++$this-&gt;position; &#125; function valid() &#123; return isset($this-&gt;array[$this-&gt;position]); &#125;&#125;/** * Class MyAggregate 聚合容器 */class ConcreteAggregate implements IteratorAggregate&#123; public $property; /** * 添加属性 * * @param $property */ public function addProperty($property) &#123; $this-&gt;property[] = $property; &#125; public function getIterator() &#123; return new ConcreteIterator($this-&gt;property); &#125;&#125;// Class Client 客户端测试class Client&#123; public static function test() &#123; //创建一个容器 $concreteAggregate = new ConcreteAggregate(); // 添加属性 $concreteAggregate-&gt;addProperty('属性1'); // 添加属性 $concreteAggregate-&gt;addProperty('属性2'); //给容器创建迭代器 $iterator = $concreteAggregate-&gt;getIterator(); //遍历 while($iterator-&gt;valid()) &#123; $key = $iterator-&gt;key(); $value = $iterator-&gt;current(); echo '键: '.$key.' 值: '.$value.'&lt;hr&gt;'; $iterator-&gt;next(); &#125; &#125;&#125;Client:: test(); 和 工厂方法模式非常类似,并且做到了 ‘开闭原则’, 当你具体聚合类需要更换迭代器的时候, 不用修改客户端代码, 只用维护具体的聚合类即可! (工厂方法模式, 也类似, 当你的一个日志记录器需要修改, 只用修改具体的那个工厂即可, 当然, 由于是做修改而不是扩展, 所以还是符合’开闭’原则的) 小结 迭代器模式是一种使用频率非常高的设计模式, 通过引入迭代器可以将数据的遍历功能从聚合对象中分离出来, 聚合对象只负责存储数据, 而遍历数据由迭代器来完成。 由于很多编程语言的类库都已经实现了迭代器模式, 因此在实际开发中，我们只需要直接使用Java、C#等语言已定义好的迭代器即可, 迭代器已经成为我们操作聚合对象的基本工具之一。 迭代器模式的主要优点如下： 它支持以不同的方式遍历一个聚合对象, 在同一个聚合对象上可以定义多种遍历方式。在迭代器模式中只需要用一个不同的迭代器来替换原有迭代器即可改变遍历算法, 我们也可以自己定义迭代器的子类以支持新的遍历方式。 迭代器简化了聚合类。由于引入了迭代器，在原有的聚合对象中不需要再自行提供数据遍历等方法，这样可以简化聚合类的设计。 在迭代器模式中，由于引入了抽象层，增加新的聚合类和迭代器类都很方便，无须修改原有代码，满足“开闭原则”的要求。 迭代器模式的主要缺点如下: 由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。 抽象迭代器的设计难度较大，需要充分考虑到系统将来的扩展，例如JDK内置迭代器Iterator就无法实现逆向遍历，如果需要实现逆向遍历，只能通过其子类ListIterator等来实现，而ListIterator迭代器无法用于操作Set类型的聚合对象。在自定义迭代器时，创建一个考虑全面的抽象迭代器并不是件很容易的事情。 在以下情况下可以考虑使用迭代器模式: 访问一个聚合对象的内容而无须暴露它的内部表示。将聚合对象的访问与内部数据的存储分离，使得访问聚合对象时无须了解其内部实现细节。 需要为一个聚合对象提供多种遍历方式。 为遍历不同的聚合结构提供一个统一的接口，在该接口的实现类中为不同的聚合结构提供不同的遍历方式，而客户端可以一致性地操作该接口。 参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"},{"name":"对象行为型","slug":"对象行为型","permalink":"http://blog.renyimin.com/tags/对象行为型/"}]},{"title":"OOP - Adapter","slug":"2016-07-24-OOP-Adapter","date":"2016-07-24T14:02:13.000Z","updated":"2018-01-17T06:01:29.000Z","comments":true,"path":"2016/07/24/2016-07-24-OOP-Adapter/","link":"","permalink":"http://blog.renyimin.com/2016/07/24/2016-07-24-OOP-Adapter/","excerpt":"","text":"前言 我的笔记本电脑的工作电压是20V, 而我国的家庭用电是220V, 如何让20V的笔记本电脑能够在220V的电压下工作？答案是引入一个电源适配器(AC Adapter), 俗称充电器或变压器, 有了这个电源适配器, 生活用电和笔记本电脑即可兼容! 在软件开发中, 有时也存在类似这种不兼容的情况, 我们也可以像引入一个电源适配器一样引入一个称之为适配器的角色, 来协调这些存在不兼容的结构, 这种设计方案即为适配器模式。 引用玩具厂家的例子 一开始的和谐黑枣玩具公司专门生产玩具, 生产的玩具如狗,猫,狮子,鱼等动物, 每个玩具都可以进行’张嘴’与’闭嘴’操作, 分别调用 openMouth 与 closeMouth 方法。在这个时候, 我们很容易想到可以定义一个抽象玩具类Toy, 甚至是接口Toy, 这些都不是问题, 然后其他的具体玩具类去继承/实现父类, 实现父类的方法。到现在为止, 一切看起来都很正常, 都很和谐, 代码如下: 1234567891011121314151617181920212223242526272829303132abstract class Toy&#123; public abstract function openMouth(); public abstract function closeMouth();&#125;class Dog extends Toy&#123; public function openMouth() &#123; echo \"Dog open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Dog open Mouth\\n\"; &#125;&#125;class Cat extends Toy&#123; public function openMouth() &#123; echo \"Cat open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Cat open Mouth\\n\"; &#125;&#125; 平衡的破坏后来为了扩大业务, 现在黑枣玩具公司与红枣遥控公司合作, 红枣遥控公司可以使用遥控设备对动物进行嘴巴控制, 不过红枣遥控公司的遥控设备是调用的动物的doMouthOpen及doMouthClose方法。黑枣玩具公司的程序员现在必须要做的是对Toy系列类进行升级改造, 使Toy能调用doMouthOpen及doMouthClose方法。(又或者让红枣公司来适应自己, 但毕竟自己做的是偏底层,想做强做大)。 考虑实现的方法时, 我们很直接地想到, 你需要的话我再在我的父类子类里给你添加这么两个方法就好啦。于是, 代码现在可能会被改造成:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162abstract class Toy&#123; public abstract function openMouth(); public abstract function closeMouth(); //为红枣遥控公司控制接口增加doMouthOpen方法 public abstract function doMouthOpen(); //为红枣遥控公司控制接口增加doMouthClose方法 public abstract function doMouthClose();&#125;class Dog extends Toy&#123; public function openMouth() &#123; echo \"Dog open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Dog open Mouth\\n\"; &#125; //增加的方法(用来适配红枣遥控公司) public function doMouthOpen() &#123; $this-&gt;doMouthOpen(); &#125; //增加的方法 public function doMouthClose() &#123; $this-&gt;closeMouth(); &#125;&#125;class Cat extends Toy&#123; public function openMouth() &#123; echo \"Cat open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Cat open Mouth\\n\"; &#125; //增加的方法 public function doMouthOpen() &#123; $this-&gt;doMouthOpen(); &#125; //增加的方法 public function doMouthClose() &#123; $this-&gt;closeMouth(); &#125;&#125; 当你一次又一次在父类子类里面重复添加着这两个方法的时候，总会想着如此重复的工作，但是, 当有数百个子类的时候, 这样做下去你就会觉得自己很傻。(其实我经常当这样的傻子) 更加烦躁当你刚改完上面的代码, 黑枣玩具公司又要与绿枣遥控公司合作, 因为绿枣遥控公司遥控设备更便宜稳定。不过绿枣遥控公司的遥控设备是调用的动物的operMouth(type)方法来实现嘴巴控制。如果type为0则闭嘴,反之张嘴。这下好了, 程序员又得对Toy及其子类进行升级, 这样下去搁谁都不淡定了, 你的代码可能如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677abstract class Toy &#123; public abstract function openMouth(); public abstract function closeMouth(); //这是给之前红枣公司增加的适配方法 public abstract function doMouthOpen(); public abstract function doMouthClose(); //这又是为绿枣遥控公司控制接口增加的适配方法 public abstract function operateMouth($type = 0); &#125; class Dog extends Toy &#123; public function openMouth() &#123; echo \"Dog open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Dog open Mouth\\n\"; &#125; public function doMouthOpen() &#123; $this-&gt;doMouthOpen(); &#125; public function doMouthClose() &#123; $this-&gt;closeMouth(); &#125; public function operateMouth($type = 0) &#123; if ($type == 0) &#123; $this-&gt;closeMouth(); &#125; else &#123; $this-&gt;operateMouth(); &#125; &#125; &#125; class Cat extends Toy &#123; public function openMouth() &#123; echo \"Cat open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Cat open Mouth\\n\"; &#125; public function doMouthOpen() &#123; $this-&gt;doMouthOpen(); &#125; public function doMouthClose() &#123; $this-&gt;closeMouth(); &#125; public function operateMouth($type = 0) &#123; if ($type == 0) &#123; $this-&gt;closeMouth(); &#125; else &#123; $this-&gt;operateMouth(); &#125; &#125; &#125; 在这个时候, 程序员就必须要动脑子想办法了, 就算自己勤快, 万一哪天紫枣,青枣,黄枣,山枣这些遥控公司全来的时候, 忽略自己不断增多的工作量不说, 这个Toy类可是越来越大, 总有一天程序员不崩溃, 系统也会崩溃。 问题在出在哪里呢？ 像上面那样编写代码, 代码违反了’开-闭’原则。 我们现在面临的是: 新的接口方法要实现, 旧的接口(Toy抽象类)也不能动, 那就是得引入一个新的类–我们本文的主角–适配器。 适配器要完成的功能很明确, 引用现有接口的方法实现新的接口的方法。 适配器模式 适配器模式(Adapter): 将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 通用类图: 代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116&lt;?php abstract class Toy &#123; public abstract function openMouth(); public abstract function closeMouth(); &#125; class Dog extends Toy &#123; public function openMouth() &#123; echo \"Dog open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Dog close Mouth\\n\"; &#125; &#125; class Cat extends Toy &#123; public function openMouth() &#123; echo \"Cat open Mouth\\n\"; &#125; public function closeMouth() &#123; echo \"Cat close Mouth\\n\"; &#125; &#125; //目标角色:红枣遥控公司 interface RedTarget &#123; public function doMouthOpen(); public function doMouthClose(); &#125; //目标角色:绿枣遥控公司 interface GreenTarget &#123; public function operateMouth($type = 0); &#125; //类适配器角色:红枣遥控公司 class RedAdapter implements RedTarget &#123; private $adaptee; function __construct(Toy $adaptee) &#123; $this-&gt;adaptee = $adaptee; &#125; //委派调用Adaptee的sampleMethod1方法 public function doMouthOpen() &#123; $this-&gt;adaptee-&gt;openMouth(); &#125; public function doMouthClose() &#123; $this-&gt;adaptee-&gt;closeMouth(); &#125; &#125; //类适配器角色:绿枣遥控公司 class GreenAdapter implements GreenTarget &#123; private $adaptee; function __construct(Toy $adaptee) &#123; $this-&gt;adaptee = $adaptee; &#125; //委派调用Adaptee：GreenTarget的operateMouth方法 public function operateMouth($type = 0) &#123; if ($type) &#123; $this-&gt;adaptee-&gt;openMouth(); &#125; else &#123; $this-&gt;adaptee-&gt;closeMouth(); &#125; &#125; &#125; class testDriver &#123; public function run() &#123; //实例化一只狗玩具 $adaptee_dog = new Dog(); echo \"给狗套上红枣适配器\\n\"; $adapter_red = new RedAdapter($adaptee_dog); //张嘴 $adapter_red-&gt;doMouthOpen(); //闭嘴 $adapter_red-&gt;doMouthClose(); echo \"给狗套上绿枣适配器\\n\"; $adapter_green = new GreenAdapter($adaptee_dog); //张嘴 $adapter_green-&gt;operateMouth(1); //闭嘴 $adapter_green-&gt;operateMouth(0); &#125; &#125; $test = new testDriver(); $test-&gt;run(); 最后的结果就是,Toy类及其子类在不改变自身的情况下, 通过适配器实现了不同的接口。 小结将一个类的接口转换成客户希望的另外一个接口, 使原本因不兼容而不能在一起工作的那些类,可以在一起工作。 适配器模式核心思想：把对某些相似的类的操作转化为一个统一的’接口’(这里是比喻的说话)–适配器,或者比喻为一个’界面’统一或屏蔽了那些类的细节。适配器模式还构造了一种’机制’, 使’适配’的类可以很容易的增减, 而不用修改与适配器交互的代码, 符合’减少代码间耦合’的设计原则。 参考参考参考参考 适配器参考 适配器","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"},{"name":"结构型","slug":"结构型","permalink":"http://blog.renyimin.com/tags/结构型/"}]},{"title":"Laravel-Facade","slug":"2016-07-21-Laravel-Facade","date":"2016-07-21T13:13:05.000Z","updated":"2018-01-17T03:17:56.000Z","comments":true,"path":"2016/07/21/2016-07-21-Laravel-Facade/","link":"","permalink":"http://blog.renyimin.com/2016/07/21/2016-07-21-Laravel-Facade/","excerpt":"","text":"代码追踪 以获取配置项的 Illuminate\\Support\\Facades\\Config 追踪Facade? 追踪到 Illuminate\\Support\\Facades 123456789101112131415161718192021public static function __callStatic($method, $args) &#123; $instance = static::getFacadeRoot(); if (! $instance) &#123; throw new RuntimeException(&apos;A facade root has not been set.&apos;); &#125; switch (count($args)) &#123; case 0: return $instance-&gt;$method(); case 1: return $instance-&gt;$method($args[0]); case 2: return $instance-&gt;$method($args[0], $args[1]); case 3: return $instance-&gt;$method($args[0], $args[1], $args[2]); case 4: return $instance-&gt;$method($args[0], $args[1], $args[2], $args[3]); default: return call_user_func_array([$instance, $method], $args); &#125; &#125; 这也就是为什么使用Facade的类可以直接使用静态调用的方式来调用方法, 正是Facade中的 __callStatic 方法生效了!","categories":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.renyimin.com/categories/Laravel/"}],"tags":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.renyimin.com/tags/Laravel/"},{"name":"Facade","slug":"Facade","permalink":"http://blog.renyimin.com/tags/Facade/"}]},{"title":"OOP - Facade","slug":"2016-07-19-OOP-Facade","date":"2016-07-19T11:56:09.000Z","updated":"2018-01-17T03:33:31.000Z","comments":true,"path":"2016/07/19/2016-07-19-OOP-Facade/","link":"","permalink":"http://blog.renyimin.com/2016/07/19/2016-07-19-OOP-Facade/","excerpt":"","text":"前言外观模式是一种使用频率非常高的结构型设计模式, 它通过引入一个外观角色来简化客户端与子系统之间的交互, 为复杂的子系统调用提供一个统一的入口, 降低子系统与客户端的耦合度, 且客户端调用非常方便; 在软件开发中, 有时候为了完成一项较为复杂的功能, 一个客户类需要和多个业务类交互, 由于涉及到的类比较多, 导致使用时代码较为复杂，此时，特别需要一个类似服务员一样的角色, 由它来负责和多个业务类进行交互, 而客户类只需与该类交互。 外观模式 外观模式中, 一个子系统的外部与其内部的通信, 通过一个统一的外观类进行, 外观类将客户类与子系统的内部复杂性分隔开, 使得客户类只需要与外观角色打交道, 而不需要与子系统内部的很多对象打交道。(在外观模式中, 那些需要交互的业务类被称为子系统(Subsystem)) 外观模式: 为子系统中的一组接口提供一个统一的入口。外观模式定义了一个高层接口, 这个接口使得这一子系统更加容易使用。 外观模式又称为门面模式, 它是一种对象结构型模式。 外观模式是迪米特法则的一种具体实现, 通过引入一个新的外观角色可以降低原有系统的复杂度, 同时降低客户类与子系统的耦合度。 迪米特法则(Law of Demeter)又叫作最少知道原则(Least Knowledge Principle 简写LKP)就是说一个对象应当对其他对象有尽可能少的了解, 不和陌生人说话。英文简写为: LoD. 外观模式没有一个一般化的类图描述, 通常使用下图来表示外观模式 外观模式包含如下两个角色： Facade(外观角色): 在客户端可以调用它的方法, 在外观角色中可以知道相关的(一个或者多个)子系统的功能和责任; 在正常情况下, 它将所有从客户端发来的请求委派到相应的子系统去, 传递给相应的子系统对象处理。 SubSystem(子系统角色): 在软件系统中可以有一个或者多个子系统角色, 每一个子系统可以不是一个单独的类, 而是一个类的集合, 它实现子系统的功能; 每一个子系统都可以被客户端直接调用, 或者被外观角色调用, 它处理由外观类传过来的请求; 子系统并不知道外观的存在, 对于子系统而言, 外观角色仅仅是另外一个客户端而已。 外观模式的主要目的在于降低系统的复杂程度, 在面向对象软件系统中, 类与类之间的关系越多, 表示系统中类之间的耦合度太大, 这样的系统在维护和修改时都缺乏灵活性, 因为一个类的改动会导致多个类发生变化, 而外观模式的引入在很大程度上降低了类与类之间的耦合关系。 引入外观模式之后, 增加新的子系统或者移除子系统都非常方便, 客户类无须进行修改(或者极少的修改), 只需要在外观类中增加或移除对子系统的引用即可。 从这一点来说, 外观模式在一定程度上并不符合开闭原则, 增加新的子系统需要对原有系统进行一定的修改, 虽然这个修改工作量不大。 未完待续 参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - Observer","slug":"2016-07-15-OOP-Observer","date":"2016-06-08T12:13:17.000Z","updated":"2018-01-17T03:33:16.000Z","comments":true,"path":"2016/06/08/2016-07-15-OOP-Observer/","link":"","permalink":"http://blog.renyimin.com/2016/06/08/2016-07-15-OOP-Observer/","excerpt":"","text":"前言 在日常交通中, 当红灯亮起, 来往的汽车将停止; 而绿灯亮起, 汽车可以继续前行。在这个过程中, 交通信号灯是汽车的观察目标, 而汽车是观察者; 随着交通信号灯的变化, 汽车的行为也将随之而变化, 一盏交通信号灯可以指挥多辆汽车; 在软件系统中, 有些对象之间也存在类似交通信号灯和汽车之间的关系, 一个对象的状态或行为的变化, 将导致其他对象的状态或行为也发生改变, 它们之间将产生联动。 为了更好地描述对象之间存在的这种一对多(包括一对一)的联动, 观察者模式应运而生, 它定义了对象之间一种一对多的依赖关系, 让一个对象的改变能够影响其他对象。 多人联机对战游戏的设计引出观察者模式 Sunny软件公司欲开发一款多人联机对战游戏(类似魔兽世界、星际争霸等游戏), 在该游戏中, 多个玩家可以加入同一战队组成联盟, 当战队中某一成员受到敌人攻击时将给所有其他盟友发送通知, 盟友收到通知后将作出响应。 Sunny软件公司开发人员需要提供一个设计方案来实现战队成员之间的联动。Sunny软件公司开发人员通过对系统功能需求进行分析, 发现在该系统中战队成员之间的联动过程可以简单描述为：联盟成员受到攻击–&gt;发送通知给盟友–&gt;盟友作出响应。 如果按照上述思路来设计系统, 由于联盟成员在受到攻击时需要通知他的每一个盟友, 因此每个联盟成员都需要持有其他所有盟友的信息, 这将导致系统开销较大; 因此Sunny公司开发人员决定引入一个新的角色 —— 战队控制中心 ——来负责维护和管理每个战队所有成员的信息; 当一个联盟成员受到攻击时, 将向相应的战队控制中心发送求助信息, 战队控制中心再逐一通知每个盟友盟友再作出响应。 如下图: 在图中, 受攻击的联盟成员将与战队控制中心产生联动, 战队控制中心还将与其他盟友产生联动。 如何实现对象之间的联动? 如何让一个对象的状态或行为改变时, 依赖于它的对象能够得到通知并进行相应的处理？本篇所介绍的观察者模式将为对象之间的联动提供一个优秀的解决方案, 下面就让我们正式进入观察者模式的学习。 观察者模式 观察者模式是使用频率最高的设计模式之一, 它用于建立一种对象与对象之间的依赖关系, 一个对象发生改变时将自动通知其他对象, 其他对象将相应作出反应。 观察者模式(Observer Pattern)定义： 对象之间的一种一对多依赖关系, 使得每当一个对象状态发生改变时, 其相关依赖对象皆得到通知并被自动更新。 观察者模式的别名包括发布-订阅(Publish/Subscribe)模式、模型-视图(Model/View)模式, 源-监听器(Source/Listener)模式 或 从属者(Dependents)模式。 观察者模式是一种对象行为型模式。 观察者模式描述了如何建立对象与对象之间的依赖关系, 以及如何构造满足这种需求的系统。 123观察者模式包含`观察目标` 和 `观察者` 两类对象, 一个目标可以有任意数目的与之相依赖的观察者, 一旦观察目标的状态发生改变, 所有的观察者都将得到通知。作为对这个通知的响应, **每个观察者都将监视观察目标的状态**以使其状态与目标状态同步, 这种交互也称为发布-订阅(Publish-Subscribe)。观察目标是通知的发布者, 它发出通知时并不需要知道谁是它的观察者, 可以有任意数目的观察者订阅它并接收通知。 观察者模式结构中通常包括观察目标和观察者两个继承层次结构，其结构如下图所示： 在观察者模式结构图中包含如下几个角色: Subject(目标): 目标又称为主题, 它是指被观察的对象。 在目标中定义了一个观察者集合, 一个目标可以接受任意数量的观察者来观察目标自己, 目标提供一系列方法来增加和删除观察者对象, 同时它定义了通知方法 notify()。目标类可以是接口，也可以是抽象类或具体类。 ConcreteSubject(具体目标): 具体目标是目标类的子类; 通常它包含有经常发生改变的数据, 当它的状态发生改变时, 向它的各个观察者发出通知; Observer(观察者): 观察者将对观察目标的改变做出反应, 观察者一般定义为接口, 该接口声明了更新数据的方法 update(), 因此又称为抽象观察者。 ConcreteObserver(具体观察者): 在具体观察者中维护一个指向具体目标对象的引用, 它存储了本观察者的有关状态, 这些状态需要和具体目标的状态保持一致; 它实现了在抽象观察者Observer中定义的update()方法, 通常在实现时, 可以调用具体目标类的 attach() 方法将自己添加到目标类的集合中或通过 detach() 方法将自己从目标类的集合中删除。 下面通过代码来进行分析 先看被观察的目标 12345678910111213141516171819202122232425262728293031323334353637383940414243interface Subject&#123; //注册方法, 用于向观察者集合中增加一个观察者 public function attach(Observer $observer); //注销方法, 用于在观察者集合中删除一个观察者 public function detach(Observer $observer); //通知所有注册过的观察者对象 public function notify();&#125;class ConcreteSubject&#123; // 定义一个观察者集合,用于存放所有观察者对象 private $observers = []; //注册方法, 用于向观察者集合中增加一个观察者 public function attach(Observer $observer) &#123; return array_push($this-&gt;observers, $observer); &#125; //注销方法, 用于在观察者集合中删除一个观察者 public function detach(Observer $observer) &#123; $index = array_search($observer, $this-&gt;observers); if ($index === FALSE || ! array_key_exists($index, $this-&gt;observers)) &#123; return FALSE; &#125; unset($this-&gt;observers[$index]); return TRUE; &#125; //通知所有观察者 public function notify() &#123; if (!is_array($this-&gt;observers)) return false; foreach ($this-&gt;observers as $observer) $observer-&gt;update(); return true; &#125;&#125; 观察者 1234567891011121314151617181920//抽象观察者角色interface Observer &#123; // 更新方法 public function update();&#125;class ConcreteObserver implements Observer &#123; //观察者的名称 private $name; public function __construct($name) &#123; $this-&gt;name = $name; &#125; //更新方法 public function update() &#123; echo 'Observer ', $this-&gt;name, ' has notified.&lt;br /&gt;'; &#125;&#125; 客户端操作 1234567891011121314151617//实例化一个'观察目标'$subject = new ConcreteSubject();//实例化一个观察者$observer1 = new ConcreteObserver('lant01');//'观察目标'添加第一个观察者$subject-&gt;attach($observer1);//'观察目标' 通知 已经观察了目标自己的观察者$subject-&gt;notify();echo '添加第二个观察者后, 再次通知: &lt;br/&gt;';$observer2 = new ConcreteObserver('lant02');$subject-&gt;attach($observer2);$subject-&gt;notify();echo '删除第一个观察者后, 再次通知: &lt;br/&gt;';$subject-&gt;detach($observer1);$subject-&gt;notify(); 结果: 123456Observer lant01 has notified.添加第二个观察者后, 再次通知:Observer lant01 has notified.Observer lant02 has notified.删除第一个观察者后, 再次通知:Observer lant02 has notified. 复杂情况 – 违反”开放-封闭原则” 在有些更加复杂的情况下, 具体观察者类 ConcreteObserver 的 update() 方法在执行时需要使用到 具体目标类ConcreteSubject中的状态(属性) 因此在 ConcreteObserver 与 ConcreteSubject 之间有时候还存在关联或依赖关系, 在 ConcreteObserver 中定义一个 ConcreteSubject 实例, 通过该实例获取存储在 ConcreteSubject 中的状态。 如果ConcreteObserver的update()方法不需要使用到ConcreteSubject中的状态属性，则可以对观察者模式的标准结构进行简化, 在具体观察者ConcreteObserver和具体目标ConcreteSubject之间无须维持对象引用。 如果观察者和观察目标在具体层具有关联关系, 系统的扩展性将受到一定的影响, 增加新的具体目标类有时候需要修改原有观察者的代码, 在一定程度上违反了开闭原则, 但是如果原有观察者类无须关联新增的具体目标，则系统扩展性不受影响。 多人对战游戏的解决方案注意此时不太是简单的观察者模式(不是简单 观察者 对 观察目标), 因为每个玩家既可以发布求救请求, 又可以去救援别人(此时队员对应了战队中心之后, 战队中心又对应了队员)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104&lt;?php//战队控制中心interface TeamControlCenter&#123; //盟友加入战队 public function setPlayers(Observer $observer); //盟友退出战队 public function removePlayers(Observer $observer); //通知战队其他成员 public function notify($observerName);&#125;class ConcreteTeamControlCenter implements TeamControlCenter&#123; // 用于存放本战队所有成员 private $players = []; // 战队名称 private $teamName; public function __construct($teamName) &#123; $this-&gt;teamName = $teamName; &#125; //注册方法, 用于向观察者集合中增加一个观察者 public function setPlayers(Observer $player) &#123; if (array_push($this-&gt;players, $player)) echo $player-&gt;getPlayerName() . ' 成功加入 ' . $this-&gt;teamName . '战队!' , '&lt;br/&gt;'; &#125; //注销方法, 用于在观察者集合中删除一个观察者 public function removePlayers(Observer $player) &#123; $index = array_search($player, $this-&gt;players); if ($index === FALSE || ! array_key_exists($index, $this-&gt;players)) &#123; return FALSE; &#125; unset($this-&gt;players[$index]); echo $player-&gt;getPlayerName() . ' 成功退出 ' . $this-&gt;teamName . '战队!' , '&lt;br/&gt;'; &#125; //通知所有观察者 public function notify($playerName) &#123; if (!is_array($this-&gt;players)) return false; foreach ($this-&gt;players as $player) &#123; if ($player-&gt;getPlayerName() != $playerName) $player-&gt;helpOther(); &#125; &#125;&#125;//抽象观察者角色interface Observer&#123; // 接收队友求救 public function helpOther(); // 被攻击,发出求救 public function beAttacked(TeamControlCenter $concreteTeamControlCenter); // 获取名字 public function getPlayerName();&#125;//每个玩家都是观察者class Player implements Observer&#123; //玩家(观察者)的名称 private $playerName; public function __construct($playerName) &#123; $this-&gt;playerName = $playerName; &#125; public function getPlayerName() &#123; return $this-&gt;playerName; &#125; //遭受攻击, 发求救 public function beAttacked(TeamControlCenter $concreteTeamControlCenter) &#123; echo '我是 ' . $this-&gt;playerName, ', 我被攻击了&lt;br /&gt;'; // 被攻击的话, 要通知战队中心, 让战队中心通知其他队友 $concreteTeamControlCenter-&gt;notify($this-&gt;playerName); &#125; //支援盟友 public function helpOther() &#123; echo '撑住!!!' . $this-&gt;playerName, ' 来救你了&lt;br /&gt;'; &#125;&#125;//创建战队控制中心$langya_team = new ConcreteTeamControlCenter('狼牙');//创建玩家$player1 = new Player('金刚狼');$player2 = new Player('死侍');//玩家加入一个战队$langya_team-&gt;setPlayers($player1);$langya_team-&gt;setPlayers($player2);$player1-&gt;beAttacked($langya_team); 参考参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - Abstract  Factory","slug":"2016-06-08-OOP-Factory","date":"2016-06-08T12:13:17.000Z","updated":"2018-01-17T02:04:49.000Z","comments":true,"path":"2016/06/08/2016-06-08-OOP-Factory/","link":"","permalink":"http://blog.renyimin.com/2016/06/08/2016-06-08-OOP-Factory/","excerpt":"","text":"前言工厂方法模式通过引入工厂等级结构, 解决了简单工厂模式中工厂类职责太重的问题;但由于工厂方法模式中的每个工厂只生产一类产品, 可能会导致系统中存在大量的工厂类, 势必会增加系统的开销;此时, 我们可以考虑将一些相关的产品组成一个 “产品族”, 由同一个工厂来统一生产, 这就是我们本文将要学习的抽象工厂模式的基本思想。 界面皮肤库的初始设计抽象工厂未完待续 参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - Prototype","slug":"2016-07-13-OOP-Prototype","date":"2016-06-08T12:13:17.000Z","updated":"2018-01-17T03:33:47.000Z","comments":true,"path":"2016/06/08/2016-07-13-OOP-Prototype/","link":"","permalink":"http://blog.renyimin.com/2016/06/08/2016-07-13-OOP-Prototype/","excerpt":"","text":"前言Sunny软件公司一直使用自行开发的一套OA(Office Automatic, 办公自动化)系统进行日常工作办理, 但在使用过程中, 越来越多的人对工作周报的创建和编写模块产生了抱怨。追其原因, Sunny软件公司的OA管理员发现, 由于某些岗位每周工作存在重复性, 工作周报内容都大同小异, 如下图工作周报示意图。 这些周报只有一些小地方存在差异，但是现行系统每周默认创建的周报都是空白报表，用户只能通过重新输入或不断复制粘贴来填写重复的周报内容，极大降低了工作效率，浪费宝贵的时间。如何快速创建相同或者相似的工作周报，成为Sunny公司OA开发人员面临的一个新问题。 Sunny公司的开发人员通过对问题进行仔细分析, 决定按照如下思路对工作周报模块进行重新设计和实现： - 除了允许用户创建新周报外，还允许用户将创建好的周报保存为模板; - 用户在再次创建周报时，可以创建全新的周报，还可以选择合适的模板复制生成一份相同的周报，然后对新生成的周报根据实际情况进行修改，产生新的周报; - 只要按照如上两个步骤进行处理，工作周报的创建效率将得以大大提高。这个过程让我们想到平时经常进行的两个电脑基本操作：复制和粘贴，通过对已有对象的复制和粘贴，我们可以创建大量的相同对象。 如何在一个面向对象系统中实现对象的复制和粘贴呢？本篇介绍的原型模式正为解决此类问题而诞生。 原型模式 在使用原型模式时，我们需要首先创建一个原型对象，再通过复制这个原型对象来创建更多同类型的对象。原型模式的定义如下： 原型模式(Prototype Pattern): 使用原型实例指定创建对象的种类, 并且通过拷贝这些原型创建新的对象, 原型模式是一种对象创建型模式; 原型模式的工作原理很简单: 将一个原型对象传给那个要发动创建的对象, 这个要发动创建的对象通过请求原型对象拷贝自己来实现创建过程。由于在软件系统中我们经常会遇到需要创建多个相同或者相似对象的情况，因此原型模式在真实开发中的使用频率还是非常高的。原型模式是一种“另类”的创建型模式，创建克隆对象的工厂就是原型类自身，工厂方法由克隆方法来实现。 需要注意的是通过克隆方法所创建的对象是全新的对象, 它们在内存中拥有新的地址, 通常对克隆所产生的对象进行修改对原型对象不会造成任何影响, 每一个克隆对象都是相互独立的。通过不同的方式修改可以得到一系列相似但不完全相同的对象。 PHP中的拷贝有 深拷贝 和 浅拷贝，先来分析一下这两者的区别 浅拷贝: 被拷贝对象的所有变量都含有与原对象相同的值, 而且对其他对象的引用仍然是指向原来的对象, 即浅拷贝只负责当前对象实例, 对引用的对象不做拷贝。 深拷贝: 被拷贝对象的所有的变量都含有与原来对象相同的值, 除了那些引用其他对象的变量, 那些引用其他对象的变量将指向一个被拷贝的新对象，而不再是原来那些被引用的对象。(即深拷贝把要拷贝的对象所引用的对象也拷贝了一次。而这种对被引用到的对象拷贝叫做间接拷贝)。 在决定以深拷贝的方式拷贝一个对象的时候, 必须决定对间接拷贝的对象是采取 浅拷贝 还是 深拷贝。 序列化深拷贝: 利用序列化来做深拷贝, 把对象写到流里的过程是序列化的过程, 这一过程称为“冷冻”或“腌咸菜”, 反序列化对象的过程叫做“解冻”或“回鲜”。 原型模式结构图 Prototype(抽象原型类): 它是声明克隆方法的接口, 是所有具体原型类的父类, 可以是抽象类也可以是接口, 甚至还可以是具体实现类; ConcretePrototype(具体原型类): 它实现在抽象原型类中声明的克隆方法, 在克隆方法中返回自己的一个克隆对象; Client(客户类): 让一个原型对象克隆原型对象自身从而创建一个新的对象, 在客户类中只需要直接实例化或通过工厂方法等方式创建一个原型对象，再通过调用该对象的克隆方法即可得到多个相同的对象。由于客户类针对抽象原型类Prototype编程，因此用户可以根据需要选择具体原型类，系统具有较好的可扩展性，增加或更换具体原型类都很方便。原型模式的核心在于如何实现克隆方法 原型模式简单演示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;?phpinterface Prototype&#123; //浅拷贝 public function shallowCopy(); //深拷贝 public function deepCopy();&#125;class ConcretePrototype implements Prototype&#123; private $_name; public function __construct($name) &#123; $this-&gt;_name = $name; &#125; public function setName($name) &#123; $this-&gt;_name = $name; &#125; public function getName() &#123; return $this-&gt;_name; &#125; //浅拷贝 public function shallowCopy() &#123; return clone $this; &#125; //深拷贝 public function deepCopy() &#123; $serialize_obj = serialize($this); $clone_obj = unserialize($serialize_obj); return $clone_obj; &#125;&#125;class Demo&#123; public $string;&#125;class UsePrototype&#123; public function shallow() &#123; $demo = new Demo(); $demo-&gt;string = \"susan\"; $object_shallow_first = new ConcretePrototype($demo); $object_shallow_second = $object_shallow_first-&gt;shallowCopy(); var_dump($object_shallow_first-&gt;getName()); echo '&lt;br/&gt;'; var_dump($object_shallow_second-&gt;getName()); echo '&lt;br/&gt;'; $demo-&gt;string = \"sacha\"; var_dump($object_shallow_first-&gt;getName()); echo '&lt;br/&gt;'; var_dump($object_shallow_second-&gt;getName()); echo '&lt;br/&gt;'; &#125; public function deep() &#123; $demo = new Demo(); $demo-&gt;string = \"Siri\"; $object_deep_first = new ConcretePrototype($demo); $object_deep_second = $object_deep_first-&gt;deepCopy(); var_dump($object_deep_first-&gt;getName()); echo '&lt;br/&gt;'; var_dump($object_deep_second-&gt;getName()); echo '&lt;br/&gt;'; $demo-&gt;string = \"Demo\"; var_dump($object_deep_first-&gt;getName()); echo '&lt;br/&gt;'; var_dump($object_deep_second-&gt;getName()); echo '&lt;br/&gt;'; &#125;&#125;$up = new UsePrototype;$up-&gt;shallow();echo '&lt;hr&gt;';$up-&gt;deep(); 原型管理器的引入和实现原型管理器(Prototype Manager)是将多个原型对象存储在一个集合中, 供客户端使用;它是一个专门负责克隆对象的工厂, 其中定义了一个集合用于存储原型对象, 如果需要某个原型对象的一个克隆，可以通过复制集合中对应的原型对象来获得。在原型管理器中针对抽象原型类进行编程, 以便扩展。其结构如下图： 下面通过模拟一个简单的公文管理器来介绍原型管理器的设计与实现： Sunny软件公司在日常办公中有许多公文需要创建、递交和审批，例如《可行性分析报告》、《立项建议书》、《软件需求规格说明书》、《项目进展报告》等， 为了提高工作效率，在OA系统中为各类公文均创建了模板，用户可以通过这些模板快速创建新的公文，这些公文模板需要统一进行管理，系统根据用户请求的不同生成不同的新公文。 我们使用带原型管理器的原型模式实现公文管理器的设计，其结构如下图： 原型模式总结 原型模式作为一种快速创建大量相同或相似对象的方式, 在软件开发中应用较为广泛, 很多软件提供的复制(Ctrl + C)和粘贴(Ctrl + V)操作就是原型模式的典型应用; 主要优点 当创建新的对象实例较为复杂时, 使用原型模式可以简化对象的创建过程，通过复制一个已有实例可以提高新实例的创建效率。 扩展性较好，由于在原型模式中提供了抽象原型类，在客户端可以针对抽象原型类进行编程，而将具体原型类写在配置文件中，增加或减少产品类对原有系统都没有任何影响。 原型模式提供了简化的创建结构，工厂方法模式常常需要有一个与产品类等级结构相同的工厂等级结构，而原型模式就不需要这样，原型模式中产品的复制是通过封装在原型类中的克隆方法实现的，无须专门的工厂类来创建产品。 可以使用深克隆的方式保存对象的状态，使用原型模式将对象复制一份并将其状态保存起来，以便在需要的时候使用（如恢复到某一历史状态），可辅助实现撤销操作。 主要缺点 需要为每一个类配备一个克隆方法，而且该克隆方法位于一个类的内部，当对已有的类进行改造时，需要修改源代码，违背了“开闭原则”。 在实现深克隆时需要编写较为复杂的代码，而且当对象之间存在多重的嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来可能会比较麻烦。 适用场景(在以下情况下可以考虑使用原型模式) 创建新对象成本较大（如初始化需要占用较长的时间，占用太多的CPU资源或网络资源），新的对象可以通过原型模式对已有对象进行复制来获得，如果是相似对象，则可以对其成员变量稍作修改。 如果系统要保存对象的状态，而对象的状态变化很小，或者对象本身占用内存较少时，可以使用原型模式配合备忘录模式来实现。 需要避免使用分层次的工厂类来创建分层次的对象，并且类的实例对象只有一个或很少的几个组合状态，通过复制原型对象得到新实例可能比使用构造函数创建一个新实例更加方便。 参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - Factory Method","slug":"2016-06-05-OOP-Factory","date":"2016-06-05T11:12:21.000Z","updated":"2018-01-16T05:31:07.000Z","comments":true,"path":"2016/06/05/2016-06-05-OOP-Factory/","link":"","permalink":"http://blog.renyimin.com/2016/06/05/2016-06-05-OOP-Factory/","excerpt":"","text":"前言 之前已经了解到: 简单工厂模式虽然降低了一定的耦合度, 但仍然存在一个严重问题: 当系统中需要引入新产品时, 由于静态工厂方法是通过所传入参数的不同来创建不同的产品, 所以必定还要修改工厂类的源代码, 又将违背“开闭原则”。 如何实现增加新产品而不影响已有代码？工厂方法模式应运而生。 日志记录器的设计Sunny软件公司欲开发一个系统运行日志记录器(Logger), 该记录器可以通过多种途径保存系统的运行日志, 如通过文件记录或数据库记录, 用户可以通过修改配置文件灵活地更换日志记录方式。在设计各类日志记录器时, Sunny公司的开发人员发现需要对日志记录器进行一些初始化工作, 初始化参数的设置过程较为复杂, 而且某些参数的设置有严格的先后次序, 否则可能会发生记录失败。如何封装记录器的初始化过程并保证多种记录器切换的灵活性是Sunny公司开发人员面临的一个难题。 Sunny公司的开发人员通过对该需求进行分析，发现该日志记录器有两个设计要点: 需要封装日志记录器的初始化过程, 这些初始化工作较为复杂, 例如需要初始化其他相关的类, 还有可能需要读取配置文件(例如连接数据库或创建文件), 导致代码较长, 如果将它们都写在构造函数中, 会导致构造函数庞大, 不利于代码的修改和维护; 用户可能需要更换日志记录方式, 在客户端代码中需要提供一种灵活的方式来选择日志记录器, 尽量在不修改源代码的基础上更换或者增加日志记录方式。 简单工厂模式的设计 Sunny公司开发人员最初使用简单工厂模式对日志记录器进行了设计，初始结构如下图所示: 在图中, LoggerFactory充当创建日志记录器的工厂, 提供了工厂方法 createLogger() 用于创建日志记录器, Logger是抽象日志记录器接口, 其子类为具体日志记录器。其中, 工厂类LoggerFactory代码片段如下所示: 123456789101112131415161718192021222324252627//为了突出设计重点, 代码进行了简化, 省略了具体日志记录器类的初始化代码。//日志记录器工厂 class LoggerFactory &#123; //静态工厂方法 public static function createLogger($type) &#123; if($type == 'db')) &#123; //连接数据库, 代码省略 //... //创建数据库日志记录器对象 $logger = new DatabaseLogger(); //初始化数据库日志记录器，代码省略 //... return logger; &#125; else if ($type == 'file') &#123; //创建日志文件 //... //创建文件日志记录器对象 Logger logger = new FileLogger(); //初始化文件日志记录器，代码省略 //... return logger; &#125; else &#123; return null; &#125; &#125; &#125; 正如之前学习的简单工厂模式, 存在问题: 工厂类过于庞大，包含了大量的if…else…代码，导致维护和测试难度增大; 系统扩展不灵活，如果增加新类型的日志记录器，必须修改静态工厂方法的业务逻辑，违反了“开闭原则”。 如何解决这两个问题, 这就是本文所介绍的 工厂方法模式 的动机之一。 工厂方法 在简单工厂模式中只提供一个工厂类, 该工厂类处于对产品类进行实例化的中心位置, 它需要知道每一个产品对象的创建细节, 并决定何时实例化哪一个产品类。 简单工厂模式最大的缺点是: 当有新产品要加入到系统中时, 必须修改工厂类, 需要在其中加入必要的业务逻辑, 这违背了“开闭原则”。 此外, 在简单工厂模式中, 所有的产品都由同一个工厂创建, 工厂类职责较重, 业务逻辑较为复杂, 具体产品与工厂类之间的耦合度高, 严重影响了系统的灵活性和扩展性, 而工厂方法模式则可以很好地解决这一问题! 在工厂方法模式中, 我们不再提供一个统一的工厂类来创建所有的产品对象, 而是针对不同的产品提供不同的工厂, 系统提供一个与产品等级结构对应的工厂等级结构, 工厂方法模式定义如下: 1234工厂方法模式(Factory Method Pattern): 定义一个用于创建对象的接口, 让子类决定将哪一个类实例化。工厂方法模式让一个类的实例化延迟到其子类。工厂方法模式又简称为工厂模式(Factory Pattern), 又可称作虚拟构造器模式(Virtual Constructor Pattern)或多态工厂模式(Polymorphic Factory Pattern)。工厂方法模式是一种类创建型模式。 工厂方法模式提供一个抽象工厂接口来声明抽象工厂方法，而由其子类来具体实现工厂方法，创建具体的产品对象。工厂方法模式结构如下图所示： 在工厂方法模式结构图中包含如下几个角色: Product（抽象产品）：它是定义产品的接口，是工厂方法模式所创建对象的超类型，也就是产品对象的公共父类。 ConcreteProduct（具体产品）：它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，具体工厂和具体产品之间一一对应。 Factory（抽象工厂）：在抽象工厂类中，声明了工厂方法(Factory Method)，用于返回一个产品。抽象工厂是工厂方法模式的核心，所有创建对象的工厂类都必须实现该接口。 ConcreteFactory（具体工厂）：它是抽象工厂类的子类，实现了抽象工厂中定义的工厂方法，并可由客户端调用，返回一个具体产品类的实例。 与简单工厂模式相比, 工厂方法模式最重要的区别是引入了抽象工厂角色，抽象工厂可以是接口，也可以是抽象类，其典型代码如下所示： 123interface Factory &#123; public Product factoryMethod(); &#125; 在抽象工厂中声明了工厂方法, 具体产品对象的创建由其子类负责, 客户端针对抽象工厂编程, 可在运行时再指定具体工厂类, 具体工厂类实现了工厂方法, 不同的具体工厂可以创建不同的具体产品，其典型代码如下所示： 12345678class ConcreteFactory implements Factory &#123; public function factoryMethod() &#123; // 在实际使用时，具体工厂类在实现工厂方法时, 除了创建具体产品对象之外， // 还可以负责产品对象的初始化工作以及一些资源和环境配置工作，例如连接数据库、创建文件等。 return new ConcreteProduct(); &#125; &#125; 在客户端代码中，只需关心工厂类即可，**不同的具体工厂可以创建不同的产品**，典型的客户端类代码片段如下所示： 1234Factory factory; factory = new ConcreteFactory(); //可通过配置文件来实现 (通过配置来决定你要具体使用哪个具体的工厂类) Product product; product = factory-&gt;factoryMethod(); 可以通过配置文件来存储具体工厂类ConcreteFactory的类名，更换新的具体工厂时无须修改源代码，系统扩展更为方便。 工厂方法模式中的工厂方法能否为静态方法？为什么？ 貌似不太可以, 因为静态方法是类的, 不是对象的! 完整实现参考 http://blog.csdn.net/lovelion/article/details/9307137 隐藏工厂方法是参考 http://blog.csdn.net/lovelion/article/details/9307561 工厂方法模式是简单工厂模式的延伸, 它继承了简单工厂模式的优点, 同时还弥补了简单工厂模式的不足。工厂方法模式是使用频率最高的设计模式之一, 是很多开源框架和API类库的核心模式。 主要优点 在工厂方法模式中，具体的工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的具体工厂类是哪个，无须关心创建细节，甚至无须知道具体产品类的类名; 基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够让工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，就正是因为所有的具体工厂类都具有同一抽象父类; 使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，而只要添加一个具体工厂和具体产品就可以了，这样，系统的可扩展性也就变得非常好，完全符合“开闭原则”。 主要缺点 在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要运行，会给系统带来一些额外的开销; 由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到反射等技术，增加了系统的实现难度。 参考参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - Simple Factory","slug":"2016-06-04-OOP-Factory","date":"2016-06-04T13:11:30.000Z","updated":"2018-01-17T03:33:36.000Z","comments":true,"path":"2016/06/04/2016-06-04-OOP-Factory/","link":"","permalink":"http://blog.renyimin.com/2016/06/04/2016-06-04-OOP-Factory/","excerpt":"","text":"工厂模式是最常用的一类创建型设计模式, 通常所说的工厂模式是指工厂方法模式, 它也是使用频率最高的工厂模式。简单工厂模式是工厂方法模式的”小弟”, 它不属于 GoF23种设计模式, 但在软件开发中应用也较为频繁, 通常将它作为学习其他工厂模式的入门。此外，工厂方法模式还有一位”大哥” —— 抽象工厂模式。这三种工厂模式各具特色, 难度也逐个加大, 在软件开发中它们都得到了广泛的应用, 成为面向对象软件中常用的创建对象的工具。 前言 假设公司开发的CRM系统可以显示饼状图的效果, 原始设计方案如下图: 123456789101112131415161718192021222324class Client&#123; public $chartObject = null; public function __construct($type) &#123; switch ($chartType) &#123; case 'pie' : $this-&gt;chartObject = new PieChart(); break; case 'bar' : $this-&gt;chartObject = new BarChart(); break; default: //TODO break; &#125; &#125; public function show() &#123; $this-&gt;chartObject-&gt;display(); &#125;&#125; 客户端代码通过调用 ‘Client类’ 的构造函数来创建图表对象，根据参数 ‘type’ 可以得到不同类型的图表，然后再调用show()方法来显示相应的图表。 传统设计存在问题不难看出，Client类是一个 “巨大的” 类, 在该类的设计中存在如下几个问题: Client类中包含很多 “if…else…” / “switch…case…”代码块，整个类的代码相当冗长, 阅读难度、维护难度和测试难度也越大, 而且大量条件语句的存在还将影响系统的性能，程序在执行过程中需要做大量的条件判断; Client类的职责过重, 它将各种图表对象的创建和使用集中在一个类中实现, 违反了“单一职责原则”, 不利于类的重用和维护; 当需要增加新类型的图表时，必须修改Client类的源代码，违反了’开闭原则’; 客户端只能通过new关键字来直接创建图像对象, 图像类与客户端Client类耦合度较高 (比如一旦类的名字发生变更, 你也必须修改Client代码的源代码); 客户端在创建Chart对象之前可能还需要进行大量初始化设置, 例如设置柱状图的颜色、高度等, 如果在Client类的构造函数中没有提供一个默认设置, 那就只能由客户端来完成初始设置，这些代码在每次创建图像对象时都会出现, 导致代码的重复。 面对一个如此巨大、职责如此重，且与客户端代码耦合度非常高的类，我们应该怎么办？接下来介绍的 简单工厂模式 将在 一定程度上 解决上述问题。 简单工厂模式 为了将图像对象的创建和使用分离, 使用简单工厂模式对图表库进行重构, 重构后的结构如下图所示： 在图中, Chart接口充当抽象产品类, 其子类PieChart和BarChart充当具体产品类, ChartFactory充当工厂类。 现在, 我们使用工厂类的 静态工厂方法 来创建产品对象, 如果需要更换产品, 虽然也需要更改Client源码, 但是只需修改传递给静态工厂方法中的参数即可, 例如将柱状图改为饼状图, 只需将代码 $chartObject = ChartFactory::getChart(&quot;bar&quot;); 改为：$chartObject = ChartFactory::getChart(&quot;pie&quot;); 改进 现在你会发现: 在创建具体图像对象时, 每更换一个图像对象, 都需要修改客户端代码中静态工厂方法的参数(虽然修改都很小), 这对于客户端而言, 还是违反了“开闭原则”; 有没有一种方法能够在不修改客户端代码的前提下更换具体产品对象呢？答案是肯定的，下面将介绍一种常用的实现方式: 可以将静态工厂方法的参数放到配置文件中, 在配置文件中配置即可, 这样客户端代码如下所示：由$chartObject = ChartFactory::getChart(&quot;bar&quot;);改为：$type = Config::get('chartType'); $chartObject = ChartFactory::getChart(\"pie\"); 简单工厂模式总结 简单工厂模式提供了专门的工厂类用于创建对象, 将对象的创建和对象的使用分离开, 它作为一种最简单的工厂模式在软件开发中得到了较为广泛的应用; 主要优点 工厂类包含必要的判断逻辑, 可以决定在什么时候创建哪一个产品类的实例, 客户端可以免除直接创建产品对象的职责, 而仅仅“消费”产品, 简单工厂模式实现了对象创建和使用的分离; 客户端无须知道所创建的具体产品类的类名，只需要知道创建具体产品类所需要对应的参数即可, 对于一些复杂的类名, 通过简单工厂模式可以在一定程度减少使用者的记忆量; 通过引入配置文件, 可以在不修改任何客户端代码的情况下更换和增加新的具体产品类, 在一定程度上提高了系统的灵活性, 做到了 一定程度的”开放-封闭原则”, 下面会看到其实工厂类部分还是违反的。 主要缺点 由于工厂类集中了所有产品的创建逻辑, 职责过重, 一旦不能正常工作, 整个系统都要受到影响; 使用简单工厂模式势, 势必会增加系统中类的个数(引入了新的工厂类), 增加了系统的复杂度和理解难度; 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑, 在产品类型较多时, 有可能造成工厂逻辑过于复杂, 不利于系统的扩展和维护。(此处还是违反“开放-封闭原则”) 简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。 适用场景, 在以下情况下可以考虑使用简单工厂模式: 工厂类负责创建的对象比较少, 由于创建的对象较少, 不会造成工厂方法中的业务逻辑太过复杂。 客户端只知道传入工厂类的参数, 对于如何创建对象并不关心。 总之, 仍未完全做到 “开放-封闭原则” 参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - 为什么要引入工厂类?","slug":"2016-06-03-OOP-Why-Factory","date":"2016-06-03T05:10:39.000Z","updated":"2018-01-17T03:33:56.000Z","comments":true,"path":"2016/06/03/2016-06-03-OOP-Why-Factory/","link":"","permalink":"http://blog.renyimin.com/2016/06/03/2016-06-03-OOP-Why-Factory/","excerpt":"","text":"前言工厂模式(包括简单工厂模式、工厂方法模式 和 抽象工厂模式 )到底有什么用? 很多时候通过反射机制就可以很灵活地创建对象, 为毛还要工厂？ 首先要知道, 与一个对象相关的职责通常有三类: 对象本身所具有的职责 创建对象的职责 使用对象的职责 对象本身的职责比较容易理解, 就是对象自身所具有的一些数据和行为, 可通过一些公开的方法来实现它的职责。 接下来将简单讨论一下对象的创建职责 和 使用职责 对象的 创建职责 和 使用职责 通常有以下几种创建对象的方式： 使用new关键字直接创建对象; 通过反射机制创建对象; 通过clone()方法创建对象； 通过工厂类创建对象; 在客户端代码中直接使用new关键字是最简单的一种创建对象的方式，但是它的灵活性较差，下面通过一个简单的示例来加以说明 假设公司开发的CRM系统可以显示饼状图的效果, 原始设计方案如下图: 1234567891011121314151617181920212223242526272829303132&lt;?php class PieChart &#123; public function display() &#123; echo 'piechart', '&lt;br/&gt;'; &#125; &#125; class BarChart &#123; public function display() &#123; echo 'barchart', '&lt;br/&gt;'; &#125; &#125; //Client class Client &#123; public $chartObject = null; public function __construct() &#123; $this-&gt;chartObject = new PieChart(); &#125; public function show() &#123; $this-&gt;chartObject-&gt;display(); &#125; &#125; 在’client’类的构造函数中创建了’PieChart’类型的对象，并在’show’方法中调用了’chartObject’对象的’display()’方法, 这段代码看上去并没有什么问题; 下面我们来分析一下’Client’和’PieChart’之间的关系: ‘Client’类负责创建了一个’PieChart’类的对象, 并使用其方法’display()’来完成相应的业务处理; 也就是说’Client’即负责对象的创建, 又负责对象的使用, 创建对象和使用对象的职责耦合在一起; 同时, 这样的设计会导致一个很严重的问题: 如果在 ‘Client’ 中希望能够使用另一个种类型的图像方案, 比如使用柱状图’BarChart’类的对象，那就必须修改’Client’类的源代码, 违反了”开闭原则”。 如何解决? 引出工厂类最常用的一种解决方法是将 ‘chartObject’ 对象的创建职责从 ‘Client’ 类中移除, 在 ‘Client’ 类之外创建对象, 那么谁来负责创建 ‘chartObject’ 对象呢?答案是：工厂类; 通过引入工厂类, 客户类就不会再涉及对象的创建(只是对对象进行使用), 而创建对象的工厂类自然也只是负责创建对象(也不会涉及对象的使用)。引入工厂类 ChartFactory 之后的结构如下图所示: 工厂类的引入将降低维护工作量： 如果图像类的构造函数发生变更, 或者需要添加或移除不同的图像类，你只要去维护 ChartFactory 的代码, 可能就不会影响到’Client’的代码; 而且如果 Chart 抽象接口发生改变, 例如添加、移除方法或改变方法名, 只需要修改 Client, 不会给 ChartFactory 带来任何影响; 在所有的工厂模式中, 我们都强调一点: 两个类A和B之间的关系应该仅仅是 A创建B 或是 A使用B, 而不能两种关系都有。将对象的创建和使用分离, 也使得系统更加符合 ‘单一职责原则’, 有利于对功能的复用和系统的维护; 此外, 将对象的创建和使用分离还有一个好处: 防止用来实例化一个类的代码在多个类中到处都是, 可以将有关创建的代码搬移到一个工厂类中。因为有时候我们创建一个对象不只是简单调用其构造函数, 还需要设置一些参数, 可能还需要配置环境,如果将这些代码散落在每一个创建对象的客户类中, 势必会出现代码重复、创建蔓延的问题, 而这些客户类其实无须承担对象的创建工作,它们只需使用已创建好的对象就可以了。此时, 可以引入工厂类来封装对象的创建逻辑和客户代码的实例化/配置选项。 参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - Singleton-02","slug":"2016-05-27-OOP-Singleton","date":"2016-05-27T12:07:13.000Z","updated":"2018-01-17T03:33:24.000Z","comments":true,"path":"2016/05/27/2016-05-27-OOP-Singleton/","link":"","permalink":"http://blog.renyimin.com/2016/05/27/2016-05-27-OOP-Singleton/","excerpt":"","text":"前言之前已经对单例模式有了比较简单的认识接下来通过一些资料在系统了解一下单例模式; 单例模式动机 对于一个软件系统的某些类而言, 我们无须创建多个实例。 举个大家都熟知的例子 —— Windows任务管理器, 当你在Windows的”任务栏”的右键弹出菜单上多次点击”启动任务管理器”。通常情况下，无论我们启动任务管理多少次，Windows系统始终只能弹出一个任务管理器窗口，也就是说在一个Windows系统中，任务管理器存在唯一性。为什么要这样设计呢？我们可以从以下两个方面来分析：其一，如果能弹出多个窗口，且这些窗口的内容完全一致，全部是重复对象，这势必会浪费系统资源，任务管理器需要获取系统运行时的诸多信息，这些信息的获取需要消耗一定的系统资源，包括CPU资源及内存资源等，浪费是可耻的，而且根本没有必要显示多个内容完全相同的窗口;其二，如果弹出的多个窗口内容不一致，问题就更加严重了，这意味着在某一瞬间系统资源使用情况和进程、服务等信息存在多个状态，例如任务管理器窗口A显示“CPU使用率”为10%，窗口B显示“CPU使用率”为15%，到底哪个才是真实的呢？这纯属”调戏”用户，给用户带来误解，更不可取。由此可见，确保Windows任务管理器在系统中有且仅有一个非常重要。 回到实际开发中, 我们也经常遇到类似的情况, 为了节约系统资源, 有时需要确保系统中某个类只有唯一一个实例, 当这个唯一实例创建成功之后, 我们无法再创建一个同类型的其他对象, 所有的操作都只能基于这个唯一实例。 为了确保对象的唯一性, 我们可以通过单例模式来实现, 这就是单例模式的动机所在。 参考一个负载均衡器的例子 Sunny软件公司承接了一个服务器负载均衡(Load Balance)软件的开发工作，该软件运行在一台负载均衡服务器上，可以将并发访问和数据流量分发到服务器集群中的多台设备上进行并发处理，提高系统的整体处理能力，缩短响应时间。由于集群中的服务器需要动态删减，且客户端请求需要统一分发，因此需要确保负载均衡器的唯一性，只能有一个负载均衡器来负责服务器的管理和请求的分发，否则将会带来服务器状态的不一致以及请求分配冲突等问题。如何确保负载均衡器的唯一性是该软件成功的关键。 Sunny公司开发人员通过分析和权衡，决定使用单例模式来设计该负载均衡器, 将负载均衡器LoadBalancer设计为单例类, 其中包含一个存储服务器信息的集合serverList, 每次在serverList中随机选择一台服务器来响应客户端的请求,实现代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?phpclass LoadBalancer&#123; private static $instance = null; private $serverList = array(); private function __construct() &#123; &#125; private function __clone() &#123; &#125; public static function getInstance() &#123; if (null === self::$instance) &#123; self::$instance = new self(); &#125; return self::$instance; &#125; /** * 增加一台服务器 */ public function addServer($server) &#123; $this-&gt;serverList[] = $server; &#125; /** * 减少一台宕机的服务器 */ public function removeServer($key) &#123; unset($this-&gt;serverList[$key]); &#125; /** * 随机获取一台服务器 */ public function getServer() &#123; $random = mt_rand(0, count($this-&gt;serverList)-1); return $this-&gt;serverList[$random]; &#125;&#125;echo '&lt;pre/&gt;';$loadBalancer1 = LoadBalancer::getInstance();$loadBalancer2 = LoadBalancer::getInstance();var_dump($loadBalancer1 === $loadBalancer2);$loadBalancer1-&gt;addServer(\"Server 1\");$loadBalancer1-&gt;addServer(\"Server 2\");$loadBalancer2-&gt;addServer(\"Server 3\");$loadBalancer2-&gt;addServer(\"Server 4\");//模拟客户端请求的分发for ($i=0; $i&lt;10; $i++) &#123; $server = $loadBalancer1-&gt;getServer(); var_dump(\"分发请求至服务器： \" . $server);&#125; 结果: 1234567891011bool(true)string(36) \"分发请求至服务器： Server 1\"string(36) \"分发请求至服务器： Server 3\"string(36) \"分发请求至服务器： Server 4\"string(36) \"分发请求至服务器： Server 3\"string(36) \"分发请求至服务器： Server 3\"string(36) \"分发请求至服务器： Server 3\"string(36) \"分发请求至服务器： Server 3\"string(36) \"分发请求至服务器： Server 3\"string(36) \"分发请求至服务器： Server 1\"string(36) \"分发请求至服务器： Server 4\" 虽然创建了四个LoadBalancer对象，但是它们实际上是同一个对象，因此，通过使用单例模式可以确保LoadBalancer对象的唯一性。 饿汉式单例与懒汉式单例的讨论涉及到多线程未完待续… 参考参考","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOP - Singleton-01","slug":"2016-05-26-OOP-Singleton","date":"2016-05-26T10:21:28.000Z","updated":"2018-01-16T06:15:39.000Z","comments":true,"path":"2016/05/26/2016-05-26-OOP-Singleton/","link":"","permalink":"http://blog.renyimin.com/2016/05/26/2016-05-26-OOP-Singleton/","excerpt":"","text":"常见场景举例 框架底层的 数据库模型层 就可以使用单例 ThinkPHP3.2中, 虽然 数据库模型层 使用了单例模式, 但并非传统意义上所谓 三公一私 的单例: 1234567891011121314TP3.2创建数据库模型实例的过程大概为: Think\\Model -&gt; Think\\Db -&gt; Think\\Db\\Driver\\Mysql -&gt; Think\\Db\\DriverD()/M() 方法都可以调用 Think\\Model 这个模型类虽然 Think\\Model 层并未做到单例, 即 new Model(...) 实例出的对象为非单例, 但其通过调用下层 Think\\Db 的 getInstance(), 然后简单结合一个 数据库对象池$_db(注册树模式) 来保证底层各不同数据库对象的单例性; Think\\Db 的 getInstance() 通过 数据库连接池$instance 保证了下层 Think\\Db\\Driver\\Mysql 数据库连接实例的单例性而 Think\\Db 其内部与底层沟通的方法全是static型, 用户在顶层控制器中直接new也没意义只有在顶层控制器直接 new `Think\\Db\\Driver\\Mysql` 你会获得不同的数据库连接实例, 但一般也不会直接new底层!最下层 Think\\Db\\Driver 为抽象层 所以实现单例未必需要严格按照传统的规则来, 有很多变体都可以保证实现单例; 日志类TP3中的Log类比较简单, 作为基础类, 直接各方法为静态, 很简单就做到了要想使用, 就必然是单例, 基本上你new也没什么用!…未完待续 项目的配置类…未完待续 优点 提供了对唯一实例的受控访问 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象单例模式无疑可以提高系统的性能缺点 PHP语言是一种解释型的脚本语言, 这种运行机制使得每个PHP页面被解释执行后, 所有的相关资源都会被回收。 在PHP中, 所有的变量无论是全局变量还是类的静态成员, 都是页面级的, 每次页面被执行时, 都会重新建立新的对象, 所以PHP单例模式貌似只是针对单次页面级请求时出现多个应用场景并需要共享同一对象资源时是有意义的; 几个基本注意事项 通常我们都是遵循正常的”三私一公”来写单例, 但是可以看到如下代码会因为序列化,反序列化而导致单例出问题 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpclass Singleton&#123; private static $instance = null; private function __construct() &#123; &#125; private function __clone() &#123; &#125; public static function getInstance() &#123; if (null === self::$instance) self::$instance = new self(); return self::$instance; &#125;&#125;echo &apos;&lt;pre/&gt;&apos;;$test_1 = Singleton::getInstance();$test_2 = Singleton::getInstance();var_dump($test_1); //实例1var_dump($test_2); //实例1var_dump($test_1 === $test_2); // trueecho &apos;unserialize, serialize:---------------------------&lt;br/&gt;&apos;;$test_1 = unserialize(serialize($test_1));var_dump($test_1); //实例2var_dump(Singleton::getInstance()); //实例1var_dump( Singleton::getInstance() === $test_1); //falseecho &apos;unserialize, serialize:---------------------------&lt;br/&gt;&apos;;$test_3 = Singleton::getInstance();var_dump($test_3); //实例1$test_3 = unserialize(serialize($test_3));var_dump($test_3); //实例3var_dump(Singleton::getInstance()); //实例1var_dump( Singleton::getInstance() === $test_3); //false 鸟哥博文其实并不能完全解决, 看下面例子: 虽然每次反序列化后的所有实例都一致, 但是一旦碰到再次反序列化, 还是会出问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?phpclass Singleton&#123; private static $instance = null; private function __construct() &#123; &#125; private function __clone() &#123; &#125; public function __wakeup() &#123; self::$instance = $this; &#125; public static function getInstance() &#123; if (null === self::$instance) self::$instance = new self(); return self::$instance; &#125; public function __destruct() &#123; &#125;&#125;echo '&lt;pre/&gt;';$test_1 = Singleton::getInstance(); $test_2 = Singleton::getInstance(); var_dump($test_1); //实例1var_dump($test_2); //实例1var_dump($test_1 === $test_2); //trueecho 'unserialize, serialize:---------------------------&lt;br/&gt;';$test_1 = unserialize(serialize($test_1));var_dump($test_1); //实例2var_dump(Singleton::getInstance()); //实例2var_dump( Singleton::getInstance() === $test_1); //trueecho 'unserialize, serialize:---------------------------&lt;br/&gt;';$test_3 = Singleton::getInstance();var_dump($test_3); //实例2$test_3 = unserialize(serialize($test_3));var_dump($test_3); //实例3var_dump(Singleton::getInstance()); //实例3var_dump( Singleton::getInstance() === $test_3); //true 可以看到还是出现了多个不同的实例!!! 博文中有个评论比较有意思, 可以看一下: 另外, 单例模式出现继承关系时, 需要注意PHP的 self 和 static 关键字的区别 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?phpclass Singleton&#123; protected static $instance = null; protected function __construct() &#123; &#125; protected function __clone() &#123; &#125; protected function __wakeup() &#123; static::$instance = $this; &#125; public static function getInstance() &#123; if (null === static::$instance) static::$instance = new static(); return static::$instance; &#125;&#125;echo &apos;&lt;pre/&gt;&apos;;$test_1 = Singleton::getInstance();$test_2 = Singleton::getInstance();var_dump($test_1);var_dump($test_2);var_dump($test_1 === $test_2);class Log extends Singleton&#123; // 注意: 每个继承单例的子类, 必须要做清空, 否则所有的实例都是上面的实例结果 protected static $instance = null; public function write() &#123; echo &apos;success write something&apos;; &#125;&#125;class Model extends Singleton&#123; // 注意: 每个继承单例的子类, 必须要做清空, 否则所有的实例都是上面的实例结果 protected static $instance = null; public function select() &#123; echo &apos;success select something&apos;; &#125;&#125;$log_1 = Log::getInstance();$log_2 = Log::getInstance();var_dump($log_1);var_dump($log_2);var_dump($log_1 === $log_2);$model_1 = Model::getInstance();$model_2 = Model::getInstance();var_dump($model_1);var_dump($model_2);var_dump($model_1 === $model_2);var_dump($model_1 === $test_2); // false","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"OOD-S.O.L.I.D","slug":"2016-05-23-OOP-SOLID","date":"2016-05-23T10:21:21.000Z","updated":"2018-01-17T03:32:53.000Z","comments":true,"path":"2016/05/23/2016-05-23-OOP-SOLID/","link":"","permalink":"http://blog.renyimin.com/2016/05/23/2016-05-23-OOP-SOLID/","excerpt":"","text":"The Single Responsibility Principle（单一职责原则 SRP）高内聚, 低耦合 单一职责原则是最简单的面向对象设计原则，它用于控制类的粒度大小。 单一职责原则定义为: 一个类或者模块应该有且只有一个被改变的原因。 如果一个类承担的职责过多, 就等于把这些职责 耦合 在一起了。 一个职责的变化可能会影响其他的职责, 这种耦合会导致脆弱的设计, 当发生变化时, 设计会遭受到意想不到的破坏。 而如果想要避免这种现象的发生, 就要尽可能的遵守单一职责原则。此原则的核心就是解耦和增强内聚性。 单一职责原则告诉我们: 一个类不能太“累”！在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即,将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则也可考虑将它们封装在同一类中。 遵循单一职责原的优点有: 可以降低类的复杂度, 一个类只负责一项职责, 其逻辑肯定要比负责多项职责简单的多; 提高类的可读性, 提高系统的可维护性; 变更引起的风险降低, 变更是必然的, 如果单一职责原则遵守的好, 当修改一个功能时, 可以显著降低对其他功能的影响; 需要说明的一点是单一职责原则不只是面向对象编程思想所特有的, 只要是模块化的程序设计, 都适用单一职责原则; 参考: http://blog.csdn.net/lovelion/article/details/7536542 The Open/Closed Principle（开放封闭原则OCP）对抽象编程, 而不对具体编程 开放-封闭原则: 一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 任何软件都需要面临一个很重要的问题, 即, 它们的需求会随时间的推移而发生变化。当软件系统需要面对新的需求时，我们应该尽量保证系统的设计框架是稳定的。如果一个软件设计符合开闭原则，那么可以非常方便地对系统进行扩展，而且在扩展时无须修改现有代码，使得软件系统在拥有适应性和灵活性的同时具备较好的稳定性和延续性。随着软件规模越来越大，软件寿命越来越长，软件维护成本越来越高，设计满足开闭原则的软件系统也变得越来越重要。 为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。在Java、C#等编程语言中，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。在很多面向对象编程语言中都提供了接口、抽象类等机制，可以通过它们定义系统的抽象层，再通过具体类来进行扩展。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。 有必要用例子来简单说明一下, 假设公司开发的CRM系统可以显示各种类型的图表, 如 饼状图 和 柱状图 等, 为了支持多种图表显示方式, 原始设计方案如下图: 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?phpclass PieChart&#123; public function display() &#123; echo 'piechart', '&lt;br/&gt;'; &#125;&#125;class BarChart&#123; public function display() &#123; echo 'barchart', '&lt;br/&gt;'; &#125;&#125;class ChartDisplay&#123; public $chartObject = null; public function __construct() &#123; //TODO &#125; public function display($chartType) &#123; switch ($chartType) &#123; case 'pie' : $piechart = new PieChart(); $piechart-&gt;display(); break; case 'bar' : $barchart = new BarChart(); $barchart-&gt;display(); break; default: //TODO break; &#125; &#125;&#125; 问题: 现在如果需要增加一个图表类, 如折线图LineChart, 则需要修改ChartDisplay类的display()方法的源代码, 增加新的判断逻辑, 违反了开闭原则!! 现对该系统进行重构, 使之符合开闭原则 我们引入了抽象图表类AbstractChart, 并且让ChartDisplay针对抽象图表类进行编程(依赖抽象), 在ChartDisplay的display()方法中调用chart对象的display()方法显示图表。 如果需要增加一种新的图表, 如折线图LineChart, 只需要将LineChart也作为AbstractChart的子类, 在客户端向ChartDisplay中注入一个LineChart对象即可, 无须修改现有类库的源代码。 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpabstract class AbstractChart&#123; protected function display() &#123; &#125;&#125;class PieChart extends AbstractChart&#123; public function display() &#123; echo 'piechart', '&lt;br/&gt;'; &#125;&#125;class BarChart extends AbstractChart&#123; public function display() &#123; echo 'barchart', '&lt;br/&gt;'; &#125;&#125;class ChartDisplay&#123; public function __construct() &#123; //TODO &#125; public function display(AbstractChart $chart) &#123; $chart-&gt;display(); &#125;&#125;$cd = new ChartDisplay();$cd-&gt;display(new PieChart());$cd-&gt;display(new BarChart()); 参考: http://blog.csdn.net/lovelion/article/details/7537584 The Liskov Substitution Principle（里氏替换原则LSP） 所有引用基类（父类）的地方必须能透明地使用其子类对象。 子类可以实现父类的抽象方法, 但是不能覆盖父类的非抽象方法, 也就是子类可以扩展父类的功能, 但是不能改变父类原有的功能; 当子类覆盖或实现父类的方法时, 方法的前置条件(即方法的形参)要比父类方法的输入参数更宽松。(PHP是弱类型语言) 当子类的方法实现父类的抽象方法时, 方法的后置条件(即方法的返回值)要比父类更严格。(PHP是弱类型语言)参考: http://blog.csdn.net/lovelion/article/details/7540445 貌似主要就是说, 如果依赖的类可能日后会有扩展的话, 你最好设计一个抽象父类或接口, 子类继承、实现父类; 里氏代换原则是实现开闭原则的重要方式之一, 由于使用基类对象的地方都可以使用子类对象, 因此在程序中尽量使用基类类型来对对象进行定义, 而在运行时再确定其子类类型, 用子类对象来替换父类对象。 The Interface Segregation Principle（接口分离原则ISP）该原则比较好理解 不要定义过于臃肿的接口, 接口中不要有很多不相关的逻辑方法(否则一定也违背单一职责原则); 过于臃肿的接口可能会强迫用户去实现接口内部用户并不需要的方法。换句话说, 使用 多个专门的接口 比使用 一个臃肿的总接口 要好很多; 如果你在类中实现了你不需要使用的接口方法, 估计也是重写为空方法, 这其实已经违背了接口分离原则。 也就是说，一个接口或者类应该拥有尽可能少的行为, 就是少到恰好能完成它自身的职责, 这也是保证 “软件系统模块的粒度尽可能少, 以达到高度可重用的目的”; 接口包含太多的方法会降低其可用性，像这种包含了无用方法的”胖接口”会增加类之间的耦合。 如果一个类想实现该接口,那么它需要实现所有的方法,尽管有些对它来说可能完全没用，所以这样做会在系统中引入不必要的复杂度, 降低代码的可维护性或鲁棒性。 接口分离原则确保实现的接口有它们共同的职责, 它们是明确的, 易理解的, 可复用的. The Dependency Inversion Principle（依赖反转原则DIP）要针对接口编程, 而不是针对实现编程 如果说开闭原则是面向对象设计的目标的话, 那么依赖倒转原则就是面向对象设计的主要实现机制之一, 它是系统抽象化的具体实现; 上层不用去定义自己要依赖哪个具体的类, 而是定义自己依赖哪个 抽象; 然后让底层代码根据上层的要求, 去实现相应的 抽象; 这样就变成了底层对上层的依赖, 底层代码需要去 实现 上层代码定义的抽象; 依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。 在实现依赖倒转原则时, 我们需要针对抽象层编程，将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和 接口注入。 构造注入是指通过构造函数来传入具体类的对象 设值注入是指通过Setter方法来传入具体类的对象 而接口注入是指通过在接口中声明的业务方法来传入具体类的对象这些方法在定义时使用的是抽象类型, 在运行时再传入具体类型的对象, 由子类对象来覆盖父类对象。 有必要用例子来简单说明一下 由于CustomerDAO针对具体数据转换类编程, 因此在增加新的数据转换类或者更换数据转换类时都不得不修改CustomerDAO的源代码。 我们可以通过引入抽象数据转换类解决该问题，在引入抽象数据转换类DataConvertor之后，CustomerDAO针对抽象类DataConvertor编程，符合依赖倒转原则。 根据里氏代换原则，程序运行时，具体的数据转换类对象 将替换DataConvertor类型的对象，程序不会出现任何问题。更换具体数据转换类时无须修改源代码，只需要说明你需要哪个具体的类(可以在配置文件中配置)。 如果需要增加新的具体数据转换类，只要将新增数据转换类作为DataConvertor的子类即可，原有代码无须做任何修改，满足开闭原则。 重构后的结构如图2所示： 在上述重构过程中, 我们使用了 开闭原则、里氏代换原则 和 依赖倒转原则 , 在大多数情况下, 这三个设计原则会同时出现, 开闭原则是目标, 里氏代换原则是基础, 依赖倒转原则是手段, 它们相辅相成, 相互补充, 目标一致, 只是分析问题时所站角度不同而已。参考: http://blog.csdn.net/lovelion/article/details/7562783 小结开闭原则是目标, 里氏代换原则 和 依赖倒转原则 都是为了实现开闭原则! 怪不得举的例子都那么相似~~ [参考](http://blog.csdn.net/lovelion/article/details/17517213）[参考](http://blog.51cto.com/haolloyin/category2.html）","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]}]}