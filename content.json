{"meta":{"title":"Lant's","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"03.","slug":"elastic-stack/2018-09-08-03","date":"2018-09-08T02:50:15.000Z","updated":"2018-09-08T02:50:38.000Z","comments":true,"path":"2018/09/08/elastic-stack/2018-09-08-03/","link":"","permalink":"http://blog.renyimin.com/2018/09/08/elastic-stack/2018-09-08-03/","excerpt":"","text":"","categories":[{"name":"Elastic-Stack","slug":"Elastic-Stack","permalink":"http://blog.renyimin.com/categories/Elastic-Stack/"}],"tags":[{"name":"Elastic-Stack","slug":"Elastic-Stack","permalink":"http://blog.renyimin.com/tags/Elastic-Stack/"}]},{"title":"02. 安装配置","slug":"elastic-stack/2018-09-08-02","date":"2018-09-08T02:46:43.000Z","updated":"2018-09-08T02:50:44.000Z","comments":true,"path":"2018/09/08/elastic-stack/2018-09-08-02/","link":"","permalink":"http://blog.renyimin.com/2018/09/08/elastic-stack/2018-09-08-02/","excerpt":"","text":"安装Elasticsearch安装Kibana安装Logstash安装Filebeat","categories":[{"name":"Elastic-Stack","slug":"Elastic-Stack","permalink":"http://blog.renyimin.com/categories/Elastic-Stack/"}],"tags":[{"name":"Elastic-Stack","slug":"Elastic-Stack","permalink":"http://blog.renyimin.com/tags/Elastic-Stack/"}]},{"title":"01. 从ELK Stack 到 Elastic Stack","slug":"elastic-stack/2018-09-04-01","date":"2018-09-04T09:36:39.000Z","updated":"2018-09-08T02:47:35.000Z","comments":true,"path":"2018/09/04/elastic-stack/2018-09-04-01/","link":"","permalink":"http://blog.renyimin.com/2018/09/04/elastic-stack/2018-09-04-01/","excerpt":"","text":"ELK Stack 简介ELK Stack 是三个开源工具的统称: Elasticsearch, Logstash 和 Kibana Logstash: 开源的日志收集工具, 能按你所定义的配置信息来规范化数据, 并根据需要将其他送到指定的目的地; (监听9600端口) 拥有非常多的Input输入数据类型的插件, 这些Input插件可以用于从大量不同来源的信息中读取数据; 同时, 它也拥有非常多的Output输出数据类型插件, 可用于把数据提交到各种不同的目的地(其中的一种插件就是把数据传输到Elasticsearch中去);比如, 它可以从本地磁盘, 网络服务(自己监听端口, 接受用户日志), 消息队列……中, 收集各种各样的日志; 然后对日志进行分析整理, 输出到指定的输出(如 elasticsearch、redis、终端等); 它能帮助我们搜集原始数据, 修改/过滤数据并将其转换成某种有含义的数据, 完成数据格式化和重新组织数据等; Elasticsearch: 基于Lucene的开源分布式全文搜索引擎; Elasticsearch 服务会开启两个端口 9200和9300, 9200是对外服务的 9300是对集群内交互使用的; Logstash读取的数据可输出到Elasticsearch中, 完成数据的索引; Kibana: 是一个开源的可视化日志web展示工具, 提供友好的日志分析 Web 界面, 帮助你汇总、分析和搜索重要数据日志 (监听 5601 端口); Kibana使用Elasticsearch提供的API来读取/检索存放在Elasticsearch中的索引数据, 并以图表等形式对这些数据进行可视化分析; Elastic Stack诞生 上面在介绍 ELK Stack 时提到, 所有读取数据的工作都是由 Logstash 来完成的, 但是这是一种资源消耗, 因为 Logstash 需要运行在Java虚拟机上, 会消耗大量内存; 因此, 软件研发社区认为需要提高其性能, 并使用管道(pipeline)处理机制 — 一种友好且轻量级的方式来处理资源; 因此, 一种新的概念 Beats 诞生, 并加入到了 ELK Stack 家族成为重要组件(Beats 是由 GO 语言编写的) Beats 用于读取、解析并将数据输出到 Elasticsearch 或 Logstash 中; 不同的是, 它是一种轻量级的, 服务于某种特殊用途的代理(它可以是Metricbeat/Filebeat/Packetbeat等), 它们都是由Elastic开发团队提供; Elastic Stack 的起始版本号是5.0.0, 其虽然是原 ELK Stack 在 5.0 版本加入 Beats 套件后的新称呼, 但其实涵盖的内容还不止这些; 在产生数据管道的作用中, 所有组件都发挥了重要作用: Beats 和 Logstash 用于搜索, 解析, 传输数据; Elasticsearch 负责对数据的索引; Elasticsearch 索引的数据, 最后会被 Kibana 用于数据的可视化; 在基于 Elastic Stack 的数据处理管道中, 还有诸如 安全, 监控, 报警 等方面需要特别关注, 这些工具组件现在统称为 X-Pack 参考:《精通Elastic Stack》","categories":[{"name":"Elastic-Stack","slug":"Elastic-Stack","permalink":"http://blog.renyimin.com/categories/Elastic-Stack/"}],"tags":[{"name":"Elastic-Stack","slug":"Elastic-Stack","permalink":"http://blog.renyimin.com/tags/Elastic-Stack/"}]},{"title":"04. 过滤","slug":"elasticsearch/2018-06-16-04","date":"2018-06-16T09:36:51.000Z","updated":"2018-09-17T09:02:00.000Z","comments":true,"path":"2018/06/16/elasticsearch/2018-06-16-04/","link":"","permalink":"http://blog.renyimin.com/2018/06/16/elasticsearch/2018-06-16-04/","excerpt":"","text":"同样的筛选条件, 结果是不同的评分 不用过滤 使用过滤, 发现不会对评分有帮助","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/tags/Elasticsearch/"}]},{"title":"03. 集群相关 (节点, 分片及角色, 扩容, 故障测试)","slug":"elasticsearch/2018-06-10-03","date":"2018-06-10T06:26:39.000Z","updated":"2018-09-19T06:38:48.000Z","comments":true,"path":"2018/06/10/elasticsearch/2018-06-10-03/","link":"","permalink":"http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-03/","excerpt":"","text":"前言 ElasticSearch 的主旨是随时可用和按需扩容, 这里主要是说 水平(横向)扩容 — 为集群添加更多的节点将负载压力分散到这些节点中; ElastiSearch 天生就是分布式的, 它知道如何通过管理多节点来提高扩容性和可用性; 接下来将讲述如何按需配置集群、节点和分片, 并在硬件故障时确保数据安全 节点 及其 角色 节点: 一个运行中的 Elasticsearch 实例就称为一个节点; 默认情况下, es 集群中每个节点都有成为主节点的资格, 也都存储数据, 还可以提供查询服务, 这些功能是由两个属性控制的 node.master: 这个属性表示节点是否具有成为主节点的资格 (注意: 此属性的值为true, 并不意味着这个节点就是主节点; 真正的主节点, 是由多个具有主节点资格的节点进行选举产生的; 所以, 这个属性只是代表这个节点是不是具有主节点选举资格) node.data: 这个属性表示节点是否存储数据; 上面两个配置属性可以有四种组合: 节点只有成为主节点的资格(有可能成为真正的主节点), 但不会存储数据; 称为master节点 12node.master: truenode.data: false 节点没有成为主节点的资格, 即, 不参与选举, 只会存储数据; 称为data(数据)节点在集群中需要单独设置几个这样的节点负责存储数据, 后期提供存储和查询服务 12node.master: falsenode.data: true 节点既不会成为主节点, 也不会存储数据 (也叫协调节点/路由节点)这个节点的意义是作为一个client(客户端)节点, 主要是针对海量请求的时候可以进行负载均衡 12node.master: falsenode.data: false 既有成为主节点的资格, 又存储数据:如果这个节点被选举成了真正的主节点, 那么它除了干主节点要干的活, 还要存储数据, 这样对于这个节点的压力就比较大;elasticsearch 默认每个节点都是这样的配置, 在测试环境下这样做没问题, 但是实际工作中建议不要这样设置; 因为这样相当于 主节点 和 数据节点 的角色混合到一块了; 12node.master: falsenode.data: true 默认情况下, 每个节点都有成为主节点的资格, 也会存储数据, 还会处理客户端的请求; 根据前面节点及其角色的介绍, 如果尝试配置唯一的节点为 node.master: true node.data: false, 则节点中的所有分片都会是未分配状态 如果配置为 node.master: false node.data: false, 貌似无法启动 在生产集群中我们可以对这些节点的职责进行划分 建议集群中设置3台以上的节点作为master节点 node.master: true node.data: false, 这些节点只负责成为主节点, 维护整个集群的状态; 再根据数据量设置一批data节点 node.master: false node.data: true, 这些节点只负责存储数据, 后期提供建立索引和查询索引的服务, 这样的话如果用户请求比较频繁, 这些节点的压力也会比较大; 所以在集群中建议再设置一批client节点 node.master: false node.data: false, 这些节点只负责处理用户请求, 实现请求转发, 负载均衡等功能;master节点: 普通服务器即可(CPU 内存 消耗一般)data节点: 主要消耗磁盘, 内存client节点: 普通服务器即可(如果要进行分组聚合操作的话, 建议这个节点内存也分配多一点) 集群 集群是由一个或者多个拥有相同 cluster.name 配置项的节点组成, 这些节点共同承担数据和负载的压力; 当有节点加入集群中或者从集群中移除节点时, 集群将会重新平均分布所有的数据; 当一个节点被选举成为 主节点 时, 它将负责管理集群范围内的所有变更, 例如增加、删除索引, 或者增加、删除节点等; 不过, 纯粹的主节点并不需要涉及到文档级别的变更和搜索等操作, 所以, 集群所拥有的唯一一个主节点, 如果是纯粹的主节点的话, 即使流量的增加它也不会成为瓶颈; 任何节点都可以成为主节点, 到目前为止, 我们之前的示例集群就只有一个节点, 当然, 它同时也是主节点; 作为用户, 我们可以将请求发送到集群中的任何节点, 包括主节点; 每个节点都知道任意文档所处的位置, 并且能够将我们的请求直接转发到存储我们所需文档的节点, 无论我们将请求发送到哪个节点, 它都能负责从各个包含我们所需文档的节点收集回数据, 并将最终结果返回給客户端, Elasticsearch 对这一切的管理都是透明的。 集群健康, 可以通过 GET /_cluster/health 来查看, 对于返回结果, 最需要关心的是 status 字段, 它指示着当前集群在总体上是否工作正常, 它的三种颜色含义如下: green 所有的主分片和副本分片都正常运行 yellow 所有的主分片都正常运行, 但不是所有的副本分片都正常运行 red 有主分片没能正常运行 分片 我们往 Elasticsearch 添加数据时需要用到 索引(保存相关数据的地方), 而索引实际上是指向一个或者多个物理分片的逻辑命名空间; 分片: 一个分片是一个 Lucene 的实例, 它是一个底层的工作单元, 其本身就是一个完整的搜索引擎; 但是, 它可能仅保存了全部文档中的一部分; Elasticsearch 是利用分片将数据分发到集群内各处的, 分片是数据的容器, 文档保存在分片内, 分片又被分配到集群内的各个节点里; 当你的集群规模扩大或者缩小时(即增加或减少节点时), Elasticsearch 会自动的在各节点中迁移分片, 使得数据仍然均匀分布在集群里。 分片有两种类型: 主分片, 副本分片 索引内任意一个文档都归属于一个主分片, 所以主分片的数目决定着索引能够保存的最大数据量; 而副本分片只是一个主分片的拷贝, 副本分片作为硬件故障时保护数据不丢失的冗余备份, 并为搜索和返回文档等读操作提供服务; 注意: 在索引建立的时候就确定了主分片数,之后无法随意修改;而副本分片数可以随时修改; 每个索引在默认情况下会被分配5个主分片, 不过你也可以在创建索引前, 先指定索引的 主分片数 和 每个主分片对应的副本分片数, 如下, 给 blogs 索引分配3个主分片 和 每个主分片分配1个副本: 1234567PUT /blogs&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 &#125;&#125; 不过, 由于当前只有一个节点, 所以集群的健康状况为 yellow , 表示全部主分片都正常运行(集群可以正常服务所有请求), 但是副本分片没有全部处在正常状态; 实际上, 所有3个副本分片都是 unassigned —— 它们都没有被分配到任何节点, 因为当前只有一个节点, 而在同一个节点上既保存原始数据又保存副本是没有意义的; 当前这种状况, 一旦失去了唯一的节点, 也就会丢失该节点上的所有副本数据; 当前我们的集群是正常运行的, 但是在唯一的结点出现硬件故障时有丢失数据的风险; 故障转移 添加故障转移: 当集群中只有一个节点在运行时, 意味着会有一个单点故障问题 —— 没有冗余; 幸运的是, 在ES中, 我们只需再启动一个节点即可防止数据丢失; 启动第二个节点非常简单, 你可以在同一个目录内, 完全依照启动第一个节点的方式来启动一个新节点(多个节点可以共享同一个目); 只要它和第一个节点有同样的 cluster.name 配置, 它就会自动发现集群并加入到其中; 但是注意: 在不同一机器上启动节点的时候, 为了加入到同一集群, 你需要配置一个可连接到的单播主机列表 单播, 组播 单播: Elasticsearch 默认被配置为使用单播发现, 以防止节点无意中加入集群, 只有在同一台机器上运行的节点才会自动组成集群;除了同一台机器上的集群会自动发现同名节点, 使用单播, 你还可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表, 当一个节点可以联系到单播列表中的成员(节点)时, 它就会得到整个集群所有节点的状态, 然后它会联系 master 节点, 并加入集群;这意味着你的单播列表不需要包含你的集群中的所有节点, 它只是需要足够的节点, 当一个新节点联系上其中一个并且说上话就可以了;如果你使用 master 候选节点作为单播列表, 你只要列出三个就可以了, 这个配置在 elasticsearch.yml 文件中: discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;] 组播: 组播貌似仍然是作为插件提供, 并且它应该永远不要在生产环境使用, 否则可能会出现一个节点意外的加入到了你的生产环境集群中;虽然组播 本身 并没有错, 但一不小心就会导致一些愚蠢的问题, 并且导致集群变的脆弱; 最好使用单播代替组播 继续上面的第6点, 由于目前是在同一台机器上启动第二个节点, 所以不同配置单播列表, 直接启动一个节点即可; 当启动第二个节点后, 由于其使用的是和第一个节点一样的配置, 集群名也就相同, 所以会自动加入到集群; 加入集群后, blogs 索引的 3个 副本分片 将会分配到这个节点上, 这意味着当集群内任何一个节点出现问题时, 我们的数据都完好无损; 所有新索引的文档都将会保存在主分片上, 然后被并行的复制到对应的副本分片上, 这就保证了我们既可以从主分片又可以从副本分片上获得文档; 并且 cluster-health 现在展示的状态为 green, 这表示所有6个分片(包括3个主分片和3个副本分片)都在正常运行; 水平扩容 如何为我们的正在增长中的应用程序按需扩容呢? 再次尝试启动第三个新的节点, 会发现集群状态如下: 可以看到 Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点 现在每个节点上都拥有2个分片, 而不是之前的3个, 这表示每个节点的硬件资源(CPU, RAM, I/O)将被更少的分片所共享, 每个分片的性能将会得到提升 分片是一个功能完整的搜索引擎, 它拥有使用一个节点上的所有资源的能力也就是说, 目前我们这个拥有6个分片(3个主分片和3个副本分片)的索引, 可以最大扩容到6个节点, 让每个节点上只有该索引的一个分片(也可能会有其他索引的分片哦); 分片数量一定, 增加节点, 则每个分片性能将会提升, 因为被赋予的更多的硬件资源; 但是当一个索引的分片数量和集群的节点数量达到一致时, 其分片性能达到最高, 继续增加更多的副本分片是不能提高性能的, 因为每个分片从节点上获得的资源会变少, 你需要增加更多的硬件资源来提升吞吐量; 更多的扩容提升搜索性能 想要继续扩容超过6个节点, 需要先知道: 由于索引的主分片数目在索引创建时就已经确定了, 这个数目定义了这个索引能够 存储 的最大数据量也就是索引能存储的最大数据量在创建索引的时候就通过设置主分片数确定了(不过实际大小还取决于你的数据、硬件和使用场景) 由于 搜索操作 和 返回数据操作 可以同时被主分片 或 副本分片所处理, 所以当你拥有越多的副本分片时, 也将拥有越高的吞吐量 在运行中的集群上是可以动态调整副本分片数目的, 比如, 可以把副本数从默认的 1 增加到 2 : 1234PUT /blogs/_settings&#123; &quot;number_of_replicas&quot; : 2&#125; blogs 索引现在拥有9个分片: 3个主分片和6个副本分片; 这就意味着可以将集群扩容到9个节点(每个节点上只放该索引的一个分片), 相比原来3个节点时(每个节点两个分片), 虽然存储量不变, 但是集群搜索性能可以提升 3 倍; 当一个索引的分片数量和集群的节点数量达到一致时, 其分片性能将达到最高, 无法再提升分片的性能! 此时可以 通过增加更多的副本分片, 同时增加节点来提升集群的搜索性能! 集群的整体性能还是需要通过增加节点来提高! 故障测试 目前的集群状态如下: 如果关闭主节点 由于而集群必须拥有一个主节点来保证正常工作, 所以发生的第一件事情就是选举一个新的主节点; 在我们关闭主节点的同时也失去了主分片 1 和 2, 并且在缺失主分片的时候索引也不能正常工作, 如果此时来检查集群的状况, 我们看到的状态将会为 red: 不是所有主分片都在正常工作 幸运的是, 在其它节点上存在着主节点上这两个主分片的完整副本, 所以新的主节点会立即将这两个主分片在 另外两个节点上 对应的副本分片提升为主分片, 此时集群的状态将会为 yellow: 这个提升主分片的过程是瞬间发生的, 如同按下一个开关一般此时, 虽然我们又拥有所有的三个主分片, 但是由于之前设置了每个主分片需要对应2份副本分片, 而此时只有两个几点, 只存在一份副本分片, 所以集群不能为 green 的状态; 如果重新启动之前关闭的节点, 集群可以将缺失的副本分片再次进行分配, 如果它依然拥有着之前的分片, 它将尝试去重用它们, 同时仅从主分片复制发生了修改的数据文件;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/tags/Elasticsearch/"}]},{"title":"02. 适应一下ES","slug":"elasticsearch/2018-06-08-02","date":"2018-06-08T13:23:07.000Z","updated":"2018-09-18T07:44:47.000Z","comments":true,"path":"2018/06/08/elasticsearch/2018-06-08-02/","link":"","permalink":"http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-02/","excerpt":"","text":"文档该章节比较基础, 主要是为了对 Elasticsearch 有一个基本印象, 通过对雇员文档的基本操作, 了解 索引、搜索 及 聚合 等基础概念;可能有会遇到有些语句在5.X中无法运行, 比如 进行聚合操作时提示 Fielddata is disabled on text fields by default, 可参考此文章","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/tags/Elasticsearch/"}]},{"title":"01. Elasticsearch 入门 及 简单安装","slug":"elasticsearch/2018-06-08-01","date":"2018-06-08T06:24:25.000Z","updated":"2018-09-12T04:46:18.000Z","comments":true,"path":"2018/06/08/elasticsearch/2018-06-08-01/","link":"","permalink":"http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-01/","excerpt":"","text":"简介 Elasticsearch 是一个基于 Lucene 的开源, 高性能, 全文检索 和 分析引擎, 可以快速且近实时地存储, 检索以及分析海量数据; 当然, ES 不仅仅是 Lucene, 也不仅仅只是一个全文搜索引擎, 它可以被下面这样准确的形容: 一个分布式近实时分析搜索引擎; 海量数据检索及分析: 可以扩展到上百台服务器, 处理PB级结构化或非结构化数据; 近实时搜索: 从文档索引到可以被检索只有轻微延时, 约1s RESTful API: ES 建立在全文搜索引擎 Lucene 之上, 通过简单的 RESTful API 来隐藏 Lucene 的复杂性, 从而让全文搜索变得简单, 各种语言的客户端甚至命令行都可以与之交互; 面向文档型数据库, 存储的是整个对象或者文档, 它不但会存储它们, 还会为它们建立索引; 使用案例 在微服务架构下的多数据源聚合列表页(一个页面中的数据来自多个服务, 且筛选条件也涉及到多个服务中的数据字段), 如果用传统数据库解决该问题, 会大费周折, 并且效果并不好, 而如果使用 ES 来作数据聚合服务, 效果就比较清晰明了了; 您想要去收集日志或交易数据, 并且还想要去分析和挖掘这些数据来找出趋势, 统计, 或者异常现, 在这种情况下, 您可以使用 Logstash(Elasticsearch/Logstash/Kibana) 技术栈中的一部分, 来收集, 聚合, 以及解析数据, 然后让 Logstash 发送这些数据到 Elasticsearch; 如果这些数据存在于 Elasticsearch 中, 您就可以执行搜索和聚合以挖掘出任何您感兴趣的信息; GitHub 使用 Elasticsearch 对1300亿行代码进行查询; …… 版本选择 ES 的版本变更比较快, 目前(06/2018)为止, Elasticsearch已经到6.X了, 可参考官网文档, 可能很多公司还在用2.X, 或者刚切到5.X, 而且中文文档进度也比较滞后, 这也是让很多兄弟比较头疼的事情; 其实可以根据公司所选的云服务上 ES版本 来决定你的学习版本 (当前阿里云的Elasticsearch云服务为5.5.3, 因此此处也是针对5.X版本进行学习调研); 安装 安装Java, 推荐使用Java 8 : yum install java-1.8.0-openjdk* -y ES 下载 123456$ cd /usr/local/src$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.3.tar.gz$ tar -zxvf elasticsearch-5.5.3.tar.gz$ cd elasticsearch-5.5.3$ lsbin config lib LICENSE.txt modules NOTICE.txt plugins README.textile 启动 ES: es不能使用root权限启动, 所以需要创建新用户 123456$ adduser es$ passwd es$ chown -R es /usr/local/src/elasticsearch-5.5.3/$ cd /usr/local/src/elasticsearch-5.5.3/bin$ su es$ ./elasticsearch 验证es是否安装成功 可以在浏览器中打开 127.0.0.1:9200 (这里使用的是vagrant设定了虚拟主机的ip, 所以访问 http://192.168.3.200:9200/, 不过有些小坑下面会介绍 ) 或者可以 curl -X GET http://192.168.3.200:9200 启动坑点启动可能会报一些错 每个进程最大同时打开文件数太小 123456789101112131415[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]``` 解决方案: 切换到root, 可通过下面2个命令查看当前数量``` $ ulimit -Hn4096$ ulimit -Sn1024// 编辑如下文件vi /etc/security/limits.conf// 增加配置* soft nofile 65536* hard nofile 65536 elasticsearch用户拥有的内存权限太小, 至少需要262144 12ERROR: [1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案, 切换到root 123vi /etc/sysctl.conf 添加 vm.max_map_count=262144执行 sysctl -p 默认9200端口是给本机访问的, 因此es在成功启动后, 如果使用 192.168.3.200:9200 来访问, 可能失败, 因此需要在es配置文件elasticsearch.yml中增加 network.bind_host: 0.0.0.0, 重启后则可以正常访问 如果想启动多个结点, 还可能会报如下几个错 尝试启动第二个节点, 报错 123456OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000080000000, 174456832, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12)## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 174456832 bytes for committing reserved memory.# An error report file with more information is saved as:# /usr/local/src/elasticsearch-5.5.3/bin/hs_err_pid8651.log 解决方案: 其实这是因为我给虚拟机分配了2G的内存, 而elasticsearch5.X默认分配给jvm的空间大小就是2g, 所以jvm空间不够, 修改jvm空间分配 1234567vi /usr/local/src/elasticsearch-5.5.3/config/jvm.options将:-Xms2g-Xmx2g修改为:-Xms512m-Xmx512m 再次启动又报错 123...maybe these locations are not writable or multiple nodes were started without increasing [node.max_local_storage_nodes] (was [1])... 解决方案: 在 elasticsearch.yml 配置文件最后添加 node.max_local_storage_nodes: 256, 然后重新添加第二个节点 Elasticsearch Head 安装es 启动后, 访问 127.0.0.1:9200 可以查看版本集集群相关的信息, 但这不是图形化的界面, 操作起来不是很方便, 如果希望能有一个可视化的环境来操作它, 可以通过安装 Elasticsearch Head 这个插件来进行管理;Elasticsearch Head 是集群管理、数据可视化、增删改查、查询语句可视化工具, 在最新的ES5中安装方式和ES2以上的版本有很大的不同, 在ES2中可以直接在bin目录下执行 plugin install xxxx 来进行安装, 但是在ES5中这种安装方式变了, 要想在ES5中安装则必须要安装NodeJs, 然后通过NodeJS来启动Head, 具体过程如下: nodejs 安装 123// 更新node.js各版本yum源(Node.js v8.x)curl --silent --location https://rpm.nodesource.com/setup_8.x | bash -yum install -y nodejs github下载 Elasticsearch Head 源码 1234cd /usr/local/srcgit clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm install // (可能会有一些警告) 修改Elasticsearch配置文件, 编辑 elasticsearch-5.5.3/config/elasticsearch.yml, 加入以下内容: 12http.cors.enabled: true // 注意冒号后面要有空格http.cors.allow-origin: &quot;*&quot; 编辑elasticsearch-head-master文件下的Gruntfile.js, 修改服务器监听地址, 增加hostname属性, 将其值设置为 * : 123456789101112vi elasticsearch-head/Gruntfile.jsconnect: &#123; hostname: &quot;*&quot;, // 此处 server: &#123; options: &#123; port: 9100, base: &apos;.&apos;, keepalive: true &#125; &#125;&#125; 编辑elasticsearch-head-master/_site/app.js, 修改head连接es的地址，将localhost修改为es的IP地址 (注意:如果ES是在本地,就不要修改,默认就是localhost) 1this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://localhost:9200&quot;; 在启动elasticsearch-head之前要先启动elasticsearch, 然后在elasticsearch-head-master/目录下运行启动命令 1npm run start 最后验证 http://192.168.3.200:9100/ Kibana安装 下载, 此处选择了5.5.3 12wget https://artifacts.elastic.co/downloads/kibana/kibana-5.5.3-linux-x86_64.tar.gztar -zxvf kibana-5.5.3-linux-x86_64.tar.gz 修改config/kibana.yml文件, 加入以下内容: 1234server.port: 5601 server.name: &quot;kibana&quot; server.host: &quot;0.0.0.0&quot; elasticsearch.url: &quot;http://127.0.0.1:9200&quot; 然后启动kibana服务: 12 cd /usr/local/src/kibana-5.5.3-linux-x86_64/bin./kibana 浏览器访问地址:http://192.168.3.200:5601/ DevTools 与 5.x之前版本的Sense Sense 是一个 Kibana 应用它提供交互式的控制台, 通过你的浏览器直接向 Elasticsearch 提交请求, 操作es中的数据 现在不用安装了, 可以直接使用Kibana提供的 DevTools 注意此时, 之前的es集群变成yellow状态了 小结到此为止, 正常学习的Es环境已经安装完毕, 不要纠结这些服务的开机启动, 调优配置, 集群, 高可用, 监控……骚年, 暂时先让它能跑起来就行!","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.renyimin.com/tags/Elasticsearch/"}]},{"title":"28. 隔离级别 与 锁","slug":"mysql/2017-09-03-mysql-28","date":"2017-09-03T06:20:52.000Z","updated":"2018-09-03T03:54:23.000Z","comments":true,"path":"2017/09/03/mysql/2017-09-03-mysql-28/","link":"","permalink":"http://blog.renyimin.com/2017/09/03/mysql/2017-09-03-mysql-28/","excerpt":"","text":"前言 之前几篇博文已经介绍了Mysql事务, 高并发下事务将会面对的问题 及 MySQL的解决方案; MySQL主要采用 事务隔离性中的4种隔离级别 结合 MVCC机制 来进行解决; 而事务隔离级别的核心就是锁, 各隔离级别使用了不同的加锁策略; 接下来看一下各隔离级别是如何实现及如何解决高并发事务问题的; READ UNCOMMITTED 未提交读READ COMMITTED 提交读MVCC 多版本并发控制REPEATABLE READ 可重复读参考资料 《高性能MySQL》 MySQL官方文档 美团技术博客 最后更新时间 2018/09/01","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"27. 幻读, 快照读(snapshot read), 当前读 (current read)","slug":"mysql/2017-09-02-mysql-27","date":"2017-09-02T11:25:07.000Z","updated":"2018-09-01T14:02:47.000Z","comments":true,"path":"2017/09/02/mysql/2017-09-02-mysql-27/","link":"","permalink":"http://blog.renyimin.com/2017/09/02/mysql/2017-09-02-mysql-27/","excerpt":"","text":"RR + MVCC 虽然解决了 幻读 问题, 但要注意, 幻读针对的是读操作(对于其他操作就不一样了); 演示 打开 两个客户端 1,2 确保隔离级别为默认级别RR, 提供语句: 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端2中 开启事务, 然后查询数据 1234567891011121314mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端1中插入一条id为4的新数据 (未开启事务, 所以会自动提交) 123456789101112mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 || 4 | 死侍 | 18 | 0 | A bad boy |+----+-----------+-----+--------+--------------------+4 rows in set (0.00 sec) 回到 客户端2 的事务中再次查询数据, 发现数据没有变化(表示可以重复读, 并且克服了 select 幻读)!! 12345678910111213141516171819202122mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) 但如果尝试在客户端2的事务中执行 insert/delete/update , 却会发现此类操作都可以感知到客户端1提交的新数据 123mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);1062 - Duplicate entry &apos;4&apos; for key &apos;PRIMARY&apos; //( 后面会看到: 其实是因为insert是当前读)mysql&gt; 小结 虽然发现已经克服了幻读问题; 但当 在客户端2事务中 insert 插入一条id为4的新数据, 却发现提示数据已经存在, 那么这是什么问题呢? 可以参考MySQL官方文档 — 一致性非阻塞读中的一段介绍 The snapshot of the database state applies to SELECT statements within a transaction, not necessarily to DML statements. If you insert or modify some rows and then commit that transaction, a DELETE or UPDATE statement issued from another concurrent REPEATABLE READ transaction could affect those just-committed rows, even though the session could not query them. If a transaction does update or delete rows committed by a different transaction, those changes do become visible to the current transaction.个人认为应该翻译为: 数据库的快照适用于事务中的SELECT语句, 而不一定适用于所有DML语句。 如果插入或修改某些行, 然后提交该事务, 则从另一个并发REPEATABLE READ事务发出的DELETE或UPDATE语句就可能会影响那些刚刚提交的行, 即使该事务无法查询到它们。如果一个事务去更新或删除其他事务提交的行, 则那些更改对当前事务就变得可见;但是如果事务select由不同事务提交的行, 则那些更改对当前事务就不可见(此时算是rr的可重复读); 也就是RR隔离级别, 在同一事务中多次读取的话, 对 select 克服了 幻读; 但是对其他DML并没有做到(其他DML能察觉到数据被别的事务提交过了)! 这就引出了新的两个概念: 当前读 和 快照读 当前读 和 快照读通常在RC,RR隔离级别下, 不做特殊处理, 使用的 select 都是快照读, 其他dml就算是当前读; (MVCC写阻塞写) 其实, MVCC并发控制中的读操作分为两类: 快照读 (snapshot read) 与 当前读 (current read); 参考 快照读： 是通过MVVC(多版本控制)和 undo log 来实现的, 常见语句如下(貌似就是常见的悲观锁么): 1简单的select操作 (不包括: `select ... lock in share mode`, `select ... for update`) 而 当前读 根本不会创建任何快照, insert, update, delete都是当前读, 所以这几个操作会察觉到其他事务对数据做的更改(而普通select是察觉不到的): 12345select ... lock in share modeselect ... for updateinsertupdatedelete 最后更新时间 2018/09/01","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"26. MySQL 高并发下常见的事务问题","slug":"mysql/2017-09-02-mysql-26","date":"2017-09-02T06:56:32.000Z","updated":"2018-09-01T14:02:40.000Z","comments":true,"path":"2017/09/02/mysql/2017-09-02-mysql-26/","link":"","permalink":"http://blog.renyimin.com/2017/09/02/mysql/2017-09-02-mysql-26/","excerpt":"","text":"前言上一篇MySQL事务简介中对MySQL事务的 基本概念 及 特性 做了简单介绍; 接下来会分析在实际生产环境中面对高并发场景时, 事务会出现的一些常见问题; 高并发事务问题在并发量比较大的时候, 很容易出现 多个事务并行 的情况; 假设有两个事务正在同时进行, 值得注意的是: 它们两者之间是互相不知道对方的存在的, 各自都对自身所处的环境 过分乐观, 从而并没有对自己所操作的数据做一定的保护处理, 所以 最终导致了一些问题的出现; 脏读 如果 事务A 读取了另一个并行 事务B 未最终提交的写数据, 那事务A的这次读取操作就叫 脏读 因为 事务A 此时读取到的是 并行事务B 尚未最终持久化的数据 (该数据还不具备事务的 持久性) 事务B 最终可能会因为其事务单元内部其他后续操作的失败 或者 系统后续突然崩溃等原因, 导致事务B最终整体提交失败而回滚, 那么最终 事务A 之前拿到就是 脏的数据 了(当然, 如果 事务A 在后续操作中继续读取的话, 无论事务B是否结束, 其每次的更新操作, 事务A都会及时读到新数据, 只不过这同时涉及到了下一个讨论的 不可重复读问题, 暂时可以不了解) 图示: 解决方案 : RC+ 在MySQL中, 事务已经用自身隔离性解决了脏读问题 : READ COMMITED 或 以上隔离级别(RC+); READ COMMITED 隔离级别保证了: 在事务单元中, 某条语句执行时, 只有已经被其他事务提交的持久性落地数据, 才对该语句可见; 不可重复读 之前 脏读问题 的解决了, 仅仅只意味着事务单元中的每条语句读取到的数据都是 具备持久性的落地数据而已; 之前在讨论脏读问题时, 有个问题也同时存在着, 那就是一个事务单元中 不可重复读 的问题; 显然, RC 隔离级别只解决了 脏读的问题 如果在一个事务中多次读取同一个数据, 正好在两次读取之间, 另外一个事务已经完成了对该数据的修改并提交, 那问题就来了: 两次读取的结果不一样了 解决方案 : RR+ 在MySQL中, 事务已经用自身隔离性解决了 不可重复读 问题 — REPEATABLE READ 或 以上隔离级别(RR+); REPEATABLE READ 级别保证了:在事务中, 某条语句执行前, 已经被其他事务 提交/回滚 的落地数据, 对该语句都是可见的; ( READ COMMITED )在事务中, 多次读取同一个数据(在两次读取操作之间, 无论数据被 提交 多少次(即无论落地过多少遍), 每次读取的结果都应该是和事务中第一次读取的结果一样; 幻读 可以参考 MySQL官方文档对 Phantom Rows 的介绍 ) 不可重复读 和 幻读 这两个概念容易搞混 不可重复读 主要是说多次读取同一条记录, 发现该记录中某些列值被其他事务修改过; 而 幻读 主要是说多次读取一个范围内的记录(包括直接查询所有记录结果或者做聚合统计), 发现结果不一致(比如发现增加/减少了一条记录); 解决方案: RR + MVCC 其实对于 幻读 问题, 在Mysql的InnoDB存储引擎中, 是通过事务的 RR + MVCC机制 进行解决的;当然, 这里的幻读不涉及 具有当前读能力的那些语句; (也就是说只是解决幻读, 所谓幻写之类的就不在范围内了) 另外可以参考《高性能MySQL》对 RR 隔离级别的描述 理论上, RR级别是无法解决幻读的问题, 但是由于InnoDB引擎的RR级别还使用了MVCC, 所以也就避免了幻读的出现! 之所以 不可重复读 和 幻读 容易搞混, 可能是因为: 在mysql中, 由于默认就是RR隔离级别下, 该隔离级别已经解决了幻读, 所以无法模拟出幻读的场景; 而 退回到 RC隔离级别 的话, 虽然 幻读 和 不可重复读 都会出现, 但由于现象都是两次读取结果不一样, 容易分辨不出! 想了解更多, 可以参考下一篇幻读的延伸 高并发事务问题 之 更新丢失最后聊一下高并发事务的另一个问题, 也是最常遇到的问题: 丢失更新问题; 该问题和之前几个问题需要区分开: 该问题需要我们自己来解决;更新丢失问题分为两类 第一类丢失更新(回滚覆盖)简介 事务A 回滚时, 将 事务B 已经提交的数据覆盖了 需要注意的是: 这种情况在Mysql中不会出现; RU 级别演示 对于InnoDB事务的最低隔离级别 READ UNCOMMITED, 并行事务B的未提交数据都可以读到, 更别说已提交数据了 (所以回滚也会回滚到事务B提交的最新数据) 语句如下: 12345678SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;select * from test_transaction where id=2;update test_transaction set age = age-10 where id=2;rollback; 1234567SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age - 15 where id=2;commit; RC 级别演示 对于 READ COMMITTED: 在事务B提交之后, 事务A在T3阶段是可以select(快照读)到事务B最终提交的数据的, 更别说update(当前读)到了, 所以事务A最终的Rollback其实也是基于事务B提交后的数据的 (关于这里提到的快照读和当前读, 下一篇会介绍) 语句如下: 12345678SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;select * from test_transaction where id=2;update test_transaction set age = age-10 where id=2;rollback; 1234567SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age - 15 where id=2;commit; RR 级别演示 对于 REPEATABLE READ 可重复读, 事务A在T3阶段虽然select不到事务B最终提交的数据(快照读), 但是可以update(当前读)到事务B最终提交的数据的 (注意: RR与RC虽然都会有快照读, 但是快照读的结果却不一致, 其实是因为两者的MVCC机制快找时机不同导致的, 后面会讲解) 语句如下: 1234567SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;select * from test_transaction where id=2;update test_transaction set age = age+10 where id=2;rollback; 12345SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age-15 where id=2;commit; SERIALIZABLE 演示 SERIALIZABLE 串行化: 读写都加锁, 最容易出现死锁, 所以也不会出现第一类丢失更新的问题, 直接就死锁了 语句如下: 123456SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;SELECT @@SESSION.tx_isolation;begin;update test_transaction set age = age-10 where id=2;rollback; 1234567SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age -15 where id=2;commit; 第二类丢失更新(提交覆盖) 直接上图 另外, 这里可以解释一下为什么 SERIALIZABLE级别 通常不会不被采用 其实 SERIALIZABLE 虽然做了串行化, 其实也就是对读写都加了锁, 但一旦事务并行, 如果将判断库存的读操作放在事务内就很容易会死锁而放在事务外, 由于更新操作仍然会依据上一个查询的结果, 所以仍然是避免不了第二类丢失更新问题的, 会造成超卖等问题; SERIALIZABLE 的串行化本身也太低效 另外, 可以参考: https://segmentfault.com/q/1010000010353164/a-1020000010353684 解决第二类丢失更新的方案: 乐观锁 (在修改时, where判断数据是否为你读取时的数据; 或者提供数据版本字段来控制) 悲观锁 参考资料: 《高性能MySQL》 淘宝数据库内核6月报 美团技术博客 MySQL官方文档 最后更新时间 2018/09/01","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"25. MySQL 事务简介","slug":"mysql/2017-08-27-mysql-25","date":"2017-08-27T11:31:07.000Z","updated":"2018-09-01T14:02:34.000Z","comments":true,"path":"2017/08/27/mysql/2017-08-27-mysql-25/","link":"","permalink":"http://blog.renyimin.com/2017/08/27/mysql/2017-08-27-mysql-25/","excerpt":"","text":"事务的概念 事务：可以理解为一个 独立的工作单元, 在这个独立的工作单元中, 可以有一组操作; 放在这个独立工作单元中的一组操作, 要么全部执行成功, 要么全部执行失败 随处可见的例子: 假设有两个角色 ‘Iron Man’(余额500), ‘Wolverine’(余额15), 现在 ‘Iron Man’ 通过银行应用给 ‘Wolverine’ 转账100元, 那么本次转账操作至少需要三个步骤 123检查`Iron Man`余额`&gt;=100`元从`Iron Man`余额中`-100`元给`Wolverine`余额`+100`元 注意: 上面的三个步操作，就需要打包在一个事务中作为 独立的工作单元 来执行。并且在 这个独立工作单元中的三个操作, 只要有任何一个操作失败, 则整体就应该是失败的, 那就必须回滚所有已经执行了的步骤; 假设第二步操作成功, 但是第三步操作失败, 那么整个事务就应该是失败的, 就必须将第二步的操作回滚 (这也体现了事务最基本的一个特性: 保证数据的一致性) 事务的ACID特性一个运行良好的事务处理系统必须具备下面这些标准特性(高并发离不开事务的这几个标准特性) Atomicity 原子性一个事务必须被视为一个不可分割的最小工作单元;对于一个事务来说, 不能只成功执行其中的一部分操作, 整个事务中的所有操作要么全部成功提交, 要么有操作失败导致所有操作全部回滚, 这就是事务的原子性。 Consistency 一致性此一致性非彼一致性 你大概可以这样来理解: 虽然数据表中的数据可能一直在变化, 但是事务的一致性特性保证的是 数据库总是从一个数据一致性的状态 转换到 另一个数据一致性的状态, 而不是分布式中提到的数据一致性; 比如之前转账的例子: 转账前的数据一致性状态是: ‘Iron Man’(余额500), ‘Wolverine’(余额15) 转账成功后的数据一致性状态是: ‘Iron Man’(余额400), ‘Wolverine’(余额115) 转账如果失败的话, 数据的一致性的状态应该回滚到转账前的状态: ‘Iron Man’(余额500), ‘Wolverine’(余额15) Isolation 隔离性 通常来说, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的比如在之前的转账例子中, 在执行完成最后一步(第三步), 事务还没来得及最终提交之前, 此时有另一个程序去读取 Iron Man账户 的余额, 那么这个程序读到的应该是500才对 上面为什么说 通常来说, 难道还有其他情况 ?后面会详细讨论事务 隔离性 的四个 隔离级别, 到时候就知道这里为什么说 通常来说 ; (确实有特例, 比如最低隔离级别 READ UNCOMMITTED, 对其他事务的可见就造成了 脏读问题 的出现) 事务有四种隔离级别(从低到高) READ UNCOMMITTED (未提交读) READ COMMITTED (提交读)(注意: 和RR一样都采用了MVCC机制, 但与RR级别主要区别是快照时机不同, 暂时可不必了解, 后面文章会详解) REPEATABLE READ (可重复读) SERIALIZABLE (可串行化) 注意: 只有该隔离级别才会读写都加锁 Durability 持久性 一旦事务被最终提交后, 在这个独立单元中的所有操作所做的修改将会 永久保存到数据库中; 所谓永久, 也只是主观上的永久, 可以理解为被事务修改的数据是真正存放到了表中, 而不是存放在了诸如临时表之类的地方; 最后更新时间 2018/09/01","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]}]}