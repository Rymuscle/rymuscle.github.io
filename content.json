{"meta":{"title":"Lant's Blog","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"11 - Django连接MySQL (未完...)","slug":"2017-11-25-Django-11","date":"2017-11-25T13:07:00.000Z","updated":"2017-12-06T13:44:21.000Z","comments":true,"path":"2017/11/25/2017-11-25-Django-11/","link":"","permalink":"http://blog.renyimin.com/2017/11/25/2017-11-25-Django-11/","excerpt":"","text":"连接mysql数据库 当我们修改项目配置文件中的数据库配置项为如下配置项 123456789101112DATABASES = &#123; &apos;default&apos;: &#123; # &apos;ENGINE&apos;: &apos;django.db.backends.sqlite3&apos;, # &apos;NAME&apos;: os.path.join(BASE_DIR, &apos;db.sqlite3&apos;) &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;test&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;renyimin&apos;, &apos;HOST&apos;: &apos;127.0.01&apos;, &apos;PORT&apos;: &apos;3306&apos; &#125;&#125; 之后 python manage.py runserver --settings=MyDjangoBlog.settings.local 启动Django服务会发现报错: 123......django.core.exceptions.ImproperlyConfigured: Error loading MySQLdb module: No module named &apos;MySQLdb&apos;.Did you install mysqlclient or MySQL-python? 这是因为我们还没有提供Django可以连接数据库的组件: 一般我们会使用MySQL, 在python2.x中用 mysqldb 用的比较多，但是在python3.x中已经不支持那个组件了, 可以选择使用 pymysql 这里使用的是Anaconda虚拟环境, 所以使用 conda install pymysql (使用virtualenv的话, 可以 pip install pymysql ) 然后注意需要在你项目的主目录下的__init__.py(我的目录是 ~/Desktop/MyDjangoBlog/MyDjangoBlog/)，写入以下代码 12import pymysqlpymysql.install_as_MySQLdb() 之后便成功启动Django服务了; 创建model 首先你会在 应用 的 models.py 文件中创建每张表对应的模型类 创建model的时候, 是需要设置数据表相关的字段信息的, 这就涉及到字段的选择? 了解Django有哪些字段类型, 如何自定义自己的字段类型 ?https://docs.djangoproject.com/en/1.11/ref/models/fields/ Django的model相关使用 (http://python.usyiyi.cn/documents/django_182/topics/db/models.html#quick-example) 几个Django的基本命令 创建好model模型文件之后, 接下来还要接触几个Django的基本命令 数据库迁移的两大命令 12python manage.py makemigrations # 使用model层, 生成对应的数据库迁移文件python manage.py migrate TestModel # 开始执行迁移文件, 更新数据库 上面两个命令调用默认为全局，即对所有最新更改的model或迁移文件进行操作; 如果想要精确到某个迁移文件(比如0004_xxx.py), 可以运行 1python manage.py migrate app_name 0004 如果想看迁移文件的执行状态，可以用 python manage.py showmigrations 命令查看, 会列出每个应用(包含Django默认自带的应用)下的迁移文件的迁移状态: 尝试创建一张简单的user表的模型, 然后运行上面两个命令, 结果可能有 warnings 提示: 解决方法:在数据库配置项中添加如下配置:123&apos;OPTIONS&apos;: &#123; &apos;init_command&apos;: &quot;SET sql_mode=&apos;STRICT_TRANS_TABLES&apos;&quot;&#125; 如果想要查看你迁移文件所对应的sql语句, 可以使用如下命令 1python manage.py sqlmigrate blog(对应你的应用名) 0001 在执行 migrate 命令的时候, 该命令首先会找出所有还没有被应用的迁移文件 Django使用数据库中的一个django_migraton的特殊表来追踪哪些迁移文件被应用过 其次, 如果没有发现你应用下的迁移文件记录, 那就会执行, 但之后还会检查是否库中真的有你的表 如果你删除django_migraton表中对应自己应用中migration文件的那条记录, 你就可以重新使用 migrate 命令来生成表, 但如果你的表仍然存在,则会报错, 所以不要进行此类破坏性操作; 或者你如果直接在数据库中删除了你自己的表, 那么你直接运行 migrate 命令, 会发现也没有效果, 因为该命令首先会查看django_migraton, 而其中还有你迁移文件的记录; 在稍后如果觉得数据表结构不合适, 可能会更改数据表的字段信息, 如果在添加了字段之后运行迁移的两个命令时, 会出现如下错误: 12345678910111213You are trying to add a non-nullable field &apos;pub_date&apos; to article without a default; we can&apos;t do that (the database needs something to populate existing rows).Please select a fix: 1) Provide a one-off default now (will be set on all existing rows) 2) Quit, and let me add a default in models.py这段话的意思是 pub_date 字段没有默认值，而且非Null 那么 1) 指定一个一次性的值供更改数据库时使用。2) 停止当前操作，在 models.py 中给定默认值，然后再来migrate。 此时, 选择1, 然后输入 &#39;&#39; 即可, 或者你在增加字段的时候指定默认值! 目前觉着这个貌似没啥大用!! 当然, 你还可以修改字段名, 删除字段….. 每次修改完之后, migrations命令都会生成数据model的更改记录文件; 由于你每次执行完迁移命令之后, django_migraton 这张表中都会记录哪些迁移文件你做了迁移(包括你的更改表结构所生成的迁移文件), 所以每次你执行迁移命令的时候, 只会执行新增的model表结构所生成的的迁移文件; 所以迁移会很快 遗留数据库整合到Django在进行models迁移的时候, 如果表结构已经存在了呢? 虽然Django最适合用来开发新的应用，但也可以将它整合到遗留的数据库中; Django包含了很多工具，尽可能自动化解决这类问题; 首先你需要向Django提供你的数据库配置信息(这个之前已经了解过了) 也就是让Django知道你想整合的数据库在哪里 Django自带了一个叫做 inspectdb 的工具(inspectdb文档), 可以按照现有的数据库创建模型; 运行如下命令并查看输出: 1python manage.py inspectdb 因此可以重定向标准输出流来保存文件: 1python manage.py inspectdb &gt; models.py 这样就会在当前目录下生成一个models.py的模型文件, 你可以将这个模型文件放入到你创建的应用中 默认情况下，inspectdb创建的模型是未被管理的, 所以生成的模型文件中的Meta类中的 managed = False 就是告诉Django不要管理每个表的创建,修改和删除: 123456class Person(models.Model): id = models.IntegerField(primary_key=True) first_name = models.CharField(max_length=70) class Meta: managed = False db_table = &apos;CENSUS_PERSONS&apos; 也就是说你在model中对表结构做出修改的时候, 使用迁移命令 migration 会发现它并不会识别出表结构已经发生变化了, 除非你把model类中的Meta类的 managed 改成True或者删除如果你希望Django管理表的生命周期，你需要把managed选项改为 True（或者简单地把它移除，因为True是默认值） 另外需要注意的是: 遗留的数据库导入为Django的model的时候, 之前表之前的关系(一对多,多对多…)会怎样? Django数据库路由 之前我们已经对Django的setting文件做了配置, 并成功连接到了Mysql数据库, 但如果我们要做更复杂的业务, 这根本不够, 比如我们要做读写分离该如何配置? 在使用PHP的框架时, 一般我们只用在配置文件中配置好读写库的相关配置, 比如Laravel框架, 不管你用的是原生 SQL，还是查询构建器，还是 Eloquent ORM，只要配置正确，合适的连接总是会被使用; 但是Django中就没有这么简单; 在Django中, 有 数据库路由 的概念: 当我们有很多模型的时候, 通过实现一个数据库路由, 可以指定你的模型在进行哪类操作的时候, 操作哪个数据库！ 实现数据库路由 一个数据库路由是一个拥有4个方法的类，这四个方法是: db_for_read(model, **hints) # 对于该model 用哪个数据库来读 db_for_write(model, **hints) # 对于该model用哪个数据库来写 allow_relation(obj1, obj2, **hints) # 是否允许两个对象关联到数据库 allow_migrate(db, app_label, model_name=None, **hints) # 对于指定的app，是否允许对db这个数据库进行migrate 接下来, 我们可以在项目的目录下创建一个 routers.py 1 http://jingpin.jikexueyuan.com/zhuti/python/","categories":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/tags/Django/"}]},{"title":"10 - Django数据库模型前置信息","slug":"2017-11-25-Django-10","date":"2017-11-25T12:18:00.000Z","updated":"2017-12-05T14:30:45.000Z","comments":true,"path":"2017/11/25/2017-11-25-Django-10/","link":"","permalink":"http://blog.renyimin.com/2017/11/25/2017-11-25-Django-10/","excerpt":"","text":"要使用Django的数据模型, 你需要做的事情及考虑还是比较多的： 首先要选择数据库并配置数据库连接信息; 接下来就是创建表对应的模型了 Django的ORM在创建model的时候, 需要提供的表信息比较多, 因为Django会依据model帮你创建出表结构来; 在model创建时, 需要注意的点比较多, 此处暂时列出如下几点: 原先遗留数据库如何整合到Django? 数据model对应的字段类型比较多, 注意多加使用, 还可以自定义字段类型 表之间的关系 (一对多, 多对多…) 事务(Transcation)的使用 数据库索引的使用 聚合的相关用法 会涉及到model的继承问题 Django原生ORM只能针对关系型数据库? 非关系型的NoSQL数据库如何对接?（http://jingpin.jikexueyuan.com/article/11501.html）（https://www.zhihu.com/question/19818326） 更高级的 创建好model模型文件之后, 接下来还要接触几个Django的基本命令 python manage.py makemigrations python manage.py migrate TestModel 如果应用的models.py中创建的model将来可能会过多的话, 还要考虑拆分models 如果涉及到读写分离或者项目中使用多个数据库的时候, 需要配置多个数据库配置块 配置好数据库连接信息之后, 你可能启动Django还会失败, 因为你还要选择 如果配置了多个数据库配置块的话, 还需要实现 数据库路由 来决定你的查询操作是要操作哪个数据库 …… 未完待续 参考","categories":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/tags/Django/"}]},{"title":"03 - 重新规划Django项目布局结构和目录结构","slug":"2017-11-10-Django-03","date":"2017-11-10T12:21:17.000Z","updated":"2017-12-04T04:32:30.000Z","comments":true,"path":"2017/11/10/2017-11-10-Django-03/","link":"","permalink":"http://blog.renyimin.com/2017/11/10/2017-11-10-Django-03/","excerpt":"","text":"django的models拆分1.在Django开发中如果models文件过长,就需要对其进行拆分, 一般会使用的拆分方法如下: 根据功能/业务直接拆分app, 没必要将一个app写的过于冗长; 删除默认的models.py文件, 创建models包，需要在 models/ 下添加init.py文件, 然后在models下创建模型文件, 但是此时执行 python manage.py syncdb 仍然不能生成对应的数据表, 需要在__init__.py文件中导入这些modules, 在init.py中加入:12from user import *from order import * 现在执行python manage.py syncdb就会生成对应的表了． 当然，还要注意的是，最好在拆分的model中每张表都添加一个元选项: app_label, 指明是那个app下的model.例:123456class User(models.Model):name = models.CharField(max_length = 255, null = False)age = models.IntegerField(null = True)class Meta:app_label = &apos;person&apos;db_table = &apos;student&apos; 这两种方式都可行，但是比较推荐使用第一种方式，首先它不用像第二种方式每个class都添加app_label,另外拆分app会使正个项目结构更加清晰明了; 正确的使用和设置Database和Model","categories":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/tags/Django/"}]},{"title":"02 - 重新规划Django项目布局结构和目录结构","slug":"2017-11-10-Django-02","date":"2017-11-10T11:43:00.000Z","updated":"2017-12-04T05:46:33.000Z","comments":true,"path":"2017/11/10/2017-11-10-Django-02/","link":"","permalink":"http://blog.renyimin.com/2017/11/10/2017-11-10-Django-02/","excerpt":"","text":"http://www.loonapp.com/ Django(1.11.7)的默认布局之前当我们使用django-admin.py startproject MyDjangoBog 和 django-admin.py startapp blog 建立新的Django项目时, Django默认的结构如下 123456789101112131415MyDjangoBlog/ manage.py migrations/ __init__.py blog/ __init__.py admin.py models.py tests.py views.py MyDjangoBlog/ __init__.py settings.py urls.py wsgi.py 在Django默认的项目部局中, 存在着一些问题, 特别是在部署到真正的服务器时, 这些问题会越发的明显, 下面我们会一一阐述这些问题 Django项目的设置(settings.py)文件我们应该使用分离式的设置文件, django项目建立时, 会自动生成settings.py文件，为了实现分离式的设置文件, 我们首先删除settings.py, 然后建立settings目录: 123456789settings/ __init__.py base.py # 基本设置文件, 在各个环境中都相同的设置可以放入其中. local.py # 当在开发时使用的设置文件. 可以设置开发时的选项, 包括DEBUG, log的等级, 是否开启例如 django-debug-toolbar等开发工具等 test.py # 运行test时的配置, 包括test runners, in-memory数据库定义和log设置等. release.py # 当部署到预发部服务器上所用的设置 production.py # 当部署到正式服务器上所用的设置 ... # 有时, 一个开发人员的配置文件可能与另一个不同, 这时, 我们可以在settings目录中新建local_name.py 然后我们可以使用以下命令使用这些不同的设置文件： 12python manage.py shell --settings=MyDjangoBlog.settings.localpython manage.py runserver --settings=MyDjangoBlog.settings.local 将关键信息和设置文件分离1.将 SECTET_KEY, AWS key, API key 等关键信息放入设置文件中也是违反基本原则的, 因为: 配置环境不同时关键信息会改变, 程序却不会; 关键信息不是程序; 关键信息应当是隐蔽的, 如果储存在了版本管理系统中, 则任何有权访问该版本库的用户都能获知这些关键信息; 许多PAAS服务无法为每台服务器编辑设置文件, 即使可以, 这也是不正确的做法; 2.环境变量为了避免以上的问题, 我们使用环境变量 (environment variables) 来储存这些关键信息, (需要注意的是, apache不支持环境变量, 我们会在下面讲到), 使用环境变量储存关键信息有以下好处: - 将关键信息从代码中移除, 这样你就可以安心的将所有文件放入版本管理系统中; - 每个开发人员都拥有一样的local.py文件; - 在部署django项目时, 不需要修改程序代码; - 大多数PAAS都推荐这一方法, 并提供了方便的设置方法, 因此容易实现; 3.设置环境变量在使用bash的Mac或Linux中设置环境变量比较容易, 你只需要将以下代码加入.bashrc, .bash_profile, 或 .profile 其中之一即可, 如果多个项目使用相同的API, 并且关键信息都不同时, 可以将以下代码加入到 virtualenv 的 bin/activate 脚本中: 12$ export SOME_SECRET_KEY=654-3jgwg-4r3-2t4h-76jk$ export ANOTHER_SECRET_KEY=y5y-5jk8-75i5h-5g4/.-,o. 如果使用的是windows系统, 则设置稍微复杂一点, 如果使用cmd.exe, 你必须使用setx命令一个一个的设置, 一个较好的方式是使用virtualenv的 bin/activate.bat 1&gt; setx OME_SECRET_KEY=654-3jgwg-4r3-2t4h-76jk PowerShell是Windows Vista及以上自带的shell, 它比cmd.exe强大得多, 因此可以使用PowerShell来设置环境变量: 12345# 为用户User设置[Environment]::SetEnvironmentVariable(&quot;SOME_SECRET_KEY&quot;, &quot;654-3jgwg-4r3-2t4h-76jk&quot;, &quot;User&quot;)# 为全局设置[Environment]::SetEnvironmentVariable(&quot;SOME_SECRET_KEY&quot;, &quot;654-3jgwg-4r3-2t4h-76jk&quot;, &quot;Machine&quot;) 如果你使用virtuanenvwrapper, 那么可以使用virtualenvwrapper的pre-virtualenv设置环境变量, 这样可能会更方便. 如果你使用PAAS, 则请参阅不同的PAAS提供的设置方法. 4.获取环境变量如何在django的settings代码中获取这些关键信息: 123# 在settings/production.py顶部import osSOME_SECRET_KEY = os.environ[&quot;SOME_SECRET_KEY&quot;] 在以上代码中, 如果SOME_SECRET_KEY无法被获取到的话, 就会出现KeyError错误, 导致django项目无法启动. 这很好, 但KeyError没有提供更有 用的信息, 导致debug的困难, 因此, 我们在base.py(希望你还记得这是哪个文件)加入以下function, 为我们提供哪个关键信息无法获取的信息: 1234567891011# settings/base.pyimport os# 通常你不应该从django引入任何代码, 但ImproperlyConfigured是个例外from django.core.exceptions import ImproperlyConfigureddef get_env_variable(var_name): try: return os.environ[var_name] except KeyError: error_msg = &quot;Set the %s environment variable&quot; % var_name raise ImproperlyConfigured(&apos;error_msg&apos;) 然后修改之前的production.py: 123# 在settings/production.py顶部import osSOME_SECRET_KEY = get_env_variable(&apos;SOME_SECRET_KEY&apos;) 此时, 当你没有设置SOME_SECRET_KEY环境变量时, 系统会提示错误信息, 告诉你是哪个环境变量没有设置. 5.无法使用环境变量时当我们使用apache时, 我们会发现, django无法使用环境变量; 这时, 我们推荐将关键信息储存在JSON格式的文件中, 已达到将关键信息和代码分离的目的; 首先我们可以创建secrets.json文件: 1234&#123; &quot;FILENAME&quot;: &quot;secrets.json&quot;, &quot;SOME_SECRET_KEY&quot;: &quot;654-3jgwg-4r3-2t4h-76jk&quot;&#125; 在settings中使用该文件: 123456789101112131415161718# settings/base.pyimport json# 通常你不应该从django引入任何代码, 但ImproperlyConfigured是个例外from django.core.exceptions import ImproperlyConfigured# 读取json文件with open(&quot;secrets.json&quot;) as f: secrets = json.loads(f.read())def get_secret(setting, secrets=secrets): try: return secrets[setting] except KeyError: error_msg = &quot;Set the &#123;0&#125; environment variable&quot;.format(setting) raise ImproperlyConfigured(&apos;error_msg&apos;)SOME_SECRET_KEY = get_secret(&apos;SOME_SECRET_KEY&apos;) 使用不同的部署文件(requirements.txt)1.部署文件(requirements.txt)中储存的是该django项目的依赖库, 一般使用 pip freeze --local生成.本着”只安装需要的模块”的原则, 不同的设置文件, 应当对应不同的requirements.txt文件, 就像分离式的settings文件一样, 我们使用分离式的requirements文件;建立requirements目录, 其结构如下:123456requirements/ base.txt local.txt production.txt release.txt test.txt 在base.txt中, 储存的是所有开发环境中都会用到的依赖库, 例如:123Django==1.6.5psycopg2==2.5.3South==0.8.4 在local.txt中, 储存的是本地开发时用到的依赖库:12345# 导入base.txt中的依赖库-r base.txtcoverage==3.7.1django-debug-toolbar==1.2 2.当重新配置本地开发环境时, 可以使用以下代码安装依赖库:1pip install -r requirements/local.txt 设置文件中的文件路径1.我们强烈反对将绝对路径写入设置文件中, 因为如果将绝对路径写入设置文件中的话, 遇到不同的环境, 就需要重新修改, 给开发和部署带来了许多麻烦 和不确定性. 2.我们推荐使用Unipath来设置media, static和templates的路径. 这样无论部署测试环境如何变化, media和templates文件夹的设置都不会有问题. 123456789# settings/base.py 顶部from unipath import PathBASE_DIR = Path(__file__).ancestor(3)MEDIA_ROOT = BASE_DIR.child(&quot;media&quot;)STAIC_ROOT = BASE_DIR.child(&quot;static&quot;)TEMPLATES_DIRS = ( BASE_DIR.child(&quot;templates&quot;),) 正确的使用和设置Database和Model 截图 组织和设置urls.py 截图 摘自","categories":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/tags/Django/"}]},{"title":"01 - Django入门","slug":"2017-11-10-Django-01","date":"2017-11-10T11:05:00.000Z","updated":"2017-12-01T03:18:20.000Z","comments":true,"path":"2017/11/10/2017-11-10-Django-01/","link":"","permalink":"http://blog.renyimin.com/2017/11/10/2017-11-10-Django-01/","excerpt":"","text":"Python 可以帮我们做很多事情, 包括web开发, 为了让我们的开发更加方便, 和其他脚本语言(比如PHP)一样, Python也有很多web框架, 常见的比如: Django, Pylons, Tornado, Bottle, Flask 等;这里我们要说的是使用比较广泛的 Django; 本篇笔记主要是安装Django, 简单使用Django的一些基本命令, 最终运行一个web应用; Meet Django 简介 “Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. It’s free and open source.” 版本选择: Django版本能够支持的python版本? 本地python 版本: Install Django (Mac) 通过上述了解, 此处采用Django1.11.7版本: pip安装可能会有点慢, 所以采用上图中的源码包下载, 下载完成后解压进入解压包的根目录: 1执行: python setup.py install 如下安装成功: 构建项目 (Django基本命令) 新建一个 Django 项目 12cd ~/Desktop/django-admin.py startproject MyDjangoBlog 项目目录结构如下: 构建应用 (Django基本命令) 先进入项目目录下, 再执行如下命令; 创建应用: 1python manage.py startapp blog 则会在项目目录中创建一个应用: 之后使用Django自带的开发服务器 python manage.py runserver 8080 查看效果: 表示启动成功 另外, 在新建完应用之后, 要让项目知道你有这个应用了 将我们新建的应用(blog)添加到 settings.py 中的 INSTALLED_APPS中，也就是告诉Django有这么一个应用 新建的 app 如果不加到 INSTALL_APPS 中的话, django 就不能自动找到app中的模板文件(app-name/templates/下的文件)和静态文件(app-name/static/中的文件) 其他Django命令 可以使用 python manage.py 看到详细的命令列表 更多Django命令之后会逐渐接触到","categories":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://blog.renyimin.com/tags/Django/"}]},{"title":"06 - Python 环境准备入门 - Anaconda","slug":"2017-10-03-Python-06","date":"2017-10-03T03:05:31.000Z","updated":"2017-12-04T13:59:59.000Z","comments":true,"path":"2017/10/03/2017-10-03-Python-06/","link":"","permalink":"http://blog.renyimin.com/2017/10/03/2017-10-03-Python-06/","excerpt":"","text":"AnacondaAnaconda 是一个用于科学计算的Python发行版, 支持 Linux, Mac, Windows系统, 提供了包管理与环境管理的功能，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题; Anaconda利用工具/命令conda来进行package和environment的管理, 并且已经包含了Python和相关的配套工具; 言而总之, 就是 Anaconda也可以帮我们创建多套独立的Python虚拟环境并进行环境的管理, 同时也提供了对包的管理; 安装Anaconda: 在安装Anaconda之前, 其实不需要安装Python, 因为Anaconda中包括了Python; 直接在Anaconda官网下载并双击进行安装; 安装时，会发现有两个不同版本的Anaconda，分别对应Python 2.7和Python 3.6，两个版本其实除了这点区别外其他都一样。(但其实安装哪个版本并不本质, 因为通过环境管理, 还可以很方便地切换运行时的Python版本) 如下就安装好了: 12renyimindeMacBook-Pro:~ renyimin$ which conda/Users/renyimin/anaconda3/bin/conda Mac、Linux会在主目录下多了个文件夹（~/anaconda） 并且此时, Anaconda会帮你自动设置好宿主机的Python环境为Anaconda自带的Python3.6 12345renyimindeMacBook-Pro:~ renyimin$ python3Python 3.6.3 |Anaconda, Inc.| (default, Oct 6 2017, 12:04:38) [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 直接运行 python, 结果也是Anaconda自带的Python3.6.3了 12345renyimindeMacBook-Pro:~ renyimin$ pythonPython 3.6.3 |Anaconda, Inc.| (default, Oct 6 2017, 12:04:38) [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 而且, 之前我们是有pip2和pip3, 现在直接有pip了, 并且默认版本也是Anaconda自带的pip版本 123renyimindeMacBook-Pro:~ renyimin$ pip -Vpip 9.0.1 from /Users/renyimin/anaconda3/lib/python3.6/site-packages (python 3.6)renyimindeMacBook-Pro:~ renyimin$ 同时, Anaconda还内置了许多非常有用的第三方库, 由于我们现在本机既有Python2(python), 又有Python3.6(python3), 还有Anaconda自带的Python(‘python’), 所以查看包列表也是有三个pip命令可以运行 123pip (Anaconda自带的) list : 会发现有很多内置包pip2 (Mac默认带的) list : 干净的, 需要自己安装pip3 (自己装的Python3) list : 干净的, 需要自己安装 另外, 安装完后, 电脑中多了一些应用: 1234Anaconda Navigtor ：用于管理工具包和环境的图形用户界面，后续涉及的众多管理命令也可以在 Navigator 中手工实现。Jupyter notebook ：基于web的交互式计算环境，可以编辑易于人们阅读的文档，用于展示数据分析的过程。qtconsole ：一个可执行 IPython 的仿终端图形界面程序，相比 Python Shell 界面，qtconsole 可以直接显示代码生成的图形，实现多行代码输入执行，以及内置许多有用的功能和函数。spyder ：一个使用Python语言、跨平台的、科学运算集成开发环境。 安装完成后，我们还需要对所有工具包进行升级，以避免可能发生的错误。打开你电脑的终端，在命令行中输入：conda upgrade --all Conda的环境管理 用户安装的不同python环境都会被放在目录 ~/anaconda3/envs 下，可以在命令中运行 conda info -e 或者 conda env list 查看已安装的环境，当前被激活的环境会显示有一个星号或者括号: 12345renyimindeMacBook-Pro:anaconda3 renyimin$ conda info -e# conda environments:#root * /Users/renyimin/anaconda3 renyimindeMacBook-Pro:anaconda3 renyimin$ 创建一个虚拟环境(并指定python版本) 会提示你需不需要自带一些安装包 (这里需要选择是, 因为会创建一个内置很多第三方库的虚拟环境, 主要是python版本也包含在里面, 所以要选择 y ): 创建完成之后: 123456renyimindeMacBook-Pro:anaconda3 renyimin$ conda info -e# conda environments:#python36 /Users/renyimin/anaconda3/envs/python36root * /Users/renyimin/anaconda3renyimindeMacBook-Pro:anaconda3 renyimin$ 也可以尝试创建python其他的版本, 当然, 和你本机安装的Python版本没有关系, 也不受其限制, 如下安装了Python2.6 1234567renyimindeMacBook-Pro:anaconda3 renyimin$ conda info -e# conda environments:#python26 /Users/renyimin/anaconda3/envs/python26python36 /Users/renyimin/anaconda3/envs/python36root * /Users/renyimin/anaconda3renyimindeMacBook-Pro:anaconda3 renyimin$ 如何激活并进入环境 1234# 安装好后，使用activate激活某个环境activate python34 # for Windowssource activate python36 # for Linux &amp; Mac# 激活后，会发现terminal输入的地方多了python34的字样，实际上，此时系统做的事情就是把默认2.7环境从PATH中去除，再把3.4对应的命令加入PATH 如果想返回默认的python宿主环境 (注意此时宿主环境中的 python 已经成了装完anaconda之后的python了) 12deactivate python36 # for Windowssource deactivate python36 # for Linux &amp; Mac 删除一个已有的环境 1conda remove --name python36 --all Conda的包管理 conda的一些常用操作如下： 1234567891011conda list # 查看当前环境下已安装的包conda list -n python36 # 查看某个指定环境的已安装包conda search numpy # 查找package信息conda install -n python36 numpy # 安装package, 如果不用-n指定环境名称，则被安装在当前活跃环境# 也可以通过-c指定通过某个channel安装# 更新packageconda update -n python36 numpy# 删除packageconda remove -n python36 numpy 前面已经提到，conda将conda自身、python等都视为package，因此，完全可以使用conda来管理conda和python的版本，例如 12345678910111213141516171819# 更新conda，保持conda最新conda update conda# 更新anacondaconda update anaconda# 更新pythonconda update python# 假设当前环境是python 3.4, conda会将python升级为3.4.x系列的当前最新版本# 更新conda，保持conda最新conda update conda# 更新anacondaconda update anaconda# 更新pythonconda update python# 假设当前环境是python 3.4, conda会将python升级为3.4.x系列的当前最新版本 项目需要选择哪个虚拟环境, 直接在Pycharm中指定即可(和virtualenv一样) 设置国内镜像 如果需要安装很多packages，你会发现conda下载的速度经常很慢，因为Anaconda.org的服务器在国外。所幸的是，清华TUNA镜像源有Anaconda仓库的镜像，我们将其加入conda的配置即可： 12345conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/# TUNA的help中镜像地址加有引号，需要去掉 # 设置搜索时显示通道地址conda config --set show_channel_urls yes 到目前为止, 我的机器上有Mac 自带的Python2.7自己安装的Python3.6virtualenv (virtualenvwrapper)后来又装了Anaconda可以随意使用哪个都行, 也可以选择一款自己觉得方便的保留下来即可 (当然, 后两种是比较方便的)! 注意 使用Python虚拟环境的话, 要注意你拿到的Django代码需要进行配置, 因为这个项目不是你在本环境中通过django-admin生成的, 所以你项目中的SECRET_KEY并没有被django管理, 所以你需要在虚拟环境中配置相关信息:(第一项可以不配置, 启动Django server的时候指明使用哪个配置文件即可就行) 使用虚拟环境之后, 如果希望安装Django, 可以针对本环境重新进行安装的, 只要你是在本虚拟环境中, 就可以切换到Django的解压包目录下, 执行 python setup.py install 就相当于给当前虚拟环境安装了Django了; 另外, 你如果使用的是Anaconda, 那么你在当前虚拟环境中如果安装扩展的时候使用的是pip, 那么你用conda list看到的包列表中会说明这个包使用pip安装的, 那么你卸载的时候也要使用 pip uninstall .., 如果你是使用 conda install -n python36 ... 则就要使用 conda remove -n python36 .. 来卸载; 否则卸载的时候就会提示你没有此包; 感觉上还是 virtualenv + pip 比较干净整洁简单一点;","categories":[{"name":"Python","slug":"Python","permalink":"http://blog.renyimin.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.renyimin.com/tags/Python/"}]},{"title":"05 - Python 环境准备入门 - virtualevn","slug":"2017-10-03-Python-05","date":"2017-10-03T02:35:07.000Z","updated":"2017-12-04T12:08:18.000Z","comments":true,"path":"2017/10/03/2017-10-03-Python-05/","link":"","permalink":"http://blog.renyimin.com/2017/10/03/2017-10-03-Python-05/","excerpt":"","text":"前言 我的当前系统是 MacOS Sierra 10.12.6, 默认是自带了python2.7的环境 12345$ pythonPython 2.7.10 (default, Feb 7 2017, 00:08:15) [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.34)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 目前, Python有两个版本, 一个是2.x版, 一个是3.x版, 这两个版本是不兼容的;由于3.x版越来越普及, 所以这里将使用的是Python3.6进行学习; Mac上安装Python3两种方法都非常简单 从Python官网下载Python 3.6的安装程序, 网速慢的同学请移步国内镜像(百度网盘)，双击运行并傻瓜式安装即可, 安装完成之后: 12$ which python3/usr/local/bin/python3 可能也会直接为: 12$ which python3/Library/Frameworks/Python.framework/Versions/3.6/bin/python3 接下来, 卸载我们使用上面这种方法安装的Python3: 1234在安装 Python 时, 其自动生成:- Python framework, 即 Python 框架;- Python 应用目录;- 指向 Python 的连接; 1对于 Mac 自带的 Python, 其框架目录为: /System/Library/Frameworks/Python.framework 1而我们安装的 Python, 其（默认）框架目录为: /Library/Frameworks/Python.framework 1234567接下来, 我们就分别(在 Mac 终端进行)删除上面所提到的三部分, 从而删除我们自己安装的Python- 删除框架: sudo rm -rf /Library/Frameworks/Python.framework/Versions/3.6- 删除应用目录: sudo rm -rf &quot;/Applications/Python 3.6&quot;- 删除/usr/local/bin目录下的Python连接(注意,此处不要乱删, 否则brew install python3这种安装方法都会失效): ls -l /usr/local/bin | grep ‘/Library/Frameworks/Python.framework/Versions/x.x’ | awk ‘&#123;print $9&#125;’ | tr -d @ | xargs rm 如果安装了Homebrew, 也可以直接通过命令 brew install python3 安装即可, 安装完成之后: 注意, 安装的python3.6是需要通过命令python3进入python交互界面的; 1234567891011$ which python3/usr/local/bin/python3$ ls -al /usr/local/bin/python3lrwxr-xr-x 1 renyimin admin 35 12 3 14:41 /usr/local/bin/python3 -&gt; ../Cellar/python3/3.6.3/bin/python3$ python3Python 3.6.3 (default, Oct 4 2017, 06:09:15) [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 卸载也很简单: 1brew uninstall python3 现在, 我的Mac中就有了两个Python环境, 一个是Mac自带的Python2.7, 另一个就是自己安装的Python3.6; pip 在Python中, 安装第三方模块, 是通过包管理工具pip完成的; 如果你正在使用Mac或Linux，安装pip本身这个步骤就可以跳过了。 如果你正在使用Windows，请参考安装Python一节的内容，确保安装时勾选了pip和Add python.exe to Path。 Mac为我们准备了Python2.7的同时, 还默认准备了pip, 另外, 自己安装Python3.6之后, 也同时安装了pip: 自己安装的Python3.6所带的pip需要运行pip3 (注意: Mac或Linux上有可能并存Python 3.x和Python 2.x, 因此对应的pip命令是pip3) 123renyimindembp:bin renyimin$ which pip3/usr/local/bin/pip3renyimindembp:bin renyimin$ 默认安装的pip, 运行需要是 pip2 123renyimindembp:bin renyimin$ which piprenyimindembp:bin renyimin$ which pip2/usr/local/bin/pip2 virtualenv , virtualenvwrappervirtualenv 在使用 Python 开发的过程中, 项目一多,难免会碰到不同的工程依赖不同版本的库的问题, 又或者在开发过程中不想让环境里充斥各种各样的库, 引发未来的依赖灾难; 此时, 就们需要对不同的项目使用不同的环境来保持开发环境以及宿主环境的清洁; 这里, 就要隆重介绍virtualenv, 一个可以帮助我们管理不同 Python 环境的绝好工具; virtualenv : 可以在系统中建立多个不同并且相互不干扰的虚拟环境, 另外, 值得一提的是, 在 virtualenv 的虚拟环境中使用 pip 安装依赖还可以绕过某些系统的权限设置, 因为毕竟不需要向系统目录写入数据 总之, virtualenv是用来创建一个独立的Python虚拟环境的工具, 通过virtualenv可以创建一个拥有独立的python版本和安装库的虚拟开发环境。(这样一来我们就可以在虚拟环境中安装各种各种所需要的库, 从而不会造成本地的库过多所引起的使用混乱, 同时也可以创建不同的python版本来完成不同的需求开发) 由于virtualenv用起来有点麻烦, virtualenvwrapper对它进行了封装, 让它更好用, 最终我们使用virtualenvwrapper提供的命令, 但是实际工作都是virtualenv做的 virtualenv安装 (推荐使用pip安装) 1pip3 install virtualenv 其实直接安装virtualenvwrapper即可, 你会发现 virtualenv 和 virtualenvwrapper 都被安装了: 1234$ pip3 install virtualenvwrapper....Successfully installed virtualenv-15.1.0 virtualenvwrapper-4.8.2 当然, 卸载的时候要一个个地都卸载哦! 创建一个独立的python新环境: virtualenv myEnv_01, 这样就会在当前目录下生成一个myEnv_01目录, 这样, 一个新的python虚拟环境就创建好了, 并且在这个目录下会有3个目录被创建: bin : 包含一些在这个虚拟环境中可用的命令, 以及开启虚拟环境的脚本 activate include : 包含虚拟环境中的头文件, 包括 Python 的头文件; lib : 依赖库 激活虚拟环境: 123先进入虚拟环境目录 myEnv_01 中然后执行: source ./bin/activate 使用source命令启动activate脚本之后, 你的命令行提示符应该会变成这样 1(myEnv_01) renyimindembp:myEnv_01 renyimin$ 此时, 我们就已经在虚拟环境中了, 并且此时即使退出当前虚拟环境的目录, 只要命令提示符是(myEnv_01) renyimindembp:myEnv_01 renyimin$ 就表示我们还在myEnv_01这个虚拟环境中 然后重复上面步骤, 重新安装一个 myEnv_02 虚拟环境 并 激活; 在两个python虚拟环境中各自安装一个test依赖库: 12345678910111213141516# myEnv_01虚拟环境中默认是没有该扩展的(myEnv_01) renyimindembp:myEnv_01 renyimin$ pip3 listDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.pip (9.0.1)setuptools (38.2.3)wheel (0.30.0)(myEnv_01) renyimindembp:myEnv_01 renyimin$ pip3 install test# 之后就有了(myEnv_01) renyimindembp:myEnv_01 renyimin$ pip3 listDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.pip (9.0.1)setuptools (38.2.3)test (2.3.4.5)wheel (0.30.0)(myEnv_01) renyimindembp:myEnv_01 renyimin$ 此时myEnv_02 和 宿主Python环境中 并没有myEnv_01这个虚拟环境中安装的test扩展 1234567renyimindembp:myEnv_02 renyimin$ source ./bin/activate(myEnv_02) renyimindembp:myEnv_02 renyimin$ pip3 listDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.pip (9.0.1)setuptools (38.2.3)wheel (0.30.0)(myEnv_02) renyimindembp:myEnv_02 renyimin$ 1234567891011renyimindembp:~ renyimin$ pip3 listDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.pbr (3.1.1)pip (9.0.1)setuptools (36.5.0)six (1.11.0)stevedore (1.27.1)virtualenv (15.1.0)virtualenv-clone (0.2.6)wheel (0.30.0)renyimindembp:~ renyimin$ 要退出虚拟环境到达宿主环境, 无论在哪个目录下, 只要在虚拟环境中(命令提示符和宿主环境的命令提示符有区别), 直接执行 deactivate 就会退出到宿主python环境中; 如果想要删除虚拟环境, 只要把虚拟环境目录删除即可; virtualenvwrapper 有了virtualenv, 为何还要 virtualenvwrapper ? virtualenv 的一个最大的缺点就是, 每次开启虚拟环境之前, 你都需要去虚拟环境所在目录下的 bin 目录下 source 一下 activate, 这就需要我们记住每个虚拟环境所在的目录; 当然, 你可以将所有的虚拟环境目录全都集中起来, 比如放到 ~/Desktop/virtualenvs/, 这个目录下专门存放所有的虚拟环境, 对不同的虚拟环境使用不同的目录来管理; 而 virtualenvwrapper 正是这样做的, 并且, 它还省去了每次开启虚拟环境时候的 source 操作, 使得虚拟环境更加好用 安装 virtualenvwrapper: 卸载之前安装的 virtualen (因为我们要安装 virtualenvwrapper 的话, 会自动安装 virtualen), 然后直接安装 virtualenvwrapper 先: 1pip3 uninstall virtualenv 然后: 123456789101112renyimindembp:~ renyimin$ pip3 install virtualenvwrapperCollecting virtualenvwrapper Using cached virtualenvwrapper-4.8.2-py2.py3-none-any.whlCollecting virtualenv (from virtualenvwrapper) Using cached virtualenv-15.1.0-py2.py3-none-any.whlRequirement already satisfied: stevedore in /usr/local/lib/python3.6/site-packages (from virtualenvwrapper)Requirement already satisfied: virtualenv-clone in /usr/local/lib/python3.6/site-packages (from virtualenvwrapper)Requirement already satisfied: pbr!=2.1.0,&gt;=2.0.0 in /usr/local/lib/python3.6/site-packages (from stevedore-&gt;virtualenvwrapper)Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.6/site-packages (from stevedore-&gt;virtualenvwrapper)Installing collected packages: virtualenv, virtualenvwrapperSuccessfully installed virtualenv-15.1.0 virtualenvwrapper-4.8.2renyimindembp:~ renyimin$ 现在, 我们就拥有了一个可以管理虚拟环境的神器 接下来要做的比较重要, 那就是对 virtualenvwrapper 进行配置 它需要指定一个环境变量, 叫做 WORKON_HOME, 并且需要运行一下它的初始化工具 virtualenvwrapper.sh, 这个脚本在 /usr/local/bin/ 目录下; WORKON_HOME 就是它将要用来存放各种虚拟环境目录的目录, 这里我们可以设置为 ~/.virtualenvs; 12export WORKON_HOME=&apos;~/.virtualenvs&apos;source /usr/local/bin/virtualenvwrapper.sh 由于每次都需要执行这两步操作, 我们可以将其写入终端的配置文件中; 例如, 如果使用 bash, 则添加到 ~/.bashrc 中; 如果使用 zsh, 则添加到 ~/.zshrc 中; 这样每次启动终端的时候都会自动运行，终端其中之virtualenvwrapper 就可以用啦; 1如果 ~/ 下没有 .bashrc的话, 写到.bash_profile文件中也可以 利用 virtualenvwrapper, 我们可以使用命令 mkvirtualenv myEnv_001 轻松创建一个虚拟环境, 之后我们就有了一个叫做 myEnv_001 的虚拟环境, 它被存放在 $WORKON_HOME/myEnv_001 目录下, 也就是 ~/.virtualenvs/myEnv_001 新建虚拟环境之后会自动激活虚拟环境, 如果我们平时想要进入某个虚拟环境, 可以用命令 workon myEnv_001, 这样才能真正进入激活的虚拟环境中, 并且你的终端提示才会变成 (myEnv_001) renyimindembp:.virtualenvs renyimin$ 同样, 离开虚拟环境, 可以使用 deactivate 删除虚拟环境也一样简单 rmvirtualenv myEnv_001 (不像之前只使用virtualenv那样, 需要手动删除目录来删除一个虚拟环境, 没那么low了) virtualenvwrapper中的其他命令: 1234lsvirtualenv，虚拟环境的列表cdvirtualenv，进入当前激活的虚拟环境cdsitepackages，进入虚拟环境中的site-packages目录lssitepackages，site-packages目录的列表 同时, 你还可以使用 virtualenv 来操作!! 另外, 参考了解到: 命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数 --no-site-packages,这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境, 好像这个参数是默认就有的, 因为测试后发现加和不加都是干净的:123456789renyimindembp:Python renyimin$ ls myEnv_03/lib/python3.6/site-packages/__pycache__ pip-9.0.1.dist-info setuptools-38.2.3.dist-infoeasy_install.py pkg_resources wheelpip setuptools wheel-0.30.0.dist-inforenyimindembp:Python renyimin$ ls myEnv_04/lib/python3.6/site-packages/__pycache__ pip-9.0.1.dist-info setuptools-38.2.3.dist-infoeasy_install.py pkg_resources wheelpip setuptools wheel-0.30.0.dist-info 参考 创建虚拟环境的时候, python版本如何指定 当我的机器上有Python2.7和Python3.6两个Python版本的时候, 那么virtualenv创建的虚拟环境使用哪个Python版本呢? 可以通过 virtualenv -h 查看帮助命令 -p : 指定一个版本python环境, 通常当你的系统中安装了多个python版本时会用到, 默认情况下virtualenv会优先选取它的宿主python环境，也就是它安装在哪个python版本下就会默认选择哪个版本作为默认python隔离环境, 我们使用的是Python3.6带的pip3安装的virtualenv, 所以virtualenv默认安装的就是Python3.6虚拟环境; 如何让某个项目使用指定的虚拟环境 可以在Pycharm中直接指定 按照如下截图指定: 重启PyCharm之后, 会发现, 终端自动进入了之前指定的虚拟环境下: 也可以进入你的虚拟环境之后, 通过命令来运行你某个目录下的项目文件 也就是到现在为止, 我们已经能使用pip来进行第三方库的安装, 并且可以使用 virtualenvwrapper 来方便地管理python虚拟环境了 额外不过到目前, 由于设备中共存的宿主Python版本是两个, 你使用Python3的时候, 还得是运行 python3, 使用python3的pip还得使用 pip3: python 12345renyimindeMacBook-Pro:.virtualenvs renyimin$ pythonPython 2.7.10 (default, Feb 7 2017, 00:08:15) [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.34)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; python3 12345renyimindeMacBook-Pro:.virtualenvs renyimin$ python3Python 3.6.3 (default, Oct 4 2017, 06:09:15) [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 但是后面要讲的Anaconda安装完成之后, 宿主机的python命令直接就会被改为你所安装的anaconda所带的python版本;","categories":[{"name":"Python","slug":"Python","permalink":"http://blog.renyimin.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.renyimin.com/tags/Python/"}]},{"title":"04.与调度器之间通信--系统调用","slug":"2017-05-16-Iterator-generator-yield-04","date":"2017-05-16T14:15:00.000Z","updated":"2017-11-15T03:02:20.000Z","comments":true,"path":"2017/05/16/2017-05-16-Iterator-generator-yield-04/","link":"","permalink":"http://blog.renyimin.com/2017/05/16/2017-05-16-Iterator-generator-yield-04/","excerpt":"","text":"调度器现在已经正常运行了, 下一个问题是：任务和调度器之间的通信 ; 任务和调度器之间的通信: 我们将使用与 进程和操作系统之间会话 所使用的方式来通信: 系统调用 ; 使用 系统调用 这种通信方式的理由是: 操作系统与进程相比, 两者是处在不同的权限级别上, 操作系统为了执行特权级别的操作(如杀死另一个进程), 就不得不以某种方式把控制传回给内核, 这样内核就可以执行所说的操作了;(再说一遍, 这种行为在内部是通过使用中断指令来实现的, 过去使用的是通用的int指令, 如今使用的是更特殊并且更快速的syscall/sysenter指令) 而接下来我们的任务调度系统就要使用这种设计:不是简单地把调度器传递给任务(这样就允许它做它想做的任何事), 我们将通过给yield表达式传递信息来与系统调用通信, 这儿yield既是中断,也是传递信息给调度器(和从调度器传递出信息)的方法; 代码: 任务类: 和之前没什么变化 12345678910111213141516171819202122232425262728293031323334&lt;?phpclass Task &#123; protected $taskId; protected $coroutine; protected $sendValue = null; protected $beforeFirstYield = true; public function __construct($taskId, Generator $coroutine) &#123; $this-&gt;taskId = $taskId; $this-&gt;coroutine = $coroutine; &#125; public function getTaskId() &#123; return $this-&gt;taskId; &#125; public function setSendValue($sendValue) &#123; $this-&gt;sendValue = $sendValue; &#125; public function run() &#123; if ($this-&gt;beforeFirstYield) &#123; $this-&gt;beforeFirstYield = false; return $this-&gt;coroutine-&gt;current(); &#125; else &#123; $this-&gt;coroutine-&gt;send($this-&gt;sendValue); $this-&gt;sendValue = null; &#125; &#125; public function isFinished() &#123; return !$this-&gt;coroutine-&gt;valid(); &#125;&#125; 系统调用:系统调用是操作系统提供给程序设计人员的一种服务,程序设计人员在编写程序时,可以利用系统调用来请求操作系统的服务 12345678910111213&lt;?phpclass SystemCall &#123; protected $callback; public function __construct(callable $callback) &#123; $this-&gt;callback = $callback; &#125; public function __invoke(Task $task, Scheduler $scheduler) &#123; $callback = $this-&gt;callback; return $callback($task, $scheduler); &#125;&#125; 调度器: run方法相比之前做了一些修改 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?phpclass Scheduler &#123; protected $taskId = 0; //protected $taskMap = []; // taskId =&gt; task protected $taskQueue; public function __construct() &#123; $this-&gt;taskQueue = new SplQueue(); &#125; public function newTask(Generator $coroutine) &#123; $taskId = ++$this-&gt;taskId; $task = new Task($taskId, $coroutine); //$this-&gt;taskMap[$taskId] = $task; $this-&gt;schedule($task); return $taskId; &#125; public function schedule(Task $task) &#123; $this-&gt;taskQueue-&gt;enqueue($task); &#125; public function run() &#123; while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; $task = $this-&gt;taskQueue-&gt;dequeue(); $retval = $task-&gt;run(); //如果yield返回的是个系统调用(每个任务第一次的yield返回的就是个系统调用) if ($retval instanceof SystemCall) &#123; echo 123 . PHP_EOL; $retval($task, $this); continue; &#125; if ($task-&gt;isFinished()) &#123; //unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; $this-&gt;schedule($task); &#125; &#125; &#125;&#125; 测试: 12345678910111213141516171819202122232425262728&lt;?phprequire_once \"task.php\";require_once \"scheduler.php\";require_once \"systemCall.php\";function getTaskId() &#123; return new SystemCall(function(Task $task, Scheduler $scheduler) &#123; $task-&gt;setSendValue($task-&gt;getTaskId());//这里主要是在任务运行一开始进行的系统调用中设置任务的id, 并将任务继续压栈 (总共就干两件事), $scheduler-&gt;schedule($task); &#125;);&#125;//系统功能调用是操作系统提供给程序设计人员的一种服务。程序设计人员在编写程序时，可以利用系统调用来请求操作系统的服务//用户程序只在用户态下运行，有时需要访问`系统核心功能`，这时就需要通过系统调用接口来使用 `系统调用`function task($max) &#123; $tid = (yield getTaskId()); // &lt;-- here's the syscall! for ($i = 1; $i &lt;= $max; ++$i) &#123; echo \"This is task $tid iteration $i.\\n\"; yield; &#125;&#125;$scheduler = new Scheduler;//添加两个任务到队列中$scheduler-&gt;newTask(task(10));$scheduler-&gt;newTask(task(5));//运行调度器$scheduler-&gt;run(); 结果和之前的简单任务调度一样; 123456789101112131415161718renyimin$ php index1.php 123 // 可以看到, 总共运行了两次系统调用(每个任务在一开始都是各自运行一次自己的系统调用)123This is task 1 iteration 1. This is task 2 iteration 1.This is task 1 iteration 2.This is task 2 iteration 2.This is task 1 iteration 3.This is task 2 iteration 3.This is task 1 iteration 4.This is task 2 iteration 4.This is task 1 iteration 5.This is task 2 iteration 5.This is task 1 iteration 6.This is task 1 iteration 7.This is task 1 iteration 8.This is task 1 iteration 9.This is task 1 iteration 10. 参考: http://www.laruence.com/2015/05/28/3038.html","categories":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/categories/PHP高级/"},{"name":"Coroutine","slug":"PHP高级/Coroutine","permalink":"http://blog.renyimin.com/categories/PHP高级/Coroutine/"}],"tags":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/tags/PHP高级/"},{"name":"Coroutine","slug":"Coroutine","permalink":"http://blog.renyimin.com/tags/Coroutine/"}]},{"title":"03.PHP - 如何使用协程来实施任务调度","slug":"2017-05-16-Iterator-generator-yield-03","date":"2017-05-16T11:25:00.000Z","updated":"2017-11-29T19:00:42.000Z","comments":true,"path":"2017/05/16/2017-05-16-Iterator-generator-yield-03/","link":"","permalink":"http://blog.renyimin.com/2017/05/16/2017-05-16-Iterator-generator-yield-03/","excerpt":"","text":"从之前的知识可以了解到, 其实(迭代器)生成器 也只不过是一个函数, 不同的是这个函数的返回值是依次返回, 而不是只返回一个单独的值; (也就是说, 生成器使你更方便的实现了迭代器) ; 生成器为可中断的函数, 在它里面的 yield 构成了中断点 ; 再看一个简单的 迭代生成器 进行双向传输信息的 例子 : 1234567891011121314&lt;?phpfunction gen() &#123; $ret = (yield 'yield1'); var_dump($ret); $ret = (yield 'yield2'); var_dump($ret);&#125; $gen = gen();var_dump($gen-&gt;current()); // string(6) \"yield1\"var_dump($gen-&gt;send('ret1')); // string(4) \"ret1\" (the first var_dump in gen) // string(6) \"yield2\" (the var_dump of the -&gt;send() return value)var_dump($gen-&gt;send('ret2')); // string(4) \"ret2\" (again from within gen) // NULL (the return value of -&gt;send()) 那么什么是协程(Coroutine)？ 协程, 又称微线程, 纤程, 英文名Coroutine 和多线程相比, 协程的优势?（1）最大的优势就是协程极高的执行效率, 因为子程序切换不是线程切换, 而是由程序自身控制, 因此, 没有线程切换的开销; 所以, 和多线程比, 当应用的线程数量越多, 换成协程的话, 性能优势就越明显; （2）第二大优势就是不需要多线程的锁机制, 因为只有一个线程, 也不存在同时写变量冲突, 在协程中控制共享资源不加锁, 只需要判断状态就好了, 所以执行效率比多线程高很多; 协程是在应用程序的层面进行切换, 而不是线程级的切换, 所以切换带来的开销很小; 多进程+协程因为协程是一个线程执行, 那怎么利用多核CPU呢?最简单的方法是多进程+协程, 既充分利用多核, 又充分发挥协程的高效率, 可获得极高的性能。 协程（coroutine）跟具有操作系统概念的线程不一样, 实际上协程就是类函数一样的程序组件, 你可以在一个线程里面轻松创建数十万个协程,就像数十万次函数调用一样。只不过函数只有一个调用入口起始点, 返回之后就结束了, 而协程入口既可以是起始点, 又可以从上一个返回点继续执行, 也就是说协程之间可以通过 yield 方式转移执行权, 对称（symmetric）、平级地调用对方, 而不是像函数那样上下级调用关系;当然协程也可以模拟函数那样实现上下级调用关系, 这就叫非对称协程（asymmetric coroutines）; 注意： yield表达式两边的括号在PHP7以前不是可选的, 也就是说在PHP5.5和PHP5.6中圆括号是必须的 ; …. 协程特点: 为应用层实现多任务提供了工具; 协程不允许多任务同时执行，要执行其它协程，必须使用关键字yield主动放弃cpu控制权; 协程需要自己写任务管理器，以及任务调度器； 减轻了OS处理零散任务和轻量级任务的负 使用协程实现多任务协作，我们要解决的问题是你想并发地运行多任务(或者”程序”), 不过我们都知道CPU在一个时刻只能运行一个任务(不考虑多核的情况), 因此处理器需要在不同的任务之间进行切换,而且总是让每个任务运行 一小会儿 ; 多任务协作 这个术语中的”协作”很好的说明了如何进行这种切换的: 首先, 我们是通过调度器来调度每个任务运行的, 它而所谓协作就是要求当前正在运行的任务自动把控制传回给调度器, 这样就调度器就可以调度其他任务来运行了 ; 现在你应当明白 协程 和 任务调度 之间的关系: yield指令提供了任务中断自身的一种方法, 然后把控制交回给任务调度器, 因此协程可以运行多个任务; 更进一步, yield还可以用来在任务和调度器之间进行通信 ; 可以这么理解 :调度器在调度任务的时候, 是通过模拟一个队列, 然后将使用调度器创建任务(其实就是将多个任务压栈), 之后由于每个任务执行一次就会执行出栈, 并且就任务会通过yield中断当前任务并将控制权交给调度器, 调度器就可以通过这样就实现了轮询的方式执行多个任务 ; 小疑问: 12345678&lt;?phpfunction gen() &#123; yield 'foo'; yield 'bar';&#125;$gen = gen();var_dump($gen-&gt;send('something')); // 鸟哥博客相关讨论小结: // 在send之前, 如果没有显示地调用current, 那么当$gen迭代器被创建的时候一个rewind()方法已经被隐式调用 // 所以实际上发生的应该类似: 123456789&lt;?phpfunction gen() &#123; yield 'foo'; yield 'bar';&#125;$gen = gen();var_dump($gen-&gt;rewind()); //不过可惜的是, rewind的执行将虽然会导致第一个yield被执行, 但是却会忽略他的返回值.var_dump($gen-&gt;send('something')); // 真正当我们调用yield的时候, 我们得到的是第二个yield的值! 导致第一个yield的值被忽略. 先看一个简单的任务调度程序: 通过模拟cpu轮询来调度两个 循环打印的任务 任务类: 主要作用是在其内部将一个用轻量级的包装的协程函数手动进行迭代 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?phpclass Task &#123; protected $taskId; protected $coroutine; protected $sendValue = null; //在此处暂时还没有用 //通过添加 firstYieldTag 我们可以保证第一处 yield 的值能被正确返回, 因为之前我们已经了解到: //对生成器生成的迭代器进行手动迭代的话, 如果在send之前, 没有显示地调用current, 那么当迭代器被创建的时候一个rewind会默认执行, 但是不会有返回; //所以针对第一处yield, 要想看到返回值, 我们需要手动调用current protected $firstYieldTag = true; public function __construct($taskId, Generator $coroutine) &#123; $this-&gt;taskId = $taskId; $this-&gt;coroutine = $coroutine; &#125; public function getTaskId() &#123; return $this-&gt;taskId; &#125; // 使用setSendValue()方法, 你可以指定哪些值将被发送到下次的恢复(现在暂时不会用到, 在之后会用到) public function setSendValue($sendValue) &#123; $this-&gt;sendValue = $sendValue; &#125; //其实就是在这个run方法中做的手动迭代 public function run() &#123; if ($this-&gt;firstYieldTag) &#123; $this-&gt;firstYieldTag = false; // 第一次调用之后就进行标识 $this-&gt;coroutine-&gt;current(); &#125; else &#123; $this-&gt;coroutine-&gt;send($this-&gt;sendValue); $this-&gt;sendValue = null; &#125; &#125; public function isFinished() &#123; return !$this-&gt;coroutine-&gt;valid(); &#125;&#125; 调度器类: 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?phpclass Scheduler &#123; protected $taskId = 0; //protected $taskMap = []; // taskId =&gt; task protected $taskQueue; //调度器初始化其实就是简单创建了一个队列 public function __construct() &#123; $this-&gt;taskQueue = new SplQueue(); &#125; public function newTask(Generator $coroutine) &#123; $taskId = ++$this-&gt;taskId;//简单通过递增的方法来设置 任务的唯一标识 任务id $task = new Task($taskId, $coroutine);//通过 任务id 和 迭代器的生成器 来创建任务 //将创建好的任务和任务id对应起来 存入数组 //$this-&gt;taskMap[$taskId] = $task; $this-&gt;schedule($task); return $taskId; &#125; //添加任务到队列 public function schedule(Task $task) &#123; $this-&gt;taskQueue-&gt;enqueue($task); &#125; //运行调度器, 这里是模拟cpu并发 轮询执行任务的关键 (通过不断地将任务出栈和压栈) public function run() &#123; //如果任务队列不为空 while (!$this-&gt;taskQueue-&gt;isEmpty()) &#123; //将任务弹出队列 准备运行任务 $currentTask = $this-&gt;taskQueue-&gt;dequeue(); //然后运行任务 (其实每个任务就是 迭代器生成器 生成的 迭代器) //这里run其实就是对队列中的任务进行了 '一次' 迭代 $currentTask-&gt;run(); // 如果弹出队列的任务(迭代器)如果运行结束(即 迭代器对象循环结束), 则从任务数组中删除任务 if ($currentTask-&gt;isFinished()) &#123; //unset($this-&gt;taskMap[$task-&gt;getTaskId()]); &#125; else &#123; //如果任务没有运行结束则继续将任务压入队列 $this-&gt;schedule($currentTask); &#125; &#125; &#125;&#125; 测试: 1234567891011121314151617181920212223242526&lt;?phprequire_once \"task.php\";require_once \"scheduler.php\"; //第一个任务(一个`迭代器生成器`):function task1() &#123; for ($i = 1; $i &lt;= 10; ++$i) &#123; echo \"This is task 1 iteration $i.\\n\"; yield; &#125;&#125;//第二个任务(一个`迭代器生成器`):function task2() &#123; for ($i = 1; $i &lt;= 5; ++$i) &#123; echo \"This is task 2 iteration $i.\\n\"; yield; &#125;&#125; $scheduler = new Scheduler;//创建两个任务到调度器的队列中$scheduler-&gt;newTask(task1());$scheduler-&gt;newTask(task2());//运行调度器$scheduler-&gt;run(); 结果: 果然是两个任务交替执行各自的循环 12345678910111213141516renyimin$ php index.phpThis is task 1 iteration 1.This is task 2 iteration 1.This is task 1 iteration 2.This is task 2 iteration 2.This is task 1 iteration 3.This is task 2 iteration 3.This is task 1 iteration 4.This is task 2 iteration 4.This is task 1 iteration 5.This is task 2 iteration 5.This is task 1 iteration 6.This is task 1 iteration 7.This is task 1 iteration 8.This is task 1 iteration 9.This is task 1 iteration 10. 参考: http://www.laruence.com/2015/05/28/3038.html","categories":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/categories/PHP高级/"},{"name":"Coroutine","slug":"PHP高级/Coroutine","permalink":"http://blog.renyimin.com/categories/PHP高级/Coroutine/"}],"tags":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/tags/PHP高级/"},{"name":"Coroutine","slug":"Coroutine","permalink":"http://blog.renyimin.com/tags/Coroutine/"}]},{"title":"02.PHP - Generator (迭代)生成器","slug":"2017-05-13-Iterator-generator-yield-02","date":"2017-05-13T04:15:00.000Z","updated":"2017-11-29T18:56:50.000Z","comments":true,"path":"2017/05/13/2017-05-13-Iterator-generator-yield-02/","link":"","permalink":"http://blog.renyimin.com/2017/05/13/2017-05-13-Iterator-generator-yield-02/","excerpt":"","text":"Generator (迭代)生成器 之所以叫 迭代生成器, 是因为这个生成器(就是一个包含yield关键字的函数)生成的东西是个迭代器对象;( 参考PHP: 生成器类的结构, 会发现生成器这个类也确实实现了迭代器接口); 生成器函数 的核心是 yield 关键字 它最简单的调用形式看起来像 return 的用法, 但普通 return 会返回值并终止函数的执行; 而 yield 会返回一个值给循环调用此生成器的代码, 并且只是暂停 生成器函数的运行; 暂停当前过程，意味着将处理权转交由上一级继续进行，直至上一级再次调用被暂停的 生成器函数，则生成器函数会从上一次暂停的位置继续执行; 当然, yield 更重要的特性是除了可以返回一个值以外, 还能够接收一个值 参考PHP: 生成器类的结构, 可以看到 Generator 类除了实现 Iterator 接口中的必要方法以外, 还有一个 send 方法, 这个方法就是向 yield 语句处传递一个值, 同时从 yield 语句处继续执行, 直至再次遇到 yield 后控制权回到外部 ; 当然, 此时是先返回yield处的值, 然后再将接收到的外部值作用于另一个表达式(可能直接打印或者赋值给另一个变量); 测试代码: 12345678910111213141516171819202122232425262728&lt;?phpfunction printer()&#123; $i = 0; while (true) &#123; echo 123 . \"\\n\"; //同时进行接收和发送 （先返回 yield 后面的值, 然后才将 接收到的值 作用于 printf函数） printf(\"receive: %s\\n\", (yield ++$i)); echo 456 . \"\\n\"; &#125;&#125;$printer = printer();printf(\"%d\\n\", $printer-&gt;current()); //123 //1 碰到yield则中断, 将$i发出, 并将控制权交给外部的调度器var_dump($printer-&gt;send('hello')); //receive: hello 调度器再次调度,继续开始 //456 //123 //int(2) 碰到yield则中断, 将$i发出, 并将控制权交给外部的调度器printf(\"%d\\n\", $printer-&gt;current()); //yield发出的当前值果然是2var_dump($printer-&gt;send('world')); //receive: world 调度器再次调度,继续开始 //456 //123 //int(3)碰到yield则中断, 将$i发出, 并将控制权交给外部的调度器printf(\"%d\\n\", $printer-&gt;current());//yield发出的当前值果然是3 这儿yield没有作为一个语句来使用, 而是用作一个表达式, 这样, 这个yield表达式 能被演化成一个值, 这个值就是调用者传递给send()方法的值; 到这里, 我们看到 yield 可以在其位置同时进行 接收 和 返回 (双向传递), 当然, 这是实现 协程 的根本; 补充 ： 另外, 我们可以使用生成器来重新实现 range() 函数, 标准的 range() 函数需要在内存中生成一个数组包含每一个在它范围内的值，然后返回该数组, 结果就是会产生多个很大的数组。 比如, 调用 range(0, 1000000) 将导致内存占用超过 100 MB ; 做为一种替代方法, 我们可以实现一个 xrange() 生成器, 只需要足够的内存来创建 Iterator 对象并在内部跟踪生成器的当前状态，这样只需要不到1K字节的内存; 例子: 即使你打印100W个键值对, 也不一次性将这些简直对放入变量中导致内存爆掉 12345678910&lt;?phpfunction xrange($start, $limit, $step = 1) &#123; for ($i = $start; $i &lt;= $limit; $i += $step) &#123; yield $i + 1 =&gt; $i; &#125;&#125;foreach (xrange(0, 10000000000, 2) as $key =&gt; $value) &#123; printf(\"%d =&gt; %d\" . PHP_EOL, $key, $value);&#125; 参考: https://www.insp.top/article/php-knowledge-completion-generator-and-the-realization-of-coroutine","categories":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/categories/PHP高级/"},{"name":"Coroutine","slug":"PHP高级/Coroutine","permalink":"http://blog.renyimin.com/categories/PHP高级/Coroutine/"}],"tags":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/tags/PHP高级/"},{"name":"Coroutine","slug":"Coroutine","permalink":"http://blog.renyimin.com/tags/Coroutine/"}]},{"title":"01.PHP - Iterator (迭代器) 接口简介","slug":"2017-05-13-Iterator-generator-yield-01","date":"2017-05-13T03:05:00.000Z","updated":"2017-11-15T02:38:25.000Z","comments":true,"path":"2017/05/13/2017-05-13-Iterator-generator-yield-01/","link":"","permalink":"http://blog.renyimin.com/2017/05/13/2017-05-13-Iterator-generator-yield-01/","excerpt":"","text":"迭代: 可以理解为是指反复执行一个过程, 每执行一次叫做一次迭代; 在php中我们经常做迭代, 如下: 12345678910&lt;?php$mapping = ['red' =&gt; '#FF0000','green' =&gt; '#00FF00','blue' =&gt; '##0000FF'];foreach ($mapping as $key =&gt; $value) &#123;printf(\"key: %d - value: %s \\n\", $key, $value);&#125; 上述代码通过foreach对数组遍历并迭代输出其内容, 在foreach内部, 每次迭代都会将当前的元素的值赋给$value并将数组的指针移动指向下一个元素为下一次迭代做准备,从而实现顺序遍历;像这样能够让外部的迭代自己内部数据的接口就是迭代器接口;对应的那个被迭代的对象(这里是数组), 其实就是迭代器对象; PHP中提供的迭代器接口和类 PHP提供了统一的迭代器接口预定义接口中; SPL标准库中也提供了多种迭代器类; 简单实现一个迭代器 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?phpclass Xrange implements Iterator&#123; protected $start; protected $limit; protected $step; protected $i; public function __construct($start, $limit, $step = 0) &#123; $this-&gt;start = $start; $this-&gt;limit = $limit; $this-&gt;step = $step; &#125; public function rewind() &#123; $this-&gt;i = $this-&gt;start; &#125; public function next() &#123; $this-&gt;i += $this-&gt;step; &#125; public function current() &#123; return $this-&gt;i; &#125; public function key() &#123; return $this-&gt;i; &#125; public function valid() &#123; return $this-&gt;i &lt;= $this-&gt;limit; &#125;&#125;foreach (new Xrange(0, 10, 2) as $key =&gt; $value) &#123; printf(\"%d %d\" . PHP_EOL, $key, $value);&#125; 1234567$ php Iterator.php 0 02 24 46 68 810 10 补充: 可以将一个普通对象变成一个可被遍历的对象, 场景: 如一个StudentsContact对象, 这个对象是用于处理学生联系方式的, 通过 addStudent 方法注册学生, 通过 getAllStudent 获取全部注册的学生联系方式数组(比如获取一页学生联系方式列表), 我们以往是通过 StudentsContact::getAllStudent() 获取一个数组然后遍历该数组, 但是现在有了迭代器, 只要这个类继承这个接口, 就可以直接遍历该对象获取学生数组, 并且可以在获取之前在类的内部就对输出的数据做好处理工作; PHP的迭代器可以让你利用 面向对象 实现常见的数据结构, 例如列表, 堆栈, 队列与图 ; (有助于你使用纯面向对象的思想来设计你的程序)特别说明一下 对对象的遍历, 一般人觉得所谓的遍历对象*就是对一个对象里的属性或者方法一个一个的取出来, 然后做输出或者处理; 实际上, 这里的迭代器对对象的遍历并不是这个意思, 可能这句话本身的描述有问题, 比如, 可以使用迭代器模拟一个字符串对象的迭代器类, 让PHP可以对这个字符串对象进行遍历; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?phpclass String implements Iterator&#123; private $string; public function __construct($string) &#123; $this-&gt;string = $this-&gt;strToArray($string); &#125; private function strToArray($string, $l = 0) &#123; //if ($l &gt; 0) &#123; //$ret = array(); //$len = mb_strlen($string, \"UTF-8\"); //for ($i = 0; $i &lt; $len; $i += $l) &#123; //$ret[] = mb_substr($string, $i, $l, \"UTF-8\"); //&#125; //return $ret; //&#125; return preg_split(\"//u\", $string, -1, PREG_SPLIT_NO_EMPTY); &#125; public function current() &#123; return current($this-&gt;string); &#125; public function next() &#123; return next($this-&gt;string); &#125; public function key() &#123; return key($this-&gt;string); &#125; public function valid() &#123; if (key($this-&gt;string) === null) &#123; return false; &#125; else &#123; return true; &#125; &#125; public function rewind() &#123; reset($this-&gt;string); &#125;&#125;$string = new String('这个是什么213jdjlf');foreach ($string as $k =&gt; $v) &#123; echo \"&#123;$k&#125; =&gt; &#123;$v&#125;\" . \"&lt;br/&gt;\";&#125;结果:0 =&gt; 这1 =&gt; 个2 =&gt; 是3 =&gt; 什4 =&gt; 么5 =&gt; 26 =&gt; 17 =&gt; 38 =&gt; j9 =&gt; d10 =&gt; j11 =&gt; l12 =&gt; f","categories":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/categories/PHP高级/"},{"name":"Coroutine","slug":"PHP高级/Coroutine","permalink":"http://blog.renyimin.com/categories/PHP高级/Coroutine/"}],"tags":[{"name":"PHP高级","slug":"PHP高级","permalink":"http://blog.renyimin.com/tags/PHP高级/"},{"name":"Coroutine","slug":"Coroutine","permalink":"http://blog.renyimin.com/tags/Coroutine/"}]},{"title":"02 - 分布式锁","slug":"2017-04-13-distributed-02","date":"2017-04-13T12:03:09.000Z","updated":"2017-12-07T13:07:00.000Z","comments":true,"path":"2017/04/13/2017-04-13-distributed-02/","link":"","permalink":"http://blog.renyimin.com/2017/04/13/2017-04-13-distributed-02/","excerpt":"","text":"分布式锁","categories":[{"name":"分布式","slug":"分布式","permalink":"http://blog.renyimin.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://blog.renyimin.com/tags/分布式/"}]},{"title":"05 - 分布式","slug":"2017-04-17-distributed-05","date":"2017-04-13T12:03:09.000Z","updated":"2017-12-07T13:07:56.000Z","comments":true,"path":"2017/04/13/2017-04-17-distributed-05/","link":"","permalink":"http://blog.renyimin.com/2017/04/13/2017-04-17-distributed-05/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://blog.renyimin.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://blog.renyimin.com/tags/分布式/"}]},{"title":"01 - 分布式","slug":"2017-04-13-distributed-01","date":"2017-04-13T05:20:31.000Z","updated":"2017-12-07T13:07:12.000Z","comments":true,"path":"2017/04/13/2017-04-13-distributed-01/","link":"","permalink":"http://blog.renyimin.com/2017/04/13/2017-04-13-distributed-01/","excerpt":"","text":"数据一致性问题","categories":[{"name":"分布式","slug":"分布式","permalink":"http://blog.renyimin.com/categories/分布式/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://blog.renyimin.com/tags/分布式/"}]},{"title":"02 - 并发写问题","slug":"2017-04-09-concurrency-02","date":"2017-04-11T14:19:27.000Z","updated":"2017-12-11T14:04:51.000Z","comments":true,"path":"2017/04/11/2017-04-09-concurrency-02/","link":"","permalink":"http://blog.renyimin.com/2017/04/11/2017-04-09-concurrency-02/","excerpt":"","text":"初级并发写的问题保证并发写的数据安全问题MySQL锁并发测试抢购超卖问题 代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?phpnamespace App\\Http\\Controllers\\Test;use App\\Http\\Models\\Test\\Goods;use Illuminate\\Http\\Request;use App\\Http\\Requests;use App\\Http\\Controllers\\Controller;use Illuminate\\Support\\Facades\\DB;/** * 主要做一些高并发测试 * Class ConcurrencyController * @package App\\Http\\Controllers */class ConcurrencyController extends Controller&#123; /* DROP TABLE IF EXISTS `goods`; CREATE TABLE `goods` ( `id` int(10) NOT NULL AUTO_INCREMENT, `goods_name` varchar(100) NOT NULL, `num` int(100) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; INSERT INTO `goods` VALUES (1, 'iphone 6 plus', 10); */ /** * mysql模拟并发写(修改)数据 * Jmeter模拟调用10次 */ public function analogueConcurrencyByMySql() &#123; $good = Goods::select('num')-&gt;find(1); if ($good['num']&gt;0) &#123; //增加代复杂度,不然超卖不好模拟出来 usleep(500000); $res = Goods::where(['id' =&gt; 1])-&gt;decrement('num', 1);//-&gt;update(['num' =&gt; $good['num']-1]); &#125; &#125; /** * 乐观锁测试 */ public function mysqlOptimisticLock() &#123; $good = Goods::select('num')-&gt;find(1); if ($good['num']&gt;0) &#123; //增加代复杂度,不然超卖不好模拟出来 usleep(500000); Goods::where(['id' =&gt; 1])-&gt;where('num', '&gt;', '0')-&gt;decrement('num', 1);//-&gt;update(['num' =&gt; $good['num']-1]); &#125; &#125; /** * 悲观锁测试(没有事务, 测试失败) */ public function mysqlPessimisticLock1() &#123; $good = Goods::select('num')-&gt;lockForUpdate()-&gt;find(1); if ($good['num']&gt;0) &#123; //增加代复杂度,不然超卖不好模拟出来 usleep(500000); Goods::where(['id' =&gt; 1])-&gt;decrement('num', 1);//-&gt;update(['num' =&gt; $good['num']-1]); &#125; &#125; /** * 悲观锁测试(有事务, 测试成功) */ public function mysqlPessimisticLock2() &#123; try&#123; DB::beginTransaction(); $good = Goods::select('num')-&gt;lockForUpdate()-&gt;find(1); if ($good['num']&gt;0) &#123; //增加代复杂度,不然超卖不好模拟出来 usleep(500000); Goods::where(['id' =&gt; 1])-&gt;decrement('num', 1);//-&gt;update(['num' =&gt; $good['num']-1]); &#125; DB::commit(); &#125; catch(\\Exception $e) &#123; DB::rollback(); &#125; &#125;&#125; 悲观锁必须配合事务使用 Redis锁的利用 Redis的事务涉及到的WATCH Redis原子锁 memcached锁https://github.com/Yurunsoft/YurunLock 场景 如: 并发减少库存如何保证不超卖利用Redis锁 如:","categories":[{"name":"高并发","slug":"高并发","permalink":"http://blog.renyimin.com/categories/高并发/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"http://blog.renyimin.com/tags/高并发/"}]},{"title":"01 - 并发读问题","slug":"2017-04-09-concurrency-01","date":"2017-04-09T11:16:54.000Z","updated":"2017-12-07T12:58:03.000Z","comments":true,"path":"2017/04/09/2017-04-09-concurrency-01/","link":"","permalink":"http://blog.renyimin.com/2017/04/09/2017-04-09-concurrency-01/","excerpt":"","text":"初级并发读的问题如何尽可能承载更高的并发访问量","categories":[{"name":"高并发","slug":"高并发","permalink":"http://blog.renyimin.com/categories/高并发/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"http://blog.renyimin.com/tags/高并发/"}]},{"title":"07.小结 \"Jsonp\" 对比 \"CORS简单/非简单请求\"","slug":"2016-09-21-sameoriginpolicy-07","date":"2016-09-21T13:20:16.000Z","updated":"2017-10-28T02:30:36.000Z","comments":true,"path":"2016/09/21/2016-09-21-sameoriginpolicy-07/","link":"","permalink":"http://blog.renyimin.com/2016/09/21/2016-09-21-sameoriginpolicy-07/","excerpt":"","text":"Jsonp 对比 CORS简单/非简单请求都可以方便实现跨域; Jsonp简单适用, 老式浏览器全部支持, 服务器端改动很小; 但是JSONP只能发GET请求; JSONP跨域发送Cookie的话, 只用设置好cookie的domain属性为顶级域名即可 ; CORS简单请求服务端需要设置一些允许选项; 发送请求为 GET, POST, HEAD ; 跨域发送cookie的话, 不仅需要设置cookie的domain属性, 服务端和客户端都要对Credentials header属性进行设置;跨域发送cookie的话, 服务端 Access-Control-Allow-Origin 不能设置为 * , 否则会提示 :123Failed to load http://test.test.com/index.php?sex=renyimin&amp;age=100: The value of the 'Access-Control-Allow-Origin' header in the response must not be the wildcard '*' when the request's credentials mode is 'include'. Origin 'http://www.test.com' is therefore not allowed access. The credentials mode of requests initiated by the XMLHttpRequest is controlled by the withCredentials attribute. CORS非简单请求服务端需要设置一些允许选项; 发送其他请求 (PUT) .. 可以设置自定义header头 cookie方面和 CORS简单请求一样","categories":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/categories/CrossDomain/"}],"tags":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/tags/CrossDomain/"}]},{"title":"06.Ajax请求不能发送 之 \"CORS方案 -- (not-so-simple request)\"","slug":"2016-09-18-sameoriginpolicy-06","date":"2016-09-18T12:10:16.000Z","updated":"2017-10-27T10:15:27.000Z","comments":true,"path":"2016/09/18/2016-09-18-sameoriginpolicy-06/","link":"","permalink":"http://blog.renyimin.com/2016/09/18/2016-09-18-sameoriginpolicy-06/","excerpt":"","text":"预检请求 preflight 说明1.非简单请求是那种对服务器有特殊要求的请求, 比如请求方法是 PUT 或 DELETE, 或者 Content-Type 字段的类型是 application/json ; 2.非简单请求的CORS请求, 会在正式通信之前, 增加一次HTTP查询请求, 称为 &quot;预检&quot;请求(preflight) ; 浏览器先询问服务器, 当前网页所在的域名是否在服务器的许可名单之中, 以及可以使用哪些HTTP动词和头信息字段; 只有得到肯定答复, 浏览器才会发出正式的XMLHttpRequest请求, 否则就报错 ; 3.非简单请求会导致原先的一次请求变成两次, 第一次请求是 预检请求 ; 4.”预检”请求用的请求方法是 OPTIONS，表示这个请求是用来询问的，头信息里面关键字段是Origin，表示请求来自哪个源 ; 非简单请求的例子1.www.test.com/index.php 本例子使用 PUT 来进行ajax请求, 满足 非简单请求 的条件 ; 另外, 本例还自定义了请求时的 header 首部字段, 也满足 非简单请求 的条件 ; 1234567891011121314151617181920212223242526272829303132333435363738&lt;?php?&gt;&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"https://cdn.staticfile.org/jquery/3.1.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" &gt; $(document).ready(function()&#123; $(\"#btn\").click(function() &#123; //序列化name/value var data = $(\"form\").serializeArray(); $.ajax(&#123; //这里用PUT, 则为 `非简单` 请求 type: 'PUT', url: 'http://test.test.com/index.php', dataType: 'json', data: data, //或者如果你自定义了一些请求时的 header 首部字段, 那么请求就也是 复杂请求 headers: &#123;\"custom-header-field\" : \"test\"&#125;, success: function (result) &#123; console.log(result); &#125;, timeout: 3000 &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form name=\"form\"&gt; &lt;input type=\"text\" name=\"sex\"&gt; &lt;input type=\"text\" name=\"age\"&gt; &lt;input type=\"button\" id=\"btn\" value=\"button\" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 2.test.test.com/index.php 12345678910&lt;?php//服务器允许的 Originheader(\"Access-Control-Allow-Origin: http://www.test.com\");//服务器允许的 methodsheader(\"Access-Control-Allow-Methods: PUT, GET, POST\");//服务器允许设置的头部字段header(\"Access-Control-Allow-Headers: custom-header-field\");$arguments = file_get_contents('php://input');echo json_encode(['arguments' =&gt; $arguments]); 3.注意: 像上面例子的复杂跨域请求 必须: 首先和简单请求一样, 服务器端的 Access-Control-Allow-Origin 是必须设置的, 不然首先就跨不了域; 必须: 其次, 是使用了 get, post, head 之外方法的 复杂请求, 那么就必须在服务端有对应的 Access-Control-Allow-Method, 否则: 可选: 如果你自定义了 自定义首部字段 的 复杂请求, 那么也要在服务端有对应的 Access-Control-Allow-Headers, 否则: 4.另外需要关注的是: 如果你设置了自定义的首部字段, 那么即使你的请求类型是get, post, head, 自然也是复杂请求, 此时的HTTP请求方法显示的仍然如下: Request Method:OPTIONS 分析预检请求1.上面www.test.com/index.php代码进行ajax请求的时候, HTTP请求的方法是PUT, 所以浏览器会发现, 这是一个非简单请求, 就自动发出一个”预检”请求, 要求服务器确认可以这样请求 ; 2.所以请求应该是包括预检请求和真正的请求两个请求的: 3.下面是这个”预检”请求的HTTP头信息 和 回应信息: 4.可以看到, “预检”请求用的请求方法是OPTIONS, 表示这个请求是用来询问的, 头信息里面, 关键字段是Origin, 表示请求来自哪个源; 除了Origin字段，”预检”请求的头信息包括两个特殊字段:(1)Access-Control-Request-Method ：该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT ;(2)Access-Control-Request-Headers：该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段, 上例是X-Custom-Header ; 分析预检响应1.从下面预检请求的截图中，可以看到预检请求的回应中, 服务器收到”预检”请求以后, 检查了 Origin、Access-Control-Request-Method 和 Access-Control-Request-Headers 字段以后，确认允许跨源请求，就可以做出回应 ; 并且预检请求部分是不会真的发送数据的: 2.上面的HTTP回应中，关键的是 Access-Control-Allow-Origin 字段，表示 http://www.test.com 可以请求数据, 该字段也可以设为星号，表示同意任意跨源请求 ; 123Access-Control-Allow-Origin: http://www.test.com或者Access-Control-Allow-Origin: * 3.如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段 ; 这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被 XMLHttpRequest 对象的 onerror 回调函数捕获; 控制台会打印出如下的报错信息 ; 4.服务器还可能回应的其他CORS相关字段如下: 1234Access-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderAccess-Control-Allow-Credentials: trueAccess-Control-Max-Age: 1728000 （1）Access-Control-Allow-Methods 该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次&quot;预检&quot;请求。 （2）Access-Control-Allow-Headers 如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在&quot;预检&quot;中请求的字段。 （3）Access-Control-Allow-Credentials 该字段与简单请求时的含义相同。 （4）Access-Control-Max-Age 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 测试代码cors请求是否允许包含cookie?(和CORS简单请求是一样的要求) www.test.com/index.php 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?phpsetcookie('address', json_encode(['city' =&gt; 'yuncheng', 'town' =&gt; 'xiaoliang']), 0, '/', '.test.com');?&gt;&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"https://cdn.staticfile.org/jquery/3.1.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" &gt; $(document).ready(function()&#123; $.ajaxSetup(&#123;crossDomain: true, xhrFields: &#123;withCredentials: true&#125;&#125;); $(\"#btn\").click(function() &#123; //序列化name/value var data = $(\"form\").serializeArray(); $.ajax(&#123; //这里用PUT, 则为 `非简单` 请求 type: 'PUT', url: 'http://test.test.com/index.php', dataType: 'json', data: data, //或者如果你自定义了一些请求时的 header 首部字段, 那么请求就也是 复杂请求 headers: &#123;\"custom-header-field\" : \"test\"&#125;, success: function (result) &#123; console.log(result); &#125;, timeout: 3000 &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form name=\"form\"&gt; &lt;input type=\"text\" name=\"sex\"&gt; &lt;input type=\"text\" name=\"age\"&gt; &lt;input type=\"button\" id=\"btn\" value=\"button\" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; test.test.com 12345678910111213&lt;?php//服务器允许的 Origin (如果要发送cookie的话复杂请求也不能为*)header(\"Access-Control-Allow-Origin: http://www.test.com\");//服务器允许的 methodsheader(\"Access-Control-Allow-Methods: PUT, GET, POST\");//服务器允许设置的头部字段header(\"Access-Control-Allow-Headers: custom-header-field\");//要跨子域发cookie, 这个自然不能少header(\"Access-Control-Allow-Credentials: true\");$arguments = file_get_contents('php://input');$address = $_COOKIE['address'];echo json_encode(['arguments' =&gt; $arguments, 'cookie' =&gt; $address]); 参考 CORS","categories":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/categories/CrossDomain/"}],"tags":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/tags/CrossDomain/"}]},{"title":"05.Ajax请求不能发送 之 \"CORS方案 -- (simple request)\"","slug":"2016-09-18-sameoriginpolicy-05","date":"2016-09-18T04:45:07.000Z","updated":"2017-10-27T10:03:24.000Z","comments":true,"path":"2016/09/18/2016-09-18-sameoriginpolicy-05/","link":"","permalink":"http://blog.renyimin.com/2016/09/18/2016-09-18-sameoriginpolicy-05/","excerpt":"","text":"CORS说明1.CORS是一个W3C标准, 全称是 “跨域资源共享 “(Cross-origin resource sharing), 通俗说就是我们所熟知的跨域请求 ; 众所周知，在以前，跨域可以采用 代理、JSONP 等方式，而在Modern浏览器面前，这些终将成为过去式，因为有了CORS ; CORS在最初接触的时候只大概了解到，通过服务器端设置Access-Control-Allow-Origin响应头，即可使指定来源像访问同源接口一样访问跨域接口，但其实CORS的规范定义远不止这些 ; 2.它允许浏览器向跨源服务器发出XMLHttpRequest请求, 也就是克服了AJAX只能同源使用的限制 ; 3.CORS需要浏览器和服务器同时支持 (目前, 所有浏览器都支持该功能, IE浏览器不能低于IE10) ; 4.整个CORS通信过程都是浏览器自动完成, 不需要用户参与 ; 对于开发者来说, CORS通信与同源的AJAX通信没有差别, 代码完全一样, 浏览器一旦发现AJAX的请求是跨源的, 就会自动添加一些附加的头信息, 有时还会多出一次附加的请求, 但用户不会有感觉; 之所以CORS通信与同源的AJAX通信的代码没有差别, 是因为: 其实实现CORS通信的关键是服务器, 只要服务器实现了CORS接口，就可以跨源通信 CORS的两类请求1.浏览器将CORS请求分成两类: 简单请求(simple request) 和 非简单请求(not-so-simple request) 2.以下情况会被归类为 非简单请求 : 请求以 GET, HEAD 或者 POST 以外的方法发起请求 ; 虽然使用 POST，但请求数据为 application/x-www-form-urlencoded, multipart/form-data 或者 text/plain 以外的数据类型, 比如说，用 POST 发送数据类型为 application/xml 或者 text/xml 的 XML 数据的请求 ; 使用自定义请求头（比如添加诸如 X-PINGOTHER） 简单请求代码案例1.客户端代码 www.test.com/index.html : 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;https://cdn.staticfile.org/jquery/3.1.1/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; &gt; $(document).ready(function()&#123; $(&quot;#btn&quot;).click(function(k) &#123; var data = $(&quot;form&quot;).serializeArray();//序列化name/value $.ajax(&#123; type: &apos;GET&apos;, //这里用GET url: &apos;http://test.test.com/index.php&apos;, dataType: &apos;json&apos;, //类型 data: data, success: function (result) &#123;//返回的json数据 console.log(result); //回调输出 &#125;, timeout: 3000 &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form name=&quot;form&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;sex&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;age&quot;&gt; &lt;input type=&quot;button&quot; id=&quot;btn&quot; value=&quot;button&quot; /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 2.服务端代码test.test.com/index.php : 123&lt;?phpheader(\"Access-Control-Allow-Origin: http://www.test.com\");echo json_encode(['name' =&gt; 'lant', 'age' =&gt; 100]); 基本流程分析1.对于简单请求，浏览器直接发出CORS请求, 具体来说, 就是在头信息之中, 自动增加一个Origin字段 ; 浏览器发现这次跨源AJAX请求是简单请求, 就自动在头信息之中, 添加一个Origin字段: 上面的头信息中, Origin字段 用来说明本次请求来自哪个源(协议 + 域名 + 端口), 服务器根据这个值, 决定是否同意这次请求 ; 2.如果Origin源不在服务器的许可范围内 服务器仍然会返回一个正常的HTTP回应, 不过浏览器会发现, 这个回应的头信息并没有包含 Access-Control-Allow-Origin 字段(详见下文), 就知道出错了, 从而抛出一个错误, 被XMLHttpRequest的onerror回调函数捕获; 注意, 这种错误无法通过状态码识别, 因为HTTP回应的状态码有可能是200 ; 3.当然, 如果Origin源在服务器设置的许可范围内 服务器的响应就会多出如下几个头信息字段(当然也不一定是所有都包含, 具体还得看服务器如何进行设置): 1234Access-Control-Allow-Origin: http://api.bob.comAccess-Control-Allow-Credentials: trueAccess-Control-Expose-Headers: FooBarContent-Type: text/html; charset=utf-8 重点分析 :上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头:(1) Access-Control-Allow-Origin服务器要设置ajax请求可以跨域, 该字段是必须的, 它的值要么是请求时Origin字段的值，要么是一个，表示接受任意域名的请求;(2) Access-Control-Allow-Credentials该字段可选, 它的值是一个布尔值，表示是否允许发送Cookie, *默认情况下，Cookie不包括在CORS请求之中, 设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器;注意, 这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。(3) Access-Control-Expose-Headers该字段可选, CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma;如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定;上面的例子指定，getResponseHeader(‘FooBar’)可以返回FooBar字段的值。 服务器端的具体设置 服务器在设置的时候, 其实就是通过header函数设置上面的三个选项! 比如之前的例子中, 如果服务器只是简单的为了实现跨域, 直接设置如下选项即可: 123&lt;?phpheader(\"Access-Control-Allow-Origin: http://www.test1.com\");echo json_encode(['name' =&gt; 'lant', 'age' =&gt; 100]); withCredentials 属性CORS请求默认不发送Cookie和HTTP认证信息 (Jsonp是会发送cookie信息的) 1.之前在介绍Access-Control-Allow-Credentials选项的时候提到, CORS请求默认不发送Cookie和HTTP认证信息; 如果要把Cookie发到服务器: 一方面要 服务器同意指定Access-Control-Allow-Credentials字段 : 123Access-Control-Allow-Credentials: true//php中设置如下:header(\"Access-Control-Allow-Credentials: true\"); 另一方面, 开发者必须在AJAX请求中打开 withCredentials 属性: 1234var xhr = new XMLHttpRequest();xhr.withCredentials = true;//jquery中设置withCredentials的代码如下:$.ajaxSetup(&#123;crossDomain: true, xhrFields: &#123;withCredentials: true&#125;&#125;); 2.需要以上两方面都做到才可以 否则，即使服务器同意发送Cookie，浏览器也不会发送 ; 但是, 如果省略 withCredentials 设置, 有的浏览器还是会一起发送Cookie, 这时, 可以显式关闭 withCredentials ;1xhr.withCredentials = false; 3.需要注意的是: 如果要发送Cookie, Access-Control-Allow-Origin 就不能设为星号*, 必须指定明确的、与请求网页一致的域名 ; 同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传, 其他域名的Cookie并不会上传, 且(跨源)原网页代码中的document.cookie也无法读取服务器域名下的Cookie ; 测试代码1.域1中的代码(www.test.com/index.php)：123456789101112131415161718192021222324252627282930313233343536373839&lt;?php//Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传, 其他域名的Cookie并不会上传, 且(跨源)原网页代码中的document.cookie也无法读取服务器域名下的Cookiesetcookie('address', json_encode(['city' =&gt; 'yuncheng', 'town' =&gt; 'xiaoliang']), 0, '/', '.test.com');?&gt;&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"https://cdn.staticfile.org/jquery/3.1.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" &gt; $(document).ready(function()&#123; //要在跨域请求服务器时在cors请求中包含cookie, 需要开启withCredentials属性 $.ajaxSetup(&#123;crossDomain: true, xhrFields: &#123;withCredentials: true&#125;&#125;); $(\"#btn\").click(function(k) &#123; var data = $(\"form\").serializeArray();//序列化name/value $.ajax(&#123; type: 'GET', //这里用GET url: 'http://test.test.com/index.php', dataType: 'json', //类型 data: data, success: function (result) &#123;//返回的json数据 console.log(result); //回调输出 &#125;, timeout: 3000 &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form name=\"form\"&gt; &lt;input type=\"text\" name=\"sex\"&gt; &lt;input type=\"text\" name=\"age\"&gt; &lt;input type=\"button\" id=\"btn\" value=\"button\" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 2.域2中的代码(test.test.comindex.php):123456&lt;?phpheader(\"Access-Control-Allow-Origin: http://www.test.com\");//服务器允许前端在跨域cors请求时包含cookieheader(\"Access-Control-Allow-Credentials: true\");$address = $_COOKIE['address'];echo json_encode(['name' =&gt; 'lant', 'age' =&gt; 100, 'address' =&gt; $address]); 3.效果: 4.两个注意点 如果域1中在html中设置了 withCredentials 为 true : 1$.ajaxSetup(&#123;crossDomain: true, xhrFields: &#123;withCredentials: true&#125;&#125;); 那么在对应的ajax请求的域2中必须设置 1header(\"Access-Control-Allow-Credentials: true\"); 否则, 报错如下: 如果两边都不设置 withCredentials 属性的话, 也就是默认请求不带cookie, 那么即使请求方域1中设置了domain属性为 .test.com 的cookie值, 服务方(test.test.com)中也获取不到cookie, 因为域1默认请求就没有带cookie ; 参考 阮一峰参考 阮一峰 CORS","categories":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/categories/CrossDomain/"}],"tags":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/tags/CrossDomain/"}]},{"title":"04. Ajax请求不能发送 之 \"JSONP方案\"","slug":"2016-09-17-sameoriginpolicy-04","date":"2016-09-17T11:27:31.000Z","updated":"2017-10-27T09:32:16.000Z","comments":true,"path":"2016/09/17/2016-09-17-sameoriginpolicy-04/","link":"","permalink":"http://blog.renyimin.com/2016/09/17/2016-09-17-sameoriginpolicy-04/","excerpt":"","text":"JSONP1.JSONP是服务器与客户端 跨源通信 的常用方法, 最大特点就是简单适用, 老式浏览器全部支持, 服务器端改造非常小 ; 2.但是，JSONP只能发GET请求 ; 3.注意: JSONP跨子域发送Cookie的话, 只用设置好cookie的domain属性为顶级域名即可 ; ajax使用jsonp跨域的时候是可以轻松像上面这样带上cookie给所跨的域 ; 而下一篇介绍的ajax使用cors方案跨域的话, 除了设置了cookie的 document.domain 为两个地址的顶级域名, 却也不能带上cookie, 还需要注意 前端和服务端的 withCredentials 头字段 ; jsonp跨域请求案例www.test.com/index.html123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;https://cdn.staticfile.org/jquery/3.1.1/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; &gt; $(document).ready(function()&#123; //注意, 此时jsonp是会带上cookie的(当然, 如果你不设置cookie的domain, test.test.com自然获取不到www.test.com域的cookie) document.cookie = &quot;name=value; domain=test.com&quot;; $(&quot;#btn&quot;).click(function() &#123; var data = $(&quot;form&quot;).serializeArray();//序列化name/value $.ajax(&#123; type: &apos;GET&apos;, //这里用GET url: &apos;http://test.test.com/index.php&apos;, dataType: &apos;jsonp&apos;, //类型 data: data, jsonp: &apos;callback&apos;, //jsonp回调参数，必需 async: false, success: function (result) &#123;//返回的json数据 console.log(result); //回调输出 &#125;, timeout: 3000 &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form name=&quot;form&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;sex&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;age&quot;&gt; &lt;input type=&quot;button&quot; id=&quot;btn&quot; value=&quot;button&quot; /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; test.test.com/index.php1234567891011&lt;?php//jsonp回调参数，必需$callback = isset($_GET['callback']) ? trim($_GET['callback']) : '';$sex = isset($_GET['sex']) ? trim($_GET['sex']) : '';$age = isset($_GET['age']) ? trim($_GET['age']) : '';$data = [\"sex\" =&gt; $sex, \"age\" =&gt; $age];$res = json_encode($data); //json 数据// 不能用returnecho $callback . '(' . $res . ')'; //返回格式，必需 参考","categories":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/categories/CrossDomain/"}],"tags":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/tags/CrossDomain/"}]},{"title":"03.同源策略的限制 之 \"Ajax请求不能发送\"","slug":"2016-09-16-sameoriginpolicy-03","date":"2016-09-16T05:04:17.000Z","updated":"2017-10-27T09:33:06.000Z","comments":true,"path":"2016/09/16/2016-09-16-sameoriginpolicy-03/","link":"","permalink":"http://blog.renyimin.com/2016/09/16/2016-09-16-sameoriginpolicy-03/","excerpt":"","text":"同源策略的限制 - Ajax请求不能发送 同源政策规定, AJAX请求只能发给同源的网址, 否则就报错 ; 除了架设服务器代理(浏览器请求同源服务器，再由后者请求外部服务), 有三种方法规避这个限制 : JSONP CORS WebSocket 参考","categories":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/categories/CrossDomain/"}],"tags":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/tags/CrossDomain/"}]},{"title":"02.同源策略的限制 之 \"Cookie无法读取\"","slug":"2016-09-15-sameoriginpolicy-02","date":"2016-09-15T13:10:13.000Z","updated":"2017-10-27T09:18:13.000Z","comments":true,"path":"2016/09/15/2016-09-15-sameoriginpolicy-02/","link":"","permalink":"http://blog.renyimin.com/2016/09/15/2016-09-15-sameoriginpolicy-02/","excerpt":"","text":"回顾之前学习同源策略基础知识的时候, 了解了同源策略的 三种行为 限制: Cookie、LocalStorage 和 IndexDB 无法读取 DOM 无法获得 AJAX 请求不能发送 不过这里需要注意一点: “同源策略”的限制, 并没有限制住CSRF攻击“同源策略的限制”并不会导致 B站点中嵌入的 A站点超链接去读取A站点用户的cookie;假如你当前已经登录了邮箱，或bbs，同时你又访问了另外一个站点，假设这就是一个钓鱼网站; 这个网站上面可能因为某个图片吸引你，你去点击一下，此时可能就会触发一个js的点击事件，去构造一个bbs发帖的请求，去往你的bbs站点发帖，由于当前你的浏览器状态已经是登陆状态，所以session登陆cookie信息都会跟正常的请求一样，纯天然的利用当前的登陆状态，让用户在不知情的情况下，帮你发帖或干其他事情; (这也就是我们通常所说的CSRF攻击, CSRF攻击的主要目的是让用户在不知情的情况下攻击自己已登录的一个系统，类似于钓鱼); 同源策略的限制之”Cookie无法读取” 本篇构造跨域的场景来模拟”Cookie无法读取”的限制, 方法主要有: B站&lt;a href=&quot;A&quot;&gt;test&lt;/a&gt;超链接无法读取B站点的cookie; (而csrf所讨论的是B站&lt;a href=&quot;A&quot;&gt;test&lt;/a&gt;超链接可以读取A站点自己的cookie) 不通过B站超链接, 而是直接打开另一个网页来访问A站点, 结果当然也是A站点读不到B站点的Cookie ; 暂时不会涉及到 Ajax请求所涉及的cookie传递问题, 这个问题属于同源策略的第三种限制 AJAX请求不能发送; 例子 : A网页是 http://www.test.com/index.html，B网页是 http://test.test.com/index.html : A: www.test.com/index.html (此处是使用js来设置cookie进行测试; 当然, 用服务端代码php测试也是OK的) 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;script type=&quot;application/javascript&quot;&gt; document.cookie=&quot;name=value;&quot;;&lt;/script&gt;&lt;/html&gt; B: test.test.com/index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;script type=&quot;application/javascript&quot;&gt; console.log(document.cookie);&lt;/script&gt;&lt;/html&gt; // 可以看到, 同顶级域名也不能跨子域名获取cookie //同理, 直接在http://www.test.com/index.html中超链接点击到http://test.test.com/index.html也是获取不到cookie的 ; 合理规避Cookie无法读取的限制 虽然同源导致的这些限制是必要, 但是有些情况下, 其实我们是需要 合理 规避Cookie无法读取的限制的 ; 比如: 如果两个网页的顶级域名相同, 只是二级域名不同的话, 浏览器其实是允许你通过设置 document.domain 来共享 Cookie 的; 例子: A网页是 http://www.test.com/index.html，B网页是 http://test.test.com/index.html, 那么只要设置相同的 document.domain，两个网页就可以共享Cookie : A: www.test.com/index.html (此处是使用js来设置cookie进行测试; 当然, 用php代码也是OK的) 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;script type=&quot;application/javascript&quot;&gt; document.cookie=&quot;name=value; domain=test.com&quot;;&lt;/script&gt;&lt;/html&gt; B: test.test.com/index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;script type=&quot;application/javascript&quot;&gt; console.log(document.cookie);&lt;/script&gt;&lt;/html&gt; 注意:这种方法只适用于 Cookie 和 iframe 窗口(DOM无法获取); 而 LocalStorage 和 IndexDB 无法通过这种方法来规避同源政策，而要使用之后会介绍的PostMessage API ; 参考 阮一峰","categories":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/categories/CrossDomain/"}],"tags":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/tags/CrossDomain/"}]},{"title":"01.浏览器的同源策略(Same origin policy)","slug":"2016-09-15-sameoriginpolicy-01","date":"2016-09-15T11:21:54.000Z","updated":"2017-10-27T08:57:30.000Z","comments":true,"path":"2016/09/15/2016-09-15-sameoriginpolicy-01/","link":"","permalink":"http://blog.renyimin.com/2016/09/15/2016-09-15-sameoriginpolicy-01/","excerpt":"","text":"同源策略1995年，同源政策由 Netscape 公司引入浏览器。目前，所有浏览器都实行这个政策； 最初，它的含义是指，A网页设置的 Cookie，B网页不能打开，除非这两个网页”同源”，所谓 “同源” 指的是 “三个相同” ： 1.协议相同http://blog.renyimin.com 和 https://blog.renyimin.com 就不是同一个源 ； 2.域名完全相同http://blog.renyimin.com/test/index.php 和 http://blog.renyimin.com/welcome/index.html 就是同一个源; 但是 http://www.renyimin.com/test/index.php 和 http://blog.renyimin.com/test/index.php 就不是同一个源 ；请注意：localhost和127.0.0.1虽然都指向本机, 但也不是同一个源 ; 3.端口相同http://www.renyimin.com:8080/test/index.php 和 http://www.renyimin.com:80/test/index.php 就不是同一个源 ; 再举例来说，http://www.example.com/dir/page.html 这个网址，协议是 http://，域名是 www.example.com，端口是80（默认端口可以省略），它的同源情况如下： 1234567http://www.example.com/dir2/other.html：同源http://example.com/dir/other.html：不同源（域名不同）http://v2.www.example.com/dir/other.html：不同源（域名不同）http://www.example.com:81/dir/other.html：不同源（端口不同） 同源策略目的1.为了保证用户信息的安全，防止恶意的网站窃取数据;比如:用户登录一家银行网站后，又去浏览其他站点, 如果没有同源策略限制, 其他站点就也能读取银行网站的 Cookie, 会发生什么？ 如果 Cookie 包含用户银行的私密信息，这些信息就会泄漏给第三方站点, 当然, cookie中包含的敏感信息通常经过加密，很难将其反向破解, 但这并不意味着绝对安全; 不去获取cookie中的信息, 而是直接偷取Cookie去骗取银行网站的信任; 2.由此可见，”同源政策”是必需的，否则 Cookie 可以共享，互联网就毫无安全可言了 ; 同源策略的限制随着互联网的发展, “同源政策”越来越严格, 目前, 如果非同源, 共有三种行为受到限制: Cookie、LocalStorage 和 IndexDB 无法读取 DOM 无法获得 AJAX 请求不能发送 (可能我平时更过关注到的是1，3这两点限制) 不过这里需要注意一点: “同源策略”的限制, 并没有限制住CSRF攻击“同源策略的限制”并不会导致 B站点中嵌入的 A站点超链接去读取A站点用户的cookie;假如你当前已经登录了邮箱，或bbs，同时你又访问了另外一个站点，假设这就是一个钓鱼网站; 这个网站上面可能因为某个图片吸引你，你去点击一下，此时可能就会触发一个js的点击事件，去构造一个bbs发帖的请求，去往你的bbs站点发帖，由于当前你的浏览器状态已经是登陆状态，所以session登陆cookie信息都会跟正常的请求一样，纯天然的利用当前的登陆状态，让用户在不知情的情况下，帮你发帖或干其他事情; (这也就是我们通常所说的CSRF攻击, CSRF攻击的主要目的是让用户在不知情的情况下攻击自己已登录的一个系统，类似于钓鱼); 最后, 虽然这些限制是必要的，但是有时很不方便，合理的用途也受到影响, 接下来将详细介绍如何在需要的时候合理地去规避”同源政策”的限制 ; 参考 阮一峰","categories":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/categories/CrossDomain/"}],"tags":[{"name":"CrossDomain","slug":"CrossDomain","permalink":"http://blog.renyimin.com/tags/CrossDomain/"}]},{"title":"MySQL锁 - 02","slug":"2016-08-09-mysql_locks-02","date":"2016-08-09T13:07:12.000Z","updated":"2017-12-11T09:54:28.000Z","comments":true,"path":"2016/08/09/2016-08-09-mysql_locks-02/","link":"","permalink":"http://blog.renyimin.com/2016/08/09/2016-08-09-mysql_locks-02/","excerpt":"","text":"乐观锁(Optimistic Lock) 乐观锁, 也叫乐观并发控制, 它假设多用户并发的事务在处理时不会彼此互相影响, 各事务能够在不产生锁的情况下处理各自影响的那部分数据; 在提交数据更新之前, 每个事务才会检查在该事务读取数据后, 有没有其他事务又修改了该数据, 如果其他事务有更新的话, 那么当前正在提交的事务会进行回滚; 很显然, 这可以解决 丢失更新 的问题, 因为在这个事务中, 操作语句可能类似下面: 这不但可以解决丢失更新的问题, 还可以不放在事务内; 乐观锁的底层机制 (https://www.cnblogs.com/zhiqian-ali/p/6200874.html) 其底层机制是这样：在数据库内部update同一行的时候是不允许并发的，即数据库每次执行一条update语句时会获取被update行的写锁，直到这一行被成功更新后才释放 悲观锁(Pessimistic Lock) 悲观锁的特点是先获取锁, 再进行业务操作, 即悲观的认为获取锁是非常有可能失败的, 因此要先确保获取锁成功再进行业务操作; 通常所说的一锁二查三更新即指的是使用悲观锁; 通常来讲在数据库上的悲观锁需要数据库本身提供支持, 即通过常用的select … for update操作来实现悲观锁, 当数据库执行select for update时会获取被select中的数据行的行锁, 因此其他并发执行的select for update如果试图选中同一行则会发生排斥(需要等待行锁被释放), 因此达到锁的效果; for update 仅适用于InnoDB; for update 必须在事务块(BEGIN/COMMIT)中才能生效; 在进行事务操作时, 通过for update语句, MySQL会对查询结果集中每行数据都添加排他锁, 其他并行事务对该记录的查询, 更新, 删除操作都会被阻塞, 排他锁包含行锁、表锁。 for update 必须注意点: 这里需要注意的一点是, 不同的数据库对 select for update 的实现和支持都是有所区别的, 例如oracle支持 select for update no wait, 表示如果拿不到锁立刻报错, 而不是等待; 而mysql就没有 no wait 这个选项; 另外mysql还有个问题是 select for update 语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题, 因此如果在mysql中用悲观锁务必要确定走了索引, 而不是全表扫描; 很显然, 这也是为了解决 丢失更新 的问题!","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"MySQL锁 - 01","slug":"2016-08-09-mysql_locks-01","date":"2016-08-09T11:16:54.000Z","updated":"2017-12-11T12:43:41.000Z","comments":true,"path":"2016/08/09/2016-08-09-mysql_locks-01/","link":"","permalink":"http://blog.renyimin.com/2016/08/09/2016-08-09-mysql_locks-01/","excerpt":"","text":"前言 之前已经学习了事务及事务在高并发下所面临的问题, 并且介绍了事务的隔离级别是如何解决这些问题的; 那这些问题已经通过事务解决了, 为什么还要学习锁的相关知识? 这是因为我们之前介绍的隔离级别，其实它的精髓就是锁机制; 而且我们学习了锁的概念之后, 还能在高并发的时候解决非事务下(不使用事务)或者事务的隔离级别也解决不了的 丢失更新 的问题 （乐观,悲观锁的使用） 所以我们也需要对锁有一定的认识; 锁锁的名词 在学习锁相关知识之前, 先看一些关于锁的名词, 因为常见的和锁相关的词实在是比较多, 如: 锁冲突 死锁 表级锁(MYISAM, INNODB引擎) 意向锁(意向共享锁, 意向排他锁) 行级锁(记录锁) (INNODB引擎) 页级锁(BDB引擎) 共享锁(S锁)(读锁) 排他锁(X锁)(写锁) 乐观锁 悲观锁 记录锁 间隙锁 next-key锁 自动锁 显示锁 (DML锁和DDL锁：http://www.hollischuang.com/archives/909) 锁冲突线程1将A上锁后, 线程2又对A上锁, 锁不能共存否则会出现锁冲突; (共享锁和共享锁可以共存, 共享锁和排它锁不能共存, 排它锁和排他锁也不可以共存) 死锁 死锁通常发生在多个线程同时但以不同的顺序请求同一组锁的时候; 比如: 线程1锁住了A, 然后尝试对B进行加锁, 于此同时线程2已经锁住了B, 接着尝试对A进行加锁, 这时死锁就发生了, 线程1永远得不到B, 线程2也永远得不到A, 并且它们永远也不会知道发生了这样的事情; 为了得到彼此的对象(A和B), 它们将永远阻塞下去, 这种情况就是一个死锁; 有多种方法可以避免死锁, 这里只介绍常见的三种: 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表, 可以大大降低死锁机会; 在同一个事务中, 尽可能做到一次锁定所需要的所有资源, 减少死锁产生概率; 对于非常容易产生死锁的业务部分, 可以尝试使用升级锁定颗粒度, 通过表级锁定来减少死锁产生的概率; 表级锁 表级锁是MySQL中锁定粒度最大的一种锁, 表示对当前操作的整张表加锁, 它实现简单, 资源消耗较少, 被大部分MySQL引擎支持, 最常使用的MYISAM与INNODB引擎都支持表级锁定, 但INNODB默认采用的是行级锁, 表级锁定分为表共享读锁(共享锁)与表独占写锁(排他锁); (意向锁就属于表锁) 特点: 加锁快(开销小) 锁定粒度大(出现锁冲突(即:锁等待)的概率最高, 并发度最低) MYISAM引擎默认就是表级锁 (另外, 由于MYISAM引擎不支持事务, 每次操作执行完后会立即提交, 也就是每次操作只加一个锁, 其他操作只用等待就行; 而在InnoDB中, 锁是逐步获得的, 就造成了死锁的可能) 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁, 表级锁加锁速度快,但冲突多,行级锁冲突少,但加锁速度慢, 所以取了折衷的页级, 一次锁定相邻的一组记录; (BDB支持页级锁) 特点: 加锁时间和开销界于表锁和行锁之间 锁定粒度界于表锁和行锁之间, 并发度一般 BDB引擎使用的就是页级锁, 会出现死锁 行级锁 行级锁是Mysql中锁定粒度最细的一种锁, 只对当前操作的行进行加锁, 行级锁能大大减少数据库操作的冲突, 因为其加锁粒度最小, 但行级锁加锁的开销也最大。行级锁分为共享锁 和 排他锁; 特点: 加锁慢, 开销大 锁定粒度最小(发生锁冲突的概率最低, 并发度也最高) INNODB引擎使用行锁, 支持事务, 会出现死锁 Innodb中的行锁与表锁注意事项 前面提到过, Innodb引擎中既支持行锁也支持表锁, 那么什么时候会锁住整张表, 什么时候或只锁住一行? InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的; InnoDB这种行锁实现特点意味着: 只有通过索引条件检索数据, InnoDB才使用行级锁, 否则, InnoDB将使用表锁!(不过, 在实际应用中, 一般在做更改的时候, 都是使用主键进行筛选, 所以自然是行锁) 在实际应用中, 要特别注意InnoDB行锁的这一特性, 不然的话, 可能导致大量的锁冲突, 从而影响并发性能; 在不通过索引条件查询的时候,InnoDB 确实使用的是表锁,而不是行锁; 由于 MySQL 的行锁是针对索引加的锁, 而不是针对记录加的锁, 所以虽然是访问不同行的记录, 但是如果是使用相同的索引键, 是会出现锁冲突的, 应用设计的时候要注意这一点;(也就是Innodb引擎中, 写操作即使是操作不同的行, 也可能由于使用一样的索引而导致锁冲突) 当表有多个索引的时候, 不同的事务可以使用不同的索引锁定不同的行, 另外, 不论是使用主键索引、唯一索引或普通索引, InnoDB 都会使用行锁来对数据加锁; 即便在条件中使用了索引字段, 但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的, 如果 MySQL 认为全表扫效率更高, 比如对一些很小的表, 它就不会使用索引, 这种情况下 InnoDB 将使用表锁, 而不是行锁;因此, 在分析锁冲突时, 别忘了检查 SQL 的执行计划, 以确认是否真正使用了索引; 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。 共享锁(Share Lock) 共享锁又称读锁, 是读取操作创建的锁。 其他事务可以并发读取数据, 但不能对数据进行修改(获取数据上的排他锁), 直到已释放所有共享锁; (也就是共享锁只可以和共享锁共存) 如果事务T对数据A加上共享锁后, 则其他事务只能对A再加共享锁, 不能加排他锁, 获准共享锁的事务只能读数据, 不能修改数据; 对于一般的select语句, InnoDB不会加任何锁, 当然, 也可以显示手动去自己加: SELECT ... LOCK IN SHARE MODE; 在查询语句后面增加LOCK IN SHARE MODE, Mysql会对查询结果中的每行都加共享锁, 当没有其他线程对查询结果集中的任何一行使用排他锁时, 可以成功申请共享锁, 否则会被阻塞; 其他线程也可以读取使用了共享锁的表, 而且这些线程读取的是同一个版本的数据; 排他锁(Xclusive Lock) 排他锁又称写锁, 如果事务T对数据A加上排他锁后, 则其他事务不能再对A加任任何类型的锁; 获准排他锁的事务既能读数据, 又能修改数据。 对于insert、update、delete，InnoDB会自动给涉及的数据加排他锁(X), 当然, 也可以显示手动去自己加: SELECT ... FOR UPDATE; 在查询语句后面增加FOR UPDATE, Mysql会对查询结果中的每行都加排他锁, 当没有其他线程对查询结果集中的任何一行使用排他锁时, 可以成功申请排他锁, 否则会被阻塞; 意向锁 (不用干预) 意向锁是表级锁, 其设计目的主要是为了在一个事务中揭示下一行将要被请求锁的类型; InnoDB中的两个表锁: 意向共享锁(IS): 表示事务准备给数据行加入共享锁, 也就是说一个数据行加共享锁前必须先取得该表的IS锁; 意向排他锁(IX): 类似上面, 表示事务准备给数据行加入排他锁, 说明事务在一个数据行加排他锁前必须先取得该表的IX锁; 3.意向锁是InnoDB自动加的,不需要用户干预; 4.显示加共享锁或排他锁: 共享锁：SELECT ... LOCK IN SHARE MODE; 排他锁：SELECT ... FOR UPDATE; 共享锁和意向共享锁，排他锁与意向排他锁的区别 共享锁和排他锁: 系统在特定的条件下会自动添加共享锁或者排他锁, 也可以手动添加共享锁或者排他锁; 意向共享锁和意向排他锁都是系统自动添加和自动释放的, 整个过程无需人工干预; 共享锁和排他锁都是锁的行记录,意向共享锁和意向排他锁锁定的是表。 间隙锁 间隙锁是innodb中 行锁 的一种，但是这种锁锁住的却不止一行数据, 他锁住的是多行, 是一个数据范围; 通过生活中的一个小场景来认识间隙锁: a,b,c 三个人依次站成一排, 此时, 新来了一个d, 如何让新来的d不站在小红旁边? 其实只要将b和它前面的a之间的空隙封锁; 再将b和它后面的c之间的空隙封锁; 那么d就不能站到b的旁边了; 这里的a, b, c, d 如果对应到数据表中, 那就是就是一条条记录； 他们之间的空隙也就是间隙, 而封锁他们之间间隙的锁, 就叫做间隙锁; (http://www.jianshu.com/p/bf862c37c4c9) next-key锁 MYISAM 和 INNODB相比:MYISAM不会出现死锁(因为MYISAM没有事务)","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"MySQL(INNODB引擎)事务 - 01","slug":"2016-08-07-mysql_transaction-01","date":"2016-08-07T13:01:07.000Z","updated":"2017-12-11T09:19:09.000Z","comments":true,"path":"2016/08/07/2016-08-07-mysql_transaction-01/","link":"","permalink":"http://blog.renyimin.com/2016/08/07/2016-08-07-mysql_transaction-01/","excerpt":"","text":"事务的概念 事务可以理解为一个独立的工作单元, 在这个独立的工作单元中, 有一组操作(一般会有多个’写操作’); 放在事务中的多个操作, “要么全部执行成功, 要么全部执行失败”, 这当然也是事务的目的; 还是通过最经典的银行应用来解释事务 假设用户A通过银行的ATM取款机给用户B转账100元, 那么银行ATM应用的转账程序中至少需要三个步骤才能完成转账操作: 123检查A用户余额`&gt;=100`元从A用户余额中`-100`元给B用户余额`+100`元 注意:上面的三个步骤的操作必须打包在一个事务中, 来作为一个独立的工作单元来执行, 在这个独立工作单元(即事务)中的这三个操作, 只要有任何一个操作失败, 则事务就整体就是失败的, 那就必须回滚所有的步骤(当然,主要是回滚写操作); 假设第二步(从A用户余额中-100元)操作成功, 但是第三步(给B用户余额+100元)操作失败, 那么整个事务也就应该是失败的, 那就必须将第二步的操作也回滚; 事务的ACID特性一个运行良好的事务处理系统必须具备这些标准特性 Atomicity 原子性一个事务必须被视为一个不可分割的最小工作单元, 整个事务中的所有操作要么全部提交成功, 要么全部失败回滚;对于一个事务来说, 不可能只成功执行其中的一部分操作, 这就是事务的原子性; Consistency 一致性事务的一致性会保证数据库总是从一个一致性的状态转换到另一个一致性的状态;(比如在之前的转账例子中, 即使已经行完了第二步(从A用户余额中-100元), 但在开始执行第三步(给B用户余额+100元)时系统突然崩溃, 那么A用户的余额也不会损失100元, 因为事务最终没有提交, 所以事务中所做的修改也不会保存到数据库中; Isolation 隔离性 通常来说, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的;(比如在之前的转账例子中, 在执行完第二步但是第三步还没开始的时候, 此时有另一个账户汇总的程序开始运行, 那么这个程序所拿到的A账户余额应该是没有被-100的余额才对) 后面我们还会详细讨论事务隔离性的 隔离级别, 就知道这里为什么说通常来说对其他事务是不可见的; (也就是还有特例, 比如最低隔离级别 READ UNCOMMITTED ) Durability 持久性一旦事务被最终提交, 则在事务这个独立单元中的所有操作所做的修改将会 理论上永久保存到数据库中; 事务会出现的问题在并发量比较大的时候, 很容易出现多个事务同时进行的情况, 假设有两个事务正在同时进行, 两者之间是互相不知道对方的存在的, 各自都对自身所处的环境过分乐观, 从而并没有对操作的数据做一定的保护处理, 所以最终导致一些问题的出现; 脏读 mysql中一个事务读取了另一个并行事务未提交的写数据, 那这个读取就是脏读 同一个事务单元内, 多次读取同一个数据, 获取到的结果却不一样; 首次之后再次读取的结果是其他与该事物并行的事务未提交的修改, 也就是还没有成为永久数据（最终还可能会被其他某个事务反悔(rollback)的数据） 图示: 事务A在T4阶段读取库存为20, 这个库存其实就属于脏数据, 因为这个数据是事务B最终会撤销掉的数据, 所以如果事务A使用库存20进行后续的操作, 就会引发问题; 解决方案 - 事务的隔离性 当事务的隔离级别为 read commited 及以上隔离级别时, 可以让一个事务只能读取另一个事务已经提交的数据, 这样就可以避免了上面的脏读现象; 但是脏读解决后, 还是有问题存在的: 试想一下, 既然解决脏读之后, 一个事务只能读取另一个事务已经提交的数据, 那么就会出现, 在同一个事务单元内, 多次读取同一个数据, 虽然首次之后再次读取的结果是永久数据, 但也有可能和第一次数据不一样; 这种情况就是 不可重复读; 不可重复读 同一事务内读取的同一数据不一样 (只不过第二次读取到的数据是永久的) 同一个事务单元内, 多次读取同一个数据, 获取到的结果却不一样; 首次之后再次读取的结果是其他与该事物并行的事务已经提交的修改; 但很明显, 同一个事务内的两次读取结果不一样; 解决方案 - 事务的隔离性 当事务的隔离级别为 repeatable read 或以上级别时, 一个事务内部对数据的多次查询都是相同的(无论该数据在中途是否被其他事务修改过, 本事务都不理会), 这样就避免了不可重复读的问题; 但是该隔离级别依然解决不了幻读的问题!! 但是不可重复读解决后, 还是有问题存在的: 因为一个事务内部, 如果第二次读取同一个数据, 为了保持和首次读取一致而忽略并行事务对其所做的修改的话, 那么很显然, 会造成另一个问题, 那就是并行事务的修改会被忽略掉; 这就是最后将会介绍的一个问题 丢失更新; 幻读 (间隙锁) 幻读主要是查询记录的数量问题 在上图中, 事务A一开始查询没有数据, 但是插入记录失败, 提示主键冲突; 这种查询明明没有, 插入却提示已经存在的现象, 叫做幻读; 幻读和不可重复读类似, 即两次读取的结果不一致, 两者的不同点在于: 不可重复读针对数据的修改造成的读不一致; 而幻读针对数据的插入和删除造成的读不一致, 如同发生幻觉一样; 如何避免这个问题? 当事务的隔离级别为 SERIALIZABLE 时, 会通过间隙锁来防止幻读的出现, 即锁定特定数据的前后间隙让数据无法被插入; 丢失更新 先看一下丢失更新的例子: 由于事务A与事务B互相不知道对方的存在，因此导致了悲剧的发生 解决方案 – 貌似无法通过隔离级别来进行解决通过乐观锁可以解决这个问题, 事务在进行更新余额操作的时候, SQL修改为 update table set kucun=1100 where id=xxx **** and kucun=1000****, 通过加上一个金额的判断, 这样的话, 如果更改之前数据没有修改则执行成功, 否则执行失败回滚; 事务的4种隔离级别事务的隔离性比较复杂, 在SQL标准中定义了四种隔离级别, 每一种级别都规定了在一个事务中所做的修改, 哪些在事务内和事务间是可见的, 哪些是不可见的, 较低的隔离级别通常可以执行更高的并发, 系统的开销也更低; 下面简单了解一下四种隔离级别 READ UNCOMMITTED (未提交读)出现 脏读 在READ UNCOMMITTED级别, 事务中的修改, 即使没有提交, 对其他事务也都是可见的; 也就是说事务可以读取未递交的数据, 这也就造成了脏读(Dirty Read)的出现; 这个级别会导致很多问题, 从性能上来说, READ UNCOMMITTED级别也不会比其他的级别好太多, 但却缺乏其他级别的很多好处, 所以在实际应用中一般很少使用; READ COMMITTED (提交读)解决 脏读, 出现 不可重复读 大多数数据库系统的默认隔离级别都是READ COMMIT(但MySQL不是); READ COMMIT满足前面提到的隔离性的简单定义: 一个事务开始时, 只能”看见”已经提交的事务所做的修改; 也就是说一个事务从开始直到事务提交之前, 所做的任何修改对其他事务都是不可见的; 这也就解决了脏读的问题!! 这个级别有时候也叫不可重复读(nonrepeatable read), 应为两次执行同样的查询, 可能会得到不一样的结果; REPEATABLE READ (可重复读)解决脏读, 解决 不可重复读, 依然无法解决 幻读 首先 REPEATABLE READ 比 READ COMMITTED 的隔离级别高, 也可以解决脏读的问题; 该级别保证了在同一个事务中多次读取同样的记录的结果是一致的; 但是理论上, 可重复读这个隔离级别还是无法解决另外一个幻读(Phantom Read)的问题; 所谓幻读, 指的是当某个事务在读取某个范围内的记录时, 另外一个事务又在该范围内插入了新的记录, 当之前的事务再次读取该范围的记录时, 会产生幻行(Phantom Row); InnoDB和XtraDB存储引擎通过多版本并发控制(MVCC)解决了幻读的问题 可重复读是MySQL的默认事务隔离级别; SERIALIZABLE(可串行化)SERIALIZABLE是最高的隔离级别, 他通过强制事务串行执行, 避免了前面说的幻读的问题;简单来说, SERIALIZABLE 会在读取的每一行数据上都加锁, 所以可能导致大量的超时和锁争用的问题, 实际应用中也很少用到这个隔离级别, 只有在非常需要保障数据一致性而且可以接受没有并发的情况下, 才考虑采用该级别; 小结当然, 上面描述的通过事务的隔离级别所解决的问题, 首先都需要放在事务中!","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"04 - 授权码模式各阶段参数分析","slug":"2016-05-25-OAuth-04","date":"2016-05-25T12:10:12.000Z","updated":"2017-10-25T08:44:37.000Z","comments":true,"path":"2016/05/25/2016-05-25-OAuth-04/","link":"","permalink":"http://blog.renyimin.com/2016/05/25/2016-05-25-OAuth-04/","excerpt":"","text":"第一阶段: 第三方站点将导向授权页 第三方应用将用户导向授权页时, 传递的参数如下: response_type: 表示授权类型, 必选项, 此处由于采用的是授权码模式, 所以值固定为 “code” client_id/AppID: 表示客户端的ID, 必选项由于你可能会有多个站点需要对接OAuth授权服务器, 所以一般在授权服务平台登录之后, 是可以创建多个 应用 的 (不同的站点对接授权服务器中不同的应用);每个应用对应你的一个 第三方站点, 开放平台会为每个应用(第三方站点)生成相应的 AppID 和 AppSecret/AppKey, 主要用来验证应用的合法性; redirect_uri: 设定的重定向到第三方站点URI, 必选项 scope: 表示申请的权限范围, 可选项 state: 表示客户端的当前状态, 可以指定任意值, 认证服务器会原封不动地返回这个值 下面是各开放平台的参数对比: 新浪 QQ 微信 GitHub 蚂蚁金服 简单测试: redirect_uri在OAuth服务器中为第三方站点创建 应用 的时候, 设定的回调地址, 无论在认证服务器, 还是在第三方站点, 都会对其进行校验, 以防篡改; 新浪授权传递错误 redirect_uri 简书qq授权传递错误 redirect_uri state第三方站点会对state做校验给了一个新的弹框用来进行授权, 但是如果恶意用户复制出弹框中的url, 之后再修改state并刷新页面, 授权后发现: 从上面各平台也可以看到, 返回参数相对比较简单; 返回的code是和授权页登录的用户身份相关的; (后面的access_token也是通过code和用户身份关联起来的) 第二阶段: 通过Authorization Code获取Access Token 如果第三方站点的用户在第一阶段的授权页中选择对第三方站点授权, 那么就第三方站点就会收到授权服务器的Authorization Code, 进而进入本阶段;(每个用户在授权后, 第三方站点都需要到授权服务器上为用户获取一个access_token, 这个access_token就是以后第三方站点从授权服务器上获取用户信息的凭证了, 一般在获取到access_token令牌之后, 可以存储到session中) 本阶段, 我们在自己的第三方站点中就可以使用第一阶段的Authorization Code获取Access Token: 微信 qq 基本上入参就像QQ互联那样大概有5个 (需要对每个参数进行了解); 本阶段的返回参数比较有讲究, 一般为如下三个 access_token 授权令牌access_token一般在获取到之后, 第三方站点可以将其 保存到用户的session中 , 第三方站点之后要获取用户在授权服务器上的资源的时候, 就需要带上当前session中用户的access_token去获取; expires_in 该access token的有效期,单位为秒 (微信公众平台access_token有效期为2小时, qq互联平台为3个月 可以作为参考)设置access_token有效期也是为了定期修改access_token, 以提高安全性;(并且微信对获取access_token这个基础API是有限制的，每天最多请求2000次, 因为有效期为2小时, 每天2000次也足够了;) refresh_token 授权自动续期时使用 (微信公众平台refresh_token有效期为30天, qq互联平台具体不详, 可以作为参考) (可选)权限自动续期问题 注意微信公众平台: 1.若access_token已超时，那么进行refresh_token会获取一个新的access_token，新的超时时间, 并且一旦使用refresh_token来刷新access_token的话, refresh_token的过期时间也会更新(自动延期) ; 2.若access_token未超时，那么进行refresh_token不会改变access_token，但超时时间会刷新，相当于续期access_token ; 这里说的超时时间刷新, 指的自然是第三方站点和授权服务器上的超时时间都要更新了(只不过你如果只是做对接的话, 授权服务器这部分人家已经开发好了, 如果你是授权服务器也是自己开发的话, 那你就需要注意这里了) 其实第三方站点在受到授权服务器分配给当前用户的access_token之后, 假设说授权服务器返回access_token的过期时间为7200s(2小时), 那么第三方站点将access_token保存到用户session中, 并设置过期时间为6600s(中间可以有个10分钟的服务器时间差); 如果第三方站点在使用access_token为用户获取授权服务器中的资源时, 发现session中的access_token并没有过期, 那么请求后就需要为access_token续期(第三方站点和授权服务器上都要做续期) 如果第三方站点在使用access_token为用户获取授权服务器中的资源时, 发现session中的access_token过期, 则就需要使用refresh_token调用生成access_token的api接口重新生成access_token来进行续期； qq: 这样下来, 基本上第三方站点只有在大于refresh_token的过期时间都没有调用过授权服务器的话, 才需要用户重新登录; 第三阶段(比较简单): 第三方站点通过access_token获取授权平台资源服务器上的用户资源 获取access_token后，进行接口调用，有以下前提： access_token有效且未超时； 微信用户已授权给第三方应用帐号相应接口作用域(scope);也就是在授权服务器上还会使用access_token去检测对应的scope权限是否正确; 许多开放平台在申请完access_token令牌之后, 都提供了对应接口来获取用户相关信息QQ互联提供了相应的接口, 使用Access Token来获取用户的OpenID;新浪开放平台提供了相应的接口来获取access_token对应的用户信息;而微信公众平台: 在获取access_token的时候, 会同时返回openid表示微信用户在本公众号中的唯一标识;","categories":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/categories/后端架构/"},{"name":"OAuth2.0","slug":"后端架构/OAuth2-0","permalink":"http://blog.renyimin.com/categories/后端架构/OAuth2-0/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/tags/后端架构/"},{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"http://blog.renyimin.com/tags/OAuth2-0/"}]},{"title":"03 - OAuth2.0的CSRF攻击","slug":"2016-05-24-OAuth-03","date":"2016-05-24T11:27:36.000Z","updated":"2017-10-25T08:01:49.000Z","comments":true,"path":"2016/05/24/2016-05-24-OAuth-03/","link":"","permalink":"http://blog.renyimin.com/2016/05/24/2016-05-24-OAuth-03/","excerpt":"","text":"假设有如下几个角色:受害者 lant ;攻击者 rymuscle ;第三方Web应用 liangren网 (它允许用户将其在 sandiruiqi网 的账号 和 liangren网 的账号进行绑定) ;OAuth2服务提供平台 sandiruiqi网 ; 攻击流程 攻击者rymuscle 登录 liangren网 并且选择使用自己的 sandiruiqi网 账号登录 ; liangren网 将 攻击者rymuscle 重定向到 sandiruiqi网 的授权页(这时可能需要 攻击者rymuscle 登录过sandiruiqi网), sandiruiqi网 的授权页向 攻击者rymuscle 显示 “是否授权liangren网访问” ; 攻击者rymuscle 在点击”同意授权”之后, 截获 sandiruiqi网 服务器返回的含有 Authorization Code 参数的HTTP响应 ; 然后 攻击者rymuscle 精心构造一个Web页面, 它会触发 liangren网 向 sandiruiqi网 发起令牌申请的请求, 而这个请求中的Authorization Code参数正是上一步 攻击者rymuscle 截获到的code ; 攻击者rymuscle 将这个Web页面放到互联网上, 等待或者诱骗受害者来访问 ; 假设正好一个受害者 lant 访问了 攻击者rymuscle 准备的这个Web页面后, 令牌申请流程在 受害者lant 的浏览器里被顺利触发, laingren网 从 sandiruiqi网 那里获取到access_token, 但是这个token以及通过它进一步获取到的用户信息却都是攻击者 攻击者rymuscle 的 ; 也就是最终 liangren网 将 攻击者rymuscle 的 sandiruiqi 账号同 lant 的 liangren网 账号关联了起来 从此以后, lant只要没有察觉到自己最初被悄悄使用了 攻击者rymuscle 的sandiruiqi网 账号登录, 那么他在 liangren网 上的所有资料, 都可以被 攻击者rymuscle 所看到, 并且 攻击者rymuscle 可能在 lant 的账号中做一些非法操作; 整体时序图分析 先看标准oauth时序图 下面是从网上copy的一张图, 从整体上来看, 这次攻击的时序图类似下图: 可以看到, 攻击的关键点在于:OAuth2的认证流程是分为好几步来完成的, 在标准oauth图的第3步, 第三方应用在收到一个GET请求时, 除了能知道当前用户的cookie, 以及URL中的Authorization Code之外, 难以分辨出这个请求到底是用户本人的意愿, 还是攻击者利用用户的身份伪造出来的请求; 于是乎, 攻击者就能使用移花接木的手段, 提前准备一个含有自己的Authorization Code的请求, 并让受害者的浏览器来接着完成后续的令牌申请流程 ; 难点(涉及到了非state参数防御): 尽管这个攻击既巧妙又隐蔽, 但是要成功进行这样的CSRF攻击也是比较困难的 : 整个攻击必须在短时间内完成, 因为OAuth2提供者颁发的Authorization Code有效期很短, OAuth2官方推荐的时间是不大于10分钟, 而一旦Authorization Code过期那么后续的攻击也就不能进行下去了; 一个Authorization Code只能被使用一次, 如果OAuth2提供者收到重复的Authorization Code, 它会拒绝当前的令牌申请请求, 不止如此, 根据OAuth2官方推荐, 它还可以把和这个已经使用过的Authorization Code相关联的access_token全部撤销掉, 进一步降低安全风险; 其实貌似只要做到Authorization Code只能被使用一次, 就可以防止csrf在此处的攻击了, 因为 rymuscle 在攻击的时候, 一旦获得 Authorization Code, 第三方站点服务器就会使用 Authorization Code 去申请access_token, 然后只要标记 Authorization Code 为已经使用, 那么 受害者lant 即使点击 攻击者rymuscle 构造好的链接也没用, 因为连接中的 Authorization Code 已经被标记为使用过了; 所以不一定非要使用下面的state参数来进行防御比如微信公众平台的OAuth授权: state参数就是可选的新浪开放平台的OAuth授权, state参数也是可选的当然, 他们不一定做的是和此处一样的防御方案, 但明显不依赖于state参数来解决问题; state参数防御: 要防止这样的攻击其实很容易, 作为第三方应用的开发者, 只需在OAuth认证过程中加入 state 参数, 并验证它的参数值即可; 在将用户重定向到OAuth2的Authorization Endpoint去的时候, 为用户生成一个随机的字符串, 并作为state参数加入到URL中 ; 在收到OAuth2服务提供者返回的Authorization Code请求的时候, 验证接收到的state参数值, 如果是正确合法的请求, 那么此时接受到的参数值应该和上一步提到的为该用户生成的state参数值完全一致, 否则就是异常请求; 但需要注意 state参数 需要具备下面几个特性: 不可预测性: 足够的随机, 使得攻击者难以猜到正确的参数值 ;如果你每次生成的state都被放在一起, 比如一个库/缓存中存在很多state;那么问题就是攻击者还是可以拿着自己的code再加上一个state, 来构造一个链接欺骗用户来点击;(假设state正好就在你的库/缓存中); 重点是关联性: state参数值可以和当前用户会话(user session)相互关联的所以应该让state和具体的用户关联起来, 虽然用户还没有登录, 但是也可以让state放到session中 ;然后攻击者要猜测出来一个state的话, 即便是已经生成过了, 但是也得正好攻击的是这个用户; 唯一性: 每个用户每次请求生成的state参数值都是唯一的 ; 时效性: state参数一旦被使用则立即失效 ; 参考 蚂蚁金服开放平台: 其实可以结合以上各种方法一起来进行防御! 参考 移花接木参考 state参数漏洞参考 阮一峰","categories":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/categories/后端架构/"},{"name":"OAuth2.0","slug":"后端架构/OAuth2-0","permalink":"http://blog.renyimin.com/categories/后端架构/OAuth2-0/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/tags/后端架构/"},{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"http://blog.renyimin.com/tags/OAuth2-0/"}]},{"title":"02 - 授权码模式","slug":"2016-05-22-OAuth-02","date":"2016-05-22T12:27:36.000Z","updated":"2017-10-25T08:33:40.000Z","comments":true,"path":"2016/05/22/2016-05-22-OAuth-02/","link":"","permalink":"http://blog.renyimin.com/2016/05/22/2016-05-22-OAuth-02/","excerpt":"","text":"授权码模式运行过程 运行图 运行过程分析1.向用户取得授权许可对应图中的第1、2、3步; 2.申请访问令牌access_token令牌的申请对应图中的第4、5步; 3.使用令牌获取用户数据开放平台在申请完access_token令牌之后, 都提供了对应接口来获取用户相关信息, 比如:QQ互联: 提供了相应的接口, 使用Access Token来获取用户的OpenID;新浪开放平台: 提供了相应的接口来获取access_token对应的用户信息;而微信公众平台: 在获取access_token的时候, 会同时返回openid表示微信用户在本公众号中的唯一标识; 这一过程中涉及了不少敏感参数和数据, 例如client_secret相当于是第三方应用自己的密码, access_token某种程度上来讲就是用户的session id, 由于这些参数以及数据极其特殊, 我们当然得确保它们的安全性, HTTPS加密传输以及安全存储是必不可少的防护手段, 不过仅仅做到这些是远远不够的, 因为其实在这个流程里存在一个弱点， 容易被攻击者利用进行CSRF攻击, 下一篇笔记将会详细分析 ;","categories":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/categories/后端架构/"},{"name":"OAuth2.0","slug":"后端架构/OAuth2-0","permalink":"http://blog.renyimin.com/categories/后端架构/OAuth2-0/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/tags/后端架构/"},{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"http://blog.renyimin.com/tags/OAuth2-0/"}]},{"title":"01 - OAuth(Open Authorization)开放式授权协议","slug":"2016-05-19-OAuth-01","date":"2016-05-19T03:05:00.000Z","updated":"2017-10-27T02:19:29.000Z","comments":true,"path":"2016/05/19/2016-05-19-OAuth-01/","link":"","permalink":"http://blog.renyimin.com/2016/05/19/2016-05-19-OAuth-01/","excerpt":"","text":"OAuth是一个关于授权(authorization)的开放网络标准, 目前的版本是2.0版 OAuth之前的传统”授权”比较 简单, 直接, 暴力, 一般是直接提供自己资源服务器的账号和密码给第三方站点, 要知道这种做的法弊端太多: 12345678910111.如果用户在每个第三方站点都这样做, 那将会存在严重安全隐患:很多第三方网站为了后续的服务, 会保存用户资源服务器的账号和密码, 这样很不安全, 因为难免有些第三方平台会由于自己的安全问题而导致用户的账号和密码泄露, 从而导致用户大量信息泄露 ;2.用户无法设定第三方站点的权利范围:第三方网站拥有了获取用户某个资源服务器的账号和密码后, 就拥有了资源服务器上的所有的资料, 用户没法限制第三方站点获取资源服务器上资源的权利范围和有效期 ;3.用户想收回第三方站点的权利不太方便:用户只有修改密码, 才能收回赋予第三方网站的权力, 否则第三方网站将会永久拥有用户资源服务器上资源的权利，但是这样做, 又会使得其他所有获得用户授权的第三方应用程序全部失效 ;或者, 一些良心第三方可以设置 用户账号 和 资源服务器账号的绑定和解绑, 但不一定所有第三方都会给你做, 如果不做解绑的话, 你还真就只有前一种方法能够收回权利 ; 而OAuth的授权不会让 第三方站点 触及到用户在 资源服务器 上的帐号信息(如用户名与密码), 即第三方站点无需使用用户资源服务器上的账号与密码, 就可以获得该用户在 资源服务器 上的资源, 因此 OAuth 是安全的 ; OAuth2.0协议定义了用于获得授权的”四种主要授权类型”1.授权码(Authorization code)模式 授权码模式是功能最完整、流程最严密的授权模式(标准的Server授权模式, 非常适合Server端的Web应用); 它的特点是: 通过客户端的后台服务器, 与&quot;服务提供商&quot;的认证服务器进行互动; 运行流程图解 123456用户打开客户端以后，客户端要求用户给予授权。用户同意给予客户端授权。客户端使用上一步获得的授权，向认证服务器申请令牌。认证服务器对客户端进行认证以后，确认无误，同意发放令牌。客户端使用令牌，向资源服务器申请获取资源。资源服务器确认令牌无误，同意向客户端开放资源 场景: 比如公司需要对接 QQ, 微博, 微信(网页授权) 等登录授权; 或者公司达到可以做自己对外的开放平台; 当然, 公司如果要做对外开放平台, 可能不止使用这一种模式: 像微信网页授权使用的就是`授权码模式`； 但是微信的基础功能接口和开发者服务器交互的时候, 就使用到了`客户端模式`； 而微信服务器涉及到和开发者服务器进行消息交互的时候, 还使用了类似`JWT`的签名校验来保证数据传输的安全; 2.隐式授权模式(Implicit Grant) 也叫简化模式, 该模式不通过第三方应用程序的服务器, 而是直接在浏览器中向认证服务器申请令牌, 跳过了”授权码”这个步骤, 因此得名; 它的特点是: 所有步骤在浏览器中完成, 令牌对访问者是可见的; 流程图: 场景: 3.密码模式(Resource Owner Password Credentials) 用户向客户端提供自己的用户名和密码, 客户端使用这些信息，向”服务商提供商”索要授权 ; 这种模式要求用户提供用户名和密码来交换访问令牌access_token ; 它的特点是:客户端仍然是以单个用户的名义向”服务提供商”进行认证;在这种模式中, 用户必须把自己的密码给客户端, 但是客户端不得储存密码, 这通常用在 用户对客户端高度信任的情况下, 比如客户端也是系统的一部分; 流程图: 下图也可参考: 场景:比如当third party application、authorization server、resource owner都是自己公司内的系统, Resource owner对third party application足够信任，所以我们就能采取这种模式来实现;就像: 公司如果有多套内部后台系统, 开发人员和公司管理员可能就要准备多套账号, 比较麻烦, 为了解决这个问题, 可以做一个账号中心系统, 用户在登录各个系统后台的时候, 会先跳转到用户中心进行登录, 一旦登录成功之后, 就会给用户分发一个access_token, 用来在各个系统间作为登录认证 (这也实现了SSO单点登录);(参考: http://www.cnblogs.com/richieyang/p/4918819.html) 4.客户端模式(Client Credentials) 客户端模式指客户端以客户端自己的名义, 而不是以单个用户的名义，向”服务提供商”进行认证;严格地说, 客户端模式并不属于OAuth框架所要解决的问题; 流程图: 服务器 不提供像用户数据这样的重要资源，仅仅是一些开放的功能性API;例如微信公众平台, Google Storage或Amazon S3 等开放平台提供的基础服务接口; 场景:1.你自己实现了一套基础服务的Api(都是些基础功能接口, 并不涉及用户数据这种重要资源), 提供给内部其他系统通过认证的方式来调用;2.公司如果实力强悍的话, 也可以将公司开发的基础服务Api公开出来 供外部其他第三方站点服务器 来调用, 比如: 微信公众平台的开放接口其实就是使用这种方式(但微信的网页授权采用的就是授权码模式): 客户端模式(Client Credentials) 和 用户密码模式 有时候比较容易混淆1.客户端模式: 如果客户端以自己的身份向服务提供商进行认证, 那需要授权中心给各个应用(不管是内部系统还是第三方站点服务器)分配对应的AppID和AppSecret, 然后第三方应用使用这两个信息来向”认证服务器”申请access_token, 这种场景下, 认证服务器一般提供的接口都是功能性的基础服务接口;2.用户密码模式: 如果客户端以单个用户身份向服务提供商进行认证, 只要用户账号密码能通过认证服务器, 认证服务器就会发放access_token, 当然这种场景需要的是几方角色都属于本公司内部; 当然这里所聊的是授权相关的知识, 并没有涉及数据传输的加密及签名校验, 但其实像微信公众平台这样开放平台, 除了基础服务接口供给开发者服务器调用时不需要做数据传输的加密和签名校验; 当微信服务器和开发者服务器涉及到用户消息数据的收发时, 会推荐对数据进行加密和签名校验; 参考: http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html参考: http://www.cnblogs.com/richieyang/p/4918819.html参考: http://www.dannysite.com/blog/176/","categories":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/categories/后端架构/"},{"name":"OAuth2.0","slug":"后端架构/OAuth2-0","permalink":"http://blog.renyimin.com/categories/后端架构/OAuth2-0/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"http://blog.renyimin.com/tags/后端架构/"},{"name":"OAuth2.0","slug":"OAuth2-0","permalink":"http://blog.renyimin.com/tags/OAuth2-0/"}]}]}