{"meta":{"title":"Lant's Blog","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"nginx/2017-04-21-02","date":"2018-08-01T03:02:02.000Z","updated":"2018-08-01T03:02:02.000Z","comments":true,"path":"2018/08/01/nginx/2017-04-21-02/","link":"","permalink":"http://blog.renyimin.com/2018/08/01/nginx/2017-04-21-02/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"nginx/2017-04-28-07","date":"2018-08-01T03:02:02.000Z","updated":"2018-08-01T03:02:02.000Z","comments":true,"path":"2018/08/01/nginx/2017-04-28-07/","link":"","permalink":"http://blog.renyimin.com/2018/08/01/nginx/2017-04-28-07/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"nginx/2017-04-22-03","date":"2018-08-01T03:02:02.000Z","updated":"2018-08-01T03:02:02.000Z","comments":true,"path":"2018/08/01/nginx/2017-04-22-03/","link":"","permalink":"http://blog.renyimin.com/2018/08/01/nginx/2017-04-22-03/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"33. 单机部署集群 -- 镜像模式","slug":"rabbitmq/2018-06-29-rabbitmq-33","date":"2018-06-29T13:28:16.000Z","updated":"2018-07-27T12:40:08.000Z","comments":true,"path":"2018/06/29/rabbitmq/2018-06-29-rabbitmq-33/","link":"","permalink":"http://blog.renyimin.com/2018/06/29/rabbitmq/2018-06-29-rabbitmq-33/","excerpt":"","text":"前言 上一篇在学习普通模式的集群时, 已经知道在该模式下, 队列只存活于集群中的一个节点上(在RabbitMQ2.6.0之前, 这也是唯一的选择); 在RabbitMQ2.6.0时, RabbitMQ团队带来了内建的双活冗余选项: 镜像队列; 像普通队列那样, 镜像队列的主拷贝仅存在于一个节点(主队列, master)上, 但与普通队列的不同点是, 镜像节点在集群中的其他节点上拥有从队列(slave拷贝); 一旦队列主节点不可用, 最老的从队列将会被选举为新的主队列; (这貌似就是探索集群时一直寻找的高可用) 声明并使用镜像队列 你的应用程序并不使用 rabbitmqctl 来定义镜像(mirrored)队列; 声明镜像队列就像声明普通队列一样, 不过, 你需要传入一个额外的参数 x-ha-policy 参数到 queue.declare 调用中; 测试:","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"32. 单机部署集群 -- 普通模式","slug":"rabbitmq/2018-06-26-rabbitmq-32","date":"2018-06-26T07:28:16.000Z","updated":"2018-07-27T07:49:14.000Z","comments":true,"path":"2018/06/26/rabbitmq/2018-06-26-rabbitmq-32/","link":"","permalink":"http://blog.renyimin.com/2018/06/26/rabbitmq/2018-06-26-rabbitmq-32/","excerpt":"","text":"前言当你需要在生产环境中部署RabbitMQ时, 需要注意的是, 单实例在生产环境虽然部署起来很容易, 但是当你的rabbitmq服务器遇到内存崩溃或者断电的情况时, 这款高性能的产品就要成为你的耻辱了, 将会为你造成极大的问题!因此你需要将你的RabbitMQ变成高可用的才行; 内建集群简介 RabbitMQ最优秀的功能之一就是其内建集群, 这款消息队列中间件产品本身是基于Erlang编写, Erlang语言天生具备分布式特性(通过同步Erlang集群各节点的magic cookie来实现), 因此, RabbitMQ天然支持Clustering, 这使得RabbitMQ本身不需要像ActiveMQ、Kafka那样通过ZooKeeper分别来实现HA方案和保存集群的元数据。 RabbitMQ内建集群用来完成两个目标: 允许生产者和消费者在RabbitMQ节点崩溃的情况下继续运行;你可以失去一个RabbitMQ节点, 同时客户端可以重新连接到集群中的任何其他节点并继续生产或者消费消息, 就像什么都没有发生一样; 通过增加更多的节点来线性扩展消息吞吐量;如果RabbitMQ正疲于应对庞大的消息通信量的话, 那么线性地增加更多的节点则会增加更多性能; 集群的类型Rabbit集群模式大概分为两种: 普通模式、镜像模式; 本篇主要介绍普通模式 普通模式 普通模式(也就是默认的集群模式), 对于该集群模式, 当你将多个节点组合成集群后, 需要注意的是: 不是每一个节点都有所有队列的完全拷贝 在非集群的单一节点中, 所有关于队列的信息(元数据、状态、内容)都完全存储在该节点上; 但是如果在普通集群模式下创建队列的话, 集群只会在当前节点而不是所有节点上创建完整的队列信息(元数据、状态、内容); 而其他非所有者的节点, 只知道队列的元数据和指向该队列存在的哪个节点的指针; 因此当集群中队列所有者的节点崩溃时, 该节点的队列和关联的绑定就都消失了, 并且附加在这些队列上的消费者就会无法获取其订阅的信息, 并且生产者也无法将匹配该队列绑定信息的消息发送到队列中; 接下来需要了解的一个问题是: 为什么在默认的集群模式下, RabbitMQ不将队列内容和状态复制到所有的节点上? 其实有两个原因 存储空间: 如果每个集群节点都拥有所有Queue的完全数据拷贝, 那么每个节点的存储空间会非常大, 集群的消息积压能力会非常弱(无法通过集群节点的扩容提高消息积压能力); 性能: 消息的发布者需要将消息复制到每一个集群节点, 对于持久化消息来说, 网络和磁盘的负载都会明显增加, 最终只能保持集群性能平稳(甚至更糟); 所以, 通过设置集群中的唯一节点来负责特定队列, 只有该负责节点才会因队列消息而遭受磁盘活动的影响所有其他节点需要将接受到的该队列的消息传递给该队列的所有者节点, 因此, 往RabbitMQ集群添加更多的节点意味着你将拥有更多的节点来传播队列, 这些新增节点为你带来了性能的提升; 但是有人可能会想: 是否可以让消费者重新连接到集群上, 这样不就可以重新创建队列了? 但需要注意的是: 因为一般如果我们的队列设置的是持久化的, 而在该队列的主节点挂掉之后, 重新连接到队列时, 一般也不会修改队列的持久化属性; 这就需要注意一个问题, 仅当你之前创建的队列为非持久化时, 你才可以重新创建该队列为持久化, 因为这是为了保证你之前的持久化队列节点在重新被恢复启动后, 其中的消息还会被恢复, 而如果你创建一个新的持久化队列, 如果覆盖之前的持久化队列, 那消息不就丢了!!所以如果之前是持久化队列, 而且还是以持久化的方式创建该队列, 集群就会报错误, 后面会进行测试! 了解内部元数据RabbitMQ内部会始终同步四种类型的内部元数据: 队列元数据: 队列名称和它的属性 (是否可持久化, 是否自动删除); 交换器元数据: 交换器名称、类型和属性 (可持久化等); 绑定元数据: 一张简单的表格展示了如何将消息路由到队列; vhost元数据: 为vhost内的队列、交换器和绑定提供命名空间和安全属性; 内存or磁盘节点 每个Rabbitmq节点, 不管是单一节点系统或者是庞大集群的一部分, 要么是内存节点(RAM node), 要么是磁盘节点(disk node): 内存节点将所有的队列、交换器、绑定、用户、权限和vhost的元数据定义都仅存储在内存中; 而磁盘节点则将元数据存储在磁盘中; 非集群单一节点: 在单一节点的非集群环境中, RabbitMQ默认会将元数据都存放在内存中; 但是, 会将标记为可持久化的队列和交换器(以及它们的绑定)存储到硬盘上, 存储到硬盘上可以确保队列和交换器在重启Rabbitmq节点后重新被创建; 集群节点类型 当你引入Rabbitmq集群后, RabbitMQ需要追踪的元数据类型包括: 集群节点位置, 以及节点与已记录的其他类型的元数据的关系; 集群对元数据的存储提供了选择:将元数据存储到磁盘上 (集群中创建节点时的默认设置) 或者 存储到RAM内存中 注意, RabbitMQ要求在集群中至少要有一个磁盘节点, 所有其他节点可以是内存节点。当节点加入或者离开集群时, 它们必须要将变更至少通知到一个磁盘节点; 如果只有一个磁盘节点, 而不凑巧的是它有刚好崩溃, 那么集群虽然可以继续路由消息, 但是不能做一下操作: 创建队列 创建交换器 创建绑定 添加用户 更改权限 添加或删除集群节点 集群配置钱准备 在开始配置集群前, 首先要确保现存的Rabbitmq没有运行, 因此需要关闭节点 (本机为mac, 关闭操作如下) 123renyimindeMacBook-Pro:~ renyimin$ brew services stop rabbitmqStopping `rabbitmq`... (might take a while)==&gt; Successfully stopped `rabbitmq` (label: homebrew.mxcl.rabbitmq) 可以发现一个问题, 就是停止Rabbitmq服务之后, 貌似 RabbitMQ Management 的Web UI界面还是可以正常打开运行; 所以正确的关闭节点貌似是 rabbitmqctl stop 开始配置集群前需要注意: 通常来讲, 使用 rabbitmq-server 命令启动节点之后就大功告成了, 但是如果不用额外参数的话, 该命令会使用默认的节点名称 rabbit 和监听端口 5672;所以如果你想用该命令在一台机器上同时启动3个节点的话, 那么第2，3个节点都会因为节点名称和端口号冲突而导致启动失败; 因此, 为了在本机正常启动5个节点, 可以在每次调用 rabbitmq-server前, 通过设置环境变量 RABBITMQ_NODENAME, RABBITMQ_NODE_PORT 来明确指定唯一的节点名称和端口号!在此处做实验时, 将会采用 rabbit, rabbit_1,rabbit_2 命名节点名; 端口号为5612，5613, 5614 注意, 到目前为止, 虽然尚未谈论RabbitMQ的插件, 不过你有可能已经启用了一部分插件了; 如果确实如此的话, 你需要在启动集群节点前将插件禁用!这是因为像 RabbitMQ Management 这样的插件会监听专门的端口来提供服务(例如 Management 插件的 Web UI), 目前还没讲到如何设置插件监听不同的端口, 所以当第二个节点和之后的节点启动了它们的插件后, 就会和第一个启动节点的c插件相冲突, 然后节点就都崩溃了;可以先不禁用插件, 这样在启动多个节点时, 可以根据报错一个个关闭插件也可以; (rabbitmq-plugins disable 插件名) RabbitMQ集群的搭建 启动节点 注意: 启动的时候, 直接加上 -detached 参数的话, 可能会有些报错信息比如 error : cannot_delete_plugins_expand_dir, 这就是因为需要使用root权限才可以, 你可以使用 pa aux | grep rabbitmq 查看是否三个进程都成功启动了 注意: 启动时, 貌似不能像书上那样, RABBITMQ_NODENAME 只设置节点名, 最好设置上节点host 如下: 1234567renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detachedWarning: PID file not written; -detached was passed.renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit_1@localhost rabbitmq-server -detachedWarning: PID file not written; -detached was passed.renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit_2@localhost rabbitmq-server -detachedWarning: PID file not written; -detached was passed.renyimindeMacBook-Pro:~ renyimin$ 然后可以查看个节点状态 123renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost statusrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost statusrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost status 现在启动了三个节点 rabbit, rabbit_1, rabbit_2, 并且每个节点都会有系统的主机名在@后; 但是每个节点仍然是独立节点, 拥有自己的元数据, 并且不知道其他节点的存在; 集群中的第一个节点rabbit,将初始元数据带入集群, 并且无需被告知加入; 而第二个和之后的节点, 将加入第一个节点rabbit, 并获取rabbit节点的元数据; 要将rabbit_1和rabbit_2节点加入rabbit, 要停止该Erlang节点上运行的rabbitmq应用程序, 并重设它们的元数据, 这样它们才可以被加入rabbit节点并且获取rabbit节点的元数据; 可以使用 rabbitmqctl 来完成这些工作 停止rabbit_1节点上的应用程序 12renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost stop_appStopping rabbit application on node rabbit_1@renyimindeMacBook-Pro ... 重设rabbit_1节点的元数据和状态为清空状态 12renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost resetResetting node rabbit_1@renyimindeMacBook-Pro ... 这样你就准备好了一个 停止运行的并且清空了的 rabbit 应用, 现在可以准备好将其加入到集群中的第一个节点rabbit中:注意书上的 cluster 命令好像已经不用了, 换成了 join_cluster 123renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost join_cluster rabbit@localhostClustering node rabbit_1@localhost with rabbit@localhostrenyimindeMacBook-Pro:~ renyimin$ 最后, 可以重启第二个节点的应用程序 1234renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_appStarting node rabbit_1@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ 节点rabbit_2加入集群的步骤同上, 具体操作如下: 12345678910111213renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_appStarting node rabbit_1@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_appStopping rabbit application on node rabbit_2@localhost ...renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost resetResetting node rabbit_2@localhost ...renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost join_cluster rabbit@localhostClustering node rabbit_2@localhost with rabbit@localhostrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_appStarting node rabbit_2@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ 查看集群状态, 可以在任意一个节点通过 rabbitmqctl cluster_status 进行查看 123456789101112131415161718192021222324252627282930renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_statusCluster status of node rabbit@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_statusCluster status of node rabbit_1@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost cluster_statusCluster status of node rabbit_2@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit_2@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ 注意: 上面使用比较多的 rabbitmqctl 命令的关键参数是 -n, 这会告诉rabbitmqctl命令, 你想在指定节点而非默认节点rabbit@上执行命令; 记住, Erlang节点间通过Erlang cookie的方式来允许互相通信。因为rabbitmqctl使用Erlang OPT通信机制来和Rabbit节点通信, 运行rabbitmqctl的机器和所要连接的Rabbit节点必须使用相同的Erlang cookie, 否则你会得到一个错误;当然, 上面的集群是在本机做伪集群, Erlang cookie 自然也都是一致的! 将节点从集群中删除 forget_cluster_node 1234567renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_1@localhostRemoving node rabbit_1@localhost from the clusterrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_2@localhostRemoving node rabbit_2@localhost from the clusterrenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_3@localhostRemoving node rabbit_3@localhost from the clusterrenyimindeMacBook-Pro:~ renyimin$ 集群节点类型设置与修改 可以在将节点加入集群时, 设定节点的类型 (参考) 比如 rabbitmqctl -n rabbit_3@localhost join_cluster --ram rabbit@localhost 之前已经通过 rabbitmqctl cluster_status 查看了集群的状态, 里面比较重要的是 nodes 部分 下面告诉你有三个节点加入了集群, 并且三个节点都是 disc 磁盘节点! 1234567[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit_2@localhost,[]&#125;]&#125;] running_nodes 部分告诉你集群中的哪些节点正在运行; 现在你可以连接到这三个running_nodes中的任何一个, 并且开始创建队列, 发布消息或者执行任何其他AMQP任务; 你也可以对节点类型进行修改, 如下将rabbit_2节点类型修改为内存节点 (注意: 修改节点类型, 需要先停止节点应用) 1234567891011121314151617181920renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_appStopping rabbit application on node rabbit_2@localhost ...renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost change_cluster_node_type ramTurning rabbit_2@localhost into a ram noderenyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_appStarting node rabbit_2@localhost ... completed with 1 plugins.renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_statusCluster status of node rabbit_1@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost]&#125;, &#123;ram,[rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;]&#125;]renyimindeMacBook-Pro:~ renyimin$ 测试 运行生产者代码, 在集群中的rabbit节点中创建持久化队列 初始集群状态123456789renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_statusCluster status of node rabbit@localhost ...[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;, &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;, &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindemacbook-pro.rrcoa.com&quot;&gt;&gt;&#125;, &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;, &#123;rabbit_1@localhost,[]&#125;, &#123;rabbit@localhost,[]&#125;]&#125;] - 运行生产者, 查看创建的队列(已经有一条msg放入队列中) 123456789101112131415161718192021renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...prefetchCountQueue 0localClusterQueue 1renyimindeMacBook-Pro:~ renyimin$ kill掉该持久化队列localClusterQueue所在的主节点rabbit 查看节点进程 12345renyimindeMacBook-Pro:~ renyimin$ ps aux | grep rabbitmqroot 2656 0.4 0.3 4150148 58156 ?? S 三01下午 5:09.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5672&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost&quot; -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 -noshell -noinputrenyimin 28537 0.0 0.0 2423384 232 s007 R+ 3:12下午 0:00.00 grep rabbitmqroot 72516 0.0 0.5 4143168 79400 ?? S 1:03下午 0:16.71 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_2@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5674&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost&quot; -kernel inet_dist_listen_min 25674 -kernel inet_dist_listen_max 25674 -noshell -noinputroot 71841 0.0 0.5 4138448 77104 ?? S 1:01下午 0:15.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_1@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5673&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost&quot; -kernel inet_dist_listen_min 25673 -kernel inet_dist_listen_max 25673 -noshell -noinput sudo kill 2656 将生产者改连 rabbit_1 节点, 重新运行生产者 报错: 挂掉的主节点中已存在该持久化队列, 如果在主节点挂掉后, 你能直接连接其他节点创建该队列的话, 此时创建的是个新队列, 要知道, 宕机的主节点中的持久化队列还在等待恢复呢, 它内部可能让然有很多msg需要恢复并被处理;所以Rabbit集群的这个问题是有原因的!! 可以重新启动该节点 sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detached 会发现之前的持久化队列会被恢复123456789101112131415161718renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 1prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 1prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 1prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$ 此时即使生产者连接着 rabbit_1 也可以创建该同名持久化队列了 重新运行刚才连接到 rabbit_1 的生产者, 不会报错了, 而是正确往队列发布了一条消息123456renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queuesTimeout: 60.0 seconds ...Listing queues for vhost / ...localClusterQueue 2prefetchCountQueue 0renyimindeMacBook-Pro:~ renyimin$","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"20. 消费者预取 Consumer Prefetch","slug":"rabbitmq/2018-06-13-rabbitmq-20","date":"2018-06-13T11:23:36.000Z","updated":"2018-07-19T02:06:14.000Z","comments":true,"path":"2018/06/13/rabbitmq/2018-06-13-rabbitmq-20/","link":"","permalink":"http://blog.renyimin.com/2018/06/13/rabbitmq/2018-06-13-rabbitmq-20/","excerpt":"","text":"Consumer Prefetch 作为限制 unacked 消息数量的更自然有效的方法; AMQP 0-9-1 指定了 basic.qos 方法, 以便你在消费者进行消费时, 可以限制channel(或connection)上未确认消息的数量; 但是值得注意的是: channel 并不是理想的设定范围, 因为单个channel可能从多个队列进行消费, channel和queue需要为每个发送的消息相互协调, 以确保它们不会超出限制, 这在单台机器上会慢, 而在整个集群中使用时会非常慢; 此外, 对于许多用途, 指定适用于每个消费者的预取计数更会简单一些; 因此, RabbitMQ在 basic.qos 方法中重新定义了全局标志的含义 (在php-amqplib中basic_qos()的第三个参数a_global): 请注意, 在大多数API中, 全局标志的默认值为false; (php-amqplib的basic_qos()方法的第三个参数a_global默认也为false) 简要分析 在使用RabbitMQ时, 如果完全不配置QoS, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是采用默认方式, 将队列中的所有消息按照网络和客户端允许的速度尽快轮发到与队列绑定的consumers端; 而consumers会在本地缓存所有投递过来的messages, 这样的话, 就可能会导致 如果某个消费者的业务逻辑处理比较复杂(将会在较长时间之后才会操作完成并进行ack), 这也就导致消费慢的Consumer将会在本地堆积很多消息, 从而导致内存不足或者对其他进程造成影响 (消费者可能被撑到假死); 而其他消费能力强的Consumers, 可能已经很快地消费完成处于闲置状态, 从而造成资源浪费; 同时, 新启的消费者也无法分担已经被之前消费者缓存到其本地的消息, 所以此时即便启动更多消费者, 也无力缓解大量的 unacked 消息积压, 让你产生疑惑; 而当你设置了Qos之后, RabbitMQ虽然也是将队列中的消息尽快轮发到Consumers中, 但是因为消费者具有的 prefetch_count 消息预取值上限, 所以RabbitMQ在轮发消息的时候, 如果发现消费者的 unacked 消息达到了 prefetch_count 的值, 即使rabbitmq中有很多ready的就绪消息, 也不会给该Consumer继续投递消息了(只有消费者的 unacked 消息小于prefetch_count的值时, 才会继续通过轮发方式给该consumer投递ready消息), 如果此时有新的消费者加入, 它也将会拿到未投递出去的ready消息! 可以通过启动 prefetchCountConsumer1，prefetchCountConsumer2 两个消费者(prefetch_count 均为10), 然后使用下面测试中的生产者发送100条消息, 前期观察会发现队列中消息的最大 unacked 为20, 并且你会发现队列中处于ready状态的消息会每次2个的递减, 这就预示着, 每次这两个消费者只要 unacked 的消息书小于prefetch_count(10), Rabbitmq才会给这两个consumer各自发送一条msg; 之后如果启动了 prefetchCountConsumer3(prefetch_count为20), 此时会发现队列中消息的最大 unacked 会为40, prefetchCountConsumer3的加入会使得队列中处于ready状态的消息直接骤减20个, 最后rabbitmq中的ready消息已经为0, 每个消费者还在继续消费各自未 unacked 的消息, 最终消费完成后, 整个队列中的 unacked 消息为0; Qos的设置只有在开启手动ack后才会生效 (即, prefetch_count 在 no_ask=false 的情况下生效) 测试 一般情况下, 同一队列绑定的多个消费者都是处理同一个业务, 而且如果在同一台机器启动, 消费能力应该都差不多, 但也难免出现如: 消费者资源分配不均 或者 两个消费者在处理业务时所请求的服务端机器配置有差异(假设SLB后又2台配置不均的机器), 这种情况还是应该考虑进来的! 本测试比较简单, 主要测试在默认不设置Qos的情况下, 两个消费能力不同的消费者在处理消息时存在的问题之一: 由于这种情况下, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是只顾自己轮发消息, 这样就会导致消息被轮发完成后, 消费能力高的消费者可能很快消费完消息并处于闲置状态, 而消费能力低的消费者却在很慢地进行消费, 这样就造成了资源的浪费; 准备 创建消费者1 ‘qosCustomer1’ (简单打印消息内容) , 代码参考, 启动消费者 php artisan qosConsumer1 创建消费者2 ‘qosCustomer2’ (sleep 5秒, 模拟处理能力比较差) , 代码参考, 启动消费者 php artisan qosConsumer2 创建生产者一次向队列 ‘qosQueue’ 中推送10条消息 , 代码参考, 请求一次生产者 http://www.rabbit.com/testQos 注意需要先启动消费者, 再请求生产者; (如果先请求了生产者, 可能在启动第一个消费者之后, 其会迅速消费完10条消息, 这样就无法模拟效果了) 测试发现 qosCustomer1 : 迅速打印出结果(1,3,5,7,9), 然后就处于闲置状态了 qosCustomer2 : 还在缓慢打印(2,4,6,8,10) 可以看到, 如果不设置Qos, Rabbitmq会尽快将消息从队列中轮发投递出去, 不会对消费者的消费能力进行任何评估! 所以: 为了避免这种浪费资源的情况, 你可能就需要根据上一篇讲解的 prefetch_count 来针对不同消费者进行设置; 问题答疑测试 根据上面的描述, 有个疑问: 在默认不设置Qos的情况下, 既然生产者发布的消息会尽可能全部推送给消费者进程, 队列中会尽可能将消息全部推出, 缓存在消费者本地, 那当消费者断开时, 消息是如何恢复到队列中的? 或者不会恢复到队列中? 为了答疑, 下面进行测试 准备测试代码 创建消费者1 ‘prefetchCountConsumer1’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), 代码参考 创建消费者2 ‘prefetchCountConsumer2’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), 代码参考 生产者一次向队列 ‘prefetchCountQueue’ 中推送100条消息 , 代码参考 测试: 在生产者请求一次之后(http://www.rabbit.com/prefetchCount), ready : 100, unacked: 0, total : 100, 表示队列中已经有100条消息已经就绪, 等待发出 运行第一个php artisan prefetchCountConsumer1之后, ready : 0, unacked : 100, total : 100 (也就是说, queue中已经没有 ready状态, 即准备好待发送的消息了, 消息都传递给消费者1了) 随着消费者的缓慢消费, ready : 0, unacked : 94, total : 94 () 如果模拟 挂掉第一个消费者之后, 会发现, ready : 83， unacked : 0, total : 83 (也就是说消费者意外宕掉之后, 队列中的消息会重新处于就绪状态, 等待着新的消费者来消费) 再次启动消费者2 php artisan testQosConsumerPrefetchCount2之后, ready : 0, unacked : 80, total : 80 (消息又会被全量发送给消费者2) 注意: 如果此时启动消费者1, 你会发现, 它是无法帮助消费者2进行消费的, 因为消息都在消费者2的本地, 所以队列中并没有 ready状态的就绪消息; 测试注意: 上述测试过程如果先启动两个消费者, 然后再发布消息进行测试, 你会发现, 由于两个消费者都设置了预取值, 而且相等, 所以消息仍然会快速轮发给这两个消费者; 如果将两个消费者的 prefetch_count 都设置为10, 那么你会发现, unacked 最多也就是两个消费者的prefetch_count和, 即20个 小结 消费者的 unacked 消息数量如果未达到Qos设置的 prefetch_count 量, Rabbit不会顾及消费者的消费能力, 会尽可能将queue中的消息全部推送出去给消费者; 因此, 当你发现消费者消费缓慢, 产生大量 unacked 消息时, 即便增加新的消费者, 也无法帮助之前的消费者分担消息(除非消费者1的 unacked 达到了 prefetch_count 限制), 只能分担队列中处于 ready 状态的消息; 除非你断开之前的消费者, 然后启动一个新的消费者, 消费者中积压的消息才会重新放入队列中 (因为之前的消费者挂掉之后, 其处理后的剩余消息在 queue中会恢复为 ready 状态) 但是注意: 新启动的这个消费者如果设置额prefetch_count不合理的话, 假设与之前消费者的 预取值 设置一样大, 它很快也会产生大量 unacked 消息 所以, 在新启消费者的时候, 需要设计好 prefetch_count 的大小, 然后可以启动多个消费者来共同进行消费; 扩展 rabbitmq对 basic.qos 信令的处理 首先, basic.qos 是针对 channel 进行设置的, 也就是说只有在channel建立之后才能发送basic.qos信令; RabbitMQ只支持通道级的预取计数, 而不是connection级的 或者 基于大小的预取;预取 在rabbitmq的实现中, 每个channel都对应会有一个rabbit_limiter进程, 当收到basic.qos信令后, 在rabbit_limiter进程中记录信令中prefetch_count的值, 同时记录的还有该channel未ack的消息个数; 在php-amqplib中, 可以使用 channel 的 basic_qos() 方法来进行控制, basic_qos() 有三个参数: prefetch_size : 限制预取的消息大小的参数, rabbitmq暂时没有实现 (如果prefetch_size字段不是默认值0, 则会通知客户端出错, 通知客户端RabbitMQ系统没有实现该参数的功能, 还可以参考此文)当你设置prefetch_size大于0的时候, 会出现如下报错 prefetch_count : 预取消息数量 global: 在3.3.0版本中对global这个参数的含义进行了重新定义, 即glotal=true时表示在当前channel上所有的consumer都生效(包括已有的), 否则只对设置了之后新建的consumer生效;","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"19. 消费者预取 Consumer Prefetch (避免队列大量unacked积压及Consumer假死)","slug":"rabbitmq/2018-06-12-rabbitmq-19","date":"2018-06-12T03:26:55.000Z","updated":"2018-07-21T03:21:13.000Z","comments":true,"path":"2018/06/12/rabbitmq/2018-06-12-rabbitmq-19/","link":"","permalink":"http://blog.renyimin.com/2018/06/12/rabbitmq/2018-06-12-rabbitmq-19/","excerpt":"","text":"RabbitMQ关于吞吐量,延迟和带宽的一些理论 假设你在Rabbit中有一个队列, 并有一些客户端从这个队列中进行消费, 如果你根本没有设置QoS, 那么Rabbit将尽可能快地按照网络和客户端允许的速度将所有队列的消息推送到客户端; 因此, 消费者所占用的内存将会激增, 因为它们将所有消息都缓存在自己的RAM中; 同时, 值得注意的是: 此时如果你询问Rabbit, 队列可能会显示为空, 但是会有大量的 unacked 消息; 并且此时如果你添加新的消费者, 由于消息已经在现有的客户端中缓存, 队列中并没有 ready状态的 消息, 所以即使增加更多新的消费者, 也无法缓解队列中 unacked 消息数量, 这是相当次优的! 所以，默认的QoS预取给客户端(consumer)设置了无限的缓冲区, 这可能导致不良的行为和性能; 那么, 应该将QoS预取缓冲区大小设置为多少呢? 目标是让消费者保持工作饱和状态, 但要尽量减少客户端的缓冲区大小, 以便让更多的消息保留在Rabbit的队列中, 这样就可以供新消费者来消费; 比方说, Rabbit从这个队列中拿出一条消息, 把它投递给消费者, 需要50ms, 而Consumer处理消息需要4ms; 一旦消费者处理了消息, 它就会发送一个ack给Rabbit, 这将再次花费50ms发送给Rabbit并被Rabbit进行处理; 所以 消费完成并进行一次ack的时间 + 一次消息从队列到Consumer的投递时间 总共会花费104ms的往返时间。 如果我们消息设置了QoS预取值为1, 那么直到这个往返行程完成之前, Rabbit是不会发送下一个消息给客户端的;因此, 每次往返的104ms中, Consumer只有4ms, 或者说只有3.8％的时间忙碌, 而我们希望Consumer百分之百的时间都在忙碌中; 如果我们在每个消息的客户端上执行 总的往返时间/处理时间, 会得到 104/4 = 26如果我们设置消息的QoS预取值为26, 那就解决了我们的问题: 如果每条消息需要4ms的处理来处理, 那么总共需要 26×4 = 104ms 来处理整个缓冲区(中的消息);第一个4ms是第一个消息的处理时间, 处理完成后, 客户端然后发出一个确认(这需要50ms才能到达代理), 然后继续处理缓冲区中的下一条消息, 一次ack时间 + 新一轮消息的投递时间 = 100s, Consumer正好完成缓冲区剩下的25条消息, 然后新的26条消息也已经到达, 并准备好等待客户端来处理它;因此, 客户端始终处于忙碌状态: 具有较大的QoS预取值也不会使其更快了, 但是我们最大限度地减少了缓冲区的大小, 并且减少了客户端消息的延迟;客户端能够在下一条消息到达之前完全排空缓冲区, 因此缓冲区实际上保持为空; 如果处理时间和网络行为保持不变, 此解决方案绝对没问题 但考虑一下如果网络突然间速度减半会发生什么情况? 显然, 网络传输时间就加长了, 此时你的预取缓冲区(也就是你设置的prefetch预取值)就不够大了, 现在Consumer会就会稍有闲置, 等待新消息到达, 因为客户端能够处理消息的速度比Rabbit能够提供新消息的速度要快; 为了解决这个问题, 我们可能会决定将QoS预取大小加倍(或接近两倍), 如果我们从26开始将它推到51, 那么如果客户端处理保持在每个消息4ms, 我们现在在缓冲区中会有51 * 4 = 204ms的消息处理时间, 其中4ms将用于处理消息, 而200ms用于发送消息回复rabbit并收到下一条消息, 因此, 我们现在可以应对网络速度的减半; 再次分析: 如果网络又恢复正常运行, 现在将QoS预取加倍, 意味着每个消息都会驻留在客户端缓冲区中一段时间​​, 而不是在到达客户端时立即处理; 从现在51条消息的完整缓冲区开始, 我们知道新消息将在客户端完成处理第一条消息之后的100ms处开始出现在客户端, 但在这100毫秒内, 客户只能处理100/4 = 25个消息, 这意味着当新消息到达客户端时, 它会在客户端从缓冲区头部移除时被添加到缓冲区的末尾; 而缓冲区将始终保持(50 - 25 = 25)个消息长度, 因此每个消息将在缓冲区中保持 25 * 4 = 100ms; 因此, 增加预取缓冲区大小, 可以使consumer应对恶化的网络性能, 同时保持客户端繁忙; 同样, 如果不是网络性能的恶化, 而是客户端开始花费40ms来处理每条消息而不是之前的4ms, 会发生什么情况? 假设原始的预取缓冲区大小设置的是26条消息, 客户端现在需要花40ms处理第一条消息, 然后将确认消息发送回Rabbit并移至下一条消息;ack仍然需要50ms才能到达Rabbit, 而Rabbit发出一条新的消息需要50ms, 但在100ms内, 客户端只处理了 100/40 = 2.5 条消息, 而不是剩余的25条消息;因此当新消息到来时, 缓冲区在这一点上仍然是有 25 - 3 = 22 个消息, 这样的话, 来自Rabbit的新消息就不会被立即处理, 而是位于第23位, 落后于其他22条仍在等待处理的消息;客户端(Consumer)将会有 22 * 40 = 880ms 的时间都不会触及到那个新到的消息, 鉴于从Rabbit到客户端的网络延迟仅为50ms, 这个额外的880ms延迟现在为延迟的95％ (880 / (880 + 50) = 0.946); 当你决定尝试通过添加更多消费者来处理这种增长的积压时, 需要注意, 现在有消息正在被现有客户端缓冲, 并不是说你增加消费者就能缓解这部分的压力! 更糟糕的是, 如果我们将缓冲区大小设置为可以预取51条消息以应对网络性能下降,会发生什么?处理第一条消息后, 将在客户端缓冲另外50条消息, 100ms后(假设网络运行正常), 一条新消息将从Rabbit到达客户端, consumer在100ms中只能处理这50条消息中的两条消息(缓冲区现在为47条消息长),因此新消息将会在缓冲区中是第48位, 这样的话, 知道 47 40 = 1880ms 之后, 消费者才会开始处理新来的消息, 同样, 考虑到向客户端发送消息的网络延迟仅为50ms, 现在这个1880ms的延迟意味着客户端缓冲占延迟的97％(1880/(1880 + 50)= 0.974);这可能是不可接受的: 数据只能在客户端收到后2秒内立即处理, 才能有效且有用！*如果其他消费客户端空闲, 他们无能为力: 一旦Rabbit向客户端发送消息, 消息就是客户端的责任, 直到他们拒绝或拒绝消息; 消息发送到客户端后，客户端不能窃取彼此的消息;您希望客户端保持繁忙状态, 但客户端尽可能少地缓存消息, 以便客户端缓冲区不会延迟消息, 因此新消费客户端可以快速接收来自Rabbit队列的消息; 因此, 如果网络变慢, 缓冲区太小会导致客户端空闲; 但如果网络正常运行, 缓冲区太大会导致大量额外的延迟;如果客户端突然开始花费更长时间来处理每个缓冲区, 则会导致大量额外的延迟;很明显, 你真正想要的是可以变化的缓冲区大小, 这些问题在网络设备中很常见, 并且一直是很多研究的主题;主动队列管理算法试图尝试放弃或拒绝消息，以避免消息长时间处于缓冲区。当缓冲区保持空闲时（每条消息只遭受网络延迟，并且根本不在缓冲区中），缓冲区在那里吸收峰值，从而实现最低延迟。从网络路由器的角度来看，Jim Gettys一直在研究这个问题：局域网和广域网性能之间的差异会遇到完全相同的问题。实际上，无论何时，在生产者（在我们的例子中为Rabbit）和消费者（客户端应用程序逻辑）之间都有一个缓冲区，双方的性能可以动态变化，您将会遇到这些问题。最近发布了一种名为Controlled Delay的新算法，该算法似乎在解决这些问题方面效果很好。 小结 针对Qos的提前预习 信道预取设置(QoS)由于消息是异步发送(推送)给客户端的, 因此在任何给定时刻通常都有不止一条消息在信道上运行; 此外, 客户的手动确认本质上也是异步的, 所以有一个 未确认的交付标签的滑动窗口, 开发人员通常会倾向于限制此窗口的大小, 以避免消费者端无限制的缓冲区问题。这是通过使用 basic.qos 方法设置 预取计数 值完成的, 该值定义了channel上允许的最大未确认递送数量, 一旦数字达到配置的计数, RabbitMQ将停止在通道上传送更多消息, 除非至少有一个未确认的消息被确认;例如, 假设在通道 “Ch” 上有未确认的交付标签5,6,7和8, 并且通道 “Ch” 的预取计数(后面会学到是prefetch_count)设置为4, 则RabbitMQ将不会在 “Ch” 上推送更多交付, 除非至少有一个未完成的交付被确认(当确认帧在 delivery_tag=8 的频道上到达时, RabbitMQ将会注意到并再发送一条消息) QoS预取设置对使用 basic.get(pull API) 获取的消息没有影响, 即使在手动确认模式下也是如此; 消费者确认模式, 预取和吞吐量 确认模式 和 QoS预取值 对消费者吞吐量有显着影响, 一般来说, 增加预取值将提高向消费者传递消息的速度, 当然, 自动确认模式可以产生最佳的传送速率 但是, 在上面两种情况下, 尚未完成交付处理的消息(unacked)数量也会增加, 从而增加消费者RAM消耗; 自动确认模式或带无限预取的手动确认模式应谨慎使用, 消费者在没有确认的情况下消耗大量消息将导致其所连接的节点上的内存消耗增长; 预取值1是最保守的, 但这将显着降低吞吐量, 特别是在消费者连接延迟较高的环境中, 对于许多应用来说, 更高的价值是合适和最佳的; 100到300范围内的Qos(prefetch_count)预取值通常提供最佳的吞吐量, 并且不会面临压垮consumer的重大风险, 而更高的值往往会遇到效率递减的规律;","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"08. 事务 VS Publisher Confirms(发布者确认机制)","slug":"rabbitmq/2018-06-05-rabbitmq-08","date":"2018-06-05T11:20:56.000Z","updated":"2018-07-20T11:29:01.000Z","comments":true,"path":"2018/06/05/rabbitmq/2018-06-05-rabbitmq-08/","link":"","permalink":"http://blog.renyimin.com/2018/06/05/rabbitmq/2018-06-05-rabbitmq-08/","excerpt":"","text":"问题的出现 和消息持久化相关的一个概念是 AMQP 的事务(transaction)机制; 到目前为止, 我们讨论的是将 消息, 队列 和 交换器 设置为持久化; 这一切都工作的很好, 并且RabbitMQ也负责保证消息的安全, 但是由于 发布消息的操作并不会反回任何信息给生产者, 所以你也无法得知是否消息已经到达了服务器并且服务器是否已经将消息持久化到了硬盘; 服务器可能会在把消息写入到硬盘前就宕机了, 或者消息压根就还没有发送到服务器, 服务器就宕机了, 消息会因此而丢失, 而你却不知道; 另外, 你可能是发送多条消息, 如果部分发送成功, 部分失败呢? 这你也无法得知; 事务机制 为了确保消息能够被安全发布到Broker, 如果使用标准的AMQP 0-9-1, 保证消息不会丢失的唯一方法是使用 事务机制 (将channel事务化) php-amqplib 中与事务机制有关的方法有三个, 分别是Channel里面的 txSelect(), txCommit() 以及 txRollback(); txSelect(): 用于将当前Channel设置成是transaction模式 txCommit(): 用于提交事务 txRollback(): 用于回滚事务 但是值得注意的是事务存在的问题: AMQP 0-9-1 中的事务几乎吸干了RabbitMQ的性能, 会导致事务吞吐量严重下降; 事务会使得生产者应用程序变成同步的, 而你使用消息通信就是为了避免同步; 鉴于上面的问题, 你可能不会在生产中使用事务机制, 此处只做了个简单的事务测试, 测试代码 Publisher Confirms 既然事务存在的问题让你拒绝使用它, 但是确保消息被成功投递到服务器这个问题仍需要解决; 为了避免事务机制在解决问题时导致的新问题, RabbitMQ团队拿出了更好的方案来保证消息的投递: 发送方确认模式 它模仿协议中已经存在的 消费者确认机制 要启用这个确认机制，客户端可以通过使用 channel 的 confirm.select 方法 如果设置了 confirm.select 方法的 no-wait, 代理会用 confirm.select-ok 进行响应, 不过这点你貌似也只能通过抓包来观察: 这里说的 confirm.select-ok 是代理对发布者的响应信息 (和 php-amqplib包中的 confirm_select_ok() 方法可不是一个意思, 而且php-amqplib也没对confirm_select_ok做实现) 上面也提到了, 该确认机制是模仿已经存在的 消费者确认机制, 所以, Broker也会使用类似 ack, nack 来响应Publisher: 可以通过为 set_ack_handler , set_nack_handler 设置回调, 来监测消息是否成功到达服务器, 成功则会触发 set_ack_handler, 失败则会触发 set_nack_handler 只有在负责队列的Erlang进程中发生内部错误时才会回应nack, 所以这个在测试中也一直没有使用 set_nack_handler 捕获到错误 (是对于nack的消息, 可以设置进行重发); 注意: 这两监听函数是监听服务器对 publisher 的应答的, 可不是监听 consumer 对服务器的应答的; 一旦在channel上使用 confirm.select 方法, 就说 channel 处于 确认模式, 一旦通道处于确认模式, 就不能进行事务处理; 也就是说 事务 和 Publisher Confirm 不能同时使用; 一旦通道处于确认模式, 代理和客户端都会对消息进行计数(在第一次confirm.select时从1开始计数), 然后, broker通过在相同channel上发送 basic.ack 来处理它们, 从而确认消息; delivery-tag 字段包含确认消息的序列号;最大 Delivery Tag, 递送标签是一个64位长的值，因此其最大值为9223372036854775807.由于递送标签的范围是按每个通道划分的，因此发布商或消费者在实践中不太可能运行该值 Publisher Confirms 的顺序考虑 在大多数情况下, RabbitMQ将按发布顺序向publisher确认消息(这适用于在单个频道上发布的消息); 但是, 发布者确认是异步发出的, 并且可以确认一条消息或一组消息;由于消息确认可以以不同的顺序到达, 所以, 应用程序应尽可能不取决于确认的顺序; 发布者确认存在的问题 mandatory 属性问题 测试代码publisher confirm 不需要消费者参与, 代码参考","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"06. 持久化策略","slug":"rabbitmq/2018-05-28-rabbitmq-06","date":"2018-05-28T09:32:11.000Z","updated":"2018-07-20T09:43:29.000Z","comments":true,"path":"2018/05/28/rabbitmq/2018-05-28-rabbitmq-06/","link":"","permalink":"http://blog.renyimin.com/2018/05/28/rabbitmq/2018-05-28-rabbitmq-06/","excerpt":"","text":"持久化原理 RabbitMQ 默认情况下, Exchange, 队列, 消息 都是非持久的, 这意味着一旦消息服务器重启, 所有已声明的 Exchange, 队列, 以及 队列中的消息 都会丢失; RabbitMQ确保持久化的消息能在服务器重启之后恢复的方式是, 将它们写入磁盘上的一个持久化日志文件。当发布一条持久性消息到一个持久交换机上时, Rabbit会在消息提交到日志文件中之后才发送响应; 还需要注意的是, 如果之后这条消息被路由到一个非持久化队列, 则消息又会从上面的日志文件中删除, 并且无法从服务器重启中恢复; 一旦你从持久化队列中消费了一条持久性消息(并且进行了确认), RabbitMQ会在持久化日志中把这条消息标记为等待垃圾收集; 持久化方案 要做到消息持久化, 必须保证如下三点设置正确: exchange交换器: durable属性为true; queue队列: durable属性为true; 除了上述两点之外, 还需要在投递消息时候, 设置message的 delivery_mode 模式为2来标识消息为持久化消息; 另外: 一个包含持久化消息的非持久化队列, 在Rabbit Server重启之后, 该队列将会不复存在, 消息就会变成孤儿; 具体代码 持久化的问题 持久化由于会写磁盘, 所以会极大降低RabbitMQ每秒处理的消息总数, 降低吞吐量; 持久化在Rabbit内建集群环境下工作的并不好, 虽然RabbitMQ集群允许你和集群中的任何节点的任一队列进行通信, 但是如果队列所在的节点崩溃后, 如果队列是持久化的, 那么直到这个节点恢复之前, 这个队列都不会在整个集群中被创建出来; 后面在学习集群时, 会给出相应的解决方案;","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://blog.renyimin.com/tags/RabbitMQ/"}]},{"title":"05. 容器","slug":"docker/2017-12-16-05-docker","date":"2017-12-16T03:06:58.000Z","updated":"2018-08-04T07:41:35.000Z","comments":true,"path":"2017/12/16/docker/2017-12-16-05-docker/","link":"","permalink":"http://blog.renyimin.com/2017/12/16/docker/2017-12-16-05-docker/","excerpt":"","text":"容器 镜像(Image)和容器(Container)的关系, 就像是面向对象程序设计中的 类 和 实例 的关系一样, 镜像是静态的定义, 容器是镜像运行时的实体; 容器可以被 创建、启动、停止、删除、暂停等; 容器的实质是进程, 但与直接在宿主执行的进程不同, 容器进程运行于属于自己的独立的命名空间 因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间, 甚至自己的用户ID空间; 容器内的进程是运行在一个隔离的环境里, 使用起来, 就好像是在一个独立于宿主的系统下操作一样, 这种特性使得容器封装的应用比直接在宿主运行更加安全, 也因为这种隔离的特性, 很多人初学 Docker 时常常会把容器和虚拟机搞混; 前面讲过镜像使用的是分层存储, 容器也是如此, 每一个容器运行时, 是以镜像为基础层, 在其上创建一个当前容器的存储层, 这是为容器运行时读写而准备的存储层; 容器存储层的生存周期和容器一样, 容器消亡时, 容器存储层也随之消亡, 因此, 任何保存于容器存储层的信息都会随容器的删除而丢失; 按照 Docker 最佳实践的要求, 容器不应该向其存储层内写入任何数据, 容器存储层要保持无状态化 所有的文件写入操作, 都应该使用 数据卷(Volume)、或者 绑定宿主目录, 在这些位置的读写会跳过容器存储层, 直接对宿主(或网络存储)发生读写, 其性能和稳定性更高; 数据卷的生存周期独立于容器, 容器消亡, 数据卷不会消亡, 因此, 使用数据卷后, 容器可以随意删除、重新run, 数据却不会丢失; 容器操作启动 启动容器有两种方式：一种是基于镜像新建一个容器并启动; 另外一个是将在终止状态(stopped)的容器启动 创建并启动 因为 Docker 的容器实在太轻量级了, 很多时候用户都是随时删除和新创建容器; 新建并启动一个容器所需的命令主要为 docker run, 例如: $ docker run -d -p 5000:5000 --name myFirstRegistry registry, 是根据名为registry的镜像创建并运行一个名为myFirstRegistry容器; 当利用 docker run 来创建容器时, Docker 在后台运行的标准操作包括: 检查本地是否存在指定的镜像, 不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统, 并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 容器被启动后, 设置的挂载目录, 端口映射都会随着此容器, 容器stop后, 再次start, 这些设置都还在; 启动已终止容器: 可以利用 docker start [containerID or NAME] 命令, 直接将一个已经终止的容器启动运行; 守护态运行容器其实更多时候, 我们需要让容器在后台运行, 而不是直接运行容器并展示出结果, 此时只用在运行时加上 -d 参数即可; (在容器的第一种启动方式中已经介绍过了) 查看容器信息可以通过 docker ps 命令来查看正在运行的容器信息 可以通过 docker ps -a 命令来查看 正在运行的和终止的 容器信息 终止容器可以使用 docker stop [containerID or NAME] 来终止一个运行中的容器 重启容器可以使用 docker restart [containerID or NAME] 来重启一个运行中的容器 删除容器 可以使用 docker rm 容器ID/容器NAME 来删除一个处于终止状态的容器; 如果要删除一个运行中的容器，可以添加 -f 参数; 进入容器 可参考书中介绍 推荐使用 docker exec -it [containerID or NAME] /bin/sh 其中, /bin/bash 有可能是 /bin/sh，因为不一定所有的docker都安装了shell","categories":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/categories/Docker读书笔记/"}],"tags":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/tags/Docker读书笔记/"}]},{"title":"04.定制镜像 - docker commit手动定制","slug":"docker/2017-12-03-04-docker","date":"2017-12-03T06:09:21.000Z","updated":"2018-08-04T03:27:30.000Z","comments":true,"path":"2017/12/03/docker/2017-12-03-04-docker/","link":"","permalink":"http://blog.renyimin.com/2017/12/03/docker/2017-12-03-04-docker/","excerpt":"","text":"前言镜像是容器的基础, 每次执行 docker run 的时候都需要指定哪个镜像作为容器运行的基础。在之前的例子中, 我们所使用的都是来自于 Docker Hub 的镜像, 直接使用这些镜像是可以满足一定的需求, 而当这些镜像无法直接满足需求时, 我们就需要定制这些镜像。 docker commit 手动定制镜像 当运行一个容器后(如果不使用数据卷的话), 你所做的任何文件修改都会被记录于容器存储层里, 注意: 容器存储层的生存周期和容器一样, 容器被删除后, 存储层中的内容也就会被删除掉, 而不会保留到镜像中 如果改动了容器的存储层, 我们可以通过 docker diff 命令看到具体的改动 但是如果改动的是数据卷挂载到容器对应目录下的内容, docker diff 看不到具体的改动 Docker提供了一个 docker commit 命令，可以将容器的存储层保存下来成为镜像 换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像 以后我们运行这个新镜像的时候, 就会拥有原有容器最后的文件变化 docker commit 的语法格式为: docker commit [选项] &lt;容器ID或容器名&gt; [&lt;仓库名&gt;[:&lt;标签&gt;]], 如下: 其中 --author 是指定修改的作者，而 --message 则是记录本次修改的内容。这点和 git 版本控制相似，不过这里这些信息可以省略留空1$ docker commit --author &quot;Tao Wang &lt;twang2218@gmail.com&gt;&quot; --message &quot;修改了默认网页&quot; webserver nginx:v2 手动定制镜像~~挂载数据卷问题 之前已经配置了docker中国加速镜像, 现在通过 docker pull nginx:stable 获取一个nginx基础镜像; 直接运行这个nginx基础镜像为一个容器 由于该镜像非常基础, 甚至没有像vi的工具, 因此在启动时可以将nginx的项目根目录 /usr/share/nginx/html 映射出来, 以便于测试 12345renyimindeMacBook-Pro:~ renyimin$ docker run -d -p 8088:80 --mount type=bind,source=/Users/renyimin/Desktop/nginx_test,target=/usr/share/nginx/html --name nginx_test nginx:stable983a6495386490f36e58d194a15d3dabbf86ccbadf2e44bab67d841e2abd0eferenyimindeMacBook-Pro:~ renyimin$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES983a64953864 nginx:stable &quot;nginx -g &apos;daemon ...&quot; 20 seconds ago Up 18 seconds 0.0.0.0:8088-&gt;80/tcp nginx_test 然后直接访问 localhost:8088 会发现nginx报错403 Forbidden, 这是因为挂载到容器中/usr/share/nginx/html目录的本地目录/Users/renyimin/Desktop/nginx_test中没有任何内容 接下来, 在/Users/renyimin/Desktop/nginx_test中创建一个index.html文件, 然后直接刷新localhost:8088, 就会看到效果! 现在修改了容器的文件，也就是改动了容器的存储层, 我们可以通过 docker diff 命令看到容器当前存储层的所有改动 12345678910renyimindeMacBook-Pro:~ renyimin$ docker diff nginx_testC /runA /run/nginx.pidC /var/cache/nginxA /var/cache/nginx/client_tempA /var/cache/nginx/fastcgi_tempA /var/cache/nginx/proxy_tempA /var/cache/nginx/scgi_tempA /var/cache/nginx/uwsgi_temprenyimindeMacBook-Pro:~ renyimin$ 你会发现自己最直接的改动并没有体现出来, 其实这主要是因为你直接改动的文件是被挂载出来的, 如果不是挂载出来, 而是直接在容器中修改的话, 则会体现出来; 比如, 直接进入nginx容器, 在非挂载目录中创建一个新文件, 然后观察差异 1234567891011121314renyimindeMacBook-Pro:~ renyimin$ docker exec -it nginx_test /bin/shrenyimindeMacBook-Pro:~ renyimin$ docker diff nginx_testC /runA /run/nginx.pidC /tmp// 可以看到, 此次直接改动就体现出来了A /tmp/renyimin.htmlC /var/cache/nginxA /var/cache/nginx/client_tempA /var/cache/nginx/fastcgi_tempA /var/cache/nginx/proxy_tempA /var/cache/nginx/scgi_tempA /var/cache/nginx/uwsgi_temprenyimindeMacBook-Pro:~ renyimin$ 手动定制镜像 docker commit --author &#39;renyimin&#39; --message &quot;在/tmp下touch了一个renyimin.html文件&quot; nginx_test nginx:test01 docker image ls 可以看到这个新定制的镜像 12345renyimindeMacBook-Pro:~ renyimin$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEnginx test01 ad0f6d04a963 4 seconds ago 109MBnginx stable 8ae4d16b741a 2 weeks ago 109MB...... 还可以用 docker history 具体查看镜像内的历史记录, 如果比较 nginx:v1 的历史记录, 我们会发现新增了我们刚刚提交的这一层 1234567891011121314renyimindeMacBook-Pro:~ renyimin$ docker history nginx:test01IMAGE CREATED CREATED BY SIZE COMMENTad0f6d04a963 57 seconds ago nginx -g daemon off; 2B 在/tmp下touch了一个renyimin.html文件8ae4d16b741a 2 weeks ago /bin/sh -c #(nop) CMD [&quot;nginx&quot; &quot;-g&quot; &quot;daem... 0B&lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) STOPSIGNAL [SIGTERM] 0B&lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) EXPOSE 80/tcp 0B&lt;missing&gt; 2 weeks ago /bin/sh -c ln -sf /dev/stdout /var/log/ngi... 22B&lt;missing&gt; 2 weeks ago /bin/sh -c set -x &amp;&amp; apt-get update &amp;&amp; a... 53.7MB&lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) ENV NJS_VERSION=1.14.0.... 0B&lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.14.... 0B&lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) LABEL maintainer=NGINX ... 0B&lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) CMD [&quot;bash&quot;] 0B&lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) ADD file:919939fa0224727... 55.3MBrenyimindeMacBook-Pro:~ renyimin$ 新的镜像定制好后，就可以来尝试运行这个镜像 1234567renyimindeMacBook-Pro:~ renyimin$ docker run -d -p 8089:80 --name nginx_test01 nginx:test0188f45a479da70c07a0510edb4730773387541fd5dd16a8d379afc2d405f296bfrenyimindeMacBook-Pro:~ renyimin$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES88f45a479da7 nginx:test01 &quot;nginx -g &apos;daemon ...&quot; 3 seconds ago Up 2 seconds 0.0.0.0:8089-&gt;80/tcp nginx_test01983a64953864 nginx:stable &quot;nginx -g &apos;daemon ...&quot; 19 minutes ago Up 19 minutes 0.0.0.0:8088-&gt;80/tcp nginx_testrenyimindeMacBook-Pro:~ renyimin$ 进入此容器, 会发现使用新的镜像启动容器后, 容器中的/tmp目录下包含我们提交的index.html个文件, 当然, localhost:8089和localhost:8088不同, 8089访问的还是默认欢迎页 renyimindeMacBook-Pro:~ renyimin$ docker exec -it nginx_test01 /bin/sh cd /tmpls renyimin.html # ``` 至此, 第一次使用 docker commit 命令完成了镜像定制, 手动操作给旧的镜像添加了新的一层, 形成新的镜像, 对镜像多层存储应该有了更直观的感觉; 慎用 docker commit 使用 docker commit 命令虽然可以比较直观的帮助理解镜像分层存储的概念, 但是实际环境中并不会这样使用; 因为如果仔细观察之前的 docker diff nginx_test 的结果, 会发现还有很多文件被改动或添加了, 但这些都是无关紧要的改动 这还仅仅是最简单的操作, 如果是安装软件包、编译构建, 那会有大量的无关内容被添加进来, 如果不小心清理, 将会导致镜像极为臃肿; 此外, 使用 docker commit 意味着所有对镜像的操作都是黑箱操作, 生成的镜像也被称为黑箱镜像, 换句话说, 就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像, 别人根本无从得知;而且, 即使是这个制作镜像的人, 过一段时间后也无法记清具体在操作的, 虽然 docker diff 或许可以告诉得到一些线索, 但是这种黑箱镜像的维护工作是非常痛苦的; 而且, 回顾之前提及的镜像所使用的分层存储的概念, 除当前层外, 之前的每一层都是不会发生改变的, 换句话说, 任何修改的结果仅仅是在当前层进行标记、添加、修改, 而不会改动上一层; 如果使用 docker commit 制作镜像, 每一次修改都会让镜像更加臃肿一次, 所删除的上一层的东西并不会丢失, 会一直如影随形的跟着这个镜像, 即使根本无法访问到, 这会让镜像更加臃肿;","categories":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/categories/Docker读书笔记/"}],"tags":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/tags/Docker读书笔记/"}]},{"title":"03. Docker Registry 仓库","slug":"docker/2017-12-02-03-docker","date":"2017-12-02T09:40:28.000Z","updated":"2018-08-04T06:43:00.000Z","comments":true,"path":"2017/12/02/docker/2017-12-02-03-docker/","link":"","permalink":"http://blog.renyimin.com/2017/12/02/docker/2017-12-02-03-docker/","excerpt":"","text":"公开 Docker Registry Docker Registry 公开服务是开放给用户使用、允许用户管理镜像的 Registry 服务 一般这类公开服务允许用户免费上传、下载公开的镜像, 并可能提供收费服务供用户管理私有镜像; 最常使用的Registry公开服务是官方的 Docker Hub, 这也是默认的 Registry，并拥有大量的高质量的官方镜像; 不过由于某些原因, 在国内访问这些服务可能会比较慢, 国内的一些云服务商提供了针对 Docker Hub 的镜像服务(Registry Mirror), 这些镜像服务被称为加速器; 但有时使用 Docker Hub 或其他公共仓库仍然不方便(比如, 有时候我们的服务器无法访问互联网 或者 你不希望将自己的镜像放到公网当中), 那就需要创建一个 本地私有仓库供; 私有 Docker Registry 除了使用公开服务外, 用户还可以在本地搭建私有Docker Registry, docker-registry是官方提供的工具, 可以用于构建私有的镜像仓库; 安装运行 docker-registry 你可以通过获取官方registry镜像来在本地运行一个自己的私有镜像仓库 (如 $ docker run -d -p 5000:5000 --restart=always --name registry registry, 将使用官方的registry镜像来启动一个私有仓库) 默认情况下, 仓库中的镜像会被创建在容器的 /var/lib/registry 目录下, 你可以通过 -v 参数来将镜像文件映射到本地的指定路径中; 另外, 可以将私有仓库的配置文件指定到本地的路径下 (如 ~/Desktop/registry-config/ 下 ) 我们大可不必这么麻烦, 只是简单运行一个私有仓库服务 $ docker run -d -p 5000:5000 --restart=always --name registry registry 查看私有仓库中镜像 用 curl 查看仓库中的镜像, 可以看到你的私有仓库暂时还是空的 123$ curl 127.0.0.1:5000/v2/_catalog&#123;&quot;repositories&quot;:[]&#125;$ 还可以在浏览器中直接查看私有仓库中的镜像(并且内网其他机器也可以通过内网地址来访问你所搭建的私有仓库的镜像): 上传镜像到私有仓库中 之前我们已经通过获取官方 registry镜像 来创建好了自己的私有仓库, 接下来就可以使用 docker tag 来标记一个镜像, 然后推送它到仓库; 先查看一下本地已有的镜像 docker image ls : 12345678$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEregistry latest d1fd7d86a825 4 weeks ago 33.3MBvipservice latest 47c844c76c53 2 months ago 2.92GBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.3 47c844c76c53 2 months ago 2.92GBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.1 52bd20b1d39b 3 months ago 2.46GBdevhdjfapi.haodai.com_full latest 52bd20b1d39b 3 months ago 2.46GBoldvip.haodai.com latest 52bd20b1d39b 3 months ago 2.46GB 使用 docker tag 将 registry:lates 这个镜像标记为一个新的本地镜像 127.0.0.1:5000/registry:latest ; 格式为 docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]12345678910$ docker tag registry:latest 127.0.0.1:5000/registry:latest$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE127.0.0.1:5000/registry latest d1fd7d86a825 4 weeks ago 33.3MBregistry latest d1fd7d86a825 4 weeks ago 33.3MBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.3 47c844c76c53 2 months ago 2.92GBvipservice latest 47c844c76c53 2 months ago 2.92GBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.1 52bd20b1d39b 3 months ago 2.46GBdevhdjfapi.haodai.com_full latest 52bd20b1d39b 3 months ago 2.46GBoldvip.haodai.com latest 52bd20b1d39b 3 months ago 2.46GB 使用 docker push 上传标记的镜像 12345678$ docker push 127.0.0.1:5000/registry:latestThe push refers to a repository [127.0.0.1:5000/registry]9113493eaae1: Pushed 621c2399d41a: Pushed 59e80739ed3f: Pushed febf19f93653: Pushed e53f74215d12: Pushed latest: digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c size: 1364 然后查看仓库中的镜像，可以看到镜像已经被成功上传了 curl 查看 12curl 127.0.0.1:5000/v2/_catalog&#123;&quot;repositories&quot;:[&quot;registry&quot;]&#125; 浏览器查看 查看某个镜像的tag列表 curl -XGET http://127.0.0.1:5000/v2/nginx/tags/list 上传私有仓库问题 如果上传的时候, 打包的镜像使用的是本机的内网地址, 最后在上传的时候, 你会发现如下报错信息: 1234$ docker push 192.168.1.3:5000/registry:latestThe push refers to a repository [192.168.1.3:5000/registry]Get https://192.168.1.3:5000/v2/: http: server gave HTTP response to HTTPS clientrenyimindembp:vipvip renyimin$ 此时, 你需要将内网地址配置到本机docker的 insecure registries 中, 如下: 之后, 无论本机还是在同一内网中的其他机器也都可以推送镜像到仓库中了(之前打包好的两个镜像, 都可以成功推送到私有仓库中): 1234567891011121314151617$ docker push 192.168.1.3:5000/registryThe push refers to a repository [192.168.1.3:5000/registry]9113493eaae1: Pushed 621c2399d41a: Pushed 59e80739ed3f: Pushed febf19f93653: Pushed e53f74215d12: Pushed latest: digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c size: 1364 $ docker push 127.0.0.1:5000/registryThe push refers to a repository [127.0.0.1:5000/registry]9113493eaae1: Layer already exists 621c2399d41a: Layer already exists 59e80739ed3f: Layer already exists febf19f93653: Layer already exists e53f74215d12: Layer already exists latest: digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c size: 1364 从私有仓库中下载镜像 先删除已有镜像 12345678910111213141516$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEregistry latest d1fd7d86a825 4 weeks ago 33.3MB127.0.0.1:5000/registry latest d1fd7d86a825 4 weeks ago 33.3MB192.168.1.3:5000/registry latest d1fd7d86a825 4 weeks ago 33.3MBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.3 47c844c76c53 2 months ago 2.92GBvipservice latest 47c844c76c53 2 months ago 2.92GBoldvip.haodai.com latest 52bd20b1d39b 3 months ago 2.46GBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.1 52bd20b1d39b 3 months ago 2.46GBdevhdjfapi.haodai.com_full latest 52bd20b1d39b 3 months ago 2.46GB$ docker image rm 127.0.0.1:5000/registry:latest 192.168.1.3:5000/registry:latestUntagged: 127.0.0.1:5000/registry:latestUntagged: 127.0.0.1:5000/registry@sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6cUntagged: 192.168.1.3:5000/registry:latestUntagged: 192.168.1.3:5000/registry@sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c 再尝试从私有仓库中下载这个镜像 (两个地址都可以下载, 也是因为之前配置了 Insecure registries, 这里最后才可以使用内网地址来下载) 123456789101112131415161718192021222324252627282930$ docker pull 127.0.0.1:5000/registry:latestlatest: Pulling from registryDigest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6cStatus: Downloaded newer image for 127.0.0.1:5000/registry:latest$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE127.0.0.1:5000/registry latest d1fd7d86a825 4 weeks ago 33.3MBregistry latest d1fd7d86a825 4 weeks ago 33.3MBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.3 47c844c76c53 2 months ago 2.92GBvipservice latest 47c844c76c53 2 months ago 2.92GBdevhdjfapi.haodai.com_full latest 52bd20b1d39b 3 months ago 2.46GBoldvip.haodai.com latest 52bd20b1d39b 3 months ago 2.46GBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.1 52bd20b1d39b 3 months ago 2.46GB$ docker pull 192.168.1.3:5000/registry:latestlatest: Pulling from registryDigest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6cStatus: Downloaded newer image for 192.168.1.3:5000/registry:latest$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE192.168.1.3:5000/registry latest d1fd7d86a825 4 weeks ago 33.3MBregistry latest d1fd7d86a825 4 weeks ago 33.3MB127.0.0.1:5000/registry latest d1fd7d86a825 4 weeks ago 33.3MBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.3 47c844c76c53 2 months ago 2.92GBvipservice latest 47c844c76c53 2 months ago 2.92GBdocker-registry.haodai.com:80/devhdjfapi.haodai.com 1.1.1 52bd20b1d39b 3 months ago 2.46GBdevhdjfapi.haodai.com_full latest 52bd20b1d39b 3 months ago 2.46GBoldvip.haodai.com latest 52bd20b1d39b 3 months ago 2.46GB 几个简单问题 删除仓库镜像 自己的docker仓库中存放的镜像, 时间长了难免存在一些废弃的镜像在里面, 如果不删除就造成空间的浪费 需要对registry做适当配置, 可参考: https://docs.docker.com/registry/configuration/#override-specific-configuration-options 容器启动之后, 如果忘记挂载某个目录, 能否再进行挂载? 其实没有必要, 直接停止删除, 重开一个即可！","categories":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/categories/Docker读书笔记/"}],"tags":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/tags/Docker读书笔记/"}]},{"title":"02. 镜像","slug":"docker/2017-12-02-02-docker","date":"2017-12-02T03:56:23.000Z","updated":"2018-08-04T03:26:37.000Z","comments":true,"path":"2017/12/02/docker/2017-12-02-02-docker/","link":"","permalink":"http://blog.renyimin.com/2017/12/02/docker/2017-12-02-02-docker/","excerpt":"","text":"前言镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样, 镜像是静态的定义, 容器是镜像运行时的实体; 所以, Docker运行容器前首先需要本地存在对应的镜像, 如果本地不存在该镜像, Docker会先尝试从镜像仓库下载该镜像; 镜像的获取 Docker Hub上有大量的高质量的镜像可以用, 如何获取这些镜像呢? 从Docker镜像仓库获取镜像的命令是 docker pull, 其命令格式为：docker pull [选项] [Docker Registry地址[:端口号]/]仓库名[:标签] docker pull命令的具体选项可以通过 docker pull --help 命令看到 Docker镜像仓库地址: 地址的格式一般是 &lt;域名/IP&gt;[:端口号] (默认地址是 Docker Hub 仓库地址) 仓库名: 仓库名是 两段式名称, 即 &lt;用户名&gt;/&lt;软件名&gt; (对于 Docker Hub, 如果不给出用户名, 则默认为 library, 也就是官方镜像) 比如 $ docker pull ubuntu:16.04: 由于没有给出Docker镜像仓库地址, 因此将会从Docker Hub获取镜像; 而仓库名称是 ubuntu(没有用户名), 因此将会去官方仓库 library/ubuntu 中, 获取标签为 16.04 的镜像; 另外, 如果从 Docker Hub 下载镜像非常缓慢，可以 配置镜像加速器。 配置镜像加速器 国内从 Docker Hub 镜像仓库拉取镜像有时会遇到困难, 此时可以配置镜像加速器, Docker 官方和国内很多云服务商都提供了国内加速器服务, 例如: Docker 官方提供的中国 registry mirror 阿里云加速器 DaoCloud 加速器 此处以 Docker 官方加速器为例进行介绍(由于本人使用macOS系统,下面只列出macOS上如何配置镜像加速器, 其他系统请参考) 在任务栏点击Docker for mac 应用图标 -&gt; Perferences… -&gt; Daemon -&gt; Basic -&gt; Registry mirrors 在列表中填写加速器地址即可, 修改完成之后，点击 Apply &amp; Restart 按钮, Docker 就会重启并应用配置的镜像地址了 如果在添加加速器地址后出现 registry-mirrors no certs for egistry.docker-.... 网上查找资料后, 有人说是证书问题, 尝试修改https为http后正常 检查加速器是否生效 配置加速器之后, 如果拉取镜像仍然十分缓慢, 请手动检查加速器配置是否生效, 在命令行执行 docker info 由于我配置的是docker hub提供的中国镜像站点, 所以如果从结果中看到了如下内容，说明配置成功(你看到的可能和我的不一样)123Registry Mirrors:http://registry.docker-cn.com///如果添加了多个加速站点, 此处也会有多个 镜像相关基础操作 列出已存在镜像: docker images：列表包含了 仓库名、标签、镜像ID、创建时间 以及 所占用的空间; 注意: 虽然 镜像ID 是镜像的唯一标识, 但是一个镜像可以打包出多个不同标签的镜像(如何打包,后面会学到), 所以有些镜像的ID一样, 但是tag会不一样12345renyimindeMacBook-Pro:testVip renyimin$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE127.0.0.1:5000/registry latest d1fd7d86a825 7 weeks ago 33.3MBregistry latest d1fd7d86a825 7 weeks ago 33.3MBrenyimindeMacBook-Pro:testVip renyimin$ 删除镜像: 如果要删除本地的镜像, 可以使用 $ docker image rm [选项] &lt;镜像名1&gt; [&lt;镜像名2&gt; ...] 命令; (因为镜像ID可能会一样, 所以删除镜像用的是镜像名) 注意, 镜像名是 仓库名:标签, 如 docker image rm nginx:1.12.2 镜像更名: 镜像更改名称也很简单, 直接 $ docker tag 镜像名 新镜像名:标签 在 Docker 1.13+ 版本中推荐使用 docker image 来管理镜像 (比如 docker image ls 会列出所有镜像); 理解分层存储 镜像是多层存储，每一层是在前一层的基础上进行的修改; 而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层; 镜像构建时, 会一层层构建, 前一层是后一层的基础。每一层构建完就不会再发生改变, 后一层上的任何改变只发生在自己这一层; 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡, 这里的消亡是指容器被删除, 而不是stop容器, stop容器后, 容器中发生的改变不会被忽略, 除非容器被删除掉;","categories":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/categories/Docker读书笔记/"}],"tags":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/tags/Docker读书笔记/"}]},{"title":"01. 认识Docker","slug":"docker/2017-12-02-01-docker","date":"2017-12-02T03:03:06.000Z","updated":"2018-08-04T03:26:15.000Z","comments":true,"path":"2017/12/02/docker/2017-12-02-01-docker/","link":"","permalink":"http://blog.renyimin.com/2017/12/02/docker/2017-12-02-01-docker/","excerpt":"","text":"简介 Docker使用Google公司推出的Go语言实现; 属于操作系统层面的虚拟化技术; 也称其为容器; docker 与 传统虚拟机技术 对比 传统虚拟机技术是: 虚拟出一套硬件后; 在其上运行一个完整操作系统; 最后在该系统上再运行所需应用进程; 而容器内的应用进程直接运行于宿主的内核, 容器内没有自己的内核, 而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便; 如下图, 可以看到有应用A和应用B两个应用, 相比于传统虚拟技术, docker少了Hypervisor(所有虚拟化技术的核心)和Guest OS这两层 为什么使用docker?作为一种新兴的虚拟化方式, Docker 跟传统的虚拟化方式相比具有众多的优势 更高效的利用系统资源由于容器不需要进行 硬件虚拟 以及 运行完整操作系统 等额外开销, 所以其实Docker对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 更多好处请参考(https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html) 对比传统虚拟机总结 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为MB 一般为GB 性能 接近原生 弱于原生 系统支持量 单机支持上千个容器 一般几十个 Docker三个基本概念理解了这三个概念，就理解了 Docker 的整个生命周期 镜像 (Image)容器 (Container)仓库 (Repository) 《Docker从入门到实践》","categories":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/categories/Docker读书笔记/"}],"tags":[{"name":"Docker读书笔记","slug":"Docker读书笔记","permalink":"http://blog.renyimin.com/tags/Docker读书笔记/"}]},{"title":"03. HTTP状态码详解","slug":"http/2017-11-30-HTTP-03","date":"2017-11-30T06:30:12.000Z","updated":"2018-07-20T13:42:17.000Z","comments":true,"path":"2017/11/30/http/2017-11-30-HTTP-03/","link":"","permalink":"http://blog.renyimin.com/2017/11/30/http/2017-11-30-HTTP-03/","excerpt":"","text":"1xx 101: 参考博文WebSocket简单示例分析 (做协议升级, 还会响应: Connection: Upgrade) 2xx Web API的设计与开发 P109 200 OK : 200码非常出名, 似乎没有对它进一步说明的必要; 201 Created : 当在服务器端创建数据成功时, 会返回201状态码; 也就是使用 POST 请求方法的场景 (如:用户登录后添加了新用户, 上传了图片等新创建数据的场景) 202 Accepted : 在异步处理客户端请求时, 它用来表示服务器端已经接受了来自客户端的请求, 但处理尚未结束; 在文件格式转换, 处理远程通知(Apple Push Notification等)这类很耗时的场景中, 如果等到所有处理都结束后才向客户端返回响应消息, 就会花费相当长的时间, 造成应用可用性不高; 这时采用的方法是服务器向客户端返回一次响应消息, 然后立刻开始异步处理。 202状态码就被用于告知客户端服务器端已经开始处理请求, 但整个处理过程尚未结束; 比如: 以LinkedIn的参与讨论的API为例如果成功参与讨论并发表意见, 服务器端通常会返回201状态码;但如果需要得到群主的确认, 那么所发表的意见就无法立即在页面显示出来, 这时服务器端就需要返回202状态码; 从广义上来看, 该场景也属于异步处理, 但和程序设计里的异步执行当然不同; 204 No Content : 正如其字面意思, 当响应消息为空时会返回该状态码。 其实就是告诉浏览器, 服务端执行成功了, 但是没什么数据返回给你, 所以你不用刷新页面, 也不用导向新的页面; 在用 DELETE 方法删除数据时, 服务器端通常会返回204状态码(阮一峰博文也提到过, 对DELETE适用); 除此之外, 也有人认为在使用 PUT或PATCH 方法更新数据时, 因为只是更新已有数据, 所以返回204状态码更加自然;书中建议 DELETE 返回204; PUT或PATCH返回200并返回该方法所操作的数据; 关于204状态码的讨论可以参考 p111; 205 Reset Content : 告诉浏览器, 页面表单需要被重置; 205的意思是服务端在接收了浏览器POST请求以后, 处理成功以后, 告诉浏览器, 执行成功了, 请清空用户填写的Form表单, 方便用户再次填写; 206 Partial Content : 成功执行了一个部分或Range(范围)的请求; 206响应中, 必须包含 Content-Range, Date 以及 ETag或Content-Location首部; 3xx300 Multiple Choices : 客户端驱动方式进行内容协商时, 服务器可能返回多个连接供客户端进行选择 (比如多语言网站可能会出现); 301 Moved Permanently : 在请求的URL已经被移除时使用, 响应的Location首部中应该包含资源现在所处的URL; (比较适合永久重定向) 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是301; 则即便稍后取消了location.php中的跳转(或者修改了跳转地址), 由于浏览器还是会认为你之前的跳转是永久性的, 再次访问www.test.com/location.php仍然会跳转到之前的跳转链接(除非清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 302 Found: 与301类似, 但是客户端应该使用Location首部给出的URL来进行临时定位资源, 将来的请求仍应该使用老的URL; 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是302; 如果稍后取消了location.php中的跳转, 再次访问www.test.com/location.php, 会发现不会进行跳转, 而是访问到 location.php 修改后的代码 (不用清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 303 See Other : HTTP/1.1使用303来实现和302一样的临时重定向; 307 Temporary Redirect HTTP/1.1规范要求用307来取代302进行临时重定向; (302临时重定向留给HTTP/1.0) 所以他也具备302临时重定向的特点; 但是, 与 302, 303 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 308 Permanent Redirect 貌似不是rfc2616的标准 具备和301永久重定向的特点, 需要清除浏览器缓存才行; 但是, 与 301 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 304 Not Modified : 参考博文缓存相关 4xx Web API的设计与开发 P1134字头状态码主要用于描述因客户端请求的问题而引发的错误。也就是说, 服务器端不存在问题, 但服务器端无法理解客户端发送的请求, 或虽然服务器端能够理解但请求却没有被执行, 当遇到这些情况引发的错误时, 服务器端便会向客户端返回这一类别的状态码。因此, 当服务器端返回4字头的状态码时, 就表示客户端的访问方式发生了问题, 用户需要检查一下客户端的访问方式或访问的目标资源等。 400 Bad Request : 表示其他错误的意思, 即其他4字头状态码都无法描述的错误类型; 401 Unauthorized : 表示认证(Authentication)类型的错误 比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 403 Forbidden : 和401状态码比较相似, 所以也经常被混淆; 其实403表示的是授权(Authotization)类型的错误, 授权和认证的不同之处是: 认证表示”识别前来访问的是谁”, 而授权则表示”赋予特定用户执行特定操作的权限” 通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限” 404 Not Found : 表示访问的数据不存在, 但是 例如当客户端湿度获取不存在的用户信息时, 或者试图访问原本就不存在的端点时, 服务器就会返回404状态码; 所以, 如果客户端想要获取用户信息, 却得到服务器端返回的404状态码, 客户端仅凭”404 Not Found”将难以区分究竟是用户不存在, 还是端点URI错误导致访问了原本不存在的URI; 405 Method Not Allowed : 表示虽然访问的端点存在, 但客户端使用的HTTP方法不被服务器端允许; 比如客户端使用了POST方法来访问只支持GET方法的信息检索专用的API; 又比如客户端用了GET方法来访问更新数据专用的API等; 406 Not Acceptable : 服务器端API不支持客户端指定的数据格式时, 服务器端所返回的状态码; 比如, 服务器端只支持JSON和XML输出的API被客户端指定返回YAML的数据格式时, 服务器端就会返回406状态码; 408 Request Timeout : 当客户端发送请求至服务器端所需的时间过长时, 就会触发服务器端的超时处理, 从而使服务器端返回该状态码; 409 Conflict: 用于表示资源发生冲突时的错误 (est中就会有该错误码) 比如通过指定ID等唯一键值信息来调用注册功能的API时, 倘若已有相同ID的数据存在, 就会导致服务器端返回409状态码; 在使用邮箱地址及Facebook ID等信息进行新用户注册时, 如果该邮箱地址或者ID已经被其他用户注册, 就会引起冲突, 这时服务器端就会返回409状态码告知客户端该邮箱地址或ID已被使用; 410 Gone : 和 404状态码 相同, 都表示访问资源不存在, 只是410状态码不单表示资源不存在, 还进一步告知资源曾经存在, 只是目前已经消失了; 因此服务器端常在访问被删除的数据时返回该状态码, 但是为了返回该状态码, 服务器必须保存该数据已被删除的信息, 而且客户端也应该知晓服务器端保存了这样的信息; 但是在通过邮箱地址搜索用户信息的API中, 从保护个人信息的角度来说, 返回410状态码的做法也会受到质疑; (所以在此种资源不存在的情况下, 为了稍微安全一些, 返回410状态码需要慎重) 413 Request Entity Too Large : 413也是比较容易出现的一种状态码, 表示请求实体过大而引发的错误 请求消息体过长是指, 比如在上传文件这样的API中, 如果发送的数据超过了所允许的最大值, 就会引发这样的错误; 414 Request-URI Too Large : 414是表示请求首部过长而引发的错误 如果在进行GET请求时, 查询参数被指定了过长的数据, 就会导致服务器端返回414状态码 415 Unsupported Media Type : 和406比较相似 406我们知道是表示服务器端不支持客户端想要接收的数据格式 而415表示的是服务器端不支持客户端请求首部 Content-Type 里指定的数据格式, 也就是说, 当客户端通过POST,PUT,PATCH等方法发送的请求消息体的数据格式不被服务器支持时, 服务器端就会返回415状态码; 例如在只接收JSON格式的API里, 如果客户端请求时发送的是XML格式的数据去请求服务器端, 或者在 Content-Type 首部指定 application/xml, 都会导致该类型错误; 429 Too Many Requests : 是2012年RFC6585文档中新定义的状态码, 表示访问次数超过了所允许的范围; 例如某API存在一小时内只允许访问100次的访问限制, 这种情况下入股哦客户端视图进行第101次访问, 服务器便会返回该状态码; 表示在一定的时间内用户发送了太多的请求, 即超出了”频次限制”, 在响应中，可以提供一个 Retry-After 首部来提示用户需要等待多长时间之后再发送新的请求; 5xx 5字头状态码表示错误不发生在客户端, 而是由服务器自身问题引发的。 500 Internal Server Error : 是web应用程序开发里非常常见的错误, 当服务器代码里存在bug, 输出错误信息并停止运行等情况下, 就会返回该类型的错误; 因此, 不仅限于API, 对于5字头状态码的错误, 都要认真监视错误日志, 使系统在出错时及时告知管理员, 以便在错误发生时做好应对措施, 防止再次发生。 501 Not Implemented : ??? 502 Bad GateWay : ??? 503 Service Unavaliable : 用来表示服务器当前处于暂不可用状态 可以回送:响应首部 Retry-After 表示多久恢复; 不同的客户端与服务器端应用对于 Retry-After 首部的支持依然不太一致; 不过，一些爬虫程序，比如谷歌的爬虫程序Googlebot, 会遵循Retry-After响应首部的规则, 将其与503(Service Unavailable,当前服务不存在)响应一起发送有助于互联网引擎做出判断,在宕机结束之后继续对网站构建索引。 参考:https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Retry-After 504 Gateway Time-out: 复现这个错误码比较简单, 让你的php程序模拟耗时请求, 如下代码 123&lt;?phpsleep(70);//模拟耗时，睡70秒echo &quot;睡醒了&quot;; 就会返回 ``` 504 Gateway Time-out nginx/1.11.4 ``` 505 HTTP Version Not Supported: 服务器收到的请求, 使用的是它无法支持的HTTP协议版本; 参考:《HTTP权威指南》、《Web API的设计与开发》","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/tags/HTTP/"}]},{"title":"02. HTTP请求方法","slug":"http/2017-11-30-HTTP-02","date":"2017-11-30T03:29:12.000Z","updated":"2018-07-20T13:20:39.000Z","comments":true,"path":"2017/11/30/http/2017-11-30-HTTP-02/","link":"","permalink":"http://blog.renyimin.com/2017/11/30/http/2017-11-30-HTTP-02/","excerpt":"","text":"前言 HTTP/1.1 中实现的method, 参考RFC2616, 可以看到有: OPTIONS, HEAD, GET, POST, PUT, DELETE, TRACE, CONNECT RFC2616中提到: PATCH, LINK, UNLINK方法被定义, 但并不常见; (《图解http协议》中也提到 LINK, UNLINK 已经被http1.1废弃); 不同应用各自的实现不同, 有些应用会完整实现, 有些还会扩展, 有些可能只会实现一部分; PUT PUT: 替换资源; PUT 和 POST的区别: 在HTTP中, PUT被定义为 idempotent(幂等性) 的方法, POST则不是, 这是一个很重要的区别 应该用 PUT 还是 POST? 取决于这个REST服务的行为是否是idempotent(幂等)的假如发送两个请求, 希望服务器端是产生两个新数据，那就说明这个服务不是idempotent的, 因为多次使用产生了副作用了, 那就应该使用 POST 方法;但如果是希望后一个请求把第一个请求覆盖掉(这不正是修改么), 那这个服务就是idempotent的, 那就应该使用 PUT 方法; 虽然 POST 和 PUT 差别不大, 用错了也没关系, 但是你的服务一放到internet上，如果不遵从HTTP协议的规范，就可能给自己带来麻烦; POST POST: 上面已经提过了, POST是非幂等的; POST 和 PUT 都可以上传文件或者创建新信息, 但主要看你的REST服务行为是否是幂等的; PATCHPATCH不是HTTP标准方法的，服务端需要考虑客户端是否能够支持的问题; 对已有资源的操作: 用于对资源的 部分内容 进行更新 (例如更新某一个字段, 具体比如说只更新用户信息的电话号码字段); 而 PUT 则用于更新某个资源较完整的内容, 比如说用户要重填完整表单更新所有信息, 后台处理更新时可能只是保留内部记录ID不变; HEAD HEAD和 GET 本质是一样的, 区别在于如果使用HEAD, 响应体将不会被返回, 而仅仅返回HTTP头信息; 比如: 欲判断某个资源是否存在, 我们通常使用GET, 但这里用HEAD则意义更加明确; GET比较简单, 直接获取资源; OPTIONS这个方法使用比较少, 它用于获取当前URL所支持的方法;若请求成功, 则它会在HTTP头中包含一个名为 Allow 的头, 值是服务器所支持的方法, 如 GET, POST;之前跨域相关博文 CORS方案 not-so-simple request 中的”预检”请求用的请求方法就是 OPTIONS; CONNECT要求用隧道协议连接代理, 如使用SSL TRACE~~未完待续 DELETE参考 PURGE非规范中定义的方法","categories":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://blog.renyimin.com/tags/HTTP/"}]},{"title":"29. binlog 与 事务","slug":"mysql/2017-10-05-mysql-29","date":"2017-10-05T14:16:31.000Z","updated":"2018-08-02T09:25:48.000Z","comments":true,"path":"2017/10/05/mysql/2017-10-05-mysql-29/","link":"","permalink":"http://blog.renyimin.com/2017/10/05/mysql/2017-10-05-mysql-29/","excerpt":"","text":"","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"28. 认识MySQL的 Binary Log","slug":"mysql/2017-09-30-mysql-28","date":"2017-09-30T14:16:31.000Z","updated":"2018-08-02T10:21:32.000Z","comments":true,"path":"2017/09/30/mysql/2017-09-30-mysql-28/","link":"","permalink":"http://blog.renyimin.com/2017/09/30/mysql/2017-09-30-mysql-28/","excerpt":"","text":"Binary Log概述 MySQL的二进制日志binlog可以说是MySQL最重要的日志, 它包含了描述数据库更改的”事件”, 例如 表创建操作 或 对表数据的更改; 它还包含可能进行更改的语句的事件(例如, 不匹配任何行的DELETE), 除非使用基于行的日志记录; 也就是说, mysql的binlog记录了所有的DDL和DML语句(除了select、show之类的语句), 以事件形式记录, 还包含语句所执行的消耗的时间; 开启Binlog的性能方面的损耗? binlog日志有两个最重要的使用场景 MySQL主从复制 数据恢复 binlog日志包括两类文件: 二进制日志索引文件(文件名后缀为.index) 用于记录所有的二进制文件 二进制日志文件(文件名后缀为.00000*) 记录数据库所有的DDL和DML(除了数据查询语句select)语句事件 binlog配置 开启binlog日志： 编辑打开mysql配置文件 /etc/mys.cnf 在 [mysqld] 区块添加 log-bin=mysql-bin 确认是打开状态( ‘mysql-bin’ 是日志的基本名或前缀名); 重启mysqld使配置生效 binlog 相关操作命令 常用的binlog日志操作命令 查看binlog是否开启 : show variables like &#39;log_%&#39;; 查看所有binlog日志列表 : show master logs; 查看master状态, 即, 最后(最新)一个binlog日志的编号名称, 及其最后一个操作事件pos结束点(Position)值 : show master status; flush刷新log日志, 自此刻开始产生一个新编号的binlog日志文件 : flush logs;注意: 每当mysqld服务重启时, 会自动执行此命令, 刷新binlog日志; 在mysqldump备份数据时加 -F 选项也会刷新binlog日志; 重置(清空)所有binlog日志 : mysql&gt; reset master; 查看binlog日志内容, 常用有两种方式: 注意 binlog 是二进制文件, 普通文件查看器无法打开, 可以使用自带的 mysqlbinlog 命令查看 binlog日志与数据库文件在同目录中 使用 mysqlbinlog 自带查看命令法:123// 从下面结果可知mysql的存放目录为// 使用mysqlbinlog命令查看binlog日志内容, 下面截取其中的一个片段分析：mysqlbinlog mysql-bin.000002 数据备份与恢复mysqldump备份与恢复binlog恢复https://www.cnblogs.com/kevingrace/p/5907254.htmlhttps://cloud.tencent.com/developer/article/1032755https://www.jianshu.com/p/0f0c16c40a52","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"27. 认识MySQL的 undo Log 和 redo Log","slug":"mysql/2017-09-23-mysql-27","date":"2017-09-27T14:16:31.000Z","updated":"2018-07-27T05:36:43.000Z","comments":true,"path":"2017/09/27/mysql/2017-09-23-mysql-27/","link":"","permalink":"http://blog.renyimin.com/2017/09/27/mysql/2017-09-23-mysql-27/","excerpt":"","text":"undo log Undo日志记录某数据被修改前的值, 可以用来在事务失败时进行rollback; Undo log 是 InnoDB MVCC 事务特性的重要组成部分, 当我们对记录做了变更操作时就会产生undo记录, Undo记录默认被记录到系统表空间(ibdata)中, 但从5.6开始, 也可以使用独立的 Undo 表空间; Undo记录中存储的是老版本数据, 当一个旧的事务需要读取数据时, 为了能读取到老版本的数据, 需要顺着 undo链 找到满足其可见性的记录; 当版本链很长时, 通常可以认为这是个比较耗时的操作(例如bug#69812) 大多数对数据的变更操作包括 INSERT/DELETE/UPDATE, 其中INSERT操作在事务提交前只对当前事务可见, 因此产生的Undo日志可以在事务提交后直接删除(谁会对刚插入的数据有可见性需求呢), 而对于 UPDATE/DELETE 则需要维护多版本信息; 在InnoDB里, UPDATE和DELETE操作产生的Undo日志被归成一类, 即 update_undo。 更多细节可参考数据库内核月报 － 2015 / 04 redo log InnoDB 有两块非常重要的日志, 一个是 undo log, 另外一个是 redo log; 前者用来保证事务的原子性以及InnoDB的MVCC, 后者用来保证事务的持久性; Redo日志记录某数据块被修改后的值, 可以用来恢复未写入data file的已成功事务更新的数据; 和大多数关系型数据库一样, InnoDB记录了对数据文件的物理更改, 并保证总是日志先行, 也就是所谓的WAL, 即在持久化数据文件前, 保证之前的redo日志已经写到磁盘; LSN(log sequence number)用于记录日志序号, 它是一个不断递增的 unsigned long long 类型整数; 在 InnoDB 的日志系统中, LSN 无处不在, 它既用于表示修改脏页时的日志序号, 也用于记录checkpoint, 通过LSN, 可以具体的定位到其在redo log文件中的位置; 为了管理脏页, 在 Buffer Pool 的每个instance上都维持了一个flush list, flush list 上的 page 按照修改这些 page 的LSN号进行排序;因此定期做redo checkpoint点时, 选择的 LSN 总是所有 bp instance 的 flush list 上最老的那个page(拥有最小的LSN); 由于采用WAL的策略, 每次事务提交时需要持久化 redo log 才能保证事务不丢; 而延迟刷脏页则起到了合并多次修改的效果, 避免频繁写数据文件造成的性能问题; 更多细节可参考阿里数据库内核月报","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"}]},{"title":"26. MVCC 多版本并发控制","slug":"mysql/2017-09-22-mysql-26","date":"2017-09-22T13:10:21.000Z","updated":"2018-07-27T05:40:50.000Z","comments":true,"path":"2017/09/22/mysql/2017-09-22-mysql-26/","link":"","permalink":"http://blog.renyimin.com/2017/09/22/mysql/2017-09-22-mysql-26/","excerpt":"","text":"Multiversion Concurrency Control简介 阿里数据库内核’2017/12’月报中对 MVCC 的解释是: 多版本控制: 指的是一种 提高并发 的技术。 最早的数据库系统, 只有 读读 之间可以并发，读写，写读，写写 都要阻塞。 引入多版本之后，只有 写写 之间相互阻塞, 其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。 &lt;高性能MySQL&gt;中对 MVCC 的部分介绍 MySQL的大多数事务型存储引擎实现的其实都不是简单的行级锁。 基于提升并发性能的考虑, 它们一般都同时实现了多版本并发控制(MVCC)。 不仅是MySQL, 包括Oracle, PostgreSQL 等其他数据库系统也都实现了MVCC, 但各自的实现机制不尽相同, 因为MVCC没有一个统一的实现标准。 可以认为MVCC是行级锁的一个变种, 但是它在很多情况下避免了加锁操作, 因此开销更低。虽然实现机制有所不同, 但大都实现了非阻塞的读操作，写操作也只锁定必要的行。 MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作。其他两个隔离级别和 MVCC 不兼容, 因为 READ UNCOMMITTED 总是读取最新的数据行, 而不是符合当前事务版本的数据行。而 SERIALIZABLE 则会对所有读取的行都加锁 参考 http://mysql.taobao.org/monthly/2018/03/01/ ~~未整理完待续","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"25. 隔离级别 - READ COMMITTED","slug":"mysql/2017-09-22-mysql-25","date":"2017-09-22T06:50:52.000Z","updated":"2018-07-24T09:43:55.000Z","comments":true,"path":"2017/09/22/mysql/2017-09-22-mysql-25/","link":"","permalink":"http://blog.renyimin.com/2017/09/22/mysql/2017-09-22-mysql-25/","excerpt":"","text":"前言 READ COMMITTED 隔离级别可以解决高并发场景下, 事务 脏读 的问题; 在当前事务中, 只能读取到其他事务已完成(提交/回滚)的落地数据; 如果让你用 锁 来设计该隔离级别? 假设, 在事务A中读取数据前, 事务B对同一数据做了修改并且还没有完成(commit/rollback), 那如何让事务A无法读取事务B中 尚未落地的脏数据 呢? 在当前事务对数据做写操作的时候, 给数据加上行级的 排他锁(X lock); 其他事务在对同一数据做读操作时, 也别忘了加上 共享锁(S lock), 注意两种锁都要使用;这样, 其他事务由于加不上 共享锁/排他锁, 自然只能阻塞等事务A完成后才能读取/修改数据了; 这样做的话确实实现了效果, 也就避免了脏读, 事实上, 也解决可了 不可重复读 (因为一旦加了共享锁, 其他事务也无法加排他锁进行修改), 但问题是这是一种 很低效 的传统思路, 因为对于大部分应用来说, 读操作是多于写操作的, 当写操作加锁时, 那么读操作全部被阻塞, 这样在大用户量高并发的情况下, 会直接降低数据库的读效率。 所以, 为了提高并发性, MySQL是自然不会简单地使用传统直接加读写锁的方法来解决的问题; 注意: 如果只是 写操作加排他锁的话 是无法避免 脏读 的 (之前在了解 READ UNCOMMITTED 隔离级别时, 已经探讨过了); 事实上, MySQL是使用 写操作加排他锁 、读操作不加锁 、MVCC 多版本并发控制 来实现该隔离级别的; 具体方案 MySQL 在事务隔离级别 Read Committed 、Repeatable Read 下, InnoDB 存储引擎采用 非锁定的一致性读 －－ 即 读取数据不用加锁, 而是采用的是MVCC中 一致性非锁定读 模式; 从而做到: 写不影响读，读不影响写，写只影响写, 只有写写会阻塞; 读不影响写: 当事务A中正在执行读操作时, 事务B的写操作不会因此去等待当前事务A上S锁的释放(因为事务A读取压根就没加锁), 所以事务B可以直接对数据加X锁; 写不影响读: 当事务A中正在执行写操作时, 虽然对数据加了X锁, 但是事务B的读操作不会因此去等待当前事务行上X锁的释放, 而是会去读取快照数据 (注意: RC和RR因快照产生时机不同, 导致了两个隔离级别读取的落地数据不同, 从而导致两个隔离级别的不同) 所以总结来看, READ UNCOMMITTED 和 REPEATABLE READ 这两个隔离级别都是使用 写用排他锁、读用MVCC, 区别可以参考 MVCC 多版本并发控制","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"24. 隔离级别 - READ UNCOMMITTED 未提交读","slug":"mysql/2017-09-21-mysql-24","date":"2017-09-21T09:35:26.000Z","updated":"2018-07-27T02:13:46.000Z","comments":true,"path":"2017/09/21/mysql/2017-09-21-mysql-24/","link":"","permalink":"http://blog.renyimin.com/2017/09/21/mysql/2017-09-21-mysql-24/","excerpt":"","text":"简介 READ UNCOMMITTED 隔离级别会引起 脏读(Dirty Read) 现象的出现: 也就是说, 在该隔离级别下, 当前事务 可以读取 其他事务 未提交的(尚未具备持久性的)数据; 事务A中对数据所做的修改, 在还未最终被提交时, 对其他事务也都会是可见的; 这个级别会导致很多问题, 而且从性能上来说, READ COMMITTED 并不会比其他的级别好太多, 却缺乏其他级别的很多好处, 在实际应用中一般很少使用。 虽然该隔离级别很少使用, 但接下来仍然会简单介绍下 这个隔离级别究竟是如何进行隔离的, 竟还能容许 脏读 问题的存在; 测试准备 先准备一张测试表 test_transaction: 1234567891011121314DROP TABLE IF EXISTS `test_transaction`;CREATE TABLE `test_transaction` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `user_name` char(20) NOT NULL COMMENT &apos;姓名&apos;, `age` tinyint(3) NOT NULL COMMENT &apos;年龄&apos;, `gender` tinyint(1) NOT NULL COMMENT &apos;1:男, 2:女&apos;, `desctiption` text NOT NULL COMMENT &apos;简介&apos;, PRIMARY KEY (`id`), KEY `name_age_gender_index` (`user_name`,`age`,`gender`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;INSERT INTO `test_transaction` VALUES (1, &apos;金刚狼&apos;, 127, 1, &apos;我有一双铁爪&apos;);INSERT INTO `test_transaction` VALUES (2, &apos;钢铁侠&apos;, 120, 1, &apos;我有一身铁甲&apos;);INSERT INTO `test_transaction` VALUES (3, &apos;绿巨人&apos;, 0, 2, &apos;我有一身肉&apos;); 如下: 123456789mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 2 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) 先查看 客户端1 事务的隔离级别: SELECT @@SESSION.tx_isolation;, 可以看到, InnoDB默认事务隔离级别为 REPEATABLE READ 123456789mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; 重新设置 会话端1 的事务隔离级别为 read uncommitted: SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; 注意, 此时只是当前会话端的隔离级别被改, 其余 会话端 还是默认的 REPEATABLE READ 隔离级别 接下来将 会话端2 的事务隔离级别也设置为read uncommitted; 测试 客户端1 开启事务, 并执行一个查询 ‘读取数据’, 注意, 客户端1 的事务并未提交 1234567891011121314151617181920mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction where id=2;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 |+----+-----------+-----+--------+--------------------+1 row in set (0.00 sec) mysql&gt; 客户端2 开启事务, 并修改客户端1查询的数据 123456789101112131415mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-托尼&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 可以发现: 客户端2 可以对 客户端1 事务中正在读取的记录进行修改 (因此对该隔离级别下的锁你需要留意一下, 难道是 读锁没有阻塞写锁?) 回到 客户端1, 再次查询数据, 发现数据已经变成了’钢铁侠-托尼’; 然后客户端2 rollback 事务, 再到客户端1中查询, 发现user_name又变成了’钢铁侠’, 那之前读到 ‘钢铁侠-托尼’ 就是脏数据了, 即那就是一次 脏读; 可以用一张图来演示整个实验过程 分析该隔离级别如何加锁 重新构造测试条件 客户端1开启事务, 然后对数据做修改 1234567mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rymuscle&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 注意, 客户端1此时的事务并未提交 客户端2开启事务, 对相同的数据行做修改 12345mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rym&apos; where id=2;....阻塞等待了 最终会如下: 注意: 在上面的过程, 在客户端2阻塞阶段, 你可以通过一个新的客户端来分析, 客户端2 在锁等待的情况下, 表的加锁情况和事务状态: 查看表的加锁情况: select * from information_schema.INNODB_LOCKS; 事务状态 select * from information_schema.INNODB_TRX; 小结 所以: READ UNCOMMITTED 隔离级别下, 写操作是会加锁的, 而且是X排他锁, 直到客户端1事务完成, 锁才释放, 客户端2才能进行写操作 接下来你肯定会纳闷 “既然该隔离级别下事务在修改数据的时候加的是x锁, 并且是事务完成后才释放, 那么 客户端2 在事务中修改完数据之后, 为什么还没提交事务, 也就是x锁还在, 结果客户端1却能读取到客户端2修改的数据”？ 这完全不符合排他锁的特性啊(排他锁会阻塞除当前事务之外的其他事务的读,写操作) 其实网上已经有人在 sqlserver 的官网上找到了相关资料: 12345Transactions running at the READ UNCOMMITTED level do not issue shared locks to prevent other transactions from modifying data read by the current transaction. READ UNCOMMITTED transactions are also not blocked by exclusive locks that would prevent the current transaction from reading rows that have been modified but not committed by other transactions. When this option is set, it is possible to read uncommitted modifications, which are called dirty reads. Values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. This option has the same effect as setting NOLOCK on all tables in all SELECT statements in a transaction. This is the least restrictive of the isolation levels. 12345在 READ UNCOMMITTED 级别运行的事务不会发出 `共享锁` 去阻止其他事务修改当前事务读取的数据;READ UNCOMMITTED 事务也不会被 已被修改但未被其他事务提交的行所加的 `排他锁` 阻塞 当前事务去读取该数据; (也就是该隔离级别引起 脏读 的原因)设置此选项后, 可以读取未提交的修改, 这称为脏读。可以更改数据中的值, 并且在事务结束之前, 行可以在数据集中显示或消失;此选项与在事务中所有 SELECT语句中的所有表上设置NOLOCK具有相同的效果;这是隔离级别中限制最少的; 大概是说: 在 READ UNCOMMITTED 级别运行的事务不会发出共享锁: 也就是事务A在读取数据时, 什么锁都不加; 这样的话, 事务B就可以对同样的数据进行修改(同时会加上排他锁); 而事务A要读取事务B未提交的修改, 也不会被事务B所加的排他锁阻止, 因为排他锁会阻止其他事务再对其锁定的数据加读写锁, 但是可笑的是, 事务在该隔离级别下去读数据的话根本什么锁都不加, 这就让排他锁无法排它了; 小结 所以可以得出: READ UNCOMMITTED 隔离级别下, 读不会加任何锁; 而写会加排他锁, 并到事务结束之后释放。( 读写不阻塞, 写写阻塞 (但会读到脏数据) ) 而之前讲解第一类丢失更新问题时, 也已经了解到 SERIALIZABLE 隔离级别才会对所有读取的行都加锁;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"23. 隔离级别 与 锁","slug":"mysql/2017-09-21-mysql-23","date":"2017-09-21T06:20:52.000Z","updated":"2018-07-24T04:02:12.000Z","comments":true,"path":"2017/09/21/mysql/2017-09-21-mysql-23/","link":"","permalink":"http://blog.renyimin.com/2017/09/21/mysql/2017-09-21-mysql-23/","excerpt":"","text":"前言 之前几篇博文已经介绍了Mysql事务, 高并发下事务将会面对的问题 及 MySQL的解决方案; MySQL主要采用 事务隔离性中的4种隔离级别 结合 MVCC机制 来进行解决; 而事务隔离级别的核心就是锁, 各隔离级别使用了不同的加锁策略; 接下来看一下各隔离级别是如何实现及如何解决高并发事务问题的; READ UNCOMMITTED 未提交读READ COMMITTED 提交读MVCC 多版本并发控制REPEATABLE READ 可重复读参考资料:-《高性能MySQL》 MySQL官方文档 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"22. 幻读, 快照读(snapshot read), 当前读 (current read)","slug":"mysql/2017-09-19-mysql-22","date":"2017-09-19T11:25:07.000Z","updated":"2018-07-24T09:43:37.000Z","comments":true,"path":"2017/09/19/mysql/2017-09-19-mysql-22/","link":"","permalink":"http://blog.renyimin.com/2017/09/19/mysql/2017-09-19-mysql-22/","excerpt":"","text":"RR + MVCC 虽然解决了 幻读 问题, 但严格来说, 只是部分解决幻读问题 演示 打开 客户端1 查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 打开 客户端2 查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端2中 开启事务, 然后查询数据 1234567891011121314mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端1中插入一条id为4的新数据 (未开启事务, 所以会自动提交) 1234567891011121314mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 || 4 | 死侍 | 18 | 0 | A bad boy |+----+-----------+-----+--------+--------------------+4 rows in set (0.00 sec) mysql&gt; 在 客户端2 之前开启的事务中再次查询数据, 发现数据没有变化(表示可以重复读, 并且克服了select幻读)!! 12345678910111213141516171819202122232425262728mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);1062 - Duplicate entry &apos;4&apos; for key &apos;PRIMARY&apos; //( 后面会看到: 其实是因为insert是当前读)mysql&gt; //并且, 此时 `update/delete` 也是可以操作这条在事务中看不到的记录的! //( 后面会看到: update，delete也都是当前读) 问题的出现 虽然多次select读取, 发现已经克服了幻读问题 但当 在客户端2事务中 insert 插入一条id为4的新数据, 发现提示数据已经存在, 那么这是什么问题呢? 可以参考MySQL官方文档 – 一致性非阻塞读 The snapshot of the database state applies to SELECT statements within a transaction, not necessarily to DML statements. If you insert or modify some rows and then commit that transaction, a DELETE or UPDATE statement issued from another concurrent REPEATABLE READ transaction could affect those just-committed rows, even though the session could not query them. If a transaction does update or delete rows committed by a different transaction, those changes do become visible to the current transaction.个人认为应该翻译为: 数据库状态的快照适用于事务中的SELECT语句, 而不一定适用于所有DML语句。 如果您插入或修改某些行, 然后提交该事务, 则从另一个并发REPEATABLE READ事务发出的DELETE或UPDATE语句就可能会影响那些刚刚提交的行, 即使该事务无法查询到它们。如果事务更新或删除由不同事务提交的行, 则那些更改对当前事务就变得可见;但是如果事务select由不同事务提交的行, 则那些更改对当前事务就不可见(此时算是rr的可重复读); 小结 也就是RR隔离级别, 在同一事务中多次读取的话, 只是对 select 克服了 幻读; 但是对其他DML并没有做到(其他DML能察觉到数据被别的事务提交过了)! 这就引出了新的两个概念 当前读 和 快照读通常在RC,RR隔离级别下, 不做特殊处理, 使用的 select 都是快照读, 其他dml就算是当前读; (MVCC写阻塞写) 其实, MVCC并发控制中的读操作分为两类: 快照读 (snapshot read) 与 当前读 (current read); 参考 在RR级别下 快照读 是通过MVVC(多版本控制)和 undo log 来实现的 而 当前读 是需要加 record lock(记录锁) 和 gap lock(间隙锁) 来实现的, 如果需要实时显示数据，还是需要通过加锁来实现, 这个时候会使用next-key技术来实现。 快照读, 读取专门的快照(对于RC，快照(ReadView)会在每个语句中创建, 对于RR, 快照是在事务启动时创建的), 快照读的操作如下: 1简单的select操作 (不包括: select ... lock in share mode, select ... for update) 当前读, 读取最新版本的记录, 没有快照, 在InnoDB中, 当前读取根本不会创建任何快照。当前读的操作如下, 可以看到 insert, update, delete都是快照读, 所以这几个操作会察觉到其他事务对数据做的更改, 而select察觉不到: 12345select ... lock in share modeselect ... for updateinsertupdatedelete 使用 隔离性 的最高隔离级别 SERIALIZABLE 也可以解决 幻读, 但该隔离级别在实际中很少使用!","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"21. MySQL 高并发事务问题","slug":"mysql/2017-09-17-mysql-21","date":"2017-09-17T13:56:32.000Z","updated":"2018-07-27T02:17:52.000Z","comments":true,"path":"2017/09/17/mysql/2017-09-17-mysql-21/","link":"","permalink":"http://blog.renyimin.com/2017/09/17/mysql/2017-09-17-mysql-21/","excerpt":"","text":"前言上一篇MySQL事务简介中对MySQL事务的相关基本概念及特性做了简单描述, 但仅仅了解这些还是不够的, 在实际场景中, 你可能经常会面对一些高并发应用, 此时就需要进一步了解高并发下事务中的一些常见问题; 高并发事务问题在并发量比较大的时候, 很容易出现 多个事务并行 的情况;假设有两个事务正在同时进行, 值得注意的是: 它们两者之间是互相不知道对方的存在的, 各自都对自身所处的环境 过分乐观, 从而并没有对自己所操作的数据做一定的保护处理, 所以 最终导致了一些问题的出现; 脏读 如果 事务A 读取了另一个并行 事务B 未最终提交的写数据, 那事务A的这次读取操作就叫 脏读 因为 事务A 此时读取到的是 尚未最终持久化的数据 (事务B中修改的数据还不具备事务的 持久性 特性) 事务A 此时读取的数据也叫 脏数据事务B 最终可能会因为内部其他后续操作的失败或者系统后续突然崩溃等原因, 导致事务B最终整体提交失败而回滚, 那么最终 事务A 拿到的自然就是 脏的数据 了; 图示: 解决方案 : RC+ 在MySQL中, 事务已经用自身特性 隔离性 的 – READ COMMITED或以上隔离级别 解决了这个问题; READ COMMITED 隔离级别保证了: 在事务中, 某条语句执行前, 已经被其他事务提交的数据, 对该语句都是可见的; 不可重复读 现在, 上面的 脏读问题 已经被解决了, 那就意味着事务中的每条语句读取到的数据都是 持久性 的数据(被别的事务最终 提交/回滚 的具有持久性的落地数据); 但脏读问题的解决, 也仅仅只能保证你在事务中每次读到的数据都是持久性的数据而已; 试想, 如果在一个事务中多次读取同一个数据, 正好在两次读取之间, 另外一个事务已经完成了对该数据的修改并提交, 那问题就来了: 两次读取的结果不一样了 多次读取数据不一致, 会导致什么问题呢? 一个事务中为什么要多次读取同一数据, 什么场景下需要这么做? 如下汇款案例: 1234查询余额: 100给别人汇款: 20记录日志: ....返回余额(你可以直接计算然后返回80, 但如果你是查询的话, 就应该保证你查到的是80, 而不受其他事务干扰) 解决方案 : RR+ 在MySQL中, 事务已经用自身特性 隔离性 的 – REPEATABLE READ或以上隔离级别 解决了这个问题; REPEATABLE READ 级别保证了:在事务中, 某条语句执行前, 已经被其他事务 提交/回滚 的落地数据, 对该语句都是可见的; (READ COMMITED)在事务中, 多次读取同一个数据(在两次读取操作之间, 无论数据被 提交/回滚 多少次(即无论落地过多少遍), 每次读取的结果都应该是和事务中第一次读取的结果一样; 幻读 可以参考 MySQL官方文档对 Phantom Rows 的介绍 ) 不可重复读 和 幻读 这两个概念经常搞混 但 不可重复读 主要是说多次读取同一条记录, 发现该记录中某些列值被其他事务修改过; 而 幻读 主要是说多次读取一个范围内的记录(包括直接查询所有记录结果或者做聚合统计), 发现结果不一致(比如发现增加/减少了一条记录); 解决方案: RR + MVCC 其实对于 幻读, 在Mysql的InnoDB存储引擎中, 事务默认的 RR 级别已经通过 MVCC机制 帮我们解决了(并非完全解决), 所以该级别下, 你也模拟不出幻读的场景; 退回到 RC 隔离级别的话, 你又容易把 幻读 和 不可重复读 搞混淆, 所以这可能就是比较头痛的点吧! 另外可以参考《高性能MySQL》对 RR 隔离级别的描述 理论上, RR级别是无法解决幻读的问题, 但是由于InnoDB引擎的RR级别还使用了MVCC, 所以也就避免了幻读的出现! 想了解更多, 可以参考下一篇幻读的延伸 更新丢失最后聊一下 高并发事务 的另一个问题: 丢失更新问题, 该问题和之前几个问题需要区分开, 因为解决方案不是一类! 第一类丢失更新 A事务撤销时, 把已经提交的B事务的更新数据覆盖了 需要注意的是: 这种情况在Mysql中不会出现; 对于InnoDB事务的最低隔离级别 READ UNCOMMITED, 由于事务A对事务B中的每一步操作结果都是可见的, 更别说是事务B提交之后了, 所以, 事务A在T3阶段的修改其实已经是基于对其可见的(事务B最终提交的)数据了, 因此回滚的话, 也会回滚到事务B最终提交的数据; 测试: 12345678SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;select * from test_transaction where id=2;update test_transaction set age = age-10 where id=2;rollback; 1234567SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age - 15 where id=2;commit; 对于 READ COMMITTED 为提交读, 也就是在事务B提交之后, 事务A在T3阶段是可以select(快照读)到事务B最终提交的数据的, 更别说update(当前读)到了, 所以事务A最终的Rollback其实也是基于事务B提交后的数据的, 所以事务A的回滚最终会回滚到事务B提交的修改数据, 而不是事务A一早读取的数据; 12345678SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;select * from test_transaction where id=2;update test_transaction set age = age-10 where id=2;rollback; 1234567SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age - 15 where id=2;commit; 对于 REPEATABLE READ 可重复读, 事务A在T3阶段虽然select不到事务B最终提交的数据(快照读), 但是可以update(当前读)到事务B最终提交的数据的 123456SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;select * from test_transaction where id=2;update test_transaction set age = age+10 where id=2;rollback; 12345SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age-15 where id=2;commit; 因为 update 为当前读(不会遵守可重复读的要求), 而select为快照读! 关于快照读和当前读, 可以参考后面的文章幻读, 快照读(snapshot read), 当前读 (current read) SERIALIZABLE 读写都加锁, 会出现死锁为了不出现死锁: 也不会出现第一类丢失更新的问题 123456SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;SELECT @@SESSION.tx_isolation;begin;update test_transaction set age = age-10 where id=2;rollback; 1234567SELECT @@SESSION.tx_isolation;SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;SELECT @@SESSION.tx_isolation;begin;select * from test_transaction where id=2;update test_transaction set age = age -15 where id=2;commit; 第二类丢失更新 A事务 覆盖 B事务 已经提交的数据，造成B事务所做操作丢失 这种丢失更新, 一般是先在事务外查询出的数据, 觉得符合要求, 然后在事务A中依据查询出的结果做完运算后, 然后对数据进行的修改, 这样必然会导致事务B的更新丢失; 而如果在事务中不是依据事务外查询出的结果进行运算后再更新, 而是直接使用 类似库存递减的操作, 如 update goods set number=number-1 where id=1;, 虽然不会造成丢失更新, 但是会造成超卖现象! 另外, 如果将读写都放入事务中, 很容易造成死锁的出现 (因为serialize将事务串行化了, 读写都会互相阻塞(经过测试), 不会造成第二类丢失更新问题, 但是仍然会造成超卖!;) 解决方案: 乐观锁(在修改时, where判断数据是否为你读取时的数据; 或者提供数据版本字段来控制) 悲观锁 注意: 最高隔离级别 Serializable 在实际应用场景中并不被采用 另外, 可以参考: https://segmentfault.com/q/1010000010353164/a-1020000010353684 参考资料: 淘宝数据库内核6月报 美团技术博客 MySQL官方文档 《高性能MySQL》 https://www.jianshu.com/p/d75fcdeb07a3","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"20. MySQL 事务简介","slug":"mysql/2017-09-16-mysql-20","date":"2017-09-16T03:06:07.000Z","updated":"2018-07-26T01:45:46.000Z","comments":true,"path":"2017/09/16/mysql/2017-09-16-mysql-20/","link":"","permalink":"http://blog.renyimin.com/2017/09/16/mysql/2017-09-16-mysql-20/","excerpt":"","text":"事务的概念 事务：可以理解为一个 独立的 工作单元, 在这个 独立的 工作单元中, 可以有 一组 操作; 放在这个独立工作单元中的一组操作, 要么全部执行成功, 要么全部执行失败。 仍然通过最经典的银行转账应用来解释一下: 假设有两个角色 ‘Iron Man’(余额500), ‘Wolverine’(余额15), 现在 ‘Iron Man’ 通过该银行应用给 ‘Wolverine’ 转账100元, 那么本次转账操作至少需要三个步骤 123检查`Iron Man`余额`&gt;=100`元从`Iron Man`余额中`-100`元给`Wolverine`余额`+100`元 注意: 上面的三个步操作，其实就需要打包在一个事务中, 这样就可以保证一组操作可以作为一个 独立的工作单元 来执行。并且在 独立工作单元(即事务) 中的这三个操作, 只要有任何一个操作失败, 则事务整体就应该是失败的, 那就必须回滚所有已经执行了的步骤。 假设第二步操作成功, 但是第三步操作失败, 那么整个事务就应该是失败的, 就必须将第二步的操作回滚。(其实这里也体现了事务最基本的一个特性: 保证数据的一致性) 事务的ACID特性一个运行良好的事务处理系统必须具备下面这些标准特性(高并发场景离不开事务的这几个标准特性) Atomicity 原子性一个事务必须被视为一个不可分割的最小工作单元, 整个事务中的所有操作要么全部成功提交, 要么有操作失败导致所有操作全部回滚。对于一个事务来说, 不能只成功执行其中的一部分操作, 这就是事务的原子性。 Consistency 一致性你大概可以这样来理解: 虽然数据表中的数据可能一直在变化, 但是事务的一致性特性总是能够保证 数据库总是从一个数据一致性的状态 转换到 另一个数据一致性的状态; 比如之前转账的例子:转账前的数据一致性状态是: ‘Iron Man’(余额500), ‘Wolverine’(余额15)转账成功后的数据一致性状态是: ‘Iron Man’(余额400), ‘Wolverine’(余额115)转账如果失败的话, 数据的一致性的状态应该回滚到转账前的状态: ‘Iron Man’(余额500), ‘Wolverine’(余额15) Isolation 隔离性 通常来说, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的;比如在之前的转账例子中, 在执行完成最后一步(第三步), 事务还没来得及最终提交之前, 此时有另一个程序去读取A账户的余额, 那么这个程序读到的应该是没有被减100的余额才对 上面为什么说 通常来说, 难道还有其他情况 ?后面会详细讨论事务隔离性 的四个 隔离级别, 到时候就知道这里为什么说通常来说对其他事务是不可见的; (但确实也还有特例, 比如最低隔离级别 READ UNCOMMITTED, 对其他事务的可见就造成了 脏读问题 的出现) 事务有四种隔离级别(从低到高) READ UNCOMMITTED (未提交读) READ COMMITTED (提交读) REPEATABLE READ (可重复读) SERIALIZABLE (可串行化) 注意: 该隔离级别才会读写都加锁 Durability 持久性一旦事务被最终提交后, 在这个独立单元中的所有操作所做的修改将会 永久 保存到数据库中; (所谓永久可以理解为被事务修改的数据是真正存放到了表中, 而不是存放在了诸如临时表之类的地方);","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]},{"title":"09. Prototype 原型模式","slug":"oop/2017-09-02-09-Prototype","date":"2017-09-02T03:18:21.000Z","updated":"2018-08-03T03:37:13.000Z","comments":true,"path":"2017/09/02/oop/2017-09-02-09-Prototype/","link":"","permalink":"http://blog.renyimin.com/2017/09/02/oop/2017-09-02-09-Prototype/","excerpt":"","text":"场景举例 我们每周都会在wiki上创建文档写周报, 但其实每个人的周报格式都差不多, 只是内容细节不一样, 这样 如果每个人写周报都是在wiki中新建一个空白页, 然后再排格式、写内容、… 就会显得比较低效; 而如果每个人都可以根据已完成的周报 复制 一份作为模板, 在此基础上只用对周报内容做些修改, 既可以很容易完成工作, 又可以保证大家周报风格的一致; 这个问题映射到wiki系统的开发中, 其实也是类似的: 如果在wiki的系统设计中, 每次在创建文档时, 都只能 new 一个新的文档对象, 然后针对new出的每个新对象都需要设置 文档排版、内容 等, 这样就会显得很低效; 而如果能够以某个已经完成的文档对象为某种类型的文档对象模板(确定对象种类), 然后复制出新的文档对象, 用户仅需对此类对象做一些细节修改, 就会非常方便; 原型模式的引入 通过上面的问题场景分析, 你需要对wiki的文档模块进行重新设计 除了允许用户创建新文档外, 还允许用户对已经创建好的文档(比如周报文档)进行拷贝; 用户再次创建同类型文档(比如周报文档)时, 既可以创建全新的文档, 也可以选择合适的模板复制一份新的文档; 这种操作非常类似于常用的 复制和粘贴; 要一个面向对象系统中实现对象的复制和粘贴, 这就要引入原型模式了; 原型模式 原型模式(Prototype Pattern): 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象; 原型模式是一种对象创建型模式; 工作原理很简单: 核心就在于如何实现克隆方法 UML图: Prototype(抽象原型类): 它是声明克隆方法的接口, 是所有具体原型类的父类, 可以是抽象类也可以是接口, 甚至还可以是具体实现类; ConcretePrototype(具体原型类): 它实现在抽象原型类中声明的克隆方法, 在克隆方法中返回自己的一个克隆对象; Client(客户类): 发起创建对象的动作, 让一个原型对象克隆其自身, 从而创建一个新的对象, 在客户类中只需要直接实例化或通过工厂方法等方式创建一个原型对象, 再通过调用该对象的克隆方法即可得到多个相同的对象; 由于客户类针对抽象原型类Prototype编程, 因此用户可以根据需要(的对象种类)选择具体原型类, 系统具有较好的可扩展性, 增加或更换具体原型类, 即增加或更换对象的种类(比如周报文档,或者建立文档..)都很方便; 简单代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103&lt;?php/** * 原型接口或抽象原型 * Interface Prototype */interface Prototype&#123; public function copy();&#125;/** * 周报具体原型类 * Class ConcretePrototype1 */class WeeklyNewspaper implements Prototype&#123; public $title = &apos;统一周报模板&apos;; public $content = &apos;技术方面: php开发, java准备; 业务方面: 熟悉新业务&apos;; public function setTitle($title) &#123; $this-&gt;title = $title; &#125; public function setContent() &#123; return $this-&gt;content; &#125; public function display() &#123; // 页面展示你的周报信息 &#125; public function copy() &#123; return clone $this; &#125;&#125;/** * 简历具体原型类 * Class ConcretePrototype2 */class Resume implements Prototype&#123; public $title = &apos;PHP简历模板&apos;; public $content = &apos;技术: php, mysql; 工具: vagrant, docker;&apos;; public function setTitle($title) &#123; $this-&gt;title = $title; &#125; public function setContent() &#123; return $this-&gt;content; &#125; public function display() &#123; // 页面展示你的简历信息 &#125; public function copy() &#123; return clone $this; &#125;&#125;/** * Class Client */class Client&#123; /** * 尝试创建多份简历 */ public function copyResume(Prototype $prototype) &#123; // 不需要再new对象了 return $prototype-&gt;copy(); &#125;&#125;// 先实例化简历模板$weeklyNewspaper1 = new WeeklyNewspaper();$weeklyNewspaper1-&gt;title = &quot;这是一份统一的周报模板&quot;;// 复制周报模板, 不再需要new$client = new Client;$weeklyNewspaper2 = $client-&gt;copyResume($weeklyNewspaper1);$weeklyNewspaper3 = $client-&gt;copyResume($weeklyNewspaper1);$weeklyNewspaper4 = $client-&gt;copyResume($weeklyNewspaper1);// 两个对象相等var_dump($weeklyNewspaper1 == $weeklyNewspaper2);var_dump($weeklyNewspaper1 == $weeklyNewspaper3);var_dump($weeklyNewspaper1 == $weeklyNewspaper4);var_dump($weeklyNewspaper1 === $weeklyNewspaper2);// 重新编写周报$weeklyNewspaper2-&gt;title = &quot;这是PHP开发的周报模板&quot;;// 测试var_dump($weeklyNewspaper2-&gt;title); 深拷贝与浅拷贝 浅拷贝: 被拷贝对象的所有变量都含有与原对象相同的值, 而且对其他对象的引用仍然是指向原来的对象, 即浅拷贝只负责当前对象实例, 对引用的对象不做拷贝; 深拷贝: 被拷贝对象的所有变量都含有与原对象相同的值, 除了那些引用其他对象的变量, 那些引用其他对象的变量将指向一个被拷贝的新对象，而不再是原来那些被引用的对象;(即深拷贝把要拷贝的对象所引用的对象也拷贝了一次, 而这种对被引用到的对象拷贝叫做间接拷贝) 示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;?php/** * Interface Prototype */interface Prototype&#123; //浅拷贝 public function shallowCopy(); //深拷贝 public function deepCopy();&#125;/** * Class ConcretePrototype */class ConcretePrototype implements Prototype&#123; public $testObject = null; public function __construct($obj) &#123; $this-&gt;testObject = $obj; &#125; //浅拷贝 public function shallowCopy() &#123; return clone $this; &#125; //深拷贝 public function deepCopy() &#123; $deepObj = serialize($this); $cloneObj = unserialize($deepObj); return $cloneObj; &#125;&#125;class Demo&#123; public $title = &apos;测试类&apos;;&#125;/** * Class Client */class Client&#123; public function shallow(Prototype $prototype) &#123; return $prototype-&gt;shallowCopy(); &#125; public function deep(Prototype $prototype) &#123; return $prototype-&gt;deepCopy(); &#125;&#125;$client = new Client;$concretePrototype = new ConcretePrototype(new Demo());var_dump(&quot;浅拷贝:&quot;);$concretePrototype1 = $client-&gt;shallow($concretePrototype);var_dump($concretePrototype == $concretePrototype1);var_dump($concretePrototype === $concretePrototype1);var_dump($concretePrototype-&gt;testObject == $concretePrototype1-&gt;testObject);var_dump($concretePrototype-&gt;testObject === $concretePrototype1-&gt;testObject);var_dump(&quot;深拷贝:&quot;);$concretePrototype = new ConcretePrototype(new Demo());$concretePrototype2 = $client-&gt;deep($concretePrototype);var_dump($concretePrototype == $concretePrototype2);var_dump($concretePrototype === $concretePrototype2);var_dump($concretePrototype-&gt;testObject == $concretePrototype2-&gt;testObject);var_dump($concretePrototype-&gt;testObject === $concretePrototype2-&gt;testObject); 结果: 12345678910/Users/renyimin/Desktop/www.test.com/oop/prototype.php:65:string &apos;浅拷贝:&apos; (length=10)/Users/renyimin/Desktop/www.test.com/oop/prototype.php:67:boolean true/Users/renyimin/Desktop/www.test.com/oop/prototype.php:68:boolean false/Users/renyimin/Desktop/www.test.com/oop/prototype.php:69:boolean true/Users/renyimin/Desktop/www.test.com/oop/prototype.php:70:boolean true/Users/renyimin/Desktop/www.test.com/oop/prototype.php:72:string &apos;深拷贝:&apos; (length=10)/Users/renyimin/Desktop/www.test.com/oop/prototype.php:75:boolean true/Users/renyimin/Desktop/www.test.com/oop/prototype.php:76:boolean false/Users/renyimin/Desktop/www.test.com/oop/prototype.php:77:boolean true/Users/renyimin/Desktop/www.test.com/oop/prototype.php:78:boolean false 原型管理器 原型管理器(Prototype Manager)是将多个原型对象存储在一个集合中, 供客户端使用; 它是一个专门负责克隆对象的工厂, 其中定义了一个集合用于存储原型对象, 如果需要某个原型对象的一个克隆，可以通过复制集合中对应的原型对象来获得; 在原型管理器中针对抽象原型类进行编程, 以便扩展, 其结构如下图:","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"06. Strategy 策略模式","slug":"oop/2017-08-15-06-Strategy","date":"2017-08-15T13:36:27.000Z","updated":"2018-08-03T02:16:28.000Z","comments":true,"path":"2017/08/15/oop/2017-08-15-06-Strategy/","link":"","permalink":"http://blog.renyimin.com/2017/08/15/oop/2017-08-15-06-Strategy/","excerpt":"","text":"场景举例 在软件开发中, 常常会遇到实现某个功能有多种途径, 每种途径对应着一种算法, 比如开发一个影院售票系统, 在该系统中需要为不同类型的用户提供不同的电影票打折方式, 具体打折方案如下: 学生凭学生证可享受票价8折优惠; 年龄在10周岁及以下的儿童可享受每张票减免10元的优惠(原始票价需大于等于20元); 影院VIP用户除享受票价半价优惠外还可进行积分, 积分累计到一定额度可换取电影院赠送的奖品; 在传统开发模式下, 为了满足上述需求, 你可能会设计一个类MovieTicket，其核心代码片段如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;?php/** * 电影票类 * Class MovieTicket */class MovieTicket&#123; private $doublePrice; private $StringType; public function setPrice($price) &#123; $this-&gt;price = $price; &#125; public function setType($type) &#123; $this-&gt;type = $type; &#125; public function getPrice() &#123; return $this-&gt;calculate(); &#125; /** * 计算打折后的票价 * @return string */ public function calculate() &#123; //学生票折后票价计算 if (&apos;student&apos; == $this-&gt;type) &#123; echo &apos;学生票:&apos;; return $this-&gt;price * 0.8; //儿童票折后票价计算 &#125; else if (&apos;children&apos; == $this-&gt;type &amp;&amp; $this-&gt;price &gt;= 20) &#123; echo &apos;儿童票:&apos;; return $this-&gt;price - 10; //VIP票折后票价计算 &#125; else if (&apos;vip&apos; == $this-&gt;type) &#123; echo &apos;VIP票:&apos;; echo &apos;增加积分!&apos;; return $this-&gt;price * 0.5; //不满足任何打折要求, 则返回原始票价 &#125; else &#123; return $this-&gt;price; &#125; &#125;&#125;class Client&#123; public function test() &#123; $movieTicket = new MovieTicket(); $originalPrice = 60.0; $currentPrice = 60.0; $movieTicket-&gt;setPrice($originalPrice); var_dump(&apos;原始价为:&apos; . $originalPrice); var_dump(&quot;---------------------------------&quot;); // 可以根据session中的用户类型来进行设置 $movieTicket-&gt;setType(&apos;student&apos;); //学生票 $currentPrice = $movieTicket-&gt;getPrice(); var_dump(&apos;折后价为:&apos; . $currentPrice); var_dump(&quot;---------------------------------&quot;); $movieTicket-&gt;setType(&apos;children&apos;); //儿童票 $currentPrice = $movieTicket-&gt;getPrice(); var_dump(&apos;折后价为:&apos; . $currentPrice); &#125;&#125;$client = new Client();$client-&gt;test(); 虽然该方案可以满足电影票打折问题, 该并不是一个好的解决方案, 它至少存在如下三个问题: MovieTicket类的 calculate() 方法非常庞大, 它包含各种打折算法的实现代码, 在代码中出现了较长的 if…else… 语句, 不利于测试和维护; 增加新的打折算法或者对原有打折算法进行修改时必须修改 MovieTicket 类的源代码, 违反了”开闭原则”, 系统的灵活性和可扩展性较差; 算法的复用性差, 如果在另一个系统(如商场销售管理系统)中需要重用某些打折算法, 只能通过对源代码进行复制粘贴来重用, 无法单独重用其中的某个或某些算法(重用较为麻烦); 策略模式的引入 通过分析, 导致上面问题的主要原因在于 MovieTicket 类职责过重, 它将各种打折算法都定义在一个类中, 这既不便于算法的重用, 也不便于算法的扩展; 因此你需要对 MovieTicket 类进行重构, 将原本庞大的 MovieTicket 类的职责进行分解, 将算法的定义和使用分离, 这就是策略模式所要解决的问题; 策略模式 策略模式(Strategy): 它定义了算法家族, 将每一个算法分别封装起来(每一个封装算法的类我们都可以称之为一种策略), 并让它们之间可以互相替换, 此模式让算法的变化独立于使用算法的客户; 也称为政策模式(Policy); 策略模式是一种对象行为模式; 策略模式的主要目的是将算法的行为和环境分开, 将算法的定义放在专门的策略类中, 每一个策略类封装了一种实现算法, 使用算法的环境类针对抽象策略类进行编程, 符合依赖倒转原则, 在出现新的算法时, 只需要增加一个新的实现了抽象策略类的具体策略类即可; 打折算法 为了实现之前打折算法的复用, 并能够灵活地向系统中增加新的打折方式, 可以使用策略模式对电影院打折方案进行重构, 重构后基本结构如下: 在向 MovieTicket 中注入具体策略对象时, 为了遵守 开闭原则, 可以根据用户session中的身份, 来决定使用的具体策略类, 比如vip用户使用VipDiscount类; 总结主要体现了对抽象编程的应用 主要优点 策略模式提供了对 开闭原则 的完美支持, 用户可以在不修改原有系统的基础上选择算法或行为, 也可以灵活地增加新的算法或行为; 提供了一种算法的复用机制, 由于将算法单独提取出来封装在策略类中, 因此不同的环境类可以方便地复用这些策略类; 主要缺点 客户端必须知道所有的策略类, 并自行决定使用哪一个策略类, 以便选择恰当的算法; 策略模式将造成系统产生很多具体策略类, 任何细小的变化都将导致系统要增加一个新的具体策略类; 无法同时在客户端使用多个策略类, 客户端每次只能使用一个策略类, 不支持使用一个策略类完成部分功能后再使用另一个策略类来完成剩余功能的情况; 适用场景 一个系统需要动态地在几种算法中选择一种, 那么可以将这些算法封装到一个个具体算法类中, 而这些具体算法类都是一个抽象算法类的子类; 不希望客户端知道复杂的与算法相关的数据结构, 在具体策略类中封装算法与相关的数据结构, 可以提高算法的保密性与安全性;","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"05. Factory Method 工厂方法模式","slug":"oop/2017-08-09-OOP-05-Factory","date":"2017-08-09T11:36:28.000Z","updated":"2018-08-01T02:23:15.000Z","comments":true,"path":"2017/08/09/oop/2017-08-09-OOP-05-Factory/","link":"","permalink":"http://blog.renyimin.com/2017/08/09/oop/2017-08-09-OOP-05-Factory/","excerpt":"","text":"前言 工厂模式是最常用的一类创建型设计模式, 通常所说的工厂模式是指 工厂方法模式, 它也是使用频率最高的工厂模式; 之前已经了解了简单工厂模式, 它只有一个工厂类, 在类中承担了各种Chart图形类的创建, 并且如果有其他系列类的创建, 那么工厂类就显得很臃肿; 正如之前学习的简单工厂模式, 存在问题: 工厂类过于庞大, 可能会包含了大量的if…else…代码, 导致维护和测试难度增大; 系统扩展不灵活，如果增加新类型的对象创建, 可能就需要修改静态工厂方法的业务逻辑, 违反了 开闭原则 ; 如何解决这两个问题, 这就是本文所介绍的 工厂方法模式 的动机之一; 工厂方法模式 在简单工厂模式中只提供一个工厂类, 该工厂类处于对产品类进行实例化的中心位置, 它需要知道每一个产品对象的创建细节, 并决定何时实例化哪一个产品类; 简单工厂模式最大的缺点是: 当有新类型的产品要加入到系统中时, 可能就需要修改工厂类, 需要在其中加入必要的业务逻辑, 这违背了 开闭原则; 此外, 在简单工厂模式中, 所有的产品都由同一个工厂创建, 工厂类职责较重, 业务逻辑较为复杂, 具体产品与工厂类之间的耦合度高, 严重影响了系统的灵活性和扩展性, 而工厂方法模式则可以很好地解决这一问题; 在工厂方法模式中, 不再提供一个统一的工厂类来创建所有的产品对象, 而是提供一个抽象工厂接口来声明一个 抽象的工厂, 而由其子类 具体工厂 来实现工厂方法, 你需要针对不同的产品提供不同的工厂; 在工厂方法模式结构图中包含如下几个角色: Factory(抽象工厂): 在抽象工厂类中, 声明了工厂方法(Factory Method), 用于返回一个产品, 抽象工厂是工厂方法模式的核心, 所有工厂类都必须实现该接口; ConcreteFactory(具体工厂): 它是抽象工厂类的子类, 实现了抽象工厂中定义的工厂方法, 并可由客户端调用, 返回一个具体产品类的实例; Product(抽象产品): 它是定义产品的接口; ConcreteProduct(具体产品): 它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建, 具体工厂和具体产品之间一一对应; 代码 与简单工厂模式相比, 工厂方法模式最重要的区别是引入了抽象工厂角色, 抽象工厂可以是接口,也可以是抽象类, 其典型代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637&lt;?php$chartConfig = ['chartType' =&gt; 'PieChart'];abstract class Chart&#123; public abstract function display();&#125;class PieChart extends Chart&#123; public function display() &#123; var_dump('pieChart图'); &#125;&#125;abstract class Factory &#123; public static function factoryMethod($product) &#123;&#125;&#125;class ChartFactory extends Factory&#123; public static function factoryMethod($chart) &#123; return new $chart(); &#125;&#125;class Client&#123; public function chartTest($chartType) &#123; ChartFactory::factoryMethod($chartType)-&gt;display(); &#125;&#125;$client = new Client();$client-&gt;chartTest($chartConfig['chartType']); 在抽象工厂中声明了工厂方法, 具体产品对象的创建由其子类负责, 客户端针对抽象工厂编程, 可在运行时再指定具体工厂类, 具体工厂类实现了工厂方法, 不同的具体工厂可以创建不同的具体产品; 在客户端代码中, 只需关心抽象工厂类即可, 不同的具体工厂可以创建不同的产品; 可以通过配置文件来存储具体工厂类ConcreteFactory的类名, 更换新的具体工厂时无须修改源代码, 系统扩展更为方便; 小结工厂方法模式是简单工厂模式的延伸, 它继承了简单工厂模式的优点, 同时还弥补了简单工厂模式的不足;工厂方法模式是使用频率最高的设计模式之一, 是很多开源框架和API类库的核心模式;","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"04. Simple Factory 简单工厂模式 (创建较少的对象)","slug":"oop/2017-08-09-OOP-04-Factory","date":"2017-08-09T07:08:11.000Z","updated":"2018-08-01T01:58:48.000Z","comments":true,"path":"2017/08/09/oop/2017-08-09-OOP-04-Factory/","link":"","permalink":"http://blog.renyimin.com/2017/08/09/oop/2017-08-09-OOP-04-Factory/","excerpt":"","text":"场景举例 假设公司开发的CRM系统可以显示饼状图、柱状图等效果, 原始设计方案如下: 123456789101112131415161718192021222324class Client&#123; public $chartObject = null; public function __construct($type) &#123; switch ($chartType) &#123; case 'pie' : $this-&gt;chartObject = new PieChart(); break; case 'bar' : $this-&gt;chartObject = new BarChart(); break; default: //TODO break; &#125; &#125; public function show() &#123; $this-&gt;chartObject-&gt;display(); &#125;&#125; 客户端代码通过调用 Client类 的构造函数来创建图表对象, 根据参数 type 可以得到不同类型的图表，然后再调用show()方法来显示相应的图表; 传统设计存在问题: 不难看出，Client类是一个巨大的类 Client类中包含很多 if…else… / switch…case… 代码块, 整个类的代码相当冗长; Client类的职责过重, 它将各种图表对象的创建和使用集中在一个类中实现, 违反了单一职责原则, 不利于类的重用和维护; 当需要增加新类型的图表时，必须修改Client类的源代码，违反了开闭原则; 客户端只能通过 new 关键字来直接创建图像对象, 图像类与客户端Client类耦合度较高 (比如一旦类的名字或参数发生变更, 你也必须修改Client代码的源代码), 也会违反开闭原则; 初步改进 为了不让Client类看起来过于冗长, 可以通过配置来决定使用哪个图形类: 123456789101112131415class Client &#123; public $chartObject = null; public function __construct($type) &#123; // 一行搞定 Config::get(&apos;chartType&apos;) 可以为 pie, bar $this-&gt;chartObject = new Config::get(&apos;chartType&apos;) . Chart(); &#125; public function show() &#123; $this-&gt;chartObject-&gt;display(); &#125; &#125; 经过上面改进, 不仅可以简化代码, 而且可以保证扩展性, 当有新的图形类时, 只用增加配置和新图形类的名字对应好即可, 也不用去修改 Client 类; 已经基本解决了之前设计方案的诸多问题! 仍然存在的问题是: Client类的职责过重, 它将各种图表对象的创建和使用集中在一个类中实现, 违反了单一职责原则; 如果Client类不仅展示图表, 还做日志记录, 那么日志对象的创建也是在Client中创建并使用, 久而久之, 你的Client类中可能会创建大量的对象, 并且会依赖冗长的配置关系来在某类对象中选择所需的对象; 简单工厂模式 为了将图像对象的创建和使用分离, 使用简单工厂模式对图表库进行重构, 重构后的结构如下图所示： Chart接口充当抽象产品类, 其子类 PieChart 和 BarChart 充当具体产品类, Factory充当工厂类; 如果只是在Factory类中依然使用如下代码的话, 其实还是避免不了增加新对象对Factory类造成的修改, 虽然Factory的出现将类的创建和使用分离开来, 但是仍然会违反开闭原则; 1234567891011switch ($chartType) &#123; case &apos;pie&apos; : $this-&gt;chartObject = new PieChart(); break; case &apos;bar&apos; : $this-&gt;chartObject = new BarChart(); break; default: //TODO break;&#125; 所以这里的工厂模式其实是结合了之前的初步改进中的方法! 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?php$config = [&apos;chartType&apos; =&gt; &apos;PieChart&apos;];abstract class Chart&#123; public abstract function display();&#125;class PieChart extends Chart&#123; public function display() &#123; var_dump(&apos;pieChart图&apos;); &#125;&#125;class BarChart extends Chart&#123; public function display() &#123; var_dump(&apos;barChart图&apos;); &#125;&#125;class SimpleFactory&#123; public static function createChartObj($chart) &#123; return new $chart; &#125;&#125;class Client&#123; public function display($chartType) &#123; $chart = SimpleFactory::createChartObj($chartType); $chart-&gt;display(); &#125;&#125;$client = new Client();$client-&gt;display($config[&apos;chartType&apos;]); 问题虽然工厂类使得Chart类的创建和使用分离开了, 但仍然存在的问题是: Factory类可能是过于繁重的, Client所有想创建的对象都想使用Factory进行创建, 这样 要么你需要维护较繁重的类配置映射关系来在多种类型的对象中, 选择你需要的对象; 要么就得在Factory类中通过繁琐的 if…else 来区分不同种类的对象; 小结 简单工厂模式提供了 专门的工厂类 用于创建对象, 将对象的创建和对象的使用分离开, 它作为一种最简单的工厂模式在软件开发中得到了较为广泛的应用; 主要优点 工厂类包含必要的判断逻辑(当然也可以使用配置的方法来避免违反开闭原则), 可以决定在什么时候创建哪一个产品类的实例, 客户端可以免除直接创建产品对象的职责, 而仅仅消费产品, 简单工厂模式实现了对象创建和使用的分离; 客户端无须知道所创建的具体产品类的类名，只需要知道创建具体产品类所需要对应的参数即可, 对于一些复杂的类名, 通过简单工厂模式可以在一定程度减少使用者的记忆量; 主要缺点 由于工厂类集中了所有产品的创建逻辑, 职责过重, 一旦不能正常工作, 整个系统都要受到影响; 使用简单工厂模式, 势必会增加系统中类的个数(引入了新的工厂类), 增加了系统的复杂度和理解难度; 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑, 在产品类型较多时, 有可能造成工厂逻辑过于复杂, 不利于系统的扩展和维护, (此处还是违反开放-封闭原则);不过这一点可以使用上面使用过的, 采用配置的方式来避免 简单工厂模式由于使用了静态工厂方法, 造成工厂角色无法形成基于继承的等级结构; 适用场景, 在以下情况下可以考虑使用 简单工厂模式: 工厂类负责创建的对象比较少, 由于创建的对象较少, 不会造成工厂方法中的业务逻辑太过复杂; 客户端只知道传入工厂类的参数, 对于如何创建对象并不关心;","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"0. S.O.L.I.D 五大基本原则","slug":"oop/2017-08-06-00-SOLID","date":"2017-08-06T13:36:27.000Z","updated":"2018-07-29T04:46:23.000Z","comments":true,"path":"2017/08/06/oop/2017-08-06-00-SOLID/","link":"","permalink":"http://blog.renyimin.com/2017/08/06/oop/2017-08-06-00-SOLID/","excerpt":"","text":"单一职责原则 SRP: The Single Responsibility Principle 单一职责原则是最简单的面向对象设计原则, 用于控制类的粒度大小; 此原则的核心就是 解耦 和 增强内聚性; 单一职责原则定义为: 一个类或者模块应该有且只有一个被改变的原因; 如果一个类承担的职责过多(耦合度就越大), 它被复用的可能性就越小; 一个职责的变化可能会影响其他的职责, 这种耦合会导致脆弱的设计, 当发生变化时, 设计会遭受到意想不到的破坏(因此要将这些职责进行分离, 将不同的职责封装在不同的类中); 开放封闭原则 OCP: The Open/Closed Principle 开放-封闭原则: 一个软件实体应当对扩展开放, 对修改关闭(即软件实体应尽量在不修改原有代码的情况下进行扩展); 如果一个软件系统设计符合开闭原则, 则可以非常方便地对系统进行扩展, 而且在扩展时无须修改现有代码。 随着软件规模越来越大, 运行时间越来越长, 软件维护成本也越来越高, 设计满足开闭原则的软件系统也变得越来越重要。 此原则的核心是 对抽象编程, 而不对具体编程; 为了满足开闭原则, 需要对系统进行抽象化设计, 抽象化 是开闭原则的关键; 例子, 假设系统可以显示各种类型的图表, 如 饼状图 和 柱状图 等, 为了支持多种图表显示方式 原始设计方案如下 代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?phpclass PieChart&#123; public function display() &#123; echo 'piechart', '&lt;br/&gt;'; &#125;&#125;class BarChart&#123; public function display() &#123; echo 'barchart', '&lt;br/&gt;'; &#125;&#125;class ChartDisplay&#123; public $chartObject = null; public function __construct() &#123; //TODO &#125; public function display($chartType) &#123; switch ($chartType) &#123; case 'pie' : $piechart = new PieChart(); $piechart-&gt;display(); break; case 'bar' : $barchart = new BarChart(); $barchart-&gt;display(); break; default: //TODO break; &#125; &#125;&#125; 问题: 现在如果需要增加一个折线图 LineChart, 你就要需要修改 ChartDisplay 类的 display() 方法的源代码, 增加新的判断逻辑, 这就违反了开闭原则; 现对该系统进行重构, 使之符合开闭原则: 引入抽象图表类 AbstractChart, 并且让ChartDisplay针对抽象图表类进行编程(依赖抽象), 再在 ChartDisplay 的 display() 方法中调用具体 chart对象的display()方法显示图表 接下来, 只需要将LineChart作为AbstractChart的子类, 在客户端向ChartDisplay中注入一个LineChart对象即可, 无须修改现有类库的源代码 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpabstract class AbstractChart&#123; protected function display() &#123; &#125;&#125;class PieChart extends AbstractChart&#123; public function display() &#123; echo 'piechart', '&lt;br/&gt;'; &#125;&#125;class BarChart extends AbstractChart&#123; public function display() &#123; echo 'barchart', '&lt;br/&gt;'; &#125;&#125;class ChartDisplay&#123; public function __construct() &#123; //TODO &#125; public function display(AbstractChart $chart) &#123; $chart-&gt;display(); &#125;&#125;$cd = new ChartDisplay();$cd-&gt;display(new PieChart());$cd-&gt;display(new BarChart()); 里氏替换原则 LSP: The Liskov Substitution Principle 所有引用基类的地方, 必须能透明地使用其子类对象: 子类可以实现父类的抽象方法, 但是不能覆盖父类的非抽象方法, 也就是子类可以扩展父类的功能, 但是不能改变父类原有的功能; 主要就是说, 如果依赖的类将来有可能被扩展, 你最好设计一个抽象父类或接口, 子类继承、实现父类; 所以, 对比之前的开闭原则, 可以发现, 里氏代换原则是实现开闭原则的重要方式之一, 由于使用基类对象的地方都可以使用子类对象, 因此在程序中尽量使用基类类型来对对象进行定义, 而在运行时再确定其子类类型, 用子类对象来替换父类对象。 接口分离原则 ISP: The Interface Segregation Principle 该原则比较好理解: 不要定义过于臃肿的接口, 接口中不要有很多不相关的逻辑方法(否则一定也违背单一职责原则); 过于臃肿的接口可能会强迫用户去实现接口内部用户并不需要的方法, 换句话说, 使用 多个专门的接口 比使用 一个臃肿的总接口 要好很多; 如果你在类中实现的接口中有你不需要使用方法, 估计也是重写为空方法, 这其实已经违背了 接口分离原则 也就是说, 一个接口或者类应该拥有尽可能少的行为, 就是少到恰好能完成它自身的职责, 这也是保证软件系统模块的粒度尽可能少, 以达到高度可重用的目的; 依赖反转原则 DIP: The Dependency Inversion Principle 要针对接口编程, 而不是针对实现编程 如果说 开闭原则是面向对象设计的目标 的话, 那么依赖倒转原则就是面向对象设计的主要实现机制之一, 它是系统抽象化的具体实现; 上层不用去定义自己要依赖哪个具体的类, 而是定义自己依赖哪个 抽象; 然后让底层代码根据上层的要求, 去实现相应的 抽象; 这样就变成了底层对上层的依赖, 底层代码需要去 实现 上层代码定义的抽象; 在实现依赖倒转原则时, 我们需要针对抽象层编程, 将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象; 常用的注入方式有三种，分别是：构造注入，设值注入(Setter注入) 和 接口注入。 构造注入是指通过构造函数来传入具体类的对象 设值注入是指通过Setter方法来传入具体类的对象 而接口注入是指通过在接口中声明的业务方法来传入具体类的对象 小结在大多数情况下, 开闭原则、里氏代换原则 和 依赖倒转原则 这三个设计原则会同时出现: 开闭原则是目标, 里氏代换原则是基础, 依赖倒转原则是手段, 它们相辅相成, 相互补充, 目标一致, 只是分析问题时所站角度不同而已;","categories":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/categories/OOP/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://blog.renyimin.com/tags/OOP/"}]},{"title":"06. 虚拟主机配置","slug":"nginx/2017-04-28-06","date":"2017-04-28T12:56:27.000Z","updated":"2018-08-03T09:12:30.000Z","comments":true,"path":"2017/04/28/nginx/2017-04-28-06/","link":"","permalink":"http://blog.renyimin.com/2017/04/28/nginx/2017-04-28-06/","excerpt":"","text":"","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/tags/Nginx/"}]},{"title":"05. nginx 配置文件简析","slug":"nginx/2017-04-27-05","date":"2017-04-27T12:56:27.000Z","updated":"2018-08-03T09:11:47.000Z","comments":true,"path":"2017/04/27/nginx/2017-04-27-05/","link":"","permalink":"http://blog.renyimin.com/2017/04/27/nginx/2017-04-27-05/","excerpt":"","text":"nginx 服务器配置文件都存放在安装目录conf中, 主配置文件名为 nginx.conf , 本篇介绍其内容和基本配置方法; nginx.conf 整体结构 nginx.conf主要由三部分组成: 全局块, events块, http块; 在 http块 中又包含 http全局块 和 多个 server块; 每个 server块 中, 又包含 server全局块 和 多个 location块; 总共5块区域可以进行配置, 总体结构如下图: 全局块全局块主要设置一些影响nginx整体运行的配置指令, 通常包括 nginx服务器的用户(组) 允许生成的 worker process 数 nginx进程PID存放路径 错误日志存放路径和级别 配置文件引入 ….nginx服务器的用户(组) 只能在全局块中配置 其所用指令为 user, 配置语法为 user user [group]; 只有被设置的用户或者用户组成员才有权限启动 Nginx 进程 如果是其他用户尝试启动, 将会报错; 如果希望所有用户都可以启动nginx:一种方法是将该行注释掉;另一种方法是 user nobody nobody(将用户或者用户组设置为nobody); worker process数配置 只能在全局块中配置 worker process 是nginx服务器实现并发处理服务的关键所在, 理论上来说值越大则可以支持的并发量就越高, 但实际上也受到操作系统本身资源和硬件设备(CPU和磁盘驱动)等的制约; 配置允许生成 worker process 数的指令是 worker_process, 语法格式为 worker_process number|auto number: 指定nginx进程最多可以产生的worker process数量 auto: nginx进程将自动检测 默认配置文件中, 设置的number为1, 所以启动nginx之, 会看到除了 master process 主进程之外, 还生成了1个 worker process;尝试将number改为3, 重启ngix之后, 会看到除了 master process 主进程之外, 还生成了3个 worker process; nginx进程PID存放路径 只能在全局块中配置 nginx进程作为系统的守护进程运行时, 需要在某文件中保存当前运行进程的主进程号, nginx支持对它的存放路径进行自定义配置, 指令是 pid, 语法格式为 pid file file指定的是path及filename (默认的路径在nginx安装路径的logs目录下, 文件名为nginx.pid; 指定file时, 必须设置文件名, 如果只设置路径path, 则会报错)path可以是绝对路径, 也可以是以nginx安装目录为根目录的相对路径 比如要把nginx.pid放到nginx安装目录下的sbin目录下, 文件名为 nginx_web: pid sbin/nginx_web 错误日志存放路径和级别 可以在全局块, http全局块, server全局块, location块 中配置, 只是作用域不同; 配置错误日志使用的指令是 error_log, 语法格式是 error_log file|stderr [debug|info|notice|warn|rror|crit|alert|emerg] 可以看到, nginx服务器的日志支持输出到某一固定文件file, 或者输出到标准输出stderr; 日志的级别从左到右是从低到高, 设置某一级别后, 比这一级别高的日志都会被记录下来 nginx默认的存放和日志级别设置为 error_log logs/error error (注意: 路径如果不是绝对路径的话, 都是以nginx安装目录为根目录的相对路径) 注意: 指定的文件对于运行nginx进程的用户需要有写权限 配置文件引入 在一些情况下, 可能需要将其他的nginx配置或者第三方模块的配置引用到当前的主配置文件中;一般nginx服务有上配置了多个虚拟站点的话, 每个站点都是各自独立配置自己的配置文件, 然后引入到主配置文件中, 一般会写成 include conf.d/*.conf;; 语法结构 include file, file是要引入的配置文件, 支持相对路径 注意: 新引入进来的配置文件要求nginx进程用户对其有写权限; events块设置网络连接序列化 只能在events块 中配置 为了防止惊群效应, nginx包含了指令 accept_mutex, 当其设置为开启时, 将会对多个nginx进程接收连接进行序列化, 防止多个进程对连接的争抢, 语法格式为 accept_mutex on|off; 此指令默认为开启状态; 是否同时接收多个连接 只能在events块 中配置 nginx的每个worker process都有能力同时接收多个新到达的网络连接, 但是这需要在配置文件中进行设置, 指令为 multi_accept, 语法为 multi_accept on|off; 此指令默认为关闭状态, 即每个 worker process 一次只能接收一个新到达的网络连接; 事件驱动模型选择 只能在events块 中配置 nginx提供了多种事件驱动模型来处理网络消息, 可以使用 use 指令来强制nginx服务器选择哪种事件驱动模型进行消息处理, 语法格式为 use method; method的可选内容有: elect, poll, kqueue, epoll, rtsig, dev/poll, eventport, 关于事件驱动模型, 后面再细聊 一般使用 useepoll 配置最大连接数 只能在events块 中配置 指令 worker_connections 主要用来设置允许每一个 worker process 同时开启的最大连接数, 语法格式为 worker_connections number; 默认 number为512 注意: number不仅仅包括和前端用户建立的连接数, 而是包括所有可能的连接数; 另外, 最大连接数不能大于操作系统支持打开的最大文件句柄数量; http全局块自定义服务日志 log_format指令: 只能在 http全局块 中进行配置 access_log指令: 可以在 http全局块, server全局块, location块 进行配置 server全局块location块","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/tags/Nginx/"}]},{"title":"04. error.log 和 access.log","slug":"nginx/2017-04-24-04","date":"2017-04-27T08:36:25.000Z","updated":"2018-08-03T11:05:37.000Z","comments":true,"path":"2017/04/27/nginx/2017-04-24-04/","link":"","permalink":"http://blog.renyimin.com/2017/04/27/nginx/2017-04-24-04/","excerpt":"","text":"概述 nginx日志主要分为两种: 错误日志 和 自定义服务日志(也叫做访问日志); nginx.conf中, 虽然两个日志的相关配置默认都是注释的, 但并不意味着是关闭的, 除非显示地关闭; error.log 在 全局块, http全局块, server全局块 中都可以对nginx的错误日志进行相关配置, 只是作用域不同; 配置错误日志使用的指令是 error_log error_log error_log 语法格式是 error_log file|stderr [debug|info|notice|warn|rror|crit|alert|emerg] nginx服务器的日志支持输出到某一固定文件file, 或者输出到标准输出stderr; 日志的级别从左到右是从低到高, 设置某一级别后, 比这一级别高的日志都会被记录下来; nginx默认的存放和日志级别设置为 error_log logs/error error (注意: 路径如果不是绝对路径的话, 都是以nginx安装目录为根目录的相对路径); 注意: 指定的文件对于运行nginx进程的用户需要有写权限; 关闭日志记录 (一般不做此操作) 需要注意的是: error_log off 并不能关闭错误日志, 而是会将错误日志记录到以nginx安装目录为根目录, 下的一个文件名为off的文件中 ; 正确的关闭 error.log 记录功能的方为 error_log /dev/null ; (表示将存储日志的路径设置为”垃圾桶”) nginx的错误日志主要记录客户端访问nginx出错时的日志, 格式不支持自定义; error_log指令, 其用于配置nginx进程运行时的日志存放和级别; error_log 指令可以在 全局块, http全局块, server全局块, location块 中配置 access.log 之前在介绍过error_log指令, 其用于配置nginx进程运行时的日志存放和级别; error_log 指令可以在 全局块, http全局块, server全局块, location块 中配置 而此处所指的日志和常规的日志不同, 它是记录nginx服务器提供服务过程应答前端请求的日志, 称为服务日志 nginx的错误日志主要记录客户端访问nginx出错时的日志, 格式不支持自定义; 但是nginx的 自定义服务日志(访问日志)的格式是支持自定义的 nginx服务器支持对服务日志的 格式, 大小, 输出 等进行配置, 需要用到两个指令 access_log 和 log_format access_log指令 access_log 指令语法: access_log path [format[buffer=size]] path:配置服务日志文件的存放路径和文件名 format: 可选项, 自定义服务日志的格式字符串, 也可以通过 格式串的名称 使用log_format指令定义好的格式, 格式串的名称 在 log_format 指令中定义; size: 配置临时存放日志的内存缓冲区大小; 可以在 http全局块, server全局块, location块 进行配置 如果想关闭自定义服务日志的记录功能, 可以 access_log off; log_format指令 和 access_log 联合使用的另一个指令是 log_format 专门用来定义服务日志的格式 并且可以为格式字符串定义一个名称, 以便access_log指令可以直接调用 其语法格式为 log_format name string.... name: 为格式字符串定义的名字, 默认为 从 combined; string: 服务日志的格式字符串; (在定义过程中, 可以使用nginx配置预设的一些变量获取相关内容, 变量的名称使用双引号括起来, string整体使用单引号括起来) 在string中可以使用的变量: $request: 请求的URI和HTTP协议, 这是整个PV日志记录中最有用的信息, 记录服务器收到一个什么样的请求; $status: 记录请求返回的http状态码, 比如成功是200 ; $request_time: 整个请求的总时间, 指的就是从接受用户请求的第一个字节到发送完响应数据的时间, 即包括 接收请求数据时间、程序响应时间、输出响应数据时间; $upstream_response_time: 是指从Nginx向后端(php-cgi)建立连接开始到接受完数据然后关闭连接为止的时间;从上面的描述可以看出, $request_time 肯定大于等于 $upstream_response_time, 特别是使用POST方式传递参数时, 因为Nginx会把request body缓存住, 接收完毕后才会把数据一起发给后端;所以如果用户网络较差, 或者传递数据较大时, $request_time会比$upstream_response_time大很多;所以如果使用nginx的accesslog查看php程序中哪些接口比较慢的话, 记得在log_format中加入$upstream_response_time; $remote_addr: 客户端的IP地址; $http_user_agent: 客户端浏览器信息, 配置 ua=[$http_user_agent] 可能如下: 1ua=[Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1] rrc nginx示例 123log_format main &apos;remote_addr=[$remote_addr] http_x_forward=[$http_x_forwarded_for] time=[$time_local] request=[$request] &apos; &apos;status=[$status] byte=[$bytes_sent] elapsed=[$request_time] refer=[$http_referer] body=[$request_body] &apos; &apos;ua=[$http_user_agent] cookie=[$http_cookie] gzip=[$gzip_ratio]&apos;; 只能在 http全局块 中进行配置 小结 access_log 指令可以在 http全局块, server全局块, location块 进行配置; 而 log_format 只能在http全局块` 中进行配置; 也就是格式可以在http块全局块中定义多个, 然后http块中的每个server块可以设置自己的access.log文件位置及名称, 格式可以选择http全局块中定义的一种格式即可; 自定义服务日志切割logrotatehttp://blog.51cto.com/wn2100/2074048https://www.jianshu.com/p/514a9715de46 shell nginx日志落盘http://wiki.shanyishanmei.com/pages/viewpage.action?pageId=8989682","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/tags/Nginx/"}]},{"title":"01.","slug":"nginx/2017-04-21-01","date":"2017-04-21T14:16:31.000Z","updated":"2018-08-02T08:37:29.000Z","comments":true,"path":"2017/04/21/nginx/2017-04-21-01/","link":"","permalink":"http://blog.renyimin.com/2017/04/21/nginx/2017-04-21-01/","excerpt":"","text":"安装系列配置文件系列日志文件系列upstream模块 大数据如何根据nginx日志统计信息","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.renyimin.com/tags/Nginx/"}]}]}