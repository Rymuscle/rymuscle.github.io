{"meta":{"title":"Lant's Blog","subtitle":null,"description":null,"author":"Lant","url":"http://blog.renyimin.com"},"pages":[{"title":"分类","date":"2017-09-17T02:40:28.000Z","updated":"2017-09-18T09:08:09.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.renyimin.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-09-17T02:40:21.000Z","updated":"2017-09-18T09:08:03.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.renyimin.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"mysql(InnoDB)事务隔离级别(REPEATABLE READ) 与 锁,MVCC","slug":"2017-12-31-mysql_transaction-05","date":"2017-12-31T08:01:47.000Z","updated":"2018-01-02T01:32:58.000Z","comments":true,"path":"2017/12/31/2017-12-31-mysql_transaction-05/","link":"","permalink":"http://blog.renyimin.com/2017/12/31/2017-12-31-mysql_transaction-05/","excerpt":"","text":"REPEATABLE READ(可重复读) 之前已经了解到, 该隔离级别可以解决不可重复读问题 (当然, 也能解决脏读问题), 那么如果单纯用锁来实现, 可能会是如下这样子: 既然REPEATABLE READ 隔离级别可以解决脏读, 不可重复读的问题, 也就是它既可以让事务只能读其他事务已提交的的记录, 又能在同一事务中保证多次读取的数据即使被其他事务修改, 也是一致的。 解决脏读问题: 试想一下, 当在事务A中读取数据D的时候, 假设D之前已经在事务B中了, 并且事务B中对数据D做了修改, 但是事务B还没有完成(commit/rollback), 那如何让事务A无法读取数据D呢? 当事务B在对数据D做写操作的时候, 假设给数据D加上了行级的排他锁(X lock), 那事务A自然只能阻塞等事务A完成后才能读取数据D了, 这样就解决了脏读问题。 解决 不可重复读问题: 试想一下, 当在事务A中第一次读取了数据D之后, 直接给该数据D加S共享锁, 那其他事务自然只能阻塞等事务A完成后才能对数据D做修改操作了, 这样就解决了不可重复读, 在事务A中多次读取数据D, 都是一样的。 上面使用S锁+X锁确实可以实现 READ COMMITTED 隔离级别的效果, 也就避免了脏读问题和不可重复读问题, 当然, 这里的问题仍然是低效！！！！ 因为 MySQL 在事务隔离级别Read committed 、Repeatable Read下，InnoDB 存储引擎采用非锁定的一致性读－－即读取数据不用加锁，即采用的是MVCC中一致性非锁定读模式, 所以, InnoDB的做法是: 读不影响写，写不影响读。 读不影响写: 当数据正在执行读操作时，其他事务的写操作不会因此去等待当前事务行上S锁的释放，而是会去读取行的一个快照数据。 写不影响读：当数据正在执行写操作时，其他事务的读操作不会因此去等待当前事务行上X锁的释放，而是会去读取行的一个快照数据。 所以总结来看, READ UNCOMMITTED 和 REPEATABLE READ 这两个隔离级别都是使用 写用排他锁 + 读用MVCC, 区别可以参考 MySQL-InnoDB-MVCC多版本并发控制 MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"mysql(InnoDB)事务隔离级别(READ COMMITTED) 与 锁,MVCC","slug":"2017-12-31-mysql_transaction-04","date":"2017-12-31T02:01:47.000Z","updated":"2018-01-02T01:33:33.000Z","comments":true,"path":"2017/12/31/2017-12-31-mysql_transaction-04/","link":"","permalink":"http://blog.renyimin.com/2017/12/31/2017-12-31-mysql_transaction-04/","excerpt":"","text":"READ COMMITTED(提交读) 了解了之前 READ UNCOMMITTED 隔离级别是如何加锁的, 并且在文章中, 已经知道 READ COMMITTED 隔离级别可以解决脏读的问题, 那接下来, 对于 READ COMMITTED 隔离级别, 试想一下如果让你用锁来设计, 你会怎么做? 既然READ COMMITTED 隔离级别可以解决脏读的问题, 也就是他可以让事务只能读其他事务已提交的的记录。 如果用锁机制来实现该隔离级别: 试想一下, 当在事务A中读取数据D的时候, 假设D之前已经在事务B中了, 并且事务B中对数据D做了修改, 但是事务B还没有完成(commit/rollback), 那如何让事务A无法读取数据D呢? 当事务B在对数据D做写操作的时候, 假设给数据D加上了行级的排他锁(X lock), 那事务A自然只能阻塞等事务A完成后才能读取数据D了! 数据库这样做的话确实实现了READ COMMITTED隔离级别的效果, 也就避免了脏读, 但问题是这是一种很低效的做法, 因为对于大部分应用来说, 读操作是多于写操作的, 当写操作加锁时, 那么读操作全部被阻塞, 这样在大用户量高并发的情况下, 会直接降低数据库的读效率。 那么, 既然用锁机制实现该隔离级别是低效的做法, 数据库是如何做的? 之前在相关MVCC的文章中可以得到答案: 数据库是使用了 排他锁+MVCC 的机制来实现该隔离级别的, 而不是单纯的使用锁或者单纯的使用MVCC READ COMMITTED与锁 测试 数据表结构如下: 1234567891011mysql&gt; select * from test_transaction;+----+---------------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+---------------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 2 | 我有一双铁爪 || 2 | 钢铁侠-rym | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+---------------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 重新设置客户端1事务隔离级别为read committed: SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED; 1234567891011121314151617181920mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.00 sec) mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-COMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; 再重新打开一个客户端2并设置事务隔离级别为read committed; 在客户端1中打开事务, 然后更改数据, 先不提交; 然后在客户端2中打开事务, 读取客户端1中尚未提交的那条被修改数据 结果发现在客户端2中可以正常读取到那条数据, 只不过, 那条数据并不是被客户端1事务中修改后的数据, 而是最初的稳定数据, 这就避免了脏读!! 对于该隔离级别修改数据时使用的锁类型, 其分析方法, 和之前一篇MySQL(INNODB引擎)事务READ UNCOMMITTED隔离级别和锁的关系 是一样的： 可以在客户端1的事务在修改数据并且未提交时, 在客户端2中对同一数据进行修改, 然后在客户端2阻塞阶段通过查看表的加锁情况: select * from information_schema.INNODB_LOCKS;,事务状态: select * from information_schema.INNODB_TRX;,进行分析, 结果就不展示了, 可以自行测试一下, 该隔离级别修改数据时使用的也是排他锁, 并且客户端2的修改语句会锁等待~(和之前分析READ UNCOMMITTED隔离级别一样, 既然使用了排他锁, 竟然别的事务还能读取, 这特么不就又违反了排他锁的特性么? 还是那句话, 另一个事务在读取的时候并不会加锁, 而是用的MVCC机制读取的镜像) 小结: InnoDB在该隔离级别(READ COMMITTED)写数据是使用排他锁, 读取数据不加锁而是使用了MVCC机制, 这样就可以大大提高并发读写效率, 写不影响读, 因为读并未加锁, 读的是记录的镜像版本!! MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"mysql(InnoDB)事务隔离级别(READ UNCOMMITTED) 与 锁","slug":"2017-12-29-mysql_transaction-02","date":"2017-12-29T11:12:11.000Z","updated":"2018-01-02T01:33:59.000Z","comments":true,"path":"2017/12/29/2017-12-29-mysql_transaction-02/","link":"","permalink":"http://blog.renyimin.com/2017/12/29/2017-12-29-mysql_transaction-02/","excerpt":"","text":"前言先针对自己以前错误的思维做个记录, 可以直接跳过 由于以前看到很多资料在谈到并发控制的时候, 都会提到用锁来控制并发, MySQL也不例外, 也有很多和锁相关的概念(留到后面会单独整理一篇笔记出来), 所以一提到高并发产生的问题, 我会不自觉地提出一个疑问: 现在并发出问题了, 那怎么用锁的相关知识来解决?; 而且近期一段时间也一直在看很多有关MySQL锁相关的资料,书籍, 于是乎 死锁, 锁冲突, 行锁,表锁, 读锁, 写锁, 乐观锁, 悲观锁 ……等等 N多锁相关的名词(后面的笔记会把所有自己遇到的, 全部整理并进行分析), 大量的篇幅, 高深晦涩的描述, 直接导致我意识里认为嗯, 锁真tm高大上, 真tm高端, 肯定tm就是它了; 于是就进入了思想误区, 认为在解决脏读,不可重复读,幻读的资料中, 应该大篇幅的描述如何用锁相关的知识来解决这些问题, 然而略失落了, 资料倒是提了点儿锁的知识, 但更多的是用事务的哪个隔离级别来解决这些问题, 锁哪儿去了? 尤其是在分析脏读,不可重复读,幻读这几个问题的时候, 一上去就全乱了, 比如 脏读, 如果总是以MySQL锁的相关知识作为前提来分析, 就会陷入误区 ‘事务A读取数据的时候肯定会加S锁的, 事务B自然是无法对未完成的事务A中的数据进行修改的, 我Ca, 这种脏读的场景根本就不成立嘛!‘, 那为什么不提锁, 而是用隔离级别来解决。 ………… 晕了几天之后,终于稍微醒了点…… 参考美团技术博客 显然, 事务隔离级别的核心就是锁, 各隔离级别使用了不同的加锁策略，在分析之前的几个高并发事务问题的时候, 隔离级别(锁)自然是不能作为前置知识点的, 而是最终问题的解决方案! “READ UNCOMMITTED与锁”的困惑(未提交读) 在READ UNCOMMITTED级别, 事务中的修改, 即使还没有提交, 对其他事务也都是可见的; 也就是说事务可以读取未提交的数据, 这也就造成了 脏读(Dirty Read) 的出现。 这个级别会导致很多问题, 而且从性能上来说, READ COMMITTED 并不会比其他的级别好太多, 却缺乏其他级别的很多好处, 在实际应用中一般很少使用。 虽然很少使用, 但还是有必要了解一下, 它这个隔离级别究竟是怎么隔离的, 竟然还能容许很多问题的存在？ (老兄亏你还算个隔离级别, 怎么办事儿的…) 网上相关资料五花八门, 下面列几个出来(希望你看完不要激动): 美团技术博客: segmentfault一篇文章 CSDN一篇文章 CSDN一篇文章 说实话, 资料查到这份儿上, 我已经快崩溃了, 就READ UNCOMMITTED这个隔离级别: 有说读写都不加锁的 有说’修改完数据立即加S锁的, 修改时撤掉S锁’ 有说’写加S锁,事务结束释放’的 有说’写加X锁,事务结束释放’的 行啦, 不查了, 再查就崩溃了, 自己去测一下吧!!! 本次测试是使用MAMP PRO中mysql5.6版本 先准备一张测试表test_transaction: 1234567891011121314DROP TABLE IF EXISTS `test_transaction`;CREATE TABLE `test_transaction` ( `id` int(10) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `user_name` char(20) NOT NULL COMMENT &apos;姓名&apos;, `age` tinyint(3) NOT NULL COMMENT &apos;年龄&apos;, `gender` tinyint(1) NOT NULL COMMENT &apos;1:男, 2:女&apos;, `desctiption` text NOT NULL COMMENT &apos;简介&apos;, PRIMARY KEY (`id`), KEY `name_age_gender_index` (`user_name`,`age`,`gender`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;INSERT INTO `test_transaction` VALUES (1, &apos;金刚狼&apos;, 127, 1, &apos;我有一双铁爪&apos;);INSERT INTO `test_transaction` VALUES (2, &apos;钢铁侠&apos;, 120, 1, &apos;我有一身铁甲&apos;);INSERT INTO `test_transaction` VALUES (3, &apos;绿巨人&apos;, 0, 2, &apos;我有一身肉&apos;); 如下: 123456789mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 2 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) READ UNCOMMITTED与锁 测试演示该隔离级别脏读效果 先查看当前会话(当前客户端)事务的隔离级别: SELECT @@SESSION.tx_isolation; 可以看到: REPEATABLE READ 是InnoDB存储引擎的默认事务隔离级别 123456789mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; 重新设置当前客户端事务隔离级别为read uncommitted: SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; 注意, 此时只是当前会话端的隔离级别被改, 其余客户端连接自然还是默认的REPEATABLE READ隔离级别 接下来将客户端2的事务隔离级别也设置为read uncommitted; 客户端1开启事务,并执行一个查询’读取数据’: 1234567891011121314151617181920mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction where id=2;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 |+----+-----------+-----+--------+--------------------+1 row in set (0.00 sec) mysql&gt; 注意, 客户端1此时的事务并未提交 客户端2开启事务, 并修改客户端1查询的数据 123456789101112131415mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| READ-UNCOMMITTED |+------------------------+1 row in set (0.00 sec) mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-托尼&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 此时发现, 客户端2可以对客户端1正在读取的记录进行修改, 而根据锁相关知识, 如果说客户端1在读取记录的时候加了S锁, 那么客户端2是不能加X锁对该记录进行更改的, 所以可以得出结论: 要么是客户端1读取记录的时候没有加S锁, 要么是客户端2更改该记录的时候没有加X锁(这样即使客户端1加了S锁,对它这个不加锁的事务也无可奈何), 那么究竟是哪种情况导致的? 下面继续进行分析… 注意, 客户端2此时的事务也并未提交 切换到客户端1, 再次查询数据, 发现数据已经变成了’钢铁侠-托尼’; 然后客户端2 rollback 事务, 再到客户端1中查询,发现user_name又变成了’钢铁侠’, 那之前独到’钢铁侠-托尼’就是脏数据了, 这就是一次 脏读 测试,分析该隔离级别如何加锁 重新构造测试条件 客户端1开启事务, 然后对数据做修改 1234567mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rymuscle&apos; where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; 注意, 客户端1此时的事务并未提交 客户端2开启事务, 对相同的数据行做修改 12345mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; update test_transaction set user_name=&apos;钢铁侠-rym&apos; where id=2;....阻塞等待了 最终会如下: 注意: 在上面的过程, 在客户端2阻塞阶段, 你可以通过一个新的客户端来分析, 客户端2在锁等待的情况下的 加锁情况 和 事务状态: 查看表的加锁情况: select * from information_schema.INNODB_LOCKS; 事务状态 select * from information_schema.INNODB_TRX; 所以, READ UNCOMMITTED 隔离级别下, 写操作是会加锁的, 而且是X排他锁, 直到客户端1事务完成, 锁才释放, 客户端2才能进行写操作 接下来你肯定会纳闷 “既然该隔离级别下事务在修改数据的时候加的是x锁, 并且是事务完成后才释放, 那之前的测试客户端2在事务中修改完数据之后, 为什么事务还没完成, 也就是x锁还在, 结果客户端1却能读取到客户端2修改的数据”？这完全不符合排他锁的特性啊(要知道,排他锁会阻塞除当前事务之外的其他事务的读,写操作) 其实网上已经有人在sqlserver的官网上找到了相关资料: 12345ansactions running at the READ UNCOMMITTED level do not issue shared locks to prevent other transactions from modifying data read by the current transaction. READ UNCOMMITTED transactions are also not blocked by exclusive locks that would prevent the current transaction from reading rows that have been modified but not committed by other transactions. When this option is set, it is possible to read uncommitted modifications, which are called dirty reads. Values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. This option has the same effect as setting NOLOCK on all tables in all SELECT statements in a transaction. This is the least restrictive of the isolation levels. 翻译翻译, 在思考思考, 其实说的是在 READ UNCOMMITTED 级别运行的事务不会发出共享锁来防止其他事务修改当前事务读取的数据, 既然不加共享锁了, 那么当前事务所读取的数据自然就可以被其他事务来修改。而且当前事务要读取其他事务未提交的修改, 也不会被排他锁阻止, 因为排他锁会阻止其他事务再对其锁定的数据加读写锁, 但是可笑的是, 事务在该隔离级别下去读数据的话根本什么锁都不加, 这就让排他锁无法排它了, 因为它连锁都没有。这就导致了事务可以读取未提交的修改, 称为脏读。 所以可以得出: READ UNCOMMITTED隔离级别下, 读不会加任何锁。而写会加排他锁，并到事务结束之后释放。 参考资料:-《高性能MySQL》 MySQL官方文档 慕课mark_rock同学手记 美团技术博客","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"隔离级别与锁","slug":"隔离级别与锁","permalink":"http://blog.renyimin.com/tags/隔离级别与锁/"}]},{"title":"MySQL-InnoDB-MVCC多版本并发控制","slug":"2017-12-28-mysql_mvcc","date":"2017-12-28T13:07:12.000Z","updated":"2018-01-09T06:37:16.000Z","comments":true,"path":"2017/12/28/2017-12-28-mysql_mvcc/","link":"","permalink":"http://blog.renyimin.com/2017/12/28/2017-12-28-mysql_mvcc/","excerpt":"","text":"(Multiversion Concurrency Control) 前言最近正在啃《高性能MySQL》这本书, 当看到事务相关知识时, 决定对该知识点稍微深入一下,《高性能MySQL》中在介绍事务相关知识点时, 显然不是特别深入, 很多比较底层的知识点并没有太多的深入, 当然此处并不是要对本书做什么评判, 言归正传, 这里主要先说一下本人在啃相关知识点时的曲折之路: 首先是事务相关ACID特性, 之前已经有相关笔记进行过介绍, 这里不再重复; 接下来是高并发事务相关的问题, 像是 脏读, 不可重复读, 幻读, 更新丢失等问题之前也有相关笔记; 再下来就是MySQL应对高并发事务是如何给出解决方案的(其中包含各个隔离级别的简介); 然后就是各个隔离级别的具体介绍及与锁的关系, 也就是在这部分知识点, 发现了之前并没有过多关心的知识点 MVCC多版本并发控制, 然后已发不可收拾了… 入题下面先引用一些前辈们比较优秀的文章: 阿里数据库内核’2017/12’月报中对MVCC的解释是:多版本控制: 指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。在内部实现中，与Postgres在数据行上实现多版本不同，InnoDB是在undolog中实现的，通过undolog可以找回数据的历史版本。找回的数据历史版本可以提供给用户读(按照隔离级别的定义，有些读请求只能看到比较老的数据版本)，也可以在回滚的时候覆盖数据页上的数据。在InnoDB内部中，会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性。&lt;高性能MySQL&gt;中对MVCC的部分介绍 MySQL的大多数事务型存储引擎实现的其实都不是简单的行级锁。基于提升并发性能的考虑, 它们一般都同时实现了多版本并发控制(MVCC)。不仅是MySQL, 包括Oracle,PostgreSQL等其他数据库系统也都实现了MVCC, 但各自的实现机制不尽相同, 因为MVCC没有一个统一的实现标准。 可以认为MVCC是行级锁的一个变种, 但是它在很多情况下避免了加锁操作, 因此开销更低。虽然实现机制有所不同, 但大都实现了非阻塞的读操作，写操作也只锁定必要的行。 MVCC的实现方式有多种, 典型的有乐观(optimistic)并发控制 和 悲观(pessimistic)并发控制。 MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作。其他两个隔离级别够和MVCC不兼容, 因为 READ UNCOMMITTED 总是读取最新的数据行, 而不是符合当前事务版本的数据行。而 SERIALIZABLE 则会对所有读取的行都加锁。从书中可以了解到: MVCC是被Mysql中 事务型存储引擎InnoDB 所支持的; 应对高并发事务, MVCC比单纯的加锁更高效; MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作; MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现; 各数据库中MVCC实现并不统一 但是书中提到 “InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的”(网上也有很多此类观点), 但其实并不准确, 可以参考MySQL官方文档, 可以看到, InnoDB存储引擎在数据库每行数据的后面添加了三个字段, 不是两个!! 相关概念1.read view, 快照snapshot 淘宝数据库内核月报/2017/10/01/此文虽然是以PostgreSQL进行的说明, 但并不影响理解, 在”事务快照的实现”该部分有细节需要注意: 事务快照是用来存储数据库的事务运行情况。一个事务快照的创建过程可以概括为： 查看当前所有的未提交并活跃的事务，存储在数组中 选取未提交并活跃的事务中最小的XID，记录在快照的xmin中 选取所有已提交事务中最大的XID，加1后记录在xmax中根据不同的情况，赋值不同的satisfies，创建不同的事务快照注意: 上文中在PostgreSQL中snapshot的概念, 对应MySQL中, 其实就是你在网上看到的read view,快照这些概念;比如何登成就有关于Read view的介绍;而 此文 却仍是使用快照来介绍; 2.read view 主要是用来做可见性判断的, 比较普遍的解释便是”本事务不可见的当前其他活跃事务”, 但正是该解释, 可能会造成一节理解上的误区, 所以此处提供两个参考, 供给大家避开理解误区: read view中的高水位low_limit_id可以参考 “https://github.com/zhangyachen/zhangyachen.github.io/issues/68“, “https://www.zhihu.com/question/66320138“ 其实上面第1点中加粗部分也是相关高水位的介绍( 注意进行了+1 ) 3.另外, 对于read view快照的生成时机, 也非常关键, 正是因为生成时机的不同, 造成了RC,RR两种隔离级别的不同可见性, 可以参考 http://www.sohu.com/a/194511597_610509, https://www.cnblogs.com/digdeep/p/4947694.html 两篇文章; 在innodb中(默认repeatable read级别), 事务在begin/start transaction之后的第一条select读操作后, 会创建一个快照(read view), 将当前系统中活跃的其他事务记录记录起来; 在innodb中(默认repeatable committed级别), 事务中每条select语句都会创建一个快照(read view); 参考1234With REPEATABLE READ isolation level, the snapshot is based on the time when the first read operation is performed. 使用REPEATABLE READ隔离级别，快照是基于执行第一个读操作的时间。With READ COMMITTED isolation level, the snapshot is reset to the time of each consistent read operation.使用READ COMMITTED隔离级别，快照被重置为每个一致的读取操作的时间。 4.undo-log 可以参考数据库内核月报2015/04/01 前言 Undo log是InnoDB MVCC事务特性的重要组成部分。当我们对记录做了变更操作时就会产生undo记录，Undo记录默认被记录到系统表空间(ibdata)中，但从5.6开始，也可以使用独立的Undo 表空间。 Undo记录中存储的是老版本数据，当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着undo链找到满足其可见性的记录。当版本链很长时，通常可以认为这是个比较耗时的操作（例如bug#69812）。 大多数对数据的变更操作包括INSERT/DELETE/UPDATE，其中INSERT操作在事务提交前只对当前事务可见，因此产生的Undo日志可以在事务提交后直接删除（谁会对刚插入的数据有可见性需求呢！！），而对于UPDATE/DELETE则需要维护多版本信息，在InnoDB里，UPDATE和DELETE操作产生的Undo日志被归成一类，即update_undo 另外, 在回滚段中的undo logs分为: insert undo log 和 update undo log insert undo log : 事务对insert新记录时产生的undolog, 只在事务回滚时需要, 并且在事务提交后就可以立即丢弃。 update undo log : 事务对记录进行delete和update操作时产生的undo log, 不仅在事务回滚时需要, 一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被purge线程删除。 5.InnoDB存储引擎在数据库每行数据的后面添加了三个字段 6字节的事务ID(DB_TRX_ID)字段: 用来标识最近一次对本行记录做修改(insert|update)的事务的标识符, 即最后一次修改(insert|update)本行记录的事务id。 至于delete操作，在innodb看来也不过是一次update操作，更新行中的一个特殊位将行表示为deleted, 并非真正删除。 7字节的回滚指针(DB_ROLL_PTR)字段: 指写入回滚段(rollback segment)的 undo log record (撤销日志记录记录)。 如果一行记录被更新, 则 undo log record 包含 ‘重建该行记录被更新之前内容’ 所必须的信息。 6字节的DB_ROW_ID字段: 包含一个随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。 结合聚簇索引的相关知识点, 我的理解是, 如果我们的表中没有主键或合适的唯一索引, 也就是无法生成聚簇索引的时候, InnoDB会帮我们自动生成聚集索引, 但聚簇索引会使用DB_ROW_ID的值来作为主键; 如果我们有自己的主键或者合适的唯一索引, 那么聚簇索引中也就不会包含 DB_ROW_ID 了 。 关于聚簇索引, 《高性能MySQL》中的篇幅对我来说已经够用了, 稍后会整理一下以前的学习笔记, 然后更新上来。 6.可见性比较算法（这里每个比较算法后面的描述是建立在rr级别下，rc级别也是使用该比较算法,此处未做描述）设要读取的行的最后提交事务id(即当前数据行的稳定事务id)为 trx_id_current当前新开事务id为 new_id当前新开事务创建的快照read view 中最早的事务id为up_limit_id, 最迟的事务id为low_limit_id(注意这个low_limit_id=未开启的事务id=当前最大事务id+1)比较: 1.trx_id_current &lt; up_limit_id, 这种情况比较好理解, 表示, 新事务在读取该行记录时, 该行记录的稳定事务ID是小于, 系统当前所有活跃的事务, 所以当前行稳定数据对新事务可见, 跳到步骤5. 2.trx_id_current &gt;= trx_id_last, 这种情况也比较好理解, 表示, 该行记录的稳定事务id是在本次新事务创建之后才开启的, 但是却在本次新事务执行第二个select前就commit了，所以该行记录的当前值不可见, 跳到步骤4。 3.trx_id_current &lt;= trx_id_current &lt;= trx_id_last, 表示: 该行记录所在事务在本次新事务创建的时候处于活动状态，从up_limit_id到low_limit_id进行遍历，如果trx_id_current等于他们之中的某个事务id的话，那么不可见, 调到步骤4,否则表示可见。 4.从该行记录的 DB_ROLL_PTR 指针所指向的回滚段中取出最新的undo-log的版本号, 将它赋值该 trx_id_current，然后跳到步骤1重新开始判断。 5.将该可见行的值返回。 案例分析 下面是一个非常简版的演示事务对某行记录的更新过程, 当然, InnoDB引擎在内部要做的工作非常多: 下面是一套比较算法的应用过程也可参考https://github.com/zhangyachen/zhangyachen.github.io/issues/68中的案例 当前读和快照读 MySQL的InnoDB存储引擎默认事务隔离级别是RR(可重复读), 是通过 “行排他锁+MVCC” 一起实现的, 不仅可以保证可重复读, 还可以部分防止幻读, 而非完全防止; 为什么是部分防止幻读, 而不是完全防止? 效果: 在如果事务B在事务A执行中, insert了一条数据并提交, 事务A再次查询, 虽然读取的是undo中的旧版本数据(防止了部分幻读), 但是事务A中执行update或者delete都是可以成功的!! 因为在innodb中的操作可以分为当前读(current read)和快照读(snapshot read): 快照读(snapshot read) 简单的select操作(当然不包括 select … lock in share mode, select … for update) 4.当前读(current read) 官网文档 Locking Reads select … lock in share mode select … for update insert update delete在RR级别下，快照读是通过MVVC(多版本控制)和undo log来实现的，当前读是通过加record lock(记录锁)和gap lock(间隙锁)来实现的。innodb在快照读的情况下并没有真正的避免幻读, 但是在当前读的情况下避免了不可重复读和幻读!!! 小结 一般我们认为MVCC有下面几个特点： 每行数据都存在一个版本，每次数据更新时都更新该版本 修改时Copy出当前版本, 然后随意修改，各个事务之间无干扰 保存时比较版本号，如果成功(commit)，则覆盖原记录, 失败则放弃copy(rollback) 就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道, 因为这看起来正是，在提交的时候才能知道到底能否提交成功 而InnoDB实现MVCC的方式是: 事务以排他锁的形式修改原始数据 把修改前的数据存放于undo log，通过回滚指针与主数据关联 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） 二者最本质的区别是: 当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ Innodb的实现真算不上MVCC, 因为并没有实现核心的多版本共存, undo log 中的内容只是串行化的结果, 记录了多个事务的过程, 不属于多版本共存。但理想的MVCC是难以实现的, 当事务仅修改一行记录使用理想的MVCC模式是没有问题的, 可以通过比较版本号进行回滚, 但当事务影响到多行数据时, 理想的MVCC就无能为力了。 比如, 如果事务A执行理想的MVCC, 修改Row1成功, 而修改Row2失败, 此时需要回滚Row1, 但因为Row1没有被锁定, 其数据可能又被事务B所修改, 如果此时回滚Row1的内容，则会破坏事务B的修改结果，导致事务B违反ACID。 这也正是所谓的 第一类更新丢失 的情况。 也正是因为InnoDB使用的MVCC中结合了排他锁, 不是纯的MVCC, 所以第一类更新丢失是不会出现了, 一般说更新丢失都是指第二类丢失更新。 参考1.最初读的一篇文章2.关于read view创建时机: - http://www.sohu.com/a/194511597_610509 - https://www.cnblogs.com/digdeep/p/4947694.html 3.关于比较算法 low_limit_id 高水位事务: - https://github.com/zhangyachen/zhangyachen.github.io/issues/68 - https://www.zhihu.com/question/66320138 4.大咖问答:https://www.zhihu.com/inbox/45776742005.更多可以参考数据库内核月报: https://yq.aliyun.com/articles/303200?spm=5176.100240.searchblog.9.271fd153pQ9FgV6.官方文档","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"http://blog.renyimin.com/tags/MVCC/"}]},{"title":"MySQL(INNODB引擎)高并发事务问题及解决方案","slug":"2017-12-27-mysql_transaction-01","date":"2017-12-27T13:01:07.000Z","updated":"2018-01-04T07:14:14.000Z","comments":true,"path":"2017/12/27/2017-12-27-mysql_transaction-01/","link":"","permalink":"http://blog.renyimin.com/2017/12/27/2017-12-27-mysql_transaction-01/","excerpt":"","text":"事务的概念 事务 可以理解为一个 独立的工作单元, 在这个独立的工作单元中, 有一组操作; 放在事务(独立工作单元)中的多个操作, 要么全部执行成功, 要么全部执行失败。 不免俗套, 这还是通过最经典的银行转账应用来解释一下 假设有两个角色 ‘Iron Man’(余额500), ‘Wolverine’(余额15), 现在 Iron Man 通过该银行应用给 Wolverine 转账100元, 那么本次转账操作至少需要三个步骤: 123检查`Iron Man`余额`&gt;=100`元从`Iron Man`余额中`-100`元给`Wolverine`余额`+100`元 注意: 上面的三个步骤的操作必须打包在一个事务中, 从而可以作为一个 独立的工作单元 来执行。在这个 独立工作单元(即事务) 中的这三个操作, 只要有任何一个操作失败, 则事务就整体就是失败的, 那就必须回滚所有的步骤。 假设第二步操作成功, 但是第三步操作失败, 那么整个事务也就应该是失败的, 那就必须将第二步的操作也回滚。(到这里我们也看到了事务最基本的特性之一: 保证数据的一致性) 要知道, 在真实的高并发场景下, 事务需要做的事情其实很多很多, 因为高并发会出现很多意想不到的问题, 接下来会分析这些问题。 事务的ACID特性在分析高并发事务的问题前, 我们要先知道事务的几个标准特性, 因为一个运行良好的事务处理系统必须具备这些标准特性, 而且这些问题的解决离不开事务的这几个标准特性!!! Atomicity 原子性 一个事务必须被视为一个不可分割的最小工作单元, 整个事务中的所有操作要么全部提交成功, 要么全部失败回滚。对于一个事务来说, 不能只成功执行其中的一部分操作, 这就是事务的原子性。 Consistency 一致性 虽然可数据表中的数据可能一直在变化, 但是事务的一致性特性会保证 数据库总是从一个一致性的状态 转换到 另一个一致性的状态; 比如在之前的转账例子: 123转账前的一致性状态是: &apos;Iron Man&apos;(余额500), &apos;Wolverine&apos;(余额15)转账成功后的一致性状态是: &apos;Iron Man&apos;(余额400), &apos;Wolverine&apos;(余额115)转账如果失败的话, 一致性的状态应该回滚到转账前的状态: &apos;Iron Man&apos;(余额500), &apos;Wolverine&apos;(余额15) Isolation 隔离性 通常来说, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的;比如在之前的转账例子中, 在执行完成第二步, 但是第三步还没开始的时候, 此时有另一个账户汇总的程序开始运行, 那么这个程序所拿到的A账户余额应该是没有被 -100 的余额才对 后面我们还会详细讨论事务隔离性的 隔离级别, 到时候就知道这里为什么说通常来说对其他事务是不可见的; (也就是还有特例, 比如最低隔离级别 READ UNCOMMITTED, 对其他事务的可见就造成了脏读问题的出现) 事务有四种隔离级别(从低到高: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, SERIALIZABLE) Durability 持久性 一旦事务被最终提交, 则在事务这个独立单元中的所有操作所做的修改将会 永久保存到数据库中; (这里所说的永久可以理解为 被事务修改的数据 是真正存放到了表中, 而不是存放在了诸如临时表之类的地方。) 高并发事务的问题在并发量比较大的时候, 很容易出现 多个事务同时进行 的情况。假设有两个事务正在同时进行, 值得注意的是: 它们两者之间是互相不知道对方的存在的, 各自都对自身所处的环境过分乐观, 从而并没有对自己所操作的数据做一定的保护处理, 所以最终导致了一些问题的出现;接下来, 在分析高并发事务的问题时, 你可能已经了解了一些关于锁的概念, 但是在分析这些问题的时候, 先不要带入锁的概念, 本小节只会列出问题, 并直接告诉你各个问题是使用事务隔离性的哪个隔离级别解决掉的, 锁是解决方案, 如果带入锁的概念, 是无法去分析这些问题的。所以本节不需要带入锁!以后将会有文章分析这些解决方案(各隔离级别)具体是如何解决问题的。 脏读 如果mysql中一个事务A读取了另一个并行事务B未最终提交的写数据, 那事务A的这次读取就是脏读。(因为事务A读取的是’脏数据’, 是’非持久性’的数据) 之所以说是’非持久性数据’, ‘脏数据’, 是因为事务B最终可能会因为内部其他后续操作的失败或者系统后续突然崩溃等原因, 导致事务最终整体提交失败, 那么事务A此时读取到的数据在表中其实会被回滚, 那事务A拿到的自然就是脏的数据了。 图示: 事务A在T4阶段读取库存为20, 这个库存其实就属于脏数据, 因为事务B最终会回滚这个数据, 所以如果事务A使用库存20进行后续的操作, 就会引发问题, 因为事务A拿到的数据已经和表中的真实数据不一致了。 那么这个问题如何解决呢? 在MySQL中, 其实事务已经用自身特性（隔离性的 – READ COMMITED或以上隔离级别）解决了这个问题; READ COMMITED级别保证了, 只要是当前语句执行前已经提交的数据都是可见的。注意和REPEATABLE READ级别的区!!! 不可重复读 假设现在上面的 脏读问题 已经被完全解决了, 那就意味着事务中每次读取到的数据都是 持久性 的数据(被别的事务最终 提交/回滚 完成后的数据)。 但是你还需要知道的是: 解决了脏读问题, 只是能保证你在事务中每次读到的数据都是持久性的数据而已!!!! 如果在一个事务中多次读取同一个数据, 正好在两次读取之间, 另外一个事务确实已经完成了对该数据的修改并提交, 那问题就来了: 可能会出现多次读取结果不一致的现象。 那么这个问题如何解决呢? 在MySQL中, 其实事务已经用自身特性（隔离性的 – REPEATABLE READ或以上隔离级别）解决了这个问题; REPEATABLE READ级别保证了, 只要是当前事务执行前已经提交的数据都是可见的。注意和READ COMMITED级别的区!!! 幻读 由于很多人(当然也包括本人), 容易搞混 不可重复读 和 幻读, 这两者确实非常相似。 但 不可重复读 主要是说多次读取一条记录, 发现该记录中某些列值被修改过。 而 幻读 主要是说多次读取一个范围内的记录(包括直接查询所有记录结果或者做聚合统计), 发现结果不一致(标准档案一般指记录增多, 记录的减少应该也算是幻读)。(可以参考MySQL官方文档对 Phantom Rows 的介绍) 其实对于 幻读, MySQL的InnoDB引擎默认的RR级别已经通过MVCC自动帮我们解决了, 所以该级别下, 你也模拟不出幻读的场景; 退回到 RC 隔离级别的话, 你又容易把幻读和不可重复读搞混淆, 所以这可能就是比较头痛的点吧! 具体可以参考《高性能MySQL》对 RR 隔离级别的描述, 理论上RR级别是无法解决幻读的问题, 但是由于InnoDB引擎的RR级别还使用了MVCC, 所以也就避免了幻读的出现! 幻读的延伸MVCC虽然解决了幻读问题, 但仍然存在一个比较奇葩的问题; 接下来进行演示: 打开客户端1查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 打开客户端2查看隔离级别及初始数据 12345678910111213141516171819mysql&gt; SELECT @@SESSION.tx_isolation;+------------------------+| @@SESSION.tx_isolation |+------------------------+| REPEATABLE-READ |+------------------------+1 row in set (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端2中开启事务, 然后查询数据 1234567891011121314mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec) mysql&gt; 在客户端1中插入一条id为4的新数据 (直接自动提交) 1234567891011121314mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 || 4 | 死侍 | 18 | 0 | A bad boy |+----+-----------+-----+--------+--------------------+4 rows in set (0.00 sec) mysql&gt; 在客户端2事务中再次查询数据, 发现数据没有变化(表示可以重复读, 并且克服了幻读)!! 但是在客户端2事务中插入一条id为4的新数据, 发现提示数据已经存在!!! 12345678910111213141516171819202122232425262728mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; select * from test_transaction;+----+-----------+-----+--------+--------------------+| id | user_name | age | gender | desctiption |+----+-----------+-----+--------+--------------------+| 1 | 金刚狼 | 127 | 1 | 我有一双铁爪 || 2 | 钢铁侠 | 120 | 1 | 我有一身铁甲 || 3 | 绿巨人 | 0 | 2 | 我有一身肉 |+----+-----------+-----+--------+--------------------+3 rows in set (0.00 sec)mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);1062 - Duplicate entry &apos;4&apos; for key &apos;PRIMARY&apos;mysql&gt; //并且, 此时`update/delete`也是可以操作这条在事务中看不到的记录的! 那么这是什么问题呢? 可以参考MySQL官方文档 – 一致性非阻塞读 The snapshot of the database state applies to SELECT statements within a transaction, not necessarily to DML statements. If you insert or modify some rows and then commit that transaction, a DELETE or UPDATE statement issued from another concurrent REPEATABLE READ transaction could affect those just-committed rows, even though the session could not query them. If a transaction does update or delete rows committed by a different transaction, those changes do become visible to the current transaction.个人认为应该翻译为: 数据库状态的快照适用于事务中的SELECT语句, 而不一定适用于所有DML语句。 如果您插入或修改某些行, 然后提交该事务, 则从另一个并发REPEATABLE READ事务发出的DELETE或UPDATE语句就可能会影响那些刚刚提交的行, 即使该事务无法查询它们。 如果事务更新或删除由不同事务提交的行, 则这些更改对当前事务变得可见。 因此不少资料将MVCC并发控制中的读操作分成两类: 快照读 (snapshot read) 与 当前读 (current read)。 快照读, 读取专门的快照 (对于RC，快照（ReadView）会在每个语句中创建。对于RR，快照是在事务启动时创建的) 1简单的select操作即可(不需要加锁,如: select ... lock in share mode, select ... for update) 针对的也是select操作 当前读, 读取最新版本的记录, 没有快照。 在InnoDB中，当前读取根本不会创建任何快照。 12select ... lock in share modeselect ... for update 针对如下操作, 会让如下操作阻塞: 123insertupdatedelete 在RR级别下, 快照读是通过MVVC(多版本控制)和undo log来实现的, 当前读是通过手动加record lock(记录锁)和gap lock(间隙锁)来实现的。所以从上面的显示来看，如果需要实时显示数据，还是需要通过加锁来实现。这个时候会使用next-key技术来实现。 当然, 使用隔离性的最高隔离级别SERIALIZABLE也可以解决幻读, 但该隔离级别在实际中很少使用! 更新丢失 最后聊一下高并发事务的另一个问题 – 丢失更新问题, 该问题和之前几个问题需要区分开, 因为解决方案不是一类! 第一类丢失更新: A事务撤销时, 把已经提交的B事务的更新数据覆盖了。 不过, 通过后面MVCC相关文章最后的小结你会了解到, 这类更新丢失问题是不会出现的, 因为InnoDB存储引擎的隔离级别都使用了排他锁, 即使是 MVCC也不是纯MVCC, 也用到了排他锁! 这样的话事务A在未完成的时候, 其他事务是无法对事务A涉及到的数据做修改并提交的。 第二类丢失更新: A事务覆盖B事务已经提交的数据，造成B事务所做操作丢失。 此类更新丢失问题, 无法依靠前三种隔离级别来解决, 只能用最高隔离级别 Serializable 或者手动使用乐观锁, 悲观锁来解决。 当然, 更新操作不是在所有情况下都会导致丢失更新问题, 如果你更改的最终状态是确定的, 而不是类似递减或者递增, 那是不会造成丢失更新问题的!! 最高隔离级别Serializable在实际应用场景中并不被采用, 对于手动使用乐观锁, 悲观锁的方案, 将会在以后关于锁的文章中一并给出! 参考资料: 淘宝数据库内核6月报 《高性能MySQL》 美团技术博客 MySQL官方文档","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.renyimin.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://blog.renyimin.com/tags/事务/"}]}]}