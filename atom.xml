<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lant&#39;s</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.renyimin.com/"/>
  <updated>2018-09-08T02:50:38.000Z</updated>
  <id>http://blog.renyimin.com/</id>
  
  <author>
    <name>Lant</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>03.</title>
    <link href="http://blog.renyimin.com/2018/09/08/elastic-stack/2018-09-08-03/"/>
    <id>http://blog.renyimin.com/2018/09/08/elastic-stack/2018-09-08-03/</id>
    <published>2018-09-08T02:50:15.000Z</published>
    <updated>2018-09-08T02:50:38.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Elastic-Stack" scheme="http://blog.renyimin.com/categories/Elastic-Stack/"/>
    
    
      <category term="Elastic-Stack" scheme="http://blog.renyimin.com/tags/Elastic-Stack/"/>
    
  </entry>
  
  <entry>
    <title>02. 安装配置</title>
    <link href="http://blog.renyimin.com/2018/09/08/elastic-stack/2018-09-08-02/"/>
    <id>http://blog.renyimin.com/2018/09/08/elastic-stack/2018-09-08-02/</id>
    <published>2018-09-08T02:46:43.000Z</published>
    <updated>2018-09-08T02:50:44.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装Elasticsearch"><a href="#安装Elasticsearch" class="headerlink" title="安装Elasticsearch"></a><a href="">安装Elasticsearch</a></h2><h2 id="安装Kibana"><a href="#安装Kibana" class="headerlink" title="安装Kibana"></a><a href="">安装Kibana</a></h2><h2 id="安装Logstash"><a href="#安装Logstash" class="headerlink" title="安装Logstash"></a><a href="">安装Logstash</a></h2><h2 id="安装Filebeat"><a href="#安装Filebeat" class="headerlink" title="安装Filebeat"></a><a href="">安装Filebeat</a></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装Elasticsearch&quot;&gt;&lt;a href=&quot;#安装Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;安装Elasticsearch&quot;&gt;&lt;/a&gt;&lt;a href=&quot;&quot;&gt;安装Elasticsearch&lt;/a&gt;&lt;/h2&gt;&lt;h2 id
      
    
    </summary>
    
      <category term="Elastic-Stack" scheme="http://blog.renyimin.com/categories/Elastic-Stack/"/>
    
    
      <category term="Elastic-Stack" scheme="http://blog.renyimin.com/tags/Elastic-Stack/"/>
    
  </entry>
  
  <entry>
    <title>01. 从ELK Stack 到 Elastic Stack</title>
    <link href="http://blog.renyimin.com/2018/09/04/elastic-stack/2018-09-04-01/"/>
    <id>http://blog.renyimin.com/2018/09/04/elastic-stack/2018-09-04-01/</id>
    <published>2018-09-04T09:36:39.000Z</published>
    <updated>2018-09-08T02:47:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ELK-Stack-简介"><a href="#ELK-Stack-简介" class="headerlink" title="ELK Stack 简介"></a>ELK Stack 简介</h2><p>ELK Stack 是三个开源工具的统称: Elasticsearch, Logstash 和 Kibana</p><ol><li><p><strong><a href="">Logstash</a></strong>: 开源的日志收集工具, 能按你所定义的配置信息来规范化数据, 并根据需要将其他送到指定的目的地; (监听9600端口)</p><ul><li>拥有非常多的Input输入数据类型的插件, 这些Input插件可以用于从大量不同来源的信息中读取数据;</li><li>同时, 它也拥有非常多的Output输出数据类型插件, 可用于把数据提交到各种不同的目的地(其中的一种插件就是把数据传输到Elasticsearch中去);<br>比如, 它可以从本地磁盘, 网络服务(自己监听端口, 接受用户日志), 消息队列……中, 收集各种各样的日志; 然后对日志进行分析整理, 输出到指定的输出(如 elasticsearch、redis、终端等);</li><li>它能帮助我们搜集原始数据, 修改/过滤数据并将其转换成某种有含义的数据, 完成数据格式化和重新组织数据等;</li></ul></li><li><p><strong><a href="">Elasticsearch</a></strong>: 基于Lucene的开源分布式全文搜索引擎; Elasticsearch 服务会开启两个端口 9200和9300, 9200是对外服务的 9300是对集群内交互使用的;<br> Logstash读取的数据可输出到Elasticsearch中, 完成数据的索引; </p></li><li><p><strong><a href="">Kibana</a></strong>: 是一个开源的可视化日志web展示工具, 提供友好的日志分析 Web 界面, 帮助你汇总、分析和搜索重要数据日志 (监听 5601 端口);<br> Kibana使用Elasticsearch提供的API来读取/检索存放在Elasticsearch中的索引数据, 并以图表等形式对这些数据进行可视化分析;</p></li></ol><h2 id="Elastic-Stack诞生"><a href="#Elastic-Stack诞生" class="headerlink" title="Elastic Stack诞生"></a><a href="https://www.elastic.co/elk-stack" target="_blank" rel="noopener">Elastic Stack</a>诞生</h2><ol><li><p>上面在介绍 ELK Stack 时提到, 所有读取数据的工作都是由 Logstash 来完成的, 但是这是一种资源消耗, 因为 Logstash 需要运行在Java虚拟机上, 会消耗大量内存; 因此, 软件研发社区认为需要提高其性能, 并使用管道(pipeline)处理机制 — 一种友好且轻量级的方式来处理资源;</p></li><li><p>因此, 一种新的概念 <strong><a href="">Beats</a></strong> 诞生, 并加入到了 ELK Stack 家族成为重要组件(Beats 是由 GO 语言编写的)<br> Beats 用于读取、解析并将数据输出到 Elasticsearch 或 Logstash 中; 不同的是, 它是一种轻量级的, 服务于某种特殊用途的代理(它可以是Metricbeat/Filebeat/Packetbeat等), 它们都是由Elastic开发团队提供;</p></li><li><p>Elastic Stack 的起始版本号是5.0.0, 其虽然是原 ELK Stack 在 5.0 版本加入 Beats 套件后的新称呼, 但其实涵盖的内容还不止这些; 在产生数据管道的作用中, 所有组件都发挥了重要作用:</p><ul><li>Beats 和 Logstash 用于搜索, 解析, 传输数据;</li><li>Elasticsearch 负责对数据的索引; </li><li>Elasticsearch 索引的数据, 最后会被 Kibana 用于数据的可视化;</li><li>在基于 Elastic Stack 的数据处理管道中, 还有诸如 安全, 监控, 报警 等方面需要特别关注, 这些工具组件现在统称为 <strong><a href="">X-Pack</a></strong></li></ul></li></ol><p>参考:《精通Elastic Stack》</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;ELK-Stack-简介&quot;&gt;&lt;a href=&quot;#ELK-Stack-简介&quot; class=&quot;headerlink&quot; title=&quot;ELK Stack 简介&quot;&gt;&lt;/a&gt;ELK Stack 简介&lt;/h2&gt;&lt;p&gt;ELK Stack 是三个开源工具的统称: Elastics
      
    
    </summary>
    
      <category term="Elastic-Stack" scheme="http://blog.renyimin.com/categories/Elastic-Stack/"/>
    
    
      <category term="Elastic-Stack" scheme="http://blog.renyimin.com/tags/Elastic-Stack/"/>
    
  </entry>
  
  <entry>
    <title>07. 请求体查询, 查询与过滤, 查询条件的组合</title>
    <link href="http://blog.renyimin.com/2018/06/30/elasticsearch/2018-06-30-07/"/>
    <id>http://blog.renyimin.com/2018/06/30/elasticsearch/2018-06-30-07/</id>
    <published>2018-06-30T03:07:21.000Z</published>
    <updated>2018-09-27T08:28:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="请求体查询"><a href="#请求体查询" class="headerlink" title="请求体查询"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/full-body-search.html" target="_blank" rel="noopener">请求体查询</a></h2><ol><li><p>简易查询(query-string search) 对于用命令行进行即席查询是非常有用的; 然而, 为了充分利用查询的强大功能, 你应该使用 <strong>请求体 search API</strong>, 之所以称之为请求体查询(Full-Body Search), 因为大部分参数是通过 <strong>Http 请求体</strong>而非查询字符串来传递的;</p></li><li><p><strong>请求体查询</strong>不仅可以处理自身的查询请求, 还允许你对结果进行片段强调(高亮)、对所有或部分结果进行聚合分析, 同时还可以给出 你是不是想找 的建议, 这些建议可以引导使用者快速找到他想要的结果;</p></li><li><p>相对于使用晦涩难懂的查询字符串的方式, 一个带请求体的查询允许我们使用 <strong>查询领域特定语言（query domain-specific language）</strong> 或者 <strong>Query DSL</strong> 来写查询语句;</p></li></ol><h2 id="查询表达式"><a href="#查询表达式" class="headerlink" title="查询表达式"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/query-dsl-intro.html" target="_blank" rel="noopener">查询表达式</a></h2><ol><li><p>查询表达式(Query DSL)是一种非常灵活又富有表现力的查询语言, Elasticsearch 使用它可以以简单的 JSON 接口来展现 Lucene 功能的绝大部分功能。在你的应用中, <strong>你应该用它来编写你的查询语句</strong>, 它可以使你的查询语句更灵活、更精确、易读和易调试;</p></li><li><p>要使用这种查询表达式, 只需将查询语句传递给请求体中的 <strong>query 参数</strong>:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: YOUR_QUERY_HERE</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>空查询(empty search) 在功能上其实就等价于使用 <code>match_all</code> 查询, 正如其名字一样, 匹配所有文档:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">   &quot;query&quot;: &#123;</span><br><span class="line">       &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="查询与过滤"><a href="#查询与过滤" class="headerlink" title="查询与过滤"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_queries_and_filters.html" target="_blank" rel="noopener">查询与过滤</a></h2><ol><li><p>Elasticsearch 使用的查询语言(DSL) 拥有一套<strong>查询组件</strong>, 这些组件可以以无限组合的方式进行搭配; 这套组件可以在以下两种情况下使用</p><ul><li>过滤情况（filtering context）: 当使用于 过滤情况 时, 查询被设置成一个 <strong>不评分</strong> 的查询, 即, 查询结果只是简单的是或否, 不会计算任何评分;</li><li>查询情况（query context） : 当使用于 查询情况 时, 查询就变成了一个 <strong>评分</strong> 查询, 它不但会去判断这个文档是否匹配， 同时它还需要判断这个文档匹配的有 <strong>多好</strong>（匹配程度如何）;<br>一个评分查询计算每一个文档与此查询的 _相关程度_，同时将这个相关程度分配给表示相关性的字段 <code>_score</code>，并且按照相关性对匹配到的文档进行排序。<br>这种相关性的概念是非常适合全文搜索的情况，因为全文搜索几乎没有完全 “正确” 的答案</li></ul></li><li><p>如何选择查询与过滤: 通常的规则是, 使用 查询（query）语句来进行 全文搜索或者其它任何需要影响相关性得分的搜索; 除此以外的情况都使用过滤（filters);</p></li></ol><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_most_important_queries.html#_match_all_查询" target="_blank" rel="noopener">查询</a></h2><ol><li><p>虽然 Elasticsearch 自带了很多的查询, 但经常用到的也就那么几个 </p><ul><li><code>match_all</code> 简单的匹配所有文档, 在没有指定查询方式时(即查询体为空时), 它是默认的查询</li><li><code>match</code> 无论你在任何字段上进行的是全文搜索还是精确查询, match 查询都是你可用的标准查询<br>如果你在一个全文字段上使用 match 查询，在执行查询前，它将用正确的分析器去分析查询字符串<br>如果在一个精确值的字段上使用它， 例如数字、日期、布尔或者一个 not_analyzed 字符串字段，那么它将会精确匹配给定的值</li><li>不过, 对于精确值的查询，你可能需要使用 <code>filter</code> 过滤语句来取代查询语句，因为 filter 将会被缓存</li><li><code>multi_match</code> 查询可以在多个字段上执行相同的 match 查询</li><li><p><code>range</code> 查询找出那些落在指定区间内的数字或者时间</p></li><li><p><code>term</code> 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串<br>term 查询对于输入的文本<strong>不分析</strong>, 所以它将给定的值进行精确查询</p></li><li><code>terms</code> 查询和 <code>term</code> 查询一样, 但它允许你指定多值进行匹配, 如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件<br>和 term 查询一样，terms 查询对于输入的文本不分析。它查询那些精确匹配的值（包括在大小写、重音、空格等方面的差异）。</li><li><p>需要注意的是: term 和 terms 是不会对输入文本进行分析, 如果你的搜索如下<br>虽然索引中存在 first_name 为 John 的文档, 但是由于该字段是全文域, 分词后可能就是 john, 而使用 terms 或者 term 的话, 由于不会对查询语句中的’John’进行分词, 所以它去匹配分词后的’John’的话, 实际上就是去匹配’john’, 由于大小写不匹配, 所以查询不到结果; 如果查询改为john反而却能匹配到</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;terms&quot; : &#123;</span><br><span class="line">     &quot;first_name&quot; : [&quot;John&quot;]  </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>exists 查询和 missing 查询被用于查找某个字段是否存在, 与SQL中的 IS_NULL (missing) 和 NOT IS_NULL (exists) 在本质上具有共性;<br>注意: 字段存在和字段值为””不是一个概念, 在ES中如果要匹配一个空字符串的字段, 貌似网上查找该方法的帖子不少, 但都没有好的答案;</p></li></ul></li><li><p>这些查询方法都是在 HTTP请求体中作为 <strong>query参数</strong> 来使用的;</p></li></ol><h2 id="组合多查询"><a href="#组合多查询" class="headerlink" title="组合多查询"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/combining-queries-together.html" target="_blank" rel="noopener">组合多查询</a></h2><ol><li><p>现实的查询需求通常需要在多个字段上查询多种多样的文本, 并且根据一系列的标准来过滤; 为了构建类似的高级查询, 你需要一种能够将多查询组合成单一查询的查询方法; 可以用 <strong>bool查询</strong> 来实现需求; bool查询将多查询组合在一起, 成为用户自己想要的布尔查询, 它接收以下参数:</p><ul><li>must : 文档 必须 匹配这些条件才能被包含进来</li><li>must_not : 文档 必须不 匹配这些条件才能被包含进来</li><li>should : 如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分</li><li><p>上面的每一个子查询都独自地计算文档的相关性得分。一旦他们的得分被计算出来， bool 查询就将这些得分进行合并并且返回一个代表整个布尔操作的得分。</p></li><li><p>filter(带过滤器的查询) : 必须 匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档</p></li></ul></li><li><p>例子1: <strong>should只是针对结果进行加分</strong>, 并不会决定是否有匹配结果;</p><ul><li>只有must和must_not中的子句是决定了是否能查询出数据;</li><li>而should只是在针对查询出的数据, 如果对还能满足should子句的文档增加额外的评分; (如果非should的语句不能查询出结果, 即便should可以匹配到文档, 整体查询最终也不会有匹配结果)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">DELETE /test/</span><br><span class="line">PUT /test/cardealer/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;record_type&quot; : &quot;c2b_car_action&quot;,</span><br><span class="line">  &quot;action_point&quot; : &quot;affirm_deal_tinspection&quot;,</span><br><span class="line">  &quot;action_time&quot; : &quot;2018-09-27 10:13:40&quot;,</span><br><span class="line">  &quot;action_operator&quot; : 91,</span><br><span class="line">  &quot;action_operator_name&quot; : &quot;王玥91&quot;,</span><br><span class="line">  &quot;action_target&quot; : 206425533,</span><br><span class="line">  &quot;action_note&quot; : &quot;确认成交：竞拍成功，车辆状态：待验车&quot;</span><br><span class="line">&#125;</span><br><span class="line">PUT /test/cardealer/2</span><br><span class="line">&#123;</span><br><span class="line">  &quot;record_type&quot; : &quot;c2b_car_action&quot;,</span><br><span class="line">  &quot;action_point&quot; : &quot;affirm_deal_tinspection&quot;,</span><br><span class="line">  &quot;action_time&quot; : &quot;2018-09-27 10:13:40&quot;,</span><br><span class="line">  &quot;action_operator&quot; : 91,</span><br><span class="line">  &quot;action_operator_name&quot; : &quot;王玥91&quot;,</span><br><span class="line">  &quot;action_target&quot; : 200,</span><br><span class="line">  &quot;action_note&quot; : &quot;确认成交：竞拍成功，车辆状态：待验车&quot;</span><br><span class="line">&#125;</span><br><span class="line">PUT /test/cardealer/3</span><br><span class="line">&#123;</span><br><span class="line">  &quot;record_type&quot; : &quot;c2b_car_action&quot;,</span><br><span class="line">  &quot;action_point&quot; : &quot;affirm_deal_tinspection&quot;,</span><br><span class="line">  &quot;action_time&quot; : &quot;2018-09-27 10:13:40&quot;,</span><br><span class="line">  &quot;action_operator&quot; : 42,</span><br><span class="line">  &quot;action_operator_name&quot; : &quot;王玥42&quot;,</span><br><span class="line">  &quot;action_target&quot; : 301,</span><br><span class="line">  &quot;action_note&quot; : &quot;确认成交：竞拍成功，车辆状态：待验车&quot;</span><br><span class="line">&#125;</span><br><span class="line">PUT /test/cardealer/4</span><br><span class="line">&#123;</span><br><span class="line">  &quot;record_type&quot; : &quot;c2b_car_action&quot;,</span><br><span class="line">  &quot;action_point&quot; : &quot;affirm_deal_tinspection&quot;,</span><br><span class="line">  &quot;action_time&quot; : &quot;2018-09-27 10:13:40&quot;,</span><br><span class="line">  &quot;action_operator&quot; : 42,</span><br><span class="line">  &quot;action_operator_name&quot; : &quot;王玥42&quot;,</span><br><span class="line">  &quot;action_target&quot; : 200,</span><br><span class="line">  &quot;action_note&quot; : &quot;确认成交：竞拍成功，车辆状态：待验车&quot;</span><br><span class="line">&#125;</span><br><span class="line">PUT /test/cardealer/5</span><br><span class="line">&#123;</span><br><span class="line">  &quot;record_type&quot; : &quot;c2b_car_action&quot;,</span><br><span class="line">  &quot;action_point&quot; : &quot;abortive_married_deal&quot;,</span><br><span class="line">  &quot;action_time&quot; : &quot;2018-08-22 17:11:53&quot;,</span><br><span class="line">  &quot;action_note&quot; : &quot;撮合失败，系统自动流拍，车辆状态：销售失败&quot;,</span><br><span class="line">  &quot;action_target&quot; : 600,</span><br><span class="line">  &quot;action_operator&quot; : 83,</span><br><span class="line">  &quot;action_operator_name&quot; : &quot;王玥83&quot;</span><br><span class="line">&#125;</span><br><span class="line">GET /test/cardealer/_search</span><br><span class="line">GET /test/cardealer/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot; : &#123;</span><br><span class="line">    &quot;bool&quot; : &#123;</span><br><span class="line">      &quot;must&quot; : &#123; </span><br><span class="line">        &quot;match&quot; : &#123;&quot;record_type&quot; : &quot;c2b_car_action&quot;&#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;must_not&quot; : &#123; </span><br><span class="line">        &quot;match&quot; : &#123;&quot;action_point&quot; : &quot;abortive_married_deal&quot;&#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;should&quot; : [</span><br><span class="line">        &#123;&quot;match&quot; : &#123;&quot;action_operator&quot; : 42&#125;&#125;,</span><br><span class="line">        &#123;&quot;match&quot; : &#123;&quot;action_target&quot; : 200&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>例2: 如果不想因为某个字段的匹配而增加评分, 可以将该匹配放在 filter 过滤语句中; </p><ul><li>当然, filter 子句 和 查询子句 都决定了是否有匹配结果, 这是它两 和 should 子句的不同之处;</li><li><p>如下可以看到 filter 过滤子句 和 查询子句的 区别, 虽然结果一样, 但是结果的评分有差异</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 查询语句</span><br><span class="line">GET /test/cardealer/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot; : &#123;</span><br><span class="line">    &quot;bool&quot; : &#123;</span><br><span class="line">      &quot;must&quot; : [ </span><br><span class="line">        &#123;&quot;match&quot; : &#123;&quot;record_type&quot; : &quot;c2b_car_action&quot;&#125;&#125;,</span><br><span class="line">        &#123;&quot;match&quot; : &#123; &quot;action_operator&quot; : 42 &#125; &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;must_not&quot; : [ </span><br><span class="line">        &#123;&quot;match&quot; : &#123;&quot;action_point&quot; : &quot;abortive_married_deal&quot;&#125;&#125;,</span><br><span class="line">        &#123;&quot;match&quot; : &#123;&quot;action_target&quot; : 200&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 过滤语句</span><br><span class="line">GET /test/cardealer/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot; : &#123;</span><br><span class="line">    &quot;bool&quot; : &#123;</span><br><span class="line">      &quot;must&quot; : &#123; </span><br><span class="line">        &quot;match&quot; : &#123;&quot;record_type&quot; : &quot;c2b_car_action&quot;&#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;must_not&quot; : &#123; </span><br><span class="line">        &quot;match&quot; : &#123;&quot;action_point&quot; : &quot;abortive_married_deal&quot;&#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;filter&quot; : [</span><br><span class="line">        &#123;&quot;match&quot; : &#123;&quot;action_operator&quot; : 42&#125;&#125;,</span><br><span class="line">        &#123;&quot;match&quot; : &#123;&quot;action_target&quot; : 200&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>将 bool 查询包裹在 filter 语句中, 还可以在过滤标准中增加布尔逻辑</p></li></ul></li><li><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/combining-queries-together.html#constant_score-query" target="_blank" rel="noopener">constant_score 查询</a>   </p></li></ol><h2 id="AND-a-OR-b-型"><a href="#AND-a-OR-b-型" class="headerlink" title="AND (a OR b) 型"></a>AND (a OR b) 型</h2><ol><li><p>传统SQL经常会有如下形式的查询条件组合</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT ...</span><br><span class="line">FROM   ...</span><br><span class="line">WHERE  ...      = &quot;...&quot;</span><br><span class="line">  AND (     ... = &quot;...&quot;</span><br><span class="line">       OR ... = &quot;...&quot; )</span><br></pre></td></tr></table></figure></li><li><p>es 中写法如下 (下面展示了用 查询语句 和 过滤语句两种写法)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">GET /test/cardealer/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot; : &#123;</span><br><span class="line">    &quot;bool&quot; : &#123;</span><br><span class="line">       &quot;must&quot; : &#123;   # 不带评分的过滤查询写法只用把这里换成 filter</span><br><span class="line">          &quot;bool&quot; : &#123;</span><br><span class="line">            &quot;must&quot; : [</span><br><span class="line">              &#123; &quot;match&quot; : &#123;&quot;record_type&quot; : &quot;c2b_car_action&quot;&#125;&#125;, </span><br><span class="line">              &#123; &quot;bool&quot; : &#123; </span><br><span class="line">                &quot;should&quot; : [</span><br><span class="line">                  &#123; &quot;match&quot; : &#123;&quot;action_point&quot; : &quot;abortive_married_deal1&quot;&#125;&#125;, </span><br><span class="line">                  &#123; &quot;term&quot; : &#123;&quot;action_target&quot; : 600&#125;&#125; </span><br><span class="line">                ]</span><br><span class="line">              &#125;&#125;</span><br><span class="line">            ]</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="a-OR-a-AND-c-型"><a href="#a-OR-a-AND-c-型" class="headerlink" title="a OR (a AND c) 型"></a>a OR (a AND c) 型</h2><ol><li><p>传统SQL经常会有如下形式的查询条件组合</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT ...</span><br><span class="line">    FROM   ...</span><br><span class="line">    WHERE  ... = &quot;...&quot;</span><br><span class="line">      OR (     ... = &quot;...&quot;</span><br><span class="line">           AND ... = &quot;...&quot; )</span><br></pre></td></tr></table></figure></li><li><p>es 中写法如下 (下面展示了用 查询语句 和 过滤语句两种写法)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">GET /test/cardealer/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot; : &#123;</span><br><span class="line">    &quot;bool&quot; : &#123;</span><br><span class="line">       &quot;must&quot; : &#123;   # 不带评分的过滤查询写法只用把这里换成 filter</span><br><span class="line">          &quot;bool&quot; : &#123;</span><br><span class="line">            &quot;should&quot; : [</span><br><span class="line">              &#123; &quot;match&quot; : &#123;&quot;record_type&quot; : &quot;c2b_car_action&quot;&#125;&#125;, </span><br><span class="line">              &#123; &quot;bool&quot; : &#123; </span><br><span class="line">                &quot;must&quot; : [</span><br><span class="line">                  &#123; &quot;match&quot; : &#123;&quot;action_point&quot; : &quot;abortive_married_deal&quot;&#125;&#125;, </span><br><span class="line">                  &#123; &quot;term&quot; : &#123;&quot;action_target&quot; : 200&#125;&#125; </span><br><span class="line">                ]</span><br><span class="line">              &#125;&#125;</span><br><span class="line">            ]</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;请求体查询&quot;&gt;&lt;a href=&quot;#请求体查询&quot; class=&quot;headerlink&quot; title=&quot;请求体查询&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/cn/full-bo
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>06. 搜索相关</title>
    <link href="http://blog.renyimin.com/2018/06/16/elasticsearch/2018-06-16-06/"/>
    <id>http://blog.renyimin.com/2018/06/16/elasticsearch/2018-06-16-06/</id>
    <published>2018-06-16T09:20:09.000Z</published>
    <updated>2018-09-25T08:42:14.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="多索引-多类型-多字段"><a href="#多索引-多类型-多字段" class="headerlink" title="多索引, 多类型, 多字段"></a>多索引, 多类型, 多字段</h2><h2 id="分页"><a href="#分页" class="headerlink" title="分页"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/pagination.html" target="_blank" rel="noopener">分页</a></h2><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;多索引-多类型-多字段&quot;&gt;&lt;a href=&quot;#多索引-多类型-多字段&quot; class=&quot;headerlink&quot; title=&quot;多索引, 多类型, 多字段&quot;&gt;&lt;/a&gt;多索引, 多类型, 多字段&lt;/h2&gt;&lt;h2 id=&quot;分页&quot;&gt;&lt;a href=&quot;#分页&quot; class=&quot;
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>05. Mapping 映射</title>
    <link href="http://blog.renyimin.com/2018/06/16/elasticsearch/2018-06-16-05/"/>
    <id>http://blog.renyimin.com/2018/06/16/elasticsearch/2018-06-16-05/</id>
    <published>2018-06-16T02:31:39.000Z</published>
    <updated>2018-09-26T09:20:52.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一个奇怪的例子"><a href="#一个奇怪的例子" class="headerlink" title="一个奇怪的例子"></a>一个奇怪的例子</h2><ol><li><p>先索引两个文档到不同的索引中 (为什么不在同一个映射中创建两个文档? 或者在同一个映射中的不同类型中各自创建一个文档?):</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DELETE /test/</span><br><span class="line">PUT /test/mapping/1</span><br><span class="line">&#123;</span><br><span class="line"> &quot;title&quot;: &quot;first time to build my mapping&quot;,</span><br><span class="line"> &quot;text&quot;:  &quot;2015/12/21 18:30:25&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DELETE /test1/</span><br><span class="line">PUT /test1/mapping/1</span><br><span class="line">&#123;</span><br><span class="line"> &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line"> &quot;text&quot;:  &quot;build my mapping at 2015-12-28 13:20:25&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>尝试如下查询:</p><ul><li><code>GET /_search?q=2015</code> 结果是两个文档, 因为 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/search-lite.html#all-field-intro" target="_blank" rel="noopener">_all</a> 字段:<br>当索引一个文档的时候, Elasticsearch 会取出所有字段的值拼接成一个大的字符串, 作为 <code>_all</code> 字段进行索引;<br>之后在查询时, 如果不指定字段, 则默认会去 <code>_all</code> 字段中进行查询</li><li><code>GET /_search?q=text:2015</code> 结果只有第二个索引中的文档<br>ES在索引文档时, 如果不手动设置索引的 mapping 映射来说明索引中文档的字段类型, ES会动态帮你生成一份 mapping (ES会根据字段值猜测字段的类型), 主要是想对文档的全文域进行分析以用来创建<code>倒排索引</code>;(做<strong>全文索引</strong>)<br>当你进行搜索时, 如果指明字段, ES会根据字段类型来决定该字段是否进行全文分析, 由于第二篇文档的text是全文类型, 所以会进行全文分析, 会查询到;<br>而第一篇文档在最初进行索引时, ES将其text字段识别为 DATE 类型, 而查询时, 当你指明查询 text 字段时, ES并不会对DATE类型字段做分析, 所以检索不到第二篇文档;</li></ul></li><li><p>所以 date 字段和 string 字段 索引方式不同, 因此搜索结果也不一样; 他们最大的差异在于 代表精确值的字段 和 代表全文的字段</p><ul><li>当你查询一个 全文 域时， 会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。</li><li>当你查询一个 精确值 域时，不会分析查询字符串， 而是搜索你指定的精确值。</li></ul></li><li><p>在实际开发中, 开发者比ES更了解自己的文档信息, 很多时候都需要自行说明自己的字段类型, 以防止ES动态创建映射可能会造成的一些小问题;</p></li></ol><h2 id="Mapping映射"><a href="#Mapping映射" class="headerlink" title="Mapping映射"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/mapping-intro.html" target="_blank" rel="noopener">Mapping映射</a></h2><ol><li><p>为了能够将时间域视为时间, 数字域视为数字, 字符串域视为全文或精确值字符串, Elasticsearch 需要知道每个域中数据的类型, 这些信息就包含在映射中;</p><ul><li>索引中每个文档都有 类型, 每种类型都有它自己的 映射; </li><li>映射定义了类型中每个域的数据类型, 以及Elasticsearch如何处理这些域。映射也用于配置与类型有关的元数据。</li></ul></li><li><p>也就是说, 映射是类型的, 但事实上, 即使在不同的类型中, 也不能对相同字段做不同的类型指定; 参考<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/mapping.html" target="_blank" rel="noopener">类型和映射</a></p><ul><li>只能在不同的索引中对相同的字段设定不同的类型;</li><li>所以文章开头的实验, 要创建两个 包含不同类型text字段 的文档, 需要在不同的索引中进行创建! </li></ul></li><li><p>查看映射, 之前已经使用过 <code>GET /索引名/_mapping/类型名</code></p></li></ol><h2 id="自定义域映射"><a href="#自定义域映射" class="headerlink" title="自定义域映射"></a>自定义域映射</h2><ol><li><p>自定义映射允许你执行下面的操作:</p><ul><li>全文字符串域 和 精确值字符串域 的区别</li><li>使用特定语言分析器</li><li>优化域以适应部分匹配</li><li>指定自定义数据格式</li><li>还有更多</li><li>域最重要的属性就是 <strong>type</strong></li></ul></li><li><p>ELasticsearch 5.X 之后的字段类型不再支持 <code>string</code>, 由 <code>text</code> 或 <code>keyword</code> 取代; </p><ul><li><p><strong>text</strong> 取代了 string: 当一个字段是要被全文搜索的, 比如Email内容、产品描述, 应该使用text类型<br>它们的值在索引前，会通过 一个分析器, 在生成倒排索引以前, 字段内容会被分析器分成一个一个词项, 针对于这个域的查询在搜索前也会经过一个分析器;<br>text类型的字段不用于排序, 很少用于聚合(termsAggregation除外)</p></li><li><p>映射中的每个 <code>text</code> 字段都可以指定自己的分析器 analyzer;<br>在索引时, 如果未指定分析器, 它将在索引设置中查找名为 <code>default</code> analyzer; 否则, 它默认使用 <code>standard</code> analyzer;<br>可参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html#_search_time_analysis" target="_blank" rel="noopener">文档</a></p></li><li><p><strong>keyword类型</strong>: 适用于索引结构化的字段, 比如email地址、主机名、状态码和标签, 如果字段需要进行过滤(比如查找已发布博客中status属性为published的文章)、排序、聚合; keyword类型的字段只能通过精确值搜索到;</p></li></ul></li><li><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/mapping-intro.html" target="_blank" rel="noopener">更新映射</a></p><ul><li>当你首次 创建一个索引时, 可以使用 <code>/_mapping</code> 为新类型(或者为存在的类型更新映射)增加映射;</li><li>尽管你可以为一个已存在的映射增加一个新域, 但不能 修改 存在的域映射<br>如果一个域的映射已经存在, 那么该域的数据可能已经被索引, 如果你意图修改这个域的映射, 索引的数据可能会出错, 不能被正常的搜索</li><li>可以更新一个映射来添加一个新域, 但不能将一个存在的域从 analyzed 改为 not_analyzed</li><li>ES5.X中, 索引属性只接收true/false来代替not_analyzed/no</li><li>测试<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">DELETE /gb</span><br><span class="line"># 创建一个新索引, 指定 tweet 域使用 english 分析器</span><br><span class="line">PUT /gb</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;tweet&quot; : &#123;</span><br><span class="line">      &quot;properties&quot; : &#123;</span><br><span class="line">        &quot;tweet&quot; : &#123;</span><br><span class="line">          &quot;type&quot; :    &quot;text&quot;,</span><br><span class="line">          &quot;analyzer&quot;: &quot;english&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;date&quot; : &#123;</span><br><span class="line">          &quot;type&quot; :   &quot;date&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;name&quot; : &#123;</span><br><span class="line">          &quot;type&quot; :   &quot;text&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;user_id&quot; : &#123;</span><br><span class="line">          &quot;type&quot; :   &quot;long&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">GET /gb/_mapping</span><br><span class="line"># 在 tweet 映射增加一个新的名为 `tag` 的 not_analyzed 的文本域</span><br><span class="line">PUT /gb/_mapping/tweet</span><br><span class="line">&#123;</span><br><span class="line">  &quot;properties&quot; : &#123;</span><br><span class="line">    &quot;tag&quot; : &#123;</span><br><span class="line">      &quot;type&quot; :    &quot;keyword&quot;,</span><br><span class="line">      &quot;index&quot;:    false</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /gb/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;field&quot;: &quot;tweet&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Black-cats&quot; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /gb/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;field&quot;: &quot;tag&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;Black-cats&quot; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一个奇怪的例子&quot;&gt;&lt;a href=&quot;#一个奇怪的例子&quot; class=&quot;headerlink&quot; title=&quot;一个奇怪的例子&quot;&gt;&lt;/a&gt;一个奇怪的例子&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;先索引两个文档到不同的索引中 (为什么不在同一个映射中创建两个文档? 或者在同一个
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>04. 文档的概念, ES乐观并发控制, 文档基本操作</title>
    <link href="http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-04/"/>
    <id>http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-04/</id>
    <published>2018-06-10T06:29:07.000Z</published>
    <updated>2018-09-20T07:25:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/data-in-data-out.html" target="_blank" rel="noopener">前言</a></h2><ol><li><p>传统上, 我们以 行和列的形式 存储数据到关系型数据库中, 相当于使用电子表格; 正因为我们使用了这种不灵活的存储媒介导致所有我们使用对象的灵活性都丢失了;</p><ul><li><p>面向对象编程语言如此流行的原因之一是对象帮我们表示和处理现实世界具有潜在的复杂的数据结构的实体 </p></li><li><p>而 JSON 正是一种以人可读的文本表示对象的方法, 它已经变成 NoSQL 世界交换数据的事实标准, 当一个对象被序列化成为 JSON, 它被称为一个 JSON 文档;<br>JSON文档可以将我们的对象按对象的方式来存储, 这样我们就能更加专注于 使用 数据, 而不是在电子表格的局限性下对我们的应用建模; 我们可以重新利用对象的灵活性;</p></li><li><p>Elastcisearch 是分布式的 文档 存储, 它能存储和检索复杂的数据结构—序列化成为JSON文档</p></li></ul></li><li><p>现存的 NoSQL 解决方案虽然允许我们以文档的形式存储对象, 但是他们仍旧需要我们思考如何查询我们的数据, 以及确定哪些字段需要被索引以加快数据检索; <strong>而在 ES 中, 每个字段的所有数据都是默认被索引的, 即每个字段都有为了快速检索设置的专用倒排索引</strong>; 而且, 不像其他多数的数据库, 它<strong>能在相同的查询中使用所有这些倒排索引, 并以惊人的速度返回结果</strong>;</p></li></ol><h2 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h2><ol><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_Document_Metadata.html" target="_blank" rel="noopener">文档及其元数据介绍</a></li><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/index-doc.html" target="_blank" rel="noopener">索引文档</a>, 注意 <code>PUT</code> 和 <code>POST</code> 两个谓词的使用场景;</li><li><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/create-doc.html" target="_blank" rel="noopener">小心<strong>覆盖创建</strong></a></p><ul><li>当我们索引一个文档, 怎么确认我们正在创建一个完全新的文档, 而不是覆盖现有的呢?</li><li>最简单办法是, 使用索引请求的 POST 形式让 Elasticsearch 自动生成唯一 _id;</li><li>另外, 如果有自己的文档ID, 防止覆盖 (成功会返回 401码, 冲突则会返回 409码)<figure class="highlight plain"><figcaption><span>/website/blog/123?op_type</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/123/_create</span><br></pre></td></tr></table></figure></li></ul></li><li><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/get-doc.html#_返回文档的一部分" target="_blank" rel="noopener">返回文档中的部分字段</a></p></li><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/update-doc.html" target="_blank" rel="noopener">更新<strong>整个</strong>文档</a>, 注意, ES中文档不能修改, 需要重建或者替换</li><li>删除比较简单…</li></ol><h2 id="ES文档的丢失更新问题"><a href="#ES文档的丢失更新问题" class="headerlink" title="ES文档的丢失更新问题"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/version-control.html" target="_blank" rel="noopener">ES文档的丢失更新问题</a></h2><ol><li><p>在使用 index API 更新文档时, 一般会先读取原始文档, 然后做我们的修改, 最后重新索引整个文档; 如果两个进程同时做这系列操作的话, 最后的索引请求将获胜, 当然, 有人的更改将丢失。</p></li><li><p>假设我们使用 Elasticsearch 存储我们网上商城商品库存的数量, 每次我们卖一个商品的时候, 在 Elasticsearch 中将库存数量减少; 有一天, 管理层决定做一次促销, 突然地, 每秒要卖好几个商品, 假设有两个 web 程序并行运行, 每一个都同时处理所有商品的销售<br> <img src="/img/est/es-concurrency.png"><br> 可以看到: web_1 对 stock_count 所做的更改已经丢失; 结果就会出现超卖现象;</p></li><li><p>在数据库领域中, 有两种方法通常被用来确保并发更新时变更不会丢失:</p><ul><li><strong>悲观并发控制</strong> : 这种方法被关系型数据库广泛使用, 它假定有变更冲突可能发生, 因此阻塞访问资源以防止冲突;<br>一个典型的例子是读取一行数据之前先将其锁住, 确保只有放置锁的线程能够对这行数据进行修改。</li><li><strong>乐观并发控制</strong> : Elasticsearch 中使用的这种方法假定冲突是不可能发生的, 并且不会阻塞正在尝试的操作, 不过, 如果源数据在读写当中被修改, 更最后在更新时将会失败; 应用程序接下来将决定该如何解决冲突, 例如, 可以重试更新、使用新的数据、或者将相关情况报告给用户;</li></ul></li></ol><h2 id="ES乐观并发控制"><a href="#ES乐观并发控制" class="headerlink" title="ES乐观并发控制"></a>ES乐观并发控制</h2><ol><li><p>ES 是分布式的, 当文档创建、更新或删除时, 新版本的文档必须复制到集群中的其他节点, 而 Elasticsearch 也是异步和并发的, 这意味着这些复制请求是被并行发送的, 所以到达目的地时也许<strong>顺序是乱的</strong>;</p></li><li><p>因此 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本:</p><ul><li>ES的每个文档都有一个 <strong>_version</strong> (版本)号, 当文档被修改时版本号递增;</li><li>ES正是使用这个 <strong>_version</strong> 号来确保变更以正确顺序得到执行 (如果旧版本的文档在新版本之后到达, 它会被直接忽略)</li></ul></li><li><p>我们可以利用 _version 号来确保 应用中相互冲突的变更不会导致数据丢失, 通过指定想要修改文档的 version 号来达到这个目的, 如果该版本不是当前版本号, 我们的请求将会失败</p></li><li><p>测试</p><ul><li><p>创建一个新文档 (当然, 响应体会告诉我们, 该文档版本号目前是1)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/1/_create</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line">  &quot;text&quot;:  &quot;Just trying this out...&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>现在假设我们想编辑这个文档: 一般是先查询,将文档数据加载到 web 表单中; 然后做一些修改, 保存新的版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 查询文档, 响应体中可以看到版本号仍为1</span><br><span class="line">GET /website/blog/1</span><br><span class="line"></span><br><span class="line">// 尝试通过重建文档的索引来保存修改, 我们指定 version 为我们的修改会被应用的版本:</span><br><span class="line">// 也就是我们想要索引中的文档只有 _version 为 1 时, 本次更新才能成功; </span><br><span class="line">// 最后此请求成功, 并且响应体告诉我们 _version 已经递增到 2</span><br><span class="line">PUT /website/blog/1?version=1 </span><br><span class="line">&#123;</span><br><span class="line"> &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line"> &quot;text&quot;:  &quot;Starting to get the hang of this...&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>然而, 如果我们重新运行相同的索引请求, 仍然指定 version=1, Elasticsearch 返回 <strong>409 Conflict</strong> HTTP 响应码, 和一个如下所示的响应体:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;error&quot;: &#123;</span><br><span class="line">    &quot;root_cause&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,</span><br><span class="line">        &quot;reason&quot;: &quot;[blog][1]: version conflict, current version [2] is different than the one provided [1]&quot;,</span><br><span class="line">        &quot;index_uuid&quot;: &quot;llBrPVECRFuD45NCpJaDfg&quot;,</span><br><span class="line">        &quot;shard&quot;: &quot;3&quot;,</span><br><span class="line">        &quot;index&quot;: &quot;website&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,</span><br><span class="line">    &quot;reason&quot;: &quot;[blog][1]: version conflict, current version [2] is different than the one provided [1]&quot;,</span><br><span class="line">    &quot;index_uuid&quot;: &quot;llBrPVECRFuD45NCpJaDfg&quot;,</span><br><span class="line">    &quot;shard&quot;: &quot;3&quot;,</span><br><span class="line">    &quot;index&quot;: &quot;website&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot;: 409</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>更多请参考文档: <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/optimistic-concurrency-control.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/cn/optimistic-concurrency-control.html</a> </p></li></ol><h2 id="文档的部分更新-update"><a href="#文档的部分更新-update" class="headerlink" title="文档的部分更新 - _update"></a>文档的部分更新 - <code>_update</code></h2><ol><li><p>之前在介绍 “更新整个文档” 时, 已经了解到, 文档是不可变的, 他们不能被修改, 只能被替换; 更新一个文档的方法是检索并修改它, 然后<strong>重新索引整个文档</strong>;</p></li><li><p>但其实使用 update API 我们还可以<strong>部分更新文档</strong>, 但是, update API 必须遵循同样的规则, 从外部来看, 我们在一个文档的某个位置进行部分更新, 然而在内部, update API 简单使用与之前描述相同的 <code>检索-修改-重建索引</code> 的处理过程</p><ul><li>区别在于这个过程发生在分片内部, 这样就避免了多次请求的网络开销; 通过减少检索和重建索引步骤之间的时间, 我们也减少了其他进程的变更带来冲突的可能性。</li><li>update 请求最简单的一种形式是接收文档的一部分作为 doc 的参数, 它只是与现有的文档进行合并, 对象被合并到一起, 覆盖现有的字段, 增加新的字段</li></ul></li><li><p>例如, 我们对 博客文章 增加字段 tags 和 views , 并修改 text 字段, 如下所示:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 测试成功:</span><br><span class="line">POST /website/blog/1/_update</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot; : &#123;</span><br><span class="line">    &quot;tags&quot; : [ &quot;testing&quot; ],</span><br><span class="line">    &quot;views&quot;: 0,</span><br><span class="line">    &quot;text&quot;: &quot;哈哈&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>更多部分更新相关内容, 可参考手册: <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/partial-updates.html" target="_blank" rel="noopener">https://www.elastic.co/guide/cn/elasticsearch/guide/cn/partial-updates.html</a><br> 未完待续~~</p></li></ol><h2 id="取回多文档"><a href="#取回多文档" class="headerlink" title="取回多文档"></a><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_Retrieving_Multiple_Documents.html" target="_blank" rel="noopener">取回多文档</a></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/cn/data-in-data-out
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>03. 集群相关 (节点, 分片及角色, 扩容, 故障测试)</title>
    <link href="http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-03/"/>
    <id>http://blog.renyimin.com/2018/06/10/elasticsearch/2018-06-10-03/</id>
    <published>2018-06-10T06:26:39.000Z</published>
    <updated>2018-09-19T12:31:02.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ol><li>ElasticSearch 的主旨是随时可用和按需扩容, 这里主要是说 水平(横向)扩容 — 为集群添加更多的节点将负载压力分散到这些节点中; ElastiSearch 天生就是分布式的, 它知道如何通过管理多节点来提高扩容性和可用性;</li><li>接下来将讲述如何按需配置集群、节点和分片, 并在硬件故障时确保数据安全</li></ol><h2 id="节点-及其-角色"><a href="#节点-及其-角色" class="headerlink" title="节点 及其 角色"></a>节点 及其 角色</h2><ol><li><p>节点: 一个运行中的 Elasticsearch 实例就称为一个节点; </p></li><li><p>默认情况下, es 集群中每个节点都有成为主节点的资格, 也都存储数据, 还可以提供查询服务, 这些功能是由两个属性控制的</p><ul><li><code>node.master</code>: 这个属性表示节点是否具有成为主节点的资格 (注意: 此属性的值为true, 并不意味着这个节点就是主节点; 真正的主节点, 是由多个具有主节点资格的节点进行选举产生的; 所以, 这个属性只是代表这个节点是不是具有主节点选举资格)</li><li><code>node.data</code>: 这个属性表示节点是否存储数据;</li></ul></li><li><p>上面两个配置属性可以有四种组合:</p><ul><li><p>节点只有成为主节点的资格(有可能成为真正的主节点), 但不会存储数据; 称为master节点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.master: true</span><br><span class="line">node.data: false</span><br></pre></td></tr></table></figure></li><li><p>节点没有成为主节点的资格, 即, 不参与选举, 只会存储数据; 称为data(数据)节点<br>在集群中需要单独设置几个这样的节点负责存储数据, 后期提供存储和查询服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.master: false</span><br><span class="line">node.data: true</span><br></pre></td></tr></table></figure></li><li><p>节点既不会成为主节点, 也不会存储数据 (也叫协调节点/路由节点)<br>这个节点的意义是作为一个client(客户端)节点, 主要是针对海量请求的时候可以进行负载均衡</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.master: false</span><br><span class="line">node.data: false</span><br></pre></td></tr></table></figure></li><li><p>既有成为主节点的资格, 又存储数据:<br>如果这个节点被选举成了真正的主节点, 那么它除了干主节点要干的活, 还要存储数据, 这样对于这个节点的压力就比较大;<br>elasticsearch 默认每个节点都是这样的配置, 在测试环境下这样做没问题, 但是实际工作中建议不要这样设置; 因为这样相当于 主节点 和 数据节点 的角色混合到一块了;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.master: false</span><br><span class="line">node.data: true</span><br></pre></td></tr></table></figure></li><li><p>默认情况下, 每个节点都有成为主节点的资格, 也会存储数据, 还会处理客户端的请求;</p></li><li><p>根据前面节点及其角色的介绍, 如果尝试配置唯一的节点为 <code>node.master: true node.data: false</code>, 则节点中的所有分片都会是未分配状态</p></li><li>如果配置为 <code>node.master: false node.data: false</code>, 貌似无法启动</li></ul></li><li><p>在生产集群中我们可以对这些节点的职责进行划分</p><ul><li>建议集群中设置3台以上的节点作为master节点 <code>node.master: true node.data: false</code>, 这些节点只负责成为主节点, 维护整个集群的状态;</li><li>再根据数据量设置一批data节点 <code>node.master: false node.data: true</code>, 这些节点只负责存储数据, 后期提供建立索引和查询索引的服务, 这样的话如果用户请求比较频繁, 这些节点的压力也会比较大;</li><li>所以在集群中建议再设置一批client节点 <code>node.master: false node.data: false</code>, 这些节点只负责处理用户请求, 实现请求转发, 负载均衡等功能;<br>master节点: 普通服务器即可(CPU 内存 消耗一般)<br>data节点: 主要消耗磁盘, 内存<br>client节点: 普通服务器即可(如果要进行分组聚合操作的话, 建议这个节点内存也分配多一点)</li></ul></li></ol><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><ol><li><p>集群是由一个或者多个拥有相同 <code>cluster.name</code> 配置项的节点组成, 这些节点共同承担数据和负载的压力; 当有节点加入集群中或者从集群中移除节点时, 集群将会重新平均分布所有的数据;</p></li><li><p>当一个节点被选举成为 主节点 时, 它将负责管理集群范围内的所有变更, 例如增加、删除索引, 或者增加、删除节点等; </p><ul><li>不过, <strong>纯粹的主节点</strong>并不需要涉及到文档级别的变更和搜索等操作, 所以, 集群所拥有的唯一一个主节点, 如果是纯粹的主节点的话, 即使流量的增加它也不会成为瓶颈;  </li><li>任何节点都可以成为主节点, 到目前为止, 我们之前的示例集群就只有一个节点, 当然, 它同时也是主节点;    </li></ul></li><li><p>作为用户, 我们可以将请求发送到集群中的任何节点, 包括主节点; 每个节点都知道任意文档所处的位置, 并且能够将我们的请求直接转发到存储我们所需文档的节点, 无论我们将请求发送到哪个节点, 它都能负责从各个包含我们所需文档的节点收集回数据, 并将最终结果返回給客户端, Elasticsearch 对这一切的管理都是透明的。</p></li><li><p>集群健康, 可以通过 <code>GET /_cluster/health</code> 来查看, 对于返回结果, 最需要关心的是 <code>status</code> 字段, 它指示着当前集群在总体上是否工作正常, 它的三种颜色含义如下:</p><ul><li><strong>green</strong> 所有的主分片和副本分片都正常运行</li><li><strong>yellow</strong> 所有的主分片都正常运行, 但不是所有的副本分片都正常运行</li><li><strong>red</strong> 有主分片没能正常运行</li></ul></li></ol><h2 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h2><ol><li><p>我们往 Elasticsearch 添加数据时需要用到 索引(保存相关数据的地方), 而索引实际上是指向一个或者多个物理分片的<strong>逻辑命名空间</strong>;</p></li><li><p><strong>分片</strong>: 一个分片是一个 Lucene 的实例, 它是一个底层的工作单元, 其本身就是一个完整的搜索引擎; 但是, 它可能仅保存了全部文档中的一部分;</p></li><li><p>Elasticsearch 是利用分片将数据分发到集群内各处的, 分片是数据的容器, 文档保存在分片内, 分片又被分配到集群内的各个节点里; <strong>当你的集群规模扩大或者缩小时(即增加或减少节点时), Elasticsearch 会自动的在各节点中迁移分片, 使得数据仍然均匀分布在集群里</strong>。</p></li><li><p>分片有两种类型: 主分片, 副本分片</p><ul><li>索引内任意一个文档都归属于一个主分片, 所以主分片的数目决定着索引能够保存的最大数据量;</li><li>而副本分片只是一个主分片的拷贝, 副本分片作为硬件故障时保护数据不丢失的冗余备份, 并为搜索和返回文档等读操作提供服务;</li><li>注意: 在索引建立的时候就确定了主分片数,之后无法随意修改;而副本分片数可以随时修改;</li></ul></li><li><p>每个索引在默认情况下会被分配5个主分片, 不过你也可以在创建索引前, 先指定索引的 主分片数  和 每个主分片对应的副本分片数, 如下, 给 blogs 索引分配3个主分片 和 每个主分片分配1个副本:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PUT /blogs</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot; : &#123;</span><br><span class="line">     &quot;number_of_shards&quot; : 3,</span><br><span class="line">     &quot;number_of_replicas&quot; : 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 不过, 由于当前只有一个节点, 所以集群的健康状况为 yellow , 表示全部主分片都正常运行(集群可以正常服务所有请求), 但是副本分片没有全部处在正常状态;<br> 实际上, 所有3个副本分片都是 unassigned —— 它们都没有被分配到任何节点, 因为当前只有一个节点, 而在同一个节点上既保存原始数据又保存副本是没有意义的;<br> 当前这种状况, 一旦失去了唯一的节点, 也就会丢失该节点上的所有副本数据; 当前我们的集群是正常运行的, 但是<strong>在唯一的结点出现硬件故障时有丢失数据的风险</strong>;<br> <img src="/img/est/blogs-unassigned-yellow.png"></p></li></ol><h2 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h2><ol><li><p><strong>添加故障转移</strong>: 当集群中只有一个节点在运行时, 意味着会有一个单点故障问题 —— 没有冗余; 幸运的是, 在ES中, 我们只需再启动一个节点即可防止数据丢失;</p><ul><li>启动第二个节点非常简单, 你可以在同一个目录内, 完全依照启动第一个节点的方式来启动一个新节点(多个节点可以共享同一个目); 只要它和第一个节点有同样的 cluster.name 配置, 它就会自动发现集群并加入到其中;</li><li>但是注意: 在不同一机器上启动节点的时候, 为了加入到同一集群, 你需要配置一个可连接到的<strong>单播主机列表</strong></li></ul></li><li><p><strong>单播</strong>, 组播   </p><ul><li><p>单播: Elasticsearch 默认被配置为使用单播发现, 以防止节点无意中加入集群, 只有在同一台机器上运行的节点才会自动组成集群;<br>除了同一台机器上的集群会自动发现同名节点, 使用单播, 你还可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表, 当一个节点可以联系到单播列表中的成员(节点)时, 它就会得到整个集群所有节点的状态, 然后它会联系 master 节点, 并加入集群;<br><strong>这意味着你的单播列表不需要包含你的集群中的所有节点, 它只是需要足够的节点, 当一个新节点联系上其中一个并且说上话就可以了</strong>;<br>如果你使用 master 候选节点作为单播列表, 你只要列出三个就可以了, 这个配置在 elasticsearch.yml 文件中: <code>discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;]</code></p></li><li><p>组播: 组播貌似仍然是作为插件提供, 并且它应该永远不要在生产环境使用, 否则可能会出现一个节点意外的加入到了你的生产环境集群中;<br>虽然组播 本身 并没有错, 但一不小心就会导致一些愚蠢的问题, 并且导致集群变的脆弱;</p></li><li><p>最好使用单播代替组播</p></li></ul></li><li><p>继续上面的第6点, 由于目前是在同一台机器上启动第二个节点, 所以不同配置单播列表, 直接启动一个节点即可; </p><ul><li>当启动第二个节点后, 由于其使用的是和第一个节点一样的配置, 集群名也就相同, 所以会自动加入到集群;</li><li>加入集群后, blogs 索引的 3个 副本分片 将会分配到这个节点上, 这意味着当集群内任何一个节点出现问题时, 我们的数据都完好无损;</li><li>所有新索引的文档都将会保存在主分片上, 然后被并行的复制到对应的副本分片上, 这就保证了我们既可以从主分片又可以从副本分片上获得文档;</li><li>并且 cluster-health 现在展示的状态为 green, 这表示所有6个分片(包括3个主分片和3个副本分片)都在正常运行;<br><img src="/img/est/blogs-green.png"></li></ul></li></ol><h2 id="水平扩容"><a href="#水平扩容" class="headerlink" title="水平扩容"></a>水平扩容</h2><ol><li><p>如何为我们的正在增长中的应用程序按需扩容呢? 再次尝试启动第三个新的节点, 会发现集群状态如下:<br> <img src="/img/est/blogs-green-03.png"></p></li><li><p>可以看到 Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点</p><ul><li>现在每个节点上都拥有2个分片, 而不是之前的3个, 这表示每个节点的硬件资源(CPU, RAM, I/O)将被更少的分片所共享, 每个分片的性能将会得到提升</li><li>分片是一个功能完整的搜索引擎, 它拥有使用一个节点上的所有资源的能力<br>也就是说, 目前我们这个拥有6个分片(3个主分片和3个副本分片)的索引, 可以最大扩容到6个节点, 让每个节点上只有该索引的一个分片(也可能会有其他索引的分片哦);</li></ul></li><li><p>分片数量一定, 增加节点, 则每个分片性能将会提升, 因为被赋予的更多的硬件资源; 但是当一个索引的分片数量和集群的节点数量达到一致时, 其分片性能达到最高, 继续增加更多的副本分片是不能提高性能的, 因为每个分片从节点上获得的资源会变少, 你需要增加更多的硬件资源来提升吞吐量;</p></li></ol><h2 id="更多的扩容提升搜索性能"><a href="#更多的扩容提升搜索性能" class="headerlink" title="更多的扩容提升搜索性能"></a>更多的扩容提升搜索性能</h2><ol><li><p>想要继续扩容超过6个节点, 需要先知道:</p><ul><li>由于索引的主分片数目在索引创建时就已经确定了, 这个数目定义了这个索引能够 存储 的最大数据量<br>也就是索引能存储的最大数据量在创建索引的时候就通过设置主分片数确定了(不过实际大小还取决于你的数据、硬件和使用场景)</li><li>由于 <strong>搜索操作 和 返回数据操作 可以同时被主分片 或 副本分片所处理</strong>, 所以当你拥有越多的副本分片时, 也将拥有越高的吞吐量</li></ul></li><li><p>在运行中的集群上是可以动态调整副本分片数目的, 比如, 可以把副本数从默认的 1 增加到 2 :</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT /blogs/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;number_of_replicas&quot; : 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>blogs 索引现在拥有9个分片: 3个主分片和6个副本分片; 这就意味着可以将集群扩容到9个节点(每个节点上只放该索引的一个分片), 相比原来3个节点时(每个节点两个分片), 虽然存储量不变, 但是集群搜索性能可以提升 3 倍;</p></li><li><p>当一个索引的分片数量和集群的节点数量达到一致时, 其分片性能将达到最高, 无法再提升分片的性能! 此时可以 <strong>通过增加更多的副本分片, 同时增加节点来提升集群的搜索性能</strong>!</p></li><li><p>集群的整体性能还是需要通过增加节点来提高!</p></li></ol><h2 id="故障测试"><a href="#故障测试" class="headerlink" title="故障测试"></a>故障测试</h2><ol><li><p>目前的集群状态如下:<br> <img src="/img/est/blogs-green-03.png"></p></li><li><p>如果关闭<strong>主节点</strong></p><ul><li>由于而集群必须拥有一个主节点来保证正常工作, 所以发生的第一件事情就是选举一个新的主节点;</li><li><p>在我们关闭主节点的同时也失去了主分片 1 和 2, 并且在缺失主分片的时候索引也不能正常工作, 如果此时来检查集群的状况, 我们看到的状态将会为 red: 不是所有主分片都在正常工作<br><img src="/img/est/9200-down.png"></p></li><li><p>幸运的是, 在其它节点上存在着主节点上这两个主分片的完整副本, 所以新的主节点会立即将这两个主分片在 另外两个节点上 对应的副本分片提升为主分片, 此时集群的状态将会为 yellow: 这个提升主分片的过程是瞬间发生的, 如同按下一个开关一般<br>此时, 虽然我们又拥有所有的三个主分片, 但是由于之前设置了每个主分片需要对应2份副本分片, 而此时只有两个几点, 只存在一份副本分片, 所以集群不能为 green 的状态;<br>注意连接的端口:<br><img src="/img/est/9201-green.png"></p><p><img src="/img/est/9202-green.png"></p></li><li><p>如果重新启动之前关闭的节点, 集群可以将缺失的副本分片再次进行分配, 如果它依然拥有着之前的分片, 它将尝试去重用它们, 同时仅从主分片复制发生了修改的数据文件;<br><img src="/img/est/node-ok.png"></p></li></ul></li></ol><h2 id="配置相关"><a href="#配置相关" class="headerlink" title="配置相关"></a>配置相关</h2><ol><li><p>注意: discovery.zen.minimum_master_nodes ??</p></li><li></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;ElasticSearch 的主旨是随时可用和按需扩容, 这里主要是说 水平(横向)扩容 — 为集群添加更多的节点将负载压力分散
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>02. 适应一下ES</title>
    <link href="http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-02/"/>
    <id>http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-02/</id>
    <published>2018-06-08T13:23:07.000Z</published>
    <updated>2018-09-18T07:44:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>文档该<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_indexing_employee_documents.html" target="_blank" rel="noopener">章节</a>比较基础, 主要是为了对 Elasticsearch 有一个基本印象, 通过对雇员文档的基本操作, 了解 <code>索引</code>、<code>搜索</code> 及 <code>聚合</code> 等基础概念;<br>可能有会遇到有些语句在5.X中无法运行, 比如 </p><ul><li>进行聚合操作时提示 Fielddata is disabled on text fields by default, 可参考<a href="https://blog.csdn.net/u011403655/article/details/71107415" target="_blank" rel="noopener">此文章</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;文档该&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/cn/_indexing_employee_documents.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;章节&lt;/
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>01. Elasticsearch 入门 及 简单安装</title>
    <link href="http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-01/"/>
    <id>http://blog.renyimin.com/2018/06/08/elasticsearch/2018-06-08-01/</id>
    <published>2018-06-08T06:24:25.000Z</published>
    <updated>2018-09-20T07:06:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>主要是简单过一下 Elasticsearch 权威指南, 做一下学习记录~~</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ol><li><p>Elasticsearch 是一个基于 Lucene 的开源, 高性能, 全文检索 和 分析引擎, 可以快速且近实时地存储, 检索以及分析海量数据;</p></li><li><p>当然, ES 不仅仅是 Lucene, 也不仅仅只是一个全文搜索引擎, 它可以被下面这样准确的形容:</p><ul><li>一个分布式近实时分析搜索引擎;</li><li>海量数据检索及分析: 可以扩展到上百台服务器, 处理PB级结构化或非结构化数据;</li><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html" target="_blank" rel="noopener">近实时搜索</a>: 从文档索引到可以被检索只有轻微延时, 约1s</li><li>RESTful API: ES 建立在全文搜索引擎 Lucene 之上, 通过简单的 RESTful API 来隐藏 Lucene 的复杂性, 从而让全文搜索变得简单, 各种语言的客户端甚至命令行都可以与之交互;</li><li>面向文档型数据库, 存储的是整个对象或者文档, 它不但会存储它们, 还会为它们建立索引;</li></ul></li><li><p>使用案例</p><ul><li>在微服务架构下的多数据源聚合列表页(一个页面中的数据来自多个服务, 且筛选条件也涉及到多个服务中的数据字段), 如果用传统数据库解决该问题, 会大费周折, 并且效果并不好, 而如果使用 ES 来作数据聚合服务, 效果就比较清晰明了了;</li><li>您想要去收集日志或交易数据, 并且还想要去分析和挖掘这些数据来找出趋势, 统计, 或者异常现, 在这种情况下, 您可以使用 Logstash(Elasticsearch/Logstash/Kibana) 技术栈中的一部分, 来收集, 聚合, 以及解析数据, 然后让 Logstash 发送这些数据到 Elasticsearch; 如果这些数据存在于 Elasticsearch 中, 您就可以执行搜索和聚合以挖掘出任何您感兴趣的信息;</li><li>GitHub 使用 Elasticsearch 对1300亿行代码进行查询;</li><li>……</li></ul></li></ol><h2 id="版本选择"><a href="#版本选择" class="headerlink" title="版本选择"></a>版本选择</h2><ol><li><p>ES 的版本变更比较快, 目前(06/2018)为止, Elasticsearch已经到6.X了, 可参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/index.html" target="_blank" rel="noopener">官网文档</a>, 可能很多公司还在用2.X, 或者刚切到5.X, 而且中文文档进度也比较滞后, 这也是让很多兄弟比较头疼的事情;</p></li><li><p>其实可以根据公司所选的云服务上 ES版本 来决定你的学习版本 (当前阿里云的Elasticsearch云服务为5.5.3, 因此此处也是针对5.X版本进行学习调研);</p></li></ol><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol><li><p>安装Java, 推荐使用Java 8 : <code>yum install java-1.8.0-openjdk* -y</code></p></li><li><p>ES <a href="https://www.elastic.co/downloads/past-releases" target="_blank" rel="noopener">下载</a></p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd /usr/local/src</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.3.tar.gz</span><br><span class="line">$ tar -zxvf elasticsearch-5.5.3.tar.gz</span><br><span class="line">$ cd elasticsearch-5.5.3</span><br><span class="line">$ ls</span><br><span class="line">bin  config  lib  LICENSE.txt  modules  NOTICE.txt  plugins  README.textile</span><br></pre></td></tr></table></figure></li><li><p>启动 ES: es不能使用root权限启动, 所以需要创建新用户</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ adduser es</span><br><span class="line">$ passwd es</span><br><span class="line">$ chown -R es /usr/local/src/elasticsearch-5.5.3/</span><br><span class="line">$ cd /usr/local/src/elasticsearch-5.5.3/bin</span><br><span class="line">$ su es</span><br><span class="line">$ ./elasticsearch</span><br></pre></td></tr></table></figure></li><li><p>验证es是否安装成功</p><ul><li>可以在浏览器中打开 127.0.0.1:9200 (这里使用的是vagrant设定了虚拟主机的ip, 所以访问 <a href="http://192.168.3.200:9200/" target="_blank" rel="noopener">http://192.168.3.200:9200/</a>, 不过有些<strong>小坑</strong>下面会介绍 )</li><li>或者可以 <code>curl -X GET http://192.168.3.200:9200</code> </li></ul></li></ol><h2 id="启动坑点"><a href="#启动坑点" class="headerlink" title="启动坑点"></a>启动坑点</h2><p>启动可能会报一些错</p><ol><li><p>每个进程最大同时打开文件数太小</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]</span><br><span class="line">[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</span><br><span class="line">```    </span><br><span class="line">解决方案: 切换到root, 可通过下面2个命令查看当前数量</span><br><span class="line">```     </span><br><span class="line">$ ulimit -Hn</span><br><span class="line">4096</span><br><span class="line">$ ulimit -Sn</span><br><span class="line">1024</span><br><span class="line"></span><br><span class="line">// 编辑如下文件</span><br><span class="line">vi /etc/security/limits.conf</span><br><span class="line">// 增加配置</span><br><span class="line">*               soft    nofile          65536</span><br><span class="line">*               hard    nofile          65536</span><br></pre></td></tr></table></figure></li><li><p>elasticsearch用户拥有的内存权限太小, 至少需要262144</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ERROR: [1] bootstrap checks failed</span><br><span class="line">[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</span><br></pre></td></tr></table></figure><p> 解决方案, 切换到root</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysctl.conf </span><br><span class="line">添加 vm.max_map_count=262144</span><br><span class="line">执行 sysctl -p</span><br></pre></td></tr></table></figure></li><li><p>默认9200端口是给本机访问的, 因此es在成功启动后, 如果使用 192.168.3.200:9200 来访问, 可能失败, 因此需要在es配置文件elasticsearch.yml中增加 <strong>network.bind_host: 0.0.0.0</strong>, 重启后则可以正常访问</p></li><li><p>如果想启动多个结点, 还可能会报如下几个错</p><ul><li><p>尝试启动第二个节点, 报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000080000000, 174456832, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12)</span><br><span class="line">#</span><br><span class="line"># There is insufficient memory for the Java Runtime Environment to continue.</span><br><span class="line"># Native memory allocation (mmap) failed to map 174456832 bytes for committing reserved memory.</span><br><span class="line"># An error report file with more information is saved as:</span><br><span class="line"># /usr/local/src/elasticsearch-5.5.3/bin/hs_err_pid8651.log</span><br></pre></td></tr></table></figure><p>解决方案: 其实这是因为我给虚拟机分配了2G的内存, 而elasticsearch5.X默认分配给jvm的空间大小就是2g, 所以jvm空间不够, 修改jvm空间分配</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/src/elasticsearch-5.5.3/config/jvm.options</span><br><span class="line">将:</span><br><span class="line">-Xms2g</span><br><span class="line">-Xmx2g</span><br><span class="line">修改为:</span><br><span class="line">-Xms512m</span><br><span class="line">-Xmx512m</span><br></pre></td></tr></table></figure></li><li><p>再次启动又报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">maybe these locations are not writable or multiple nodes were started without increasing [node.max_local_storage_nodes] (was [1])</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>解决方案: 在 elasticsearch.yml 配置文件最后添加 <code>node.max_local_storage_nodes: 256</code>, 然后重新添加第二个节点</p></li></ul></li></ol><h2 id="Elasticsearch-Head-安装"><a href="#Elasticsearch-Head-安装" class="headerlink" title="Elasticsearch Head 安装"></a><a href="https://github.com/mobz/elasticsearch-head" target="_blank" rel="noopener">Elasticsearch Head 安装</a></h2><p>es 启动后, 访问 127.0.0.1:9200 可以查看版本集集群相关的信息, 但这不是图形化的界面, 操作起来不是很方便, 如果希望能有一个可视化的环境来操作它, 可以通过安装 Elasticsearch Head 这个插件来进行管理;<br>Elasticsearch Head 是集群管理、数据可视化、增删改查、查询语句可视化工具, 在最新的ES5中安装方式和ES2以上的版本有很大的不同, 在ES2中可以直接在bin目录下执行 <code>plugin install xxxx</code> 来进行安装, 但是在ES5中这种安装方式变了, 要想在ES5中安装则必须要安装NodeJs, 然后通过NodeJS来启动Head, 具体过程如下:</p><ol><li><p>nodejs 安装</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 更新node.js各版本yum源(Node.js v8.x)</span><br><span class="line">curl --silent --location https://rpm.nodesource.com/setup_8.x | bash -</span><br><span class="line">yum install -y nodejs</span><br></pre></td></tr></table></figure></li><li><p><a href="https://github.com/mobz/elasticsearch-head" target="_blank" rel="noopener">github下载</a> Elasticsearch Head 源码</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">git clone git://github.com/mobz/elasticsearch-head.git</span><br><span class="line">cd elasticsearch-head</span><br><span class="line">npm install // (可能会有一些警告)</span><br></pre></td></tr></table></figure></li><li><p>修改Elasticsearch配置文件, 编辑 elasticsearch-5.5.3/config/elasticsearch.yml, 加入以下内容:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http.cors.enabled: true // 注意冒号后面要有空格</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br></pre></td></tr></table></figure></li><li><p>编辑elasticsearch-head-master文件下的Gruntfile.js, 修改服务器监听地址, 增加hostname属性, 将其值设置为 * :</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vi elasticsearch-head/Gruntfile.js</span><br><span class="line"></span><br><span class="line">connect: &#123;</span><br><span class="line">    hostname: &quot;*&quot;,  // 此处</span><br><span class="line">    server: &#123;</span><br><span class="line">        options: &#123;</span><br><span class="line">            port: 9100,</span><br><span class="line">            base: &apos;.&apos;,</span><br><span class="line">            keepalive: true</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>编辑elasticsearch-head-master/_site/app.js, 修改head连接es的地址，将localhost修改为es的IP地址 (注意:如果ES是在本地,就不要修改,默认就是localhost)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://localhost:9200&quot;;</span><br></pre></td></tr></table></figure></li><li><p>在启动elasticsearch-head之前要先启动elasticsearch, 然后在elasticsearch-head-master/目录下运行启动命令</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm run start</span><br></pre></td></tr></table></figure></li><li><p>最后验证 <a href="http://192.168.3.200:9100/" target="_blank" rel="noopener">http://192.168.3.200:9100/</a><br> <img src="/img/est/est-9100.png"></p></li></ol><h2 id="Kibana安装"><a href="#Kibana安装" class="headerlink" title="Kibana安装"></a><a href="https://www.elastic.co/cn/products/kibana" target="_blank" rel="noopener">Kibana</a>安装</h2><ol><li><p><a href="https://www.elastic.co/downloads/past-releases" target="_blank" rel="noopener">下载</a>, 此处选择了5.5.3</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://artifacts.elastic.co/downloads/kibana/kibana-5.5.3-linux-x86_64.tar.gz</span><br><span class="line">tar -zxvf kibana-5.5.3-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>修改config/kibana.yml文件, 加入以下内容:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">server.port: 5601  </span><br><span class="line">server.name: &quot;kibana&quot;  </span><br><span class="line">server.host: &quot;0.0.0.0&quot;  </span><br><span class="line">elasticsearch.url: &quot;http://127.0.0.1:9200&quot;</span><br></pre></td></tr></table></figure></li><li><p>然后启动kibana服务:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> cd /usr/local/src/kibana-5.5.3-linux-x86_64/bin</span><br><span class="line">./kibana</span><br></pre></td></tr></table></figure><ul><li>浏览器访问地址:<a href="http://192.168.3.200:5601/" target="_blank" rel="noopener">http://192.168.3.200:5601/</a></li></ul></li><li><p>DevTools 与 5.x之前版本的Sense</p><ul><li>Sense 是一个 Kibana 应用它提供交互式的控制台, 通过你的浏览器直接向 Elasticsearch 提交请求, 操作es中的数据</li><li>现在不用安装了, 可以直接使用Kibana提供的 <strong>DevTools</strong><br><img src="/img/est/kibana-devtools.png" width="450/"></li></ul></li><li><p>注意此时, 之前的es集群变成yellow状态了<br> <img src="/img/est/est-9100-yellow.png"></p></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此为止, 正常学习的Es环境已经安装完毕, 不要纠结这些服务的开机启动, 调优配置, 集群, 高可用, 监控……<br>骚年, 暂时先让它能跑起来就行!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;主要是简单过一下 Elasticsearch 权威指南, 做一下学习记录~~&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Elasticsearch 是
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://blog.renyimin.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>28. 隔离级别 与 锁</title>
    <link href="http://blog.renyimin.com/2017/09/03/mysql/2017-09-03-mysql-28/"/>
    <id>http://blog.renyimin.com/2017/09/03/mysql/2017-09-03-mysql-28/</id>
    <published>2017-09-03T06:20:52.000Z</published>
    <updated>2018-09-03T03:54:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ol><li><p>之前几篇博文已经介绍了Mysql事务, 高并发下事务将会面对的问题 及 MySQL的解决方案; MySQL主要采用 事务隔离性中的<strong>4种隔离级别</strong> 结合 <strong>MVCC机制</strong> 来进行解决;</p></li><li><p>而事务隔离级别的核心就是锁, 各隔离级别使用了不同的加锁策略; 接下来看一下各隔离级别是如何实现及如何解决高并发事务问题的;</p></li></ol><h2 id="READ-UNCOMMITTED-未提交读"><a href="#READ-UNCOMMITTED-未提交读" class="headerlink" title="READ UNCOMMITTED 未提交读"></a><a href="">READ UNCOMMITTED 未提交读</a></h2><h2 id="READ-COMMITTED-提交读"><a href="#READ-COMMITTED-提交读" class="headerlink" title="READ COMMITTED 提交读"></a><a href="">READ COMMITTED 提交读</a></h2><h2 id="MVCC-多版本并发控制"><a href="#MVCC-多版本并发控制" class="headerlink" title="MVCC 多版本并发控制"></a><a href="">MVCC 多版本并发控制</a></h2><h2 id="REPEATABLE-READ-可重复读"><a href="#REPEATABLE-READ-可重复读" class="headerlink" title="REPEATABLE READ 可重复读"></a><a href="">REPEATABLE READ 可重复读</a></h2><p>参考资料</p><ul><li>《高性能MySQL》</li><li><a href="https://dev.mysql.com/doc/refman/5.6/en/innodb-consistent-read.html" target="_blank" rel="noopener">MySQL官方文档</a></li><li><a href="https://tech.meituan.com/innodb-lock.html" target="_blank" rel="noopener">美团技术博客</a></li></ul><p>最后更新时间 2018/09/01</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;之前几篇博文已经介绍了Mysql事务, 高并发下事务将会面对的问题 及 MySQL的解决方案; MySQL主要采用 事务隔
      
    
    </summary>
    
      <category term="MySQL" scheme="http://blog.renyimin.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://blog.renyimin.com/tags/MySQL/"/>
    
      <category term="事务" scheme="http://blog.renyimin.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>27. 幻读, 快照读(snapshot read), 当前读 (current read)</title>
    <link href="http://blog.renyimin.com/2017/09/02/mysql/2017-09-02-mysql-27/"/>
    <id>http://blog.renyimin.com/2017/09/02/mysql/2017-09-02-mysql-27/</id>
    <published>2017-09-02T11:25:07.000Z</published>
    <updated>2018-09-01T14:02:47.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>RR + MVCC</strong> 虽然解决了 <code>幻读</code> 问题, 但要注意, 幻读针对的是读操作(对于其他操作就不一样了);</p><h2 id="演示"><a href="#演示" class="headerlink" title="演示"></a>演示</h2><ol><li><p>打开 两个客户端 1,2 确保隔离级别为默认级别RR, 提供语句:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT @@SESSION.tx_isolation;</span><br><span class="line">+------------------------+</span><br><span class="line">| @@SESSION.tx_isolation |</span><br><span class="line">+------------------------+</span><br><span class="line">| REPEATABLE-READ        |</span><br><span class="line">+------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from test_transaction;</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">| id | user_name | age | gender | desctiption        |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">|  1 | 金刚狼 | 127 |      1 | 我有一双铁爪 |</span><br><span class="line">|  2 | 钢铁侠 | 120 |      1 | 我有一身铁甲 |</span><br><span class="line">|  3 | 绿巨人 |   0 |      2 | 我有一身肉    |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></li><li><p>在客户端2中 <strong>开启事务</strong>, 然后查询数据</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from test_transaction;</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">| id | user_name | age | gender | desctiption        |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">|  1 | 金刚狼 | 127 |      1 | 我有一双铁爪 |</span><br><span class="line">|  2 | 钢铁侠 | 120 |      1 | 我有一身铁甲 |</span><br><span class="line">|  3 | 绿巨人 |   0 |      2 | 我有一身肉    |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></li><li><p>在客户端1中插入一条id为4的新数据 (未开启事务, 所以会自动提交)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">mysql&gt; select * from test_transaction;</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">| id | user_name | age | gender | desctiption        |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">|  1 | 金刚狼 | 127 |      1 | 我有一双铁爪 |</span><br><span class="line">|  2 | 钢铁侠 | 120 |      1 | 我有一身铁甲 |</span><br><span class="line">|  3 | 绿巨人 |   0 |      2 | 我有一身肉    |</span><br><span class="line">|  4 | 死侍    |  18 |      0 | A bad boy          |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></li><li><p>回到 客户端2 的事务中再次查询数据, 发现数据没有变化(表示<strong>可以重复读, 并且克服了 <code>select</code> 幻读</strong>)!! </p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; begin;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from test_transaction;</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">| id | user_name | age | gender | desctiption        |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">|  1 | 金刚狼 | 127 |      1 | 我有一双铁爪 |</span><br><span class="line">|  2 | 钢铁侠 | 120 |      1 | 我有一身铁甲 |</span><br><span class="line">|  3 | 绿巨人 |   0 |      2 | 我有一身肉    |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test_transaction;</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">| id | user_name | age | gender | desctiption        |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">|  1 | 金刚狼 | 127 |      1 | 我有一双铁爪 |</span><br><span class="line">|  2 | 钢铁侠 | 120 |      1 | 我有一身铁甲 |</span><br><span class="line">|  3 | 绿巨人 |   0 |      2 | 我有一身肉    |</span><br><span class="line">+----+-----------+-----+--------+--------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></li><li><p>但如果尝试在客户端2的事务中执行 <code>insert/delete/update</code> , 却会发现此类操作都可以感知到客户端1提交的新数据</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into test_transaction (`id`,`user_name`,`age`,`gender`,`desctiption`) values (4, &apos;死侍&apos;, 18, 0, &apos;A bad boy&apos;);</span><br><span class="line">1062 - Duplicate entry &apos;4&apos; for key &apos;PRIMARY&apos;    //( 后面会看到: 其实是因为insert是当前读)</span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol><li><p>虽然发现已经克服了幻读问题; 但当 在客户端2事务中 <code>insert</code> 插入一条id为4的新数据, 却发现提示数据已经存在, 那么这是什么问题呢?</p><ul><li>可以参考<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html" target="_blank" rel="noopener">MySQL官方文档 — 一致性非阻塞读</a>中的一段介绍<blockquote><p>The snapshot of the database state applies to SELECT statements within a transaction, not necessarily to DML statements. If you insert or modify some rows and then commit that transaction, a DELETE or UPDATE statement issued from another concurrent REPEATABLE READ transaction could affect those just-committed rows, even though the session could not query them. If a transaction does update or delete rows committed by a different transaction, those changes do become visible to the current transaction.<br>个人认为应该翻译为: 数据库的快照适用于事务中的SELECT语句, 而不一定适用于所有DML语句。 如果插入或修改某些行, 然后提交该事务, 则从另一个并发REPEATABLE READ事务发出的DELETE或UPDATE语句就可能会影响那些刚刚提交的行, 即使该事务无法查询到它们。<br>如果一个事务去更新或删除其他事务提交的行, 则那些更改对当前事务就变得可见;<br>但是如果事务select由不同事务提交的行, 则那些更改对当前事务就不可见(此时算是rr的可重复读);</p></blockquote></li></ul></li><li><p>也就是RR隔离级别, 在同一事务中多次读取的话, 对 <code>select</code> 克服了 <code>幻读</code>; 但是对其他DML并没有做到(其他DML能察觉到数据被别的事务提交过了)!</p></li><li><p>这就引出了新的两个概念: 当前读 和 快照读</p></li></ol><h2 id="当前读-和-快照读"><a href="#当前读-和-快照读" class="headerlink" title="当前读 和 快照读"></a>当前读 和 快照读</h2><p>通常在RC,RR隔离级别下, 不做特殊处理, 使用的 <code>select</code> 都是快照读, 其他dml就算是当前读; (MVCC写阻塞写)</p><ol><li><p>其实, MVCC并发控制中的读操作分为两类: <code>快照读 (snapshot read)</code> 与 <code>当前读 (current read)</code>; <a href="https://www.cnblogs.com/cat-and-water/p/6427612.html" target="_blank" rel="noopener">参考</a></p></li><li><p>快照读： 是通过MVVC(多版本控制)和 <code>undo log</code> 来实现的, 常见语句如下(貌似就是常见的悲观锁么):</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">简单的select操作 (不包括: `select ... lock in share mode`, `select ... for update`)</span><br></pre></td></tr></table></figure></li><li><p>而 <code>当前读</code> 根本不会创建任何快照, insert, update, delete都是当前读, 所以这几个操作会察觉到其他事务对数据做的更改(而普通select是察觉不到的):                      </p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select ... lock in share mode</span><br><span class="line">select ... for update</span><br><span class="line">insert</span><br><span class="line">update</span><br><span class="line">delete</span><br></pre></td></tr></table></figure></li></ol><p>最后更新时间 2018/09/01</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;RR + MVCC&lt;/strong&gt; 虽然解决了 &lt;code&gt;幻读&lt;/code&gt; 问题, 但要注意, 幻读针对的是读操作(对于其他操作就不一样了);&lt;/p&gt;
&lt;h2 id=&quot;演示&quot;&gt;&lt;a href=&quot;#演示&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="MySQL" scheme="http://blog.renyimin.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://blog.renyimin.com/tags/MySQL/"/>
    
      <category term="事务" scheme="http://blog.renyimin.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>26. MySQL 高并发下常见的事务问题</title>
    <link href="http://blog.renyimin.com/2017/09/02/mysql/2017-09-02-mysql-26/"/>
    <id>http://blog.renyimin.com/2017/09/02/mysql/2017-09-02-mysql-26/</id>
    <published>2017-09-02T06:56:32.000Z</published>
    <updated>2018-09-01T14:02:40.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一篇<a href="/2017/09/16/mysql/2017-09-16-mysql-20/">MySQL事务简介</a>中对MySQL事务的 基本概念 及 特性 做了简单介绍; 接下来会分析在实际生产环境中面对高并发场景时, 事务会出现的一些常见问题; </p><h2 id="高并发事务问题"><a href="#高并发事务问题" class="headerlink" title="高并发事务问题"></a>高并发事务问题</h2><p>在并发量比较大的时候, 很容易出现 <strong>多个事务并行</strong> 的情况; 假设有两个事务正在同时进行, 值得注意的是: 它们两者之间是互相不知道对方的存在的, 各自都对自身所处的环境 <strong>过分乐观</strong>, 从而并没有对自己所操作的数据做一定的保护处理, 所以 <strong>最终导致了一些问题的出现</strong>;</p><h3 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h3><ol><li><p>如果 事务A 读取了另一个并行 事务B <strong>未最终提交的写数据</strong>, 那事务A的这次读取操作就叫 <strong>脏读</strong></p><ul><li>因为 事务A 此时读取到的是 并行事务B 尚未最终持久化的数据 (该数据还不具备事务的 持久性)</li><li>事务B 最终可能会因为其事务单元内部其他后续操作的失败 或者 系统后续突然崩溃等原因, 导致事务B最终整体提交失败而回滚, 那么最终 事务A 之前拿到就是 <strong>脏的数据</strong> 了<br>(当然, 如果 事务A 在后续操作中继续读取的话, 无论事务B是否结束, 其每次的更新操作, 事务A都会及时读到新数据, 只不过这同时涉及到了下一个讨论的 不可重复读问题, 暂时可以不了解)</li></ul></li><li><p>图示:<br> <img src="/img/mysql/transaction/dirty_read.png" width="550/"></p></li><li><p><strong>解决方案</strong> : <code>RC+</code></p><ul><li>在MySQL中, 事务已经用自身隔离性解决了脏读问题 : <strong>READ COMMITED</strong> 或 <strong>以上隔离级别</strong>(RC+);</li><li>READ COMMITED 隔离级别保证了: 在事务单元中, 某条语句执行时, 只有已经被其他事务提交的持久性落地数据, 才对该语句可见;</li></ul></li></ol><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><ol><li><p>之前 脏读问题 的解决了, 仅仅只意味着事务单元中的每条语句读取到的数据都是 具备持久性的落地数据<strong>而已</strong>; </p><ul><li>之前在讨论脏读问题时, 有个问题也同时存在着, 那就是一个事务单元中 <strong>不可重复读</strong> 的问题; </li><li>显然, RC 隔离级别只解决了 脏读的问题</li></ul></li><li><p>如果在一个事务中多次读取同一个数据, 正好在两次读取之间, 另外一个事务已经完成了对该数据的修改并提交, 那问题就来了: <strong>两次读取的结果不一样了</strong><br> <img src="/img/mysql/transaction/unReRead.png" width="550/"></p></li><li><p><strong>解决方案</strong> : <code>RR+</code></p><ul><li>在MySQL中, 事务已经用自身隔离性解决了 不可重复读 问题  — <strong>REPEATABLE READ</strong> 或 <strong>以上隔离级别</strong>(RR+);</li><li>REPEATABLE READ 级别保证了:<br>在事务中, 某条语句执行前, 已经被其他事务 提交/回滚 的落地数据, 对该语句都是可见的; ( <code>READ COMMITED</code> )<br>在事务中, 多次读取同一个数据(在两次读取操作之间, 无论数据被 提交 多少次(即无论落地过多少遍), 每次读取的结果都应该是和事务中第一次读取的结果一样;  </li></ul></li></ol><h3 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h3><ol><li><p>可以参考 <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-next-key-locking.html" target="_blank" rel="noopener">MySQL官方文档对 Phantom Rows 的介绍</a> )</p></li><li><p>不可重复读 和 幻读 这两个概念容易搞混</p><ul><li>不可重复读 主要是说多次读取同一条记录, 发现该记录中某些列值被其他事务修改过; </li><li>而 幻读 主要是说多次读取一个范围内的记录(包括直接查询所有记录结果或者做聚合统计), 发现结果不一致(比如发现增加/减少了一条记录);</li></ul></li><li><p><strong>解决方案</strong>: <code>RR + MVCC</code></p><ul><li>其实对于 幻读 问题, 在Mysql的InnoDB存储引擎中, 是通过事务的 <code>RR + MVCC机制</code> 进行解决的;<br>当然, 这里的幻读不涉及 具有当前读能力的那些语句; (也就是说只是解决幻读, 所谓幻写之类的就不在范围内了)</li><li>另外可以参考《高性能MySQL》对 <code>RR</code> 隔离级别的描述 <blockquote><p>理论上, RR级别是无法解决幻读的问题, 但是由于InnoDB引擎的RR级别还使用了MVCC, 所以也就避免了幻读的出现!</p></blockquote></li></ul></li><li><p>之所以 不可重复读 和 幻读 容易搞混, 可能是因为:</p><ul><li>在mysql中, 由于默认就是RR隔离级别下, 该隔离级别已经解决了幻读, 所以无法模拟出幻读的场景; </li><li>而 退回到 RC隔离级别 的话, 虽然 幻读 和 不可重复读 都会出现, 但由于现象都是两次读取结果不一样, 容易分辨不出! </li></ul></li><li><p>想了解更多, 可以参考下一篇<a href="/2017/09/16/mysql/2017-09-16-mysql-22/">幻读的延伸</a></p></li></ol><h2 id="高并发事务问题-之-更新丢失"><a href="#高并发事务问题-之-更新丢失" class="headerlink" title="高并发事务问题 之 更新丢失"></a>高并发事务问题 之 更新丢失</h2><p>最后聊一下高并发事务的另一个问题, 也是最常遇到的问题: <strong>丢失更新问题</strong>; 该问题和之前几个问题需要区分开: 该问题需要我们自己来解决;<br>更新丢失问题分为两类</p><h3 id="第一类丢失更新-回滚覆盖"><a href="#第一类丢失更新-回滚覆盖" class="headerlink" title="第一类丢失更新(回滚覆盖)"></a>第一类丢失更新(回滚覆盖)</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><ol><li><p>事务A 回滚时, 将 事务B 已经提交的数据覆盖了<br> <img src="/img/mysql/transaction/loss-update-01.png"></p></li><li><p>需要注意的是: 这种情况在Mysql中不会出现;</p></li></ol><h4 id="RU-级别演示"><a href="#RU-级别演示" class="headerlink" title="RU 级别演示"></a>RU 级别演示</h4><ol><li><p>对于InnoDB事务的最低隔离级别 <code>READ UNCOMMITED</code>, 并行事务B的未提交数据都可以读到, 更别说已提交数据了 (所以回滚也会回滚到事务B提交的最新数据)<br> <img src="/img/mysql/transaction/lose_update_01_r_u.png"></p></li><li><p>语句如下:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;</span><br><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">update test_transaction set age = age-10 where id=2;</span><br><span class="line">rollback;</span><br></pre></td></tr></table></figure> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;</span><br><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">update test_transaction set age = age - 15 where id=2;</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure></li></ol><h4 id="RC-级别演示"><a href="#RC-级别演示" class="headerlink" title="RC 级别演示"></a>RC 级别演示</h4><ol><li><p>对于 <code>READ COMMITTED</code>: 在事务B提交之后, 事务A在T3阶段是可以select(<strong>快照读</strong>)到事务B最终提交的数据的, 更别说update(<strong>当前读</strong>)到了, 所以事务A最终的Rollback其实也是基于事务B提交后的数据的 (关于这里提到的快照读和当前读, 下一篇会介绍)<br> <img src="/img/mysql/transaction/lose_update_01_r_c.png"></p></li><li><p>语句如下:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;</span><br><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">update test_transaction set age = age-10 where id=2;</span><br><span class="line">rollback;</span><br></pre></td></tr></table></figure> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;</span><br><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">update test_transaction set age = age - 15 where id=2;</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure></li></ol><h4 id="RR-级别演示"><a href="#RR-级别演示" class="headerlink" title="RR 级别演示"></a>RR 级别演示</h4><ol><li><p>对于 <code>REPEATABLE READ</code> 可重复读, 事务A在T3阶段虽然select不到事务B最终提交的数据(<strong>快照读</strong>), 但是可以update(<strong>当前读</strong>)到事务B最终提交的数据的<br> <img src="/img/mysql/transaction/lose_update_01_r_r.png"><br> (注意: RR与RC虽然都会有快照读, 但是快照读的结果却不一致, 其实是因为两者的MVCC机制快找时机不同导致的, 后面会讲解)</p></li><li><p>语句如下:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line"></span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">update test_transaction set age = age+10 where id=2;</span><br><span class="line">rollback;</span><br></pre></td></tr></table></figure> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">update test_transaction set age = age-15 where id=2;</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure></li></ol><h4 id="SERIALIZABLE-演示"><a href="#SERIALIZABLE-演示" class="headerlink" title="SERIALIZABLE 演示"></a>SERIALIZABLE 演示</h4><ol><li><p><code>SERIALIZABLE</code> 串行化: <strong>读写都加锁</strong>, 最容易出现死锁, 所以也不会出现第一类丢失更新的问题, 直接就死锁了<br> <img src="/img/mysql/transaction/lose_update_01_s.png"></p></li><li><p>语句如下:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;</span><br><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">update test_transaction set age = age-10 where id=2;</span><br><span class="line">rollback;</span><br></pre></td></tr></table></figure> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;</span><br><span class="line">SELECT @@SESSION.tx_isolation;</span><br><span class="line">begin;</span><br><span class="line">select * from test_transaction where id=2;</span><br><span class="line">update test_transaction set age = age -15 where id=2;</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure></li></ol><h3 id="第二类丢失更新-提交覆盖"><a href="#第二类丢失更新-提交覆盖" class="headerlink" title="第二类丢失更新(提交覆盖)"></a>第二类丢失更新(提交覆盖)</h3><ol><li><p>直接上图<br> <img src="/img/mysql/transaction/lose_update-02.png"></p></li><li><p><strong>另外, 这里可以解释一下为什么 SERIALIZABLE级别 通常不会不被采用</strong></p><ul><li>其实 SERIALIZABLE 虽然做了串行化, 其实也就是对读写都加了锁, 但一旦事务并行, 如果将判断库存的读操作放在事务内就很容易会死锁<br>而放在事务外, 由于更新操作仍然会依据上一个查询的结果, 所以仍然是避免不了第二类丢失更新问题的, 会造成<strong>超卖</strong>等问题;</li><li>SERIALIZABLE 的串行化本身也太低效</li><li>另外, 可以参考: <a href="https://segmentfault.com/q/1010000010353164/a-1020000010353684" target="_blank" rel="noopener">https://segmentfault.com/q/1010000010353164/a-1020000010353684</a></li></ul></li><li><p>解决第二类丢失更新的方案:</p><ul><li><code>乐观锁</code> (在修改时, where判断数据是否为你读取时的数据; 或者提供数据版本字段来控制)</li><li><code>悲观锁</code> </li></ul></li></ol><p>参考资料:</p><ul><li>《高性能MySQL》</li><li><a href="http://mysql.taobao.org/monthly/2017/06/07/" target="_blank" rel="noopener">淘宝数据库内核6月报</a></li><li><a href="https://tech.meituan.com/innodb-lock.html" target="_blank" rel="noopener">美团技术博客</a></li><li><a href="https://dev.mysql.com/doc/refman/5.7/en/" target="_blank" rel="noopener">MySQL官方文档</a></li></ul><p>最后更新时间 2018/09/01</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;上一篇&lt;a href=&quot;/2017/09/16/mysql/2017-09-16-mysql-20/&quot;&gt;MySQL事务简介&lt;/a&gt;中对MyS
      
    
    </summary>
    
      <category term="MySQL" scheme="http://blog.renyimin.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://blog.renyimin.com/tags/MySQL/"/>
    
      <category term="事务" scheme="http://blog.renyimin.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>25. MySQL 事务简介</title>
    <link href="http://blog.renyimin.com/2017/08/27/mysql/2017-08-27-mysql-25/"/>
    <id>http://blog.renyimin.com/2017/08/27/mysql/2017-08-27-mysql-25/</id>
    <published>2017-08-27T11:31:07.000Z</published>
    <updated>2018-09-01T14:02:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="事务的概念"><a href="#事务的概念" class="headerlink" title="事务的概念"></a>事务的概念</h2><ol><li><p>事务：可以理解为一个 <strong>独立的工作单元</strong>, 在这个独立的工作单元中, 可以有一组操作;<br> 放在这个独立工作单元中的一组操作, <strong>要么全部执行成功, 要么全部执行失败</strong></p></li><li><p>随处可见的例子: 假设有两个角色 ‘Iron Man’(余额500), ‘Wolverine’(余额15), 现在 ‘Iron Man’ 通过银行应用给 ‘Wolverine’ 转账100元, 那么本次转账操作至少需要三个步骤</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">检查`Iron Man`余额`&gt;=100`元</span><br><span class="line">从`Iron Man`余额中`-100`元</span><br><span class="line">给`Wolverine`余额`+100`元</span><br></pre></td></tr></table></figure></li><li><p><strong>注意</strong>: 上面的三个步操作，就需要打包在一个事务中作为 <strong>独立的工作单元</strong> 来执行。并且在 这个独立工作单元中的三个操作, 只要有任何一个操作失败, 则整体就应该是失败的, 那就必须回滚所有已经执行了的步骤;<br> 假设第二步操作成功, 但是第三步操作失败, 那么整个事务就应该是失败的, 就必须将第二步的操作回滚 (这也体现了事务最基本的一个特性: <strong>保证数据的一致性</strong>)</p></li></ol><h2 id="事务的ACID特性"><a href="#事务的ACID特性" class="headerlink" title="事务的ACID特性"></a>事务的ACID特性</h2><p>一个运行良好的事务处理系统必须具备下面这些标准特性(高并发离不开事务的这几个标准特性) </p><h3 id="Atomicity-原子性"><a href="#Atomicity-原子性" class="headerlink" title="Atomicity 原子性"></a>Atomicity 原子性</h3><p>一个事务必须被视为一个不可分割的最小工作单元;<br>对于一个事务来说, 不能只成功执行其中的一部分操作, 整个事务中的所有操作要么全部成功提交, 要么有操作失败导致所有操作全部回滚, 这就是事务的原子性。</p><h3 id="Consistency-一致性"><a href="#Consistency-一致性" class="headerlink" title="Consistency 一致性"></a>Consistency 一致性</h3><p>此一致性非彼一致性</p><p>你大概可以这样来理解: 虽然数据表中的数据可能一直在变化, 但是事务的一致性特性保证的是 <strong>数据库总是从一个数据一致性的状态 转换到 另一个数据一致性的状态</strong>, 而不是分布式中提到的数据一致性; </p><p>比如之前转账的例子:</p><ul><li>转账前的数据一致性状态是: ‘Iron Man’(余额500), ‘Wolverine’(余额15)</li><li>转账成功后的数据一致性状态是: ‘Iron Man’(余额400), ‘Wolverine’(余额115)</li><li>转账如果失败的话, 数据的一致性的状态应该回滚到转账前的状态: ‘Iron Man’(余额500), ‘Wolverine’(余额15)</li></ul><h3 id="Isolation-隔离性"><a href="#Isolation-隔离性" class="headerlink" title="Isolation 隔离性"></a>Isolation 隔离性</h3><ol><li><p><strong>通常来说</strong>, 一个事务所做的修改在最终提交以前, 对其他事务是不可见的<br>比如在之前的转账例子中, 在执行完成最后一步(第三步), 事务还没来得及最终提交之前, 此时有另一个程序去读取 Iron Man账户 的余额, 那么这个程序读到的应该是500才对</p></li><li><p>上面为什么说 <strong>通常来说</strong>, 难道还有其他情况 ?<br>后面会详细讨论事务 隔离性 的四个 <strong>隔离级别</strong>, 到时候就知道这里为什么说 通常来说 ; (确实有特例, 比如最低隔离级别 <code>READ UNCOMMITTED</code>, 对其他事务的可见就造成了 <code>脏读问题</code> 的出现)</p></li><li><p>事务有四种隔离级别(从低到高)</p><ul><li><code>READ UNCOMMITTED</code>    (未提交读)</li><li><code>READ COMMITTED</code>      (提交读)<br>(注意: 和RR一样都采用了MVCC机制, 但与RR级别主要区别是快照时机不同, 暂时可不必了解, 后面文章会详解)</li><li><code>REPEATABLE READ</code>     (可重复读)</li><li><code>SERIALIZABLE</code>        (可串行化) <strong>注意: 只有该隔离级别才会读写都加锁</strong></li></ul></li></ol><h3 id="Durability-持久性"><a href="#Durability-持久性" class="headerlink" title="Durability 持久性"></a>Durability 持久性</h3><ol><li>一旦事务被最终提交后, 在这个独立单元中的所有操作所做的修改将会 永久保存到数据库中; </li><li><strong>所谓永久, 也只是主观上的永久, 可以理解为被事务修改的数据是真正存放到了表中, 而不是存放在了诸如临时表之类的地方</strong>;</li></ol><p>最后更新时间 2018/09/01</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;事务的概念&quot;&gt;&lt;a href=&quot;#事务的概念&quot; class=&quot;headerlink&quot; title=&quot;事务的概念&quot;&gt;&lt;/a&gt;事务的概念&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;事务：可以理解为一个 &lt;strong&gt;独立的工作单元&lt;/strong&gt;, 在这个独立的工作单元中,
      
    
    </summary>
    
      <category term="MySQL" scheme="http://blog.renyimin.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://blog.renyimin.com/tags/MySQL/"/>
    
      <category term="事务" scheme="http://blog.renyimin.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
</feed>
