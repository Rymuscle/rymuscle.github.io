<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lant&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.renyimin.com/"/>
  <updated>2018-07-20T07:38:58.000Z</updated>
  <id>http://blog.renyimin.com/</id>
  
  <author>
    <name>Lant</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>32. 单机部署集群 -- 普通集群</title>
    <link href="http://blog.renyimin.com/2018/06/26/rabbitmq/2018-06-26-rabbitmq-32/"/>
    <id>http://blog.renyimin.com/2018/06/26/rabbitmq/2018-06-26-rabbitmq-32/</id>
    <published>2018-06-26T07:28:16.000Z</published>
    <updated>2018-07-20T07:38:58.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>当你需要在生产环境中部署RabbitMQ时, 需要注意的是, 单实例在生产环境虽然部署起来很容易, 但是当你的rabbitmq服务器遇到内存崩溃或者断电的情况时, 这款高性能的产品就要成为你的耻辱了, 将会为你造成极大的问题!<br>因此你需要将你的RabbitMQ变成高可用的才行;</p><h2 id="内建集群简介"><a href="#内建集群简介" class="headerlink" title="内建集群简介"></a>内建集群简介</h2><ol><li><p>RabbitMQ最优秀的功能之一就是其内建集群, 这款消息队列中间件产品本身是基于Erlang编写, Erlang语言天生具备分布式特性(通过同步Erlang集群各节点的magic cookie来实现), 因此, RabbitMQ天然支持Clustering, 这使得RabbitMQ本身不需要像ActiveMQ、Kafka那样通过ZooKeeper分别来实现HA方案和保存集群的元数据。</p></li><li><p>RabbitMQ内建集群用来完成两个目标:</p><ul><li>允许生产者和消费者在RabbitMQ节点崩溃的情况下继续运行;<br>你可以失去一个RabbitMQ节点, 同时客户端可以重新连接到集群中的任何其他节点并继续生产或者消费消息, 就像什么都没有发生一样;</li><li>通过增加更多的节点来线性扩展消息吞吐量;<br>如果RabbitMQ正疲于应对庞大的消息通信量的话, 那么线性地增加更多的节点则会增加更多性能;</li></ul></li></ol><h2 id="集群的类型"><a href="#集群的类型" class="headerlink" title="集群的类型"></a>集群的类型</h2><p>Rabbit集群模式大概分为两种: <strong>普通模式</strong>、<strong>镜像模式</strong>; 本篇主要介绍普通模式</p><h2 id="普通模式"><a href="#普通模式" class="headerlink" title="普通模式"></a>普通模式</h2><ol><li><p>普通模式(也就是默认的集群模式), 对于该集群模式, 当你将多个节点组合成集群后, 需要注意的是: <strong>不是每一个节点都有所有队列的完全拷贝</strong></p><ul><li><p>在非集群的单一节点中, 所有关于队列的信息(元数据、状态、内容)都完全存储在该节点上;</p></li><li><p>但是如果在普通集群模式下创建队列的话, 集群只会在当前节点而不是所有节点上创建完整的队列信息(元数据、状态、内容); 而其他非所有者的节点, 只知道队列的元数据和指向该队列存在的哪个节点的指针;</p></li><li><p>因此当集群中队列所有者的节点崩溃时, 该节点的队列和关联的绑定就都消失了, 并且附加在这些队列上的消费者就会无法获取其订阅的信息, 并且生产者也无法将匹配该队列绑定信息的消息发送到队列中;</p></li></ul></li><li><p><strong>接下来需要了解的一个问题是</strong>: 为什么在默认的集群模式下, RabbitMQ不将队列内容和状态复制到所有的节点上? 其实有两个原因</p><ul><li>存储空间: 如果每个集群节点都拥有所有Queue的完全数据拷贝, 那么每个节点的存储空间会非常大, 集群的消息积压能力会非常弱(无法通过集群节点的扩容提高消息积压能力);</li><li><p>性能: 消息的发布者需要将消息复制到每一个集群节点, 对于持久化消息来说, 网络和磁盘的负载都会明显增加, 最终只能保持集群性能平稳(甚至更糟);</p></li><li><p>所以, 通过设置集群中的唯一节点来负责特定队列, <strong>只有该负责节点才会因队列消息而遭受磁盘活动的影响</strong><br>所有其他节点需要将接受到的该队列的消息传递给该队列的所有者节点, 因此, 往RabbitMQ集群添加更多的节点意味着你将拥有更多的节点来传播队列, 这些新增节点为你带来了性能的提升;</p></li></ul></li><li><p>但是有人可能会想: 是否可以让消费者重新连接到集群上, 这样不就可以重新创建队列了? 但需要注意的是: </p><ul><li>因为一般如果我们的队列设置的是持久化的, 而在该队列的主节点挂掉之后, 重新连接到队列时, 一般也不会修改队列的持久化属性; </li><li>这就需要注意一个问题, 仅当你之前创建的队列为非持久化时, 你才可以重新创建该队列为持久化, 因为这是为了保证你之前的持久化队列节点在重新被恢复启动后, 其中的消息还会被恢复, 而如果你创建一个新的持久化队列, 如果覆盖之前的持久化队列, 那消息不就丢了!!<br>所以如果之前是持久化队列, 而且还是以持久化的方式创建该队列, 集群就会报错误, 后面会进行测试! </li></ul></li></ol><h2 id="了解内部元数据"><a href="#了解内部元数据" class="headerlink" title="了解内部元数据"></a>了解内部元数据</h2><p>RabbitMQ内部会始终同步四种类型的内部元数据:</p><ul><li>队列元数据: 队列名称和它的属性 (是否可持久化, 是否自动删除);</li><li>交换器元数据: 交换器名称、类型和属性 (可持久化等);</li><li>绑定元数据: 一张简单的表格展示了如何将消息路由到队列;</li><li>vhost元数据: 为vhost内的队列、交换器和绑定提供命名空间和安全属性;</li></ul><h2 id="内存or磁盘节点"><a href="#内存or磁盘节点" class="headerlink" title="内存or磁盘节点"></a>内存or磁盘节点</h2><ol><li><p>每个Rabbitmq节点, 不管是单一节点系统或者是庞大集群的一部分, 要么是内存节点(RAM node), 要么是磁盘节点(disk node):</p><ul><li>内存节点将所有的队列、交换器、绑定、用户、权限和vhost的元数据定义都仅存储在内存中;</li><li>而磁盘节点则将元数据存储在磁盘中;</li></ul></li><li><p>非集群单一节点: 在单一节点的非集群环境中, RabbitMQ默认会将元数据都存放在<strong>内存中</strong>; 但是, 会将标记为可持久化的队列和交换器(以及它们的绑定)存储到硬盘上, 存储到硬盘上可以确保队列和交换器在重启Rabbitmq节点后重新被创建;</p></li><li><p>集群节点类型 </p><ul><li>当你引入Rabbitmq集群后, RabbitMQ需要追踪的元数据类型包括: 集群节点位置, 以及节点与已记录的其他类型的元数据的关系;</li><li>集群对元数据的存储提供了选择:<br>将元数据存储到磁盘上 (集群中创建节点时的默认设置) 或者 存储到RAM内存中</li></ul></li><li><p>注意, RabbitMQ要求在集群中至少要有一个磁盘节点, 所有其他节点可以是内存节点。当节点加入或者离开集群时, 它们必须要将变更至少通知到一个磁盘节点; 如果只有一个磁盘节点, 而不凑巧的是它有刚好崩溃, 那么集群虽然可以继续路由消息, 但是不能做一下操作:</p><ul><li>创建队列</li><li>创建交换器</li><li>创建绑定</li><li>添加用户</li><li>更改权限</li><li>添加或删除集群节点</li></ul></li></ol><h2 id="集群配置钱准备"><a href="#集群配置钱准备" class="headerlink" title="集群配置钱准备"></a>集群配置钱准备</h2><ol><li><p>在开始配置集群前, 首先要确保现存的Rabbitmq没有运行, 因此需要关闭节点 (本机为mac, 关闭操作如下)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ brew services stop rabbitmq</div><div class="line">Stopping `rabbitmq`... (might take a while)</div><div class="line">==&gt; Successfully stopped `rabbitmq` (label: homebrew.mxcl.rabbitmq)</div></pre></td></tr></table></figure><p> 可以发现一个问题, 就是停止Rabbitmq服务之后, 貌似 RabbitMQ Management 的Web UI界面还是可以正常打开运行; 所以正确的关闭节点貌似是 <code>rabbitmqctl stop</code></p></li><li><p>开始配置集群前需要注意:</p><ul><li><p>通常来讲, 使用 <code>rabbitmq-server</code> 命令启动节点之后就大功告成了, 但是如果不用额外参数的话, 该命令会使用默认的节点名称 <code>rabbit</code> 和监听端口 <code>5672</code>;<br>所以如果你想用该命令在一台机器上同时启动3个节点的话, 那么第2，3个节点都会因为节点名称和端口号冲突而导致启动失败; </p></li><li><p>因此, 为了在本机正常启动5个节点, 可以在每次调用 <code>rabbitmq-server</code>前, 通过设置环境变量 <code>RABBITMQ_NODENAME</code>, <code>RABBITMQ_NODE_PORT</code> 来明确指定唯一的节点名称和端口号!<br>在此处做实验时, 将会采用 rabbit, rabbit_1,rabbit_2 命名节点名; 端口号为5612，5613, 5614</p></li><li><p><strong>注意</strong>, 到目前为止, 虽然尚未谈论RabbitMQ的插件, 不过你有可能已经启用了一部分插件了; 如果确实如此的话, 你需要在启动集群节点前将插件禁用!<br>这是因为像 RabbitMQ Management 这样的插件会监听专门的端口来提供服务(例如 Management 插件的 Web UI), 目前还没讲到如何设置插件监听不同的端口, 所以当第二个节点和之后的节点启动了它们的插件后, 就会和第一个启动节点的c插件相冲突, 然后节点就都崩溃了;<br>可以先不禁用插件, 这样在启动多个节点时, 可以根据报错一个个关闭插件也可以; (<code>rabbitmq-plugins disable 插件名</code>)</p></li></ul></li></ol><h2 id="RabbitMQ集群的搭建"><a href="#RabbitMQ集群的搭建" class="headerlink" title="RabbitMQ集群的搭建"></a><a href="http://www.rabbitmq.com/clustering.html#creating" target="_blank" rel="external">RabbitMQ集群的搭建</a></h2><ol><li><p>启动节点</p><ul><li><p>注意: 启动的时候, 直接加上 <code>-detached</code> 参数的话, 可能会有些报错信息比如 <code>error : cannot_delete_plugins_expand_dir</code>, 这就是因为需要使用root权限才可以, 你可以使用 <code>pa aux | grep rabbitmq</code> 查看是否三个进程都成功启动了</p></li><li><p>注意: 启动时, 貌似不能像书上那样, RABBITMQ_NODENAME 只设置节点名, 最好设置上节点host</p></li><li><p>如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detached</div><div class="line">Warning: PID file not written; -detached was passed.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit_1@localhost rabbitmq-server -detached</div><div class="line">Warning: PID file not written; -detached was passed.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit_2@localhost rabbitmq-server -detached</div><div class="line">Warning: PID file not written; -detached was passed.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>然后可以查看个节点状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost status</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost status</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost status</div></pre></td></tr></table></figure></li></ul></li><li><p>现在启动了三个节点 rabbit, rabbit_1, rabbit_2, 并且每个节点都会有系统的主机名在@后; 但是每个节点仍然是独立节点, 拥有自己的元数据, 并且不知道其他节点的存在;</p><ul><li>集群中的第一个节点rabbit,将初始元数据带入集群, 并且无需被告知加入;</li><li>而第二个和之后的节点, 将加入第一个节点rabbit, 并获取rabbit节点的元数据;  </li></ul></li><li><p>要将rabbit_1和rabbit_2节点加入rabbit, 要停止该Erlang节点上运行的rabbitmq应用程序, 并重设它们的元数据, 这样它们才可以被加入rabbit节点并且获取rabbit节点的元数据; 可以使用 <code>rabbitmqctl</code> 来完成这些工作</p><ul><li><p>停止rabbit_1节点上的应用程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost stop_app</div><div class="line">Stopping rabbit application on node rabbit_1@renyimindeMacBook-Pro ...</div></pre></td></tr></table></figure></li><li><p>重设rabbit_1节点的元数据和状态为清空状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost reset</div><div class="line">Resetting node rabbit_1@renyimindeMacBook-Pro ...</div></pre></td></tr></table></figure></li><li><p>这样你就准备好了一个 停止运行的并且清空了的 rabbit 应用, 现在可以准备好将其加入到集群中的第一个节点rabbit中:<br>注意书上的 <code>cluster</code> 命令好像已经不用了, 换成了 <code>join_cluster</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost join_cluster rabbit@localhost</div><div class="line">Clustering node rabbit_1@localhost with rabbit@localhost</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>最后, 可以重启第二个节点的应用程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_app</div><div class="line">Starting node rabbit_1@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>节点rabbit_2加入集群的步骤同上, 具体操作如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_app</div><div class="line">Starting node rabbit_1@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_app</div><div class="line">Stopping rabbit application on node rabbit_2@localhost ...</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost reset</div><div class="line">Resetting node rabbit_2@localhost ...</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost join_cluster rabbit@localhost</div><div class="line">Clustering node rabbit_2@localhost with rabbit@localhost</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_app</div><div class="line">Starting node rabbit_2@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ul></li><li><p>查看集群状态, 可以在任意一个节点通过 <code>rabbitmqctl cluster_status</code> 进行查看</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_status</div><div class="line">Cluster status of node rabbit@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;]&#125;]</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_status</div><div class="line">Cluster status of node rabbit_1@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;]&#125;]</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost cluster_status</div><div class="line">Cluster status of node rabbit_2@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_2@localhost,[]&#125;]&#125;]</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>注意: </p><ul><li>上面使用比较多的 <code>rabbitmqctl</code> 命令的关键参数是 <code>-n</code>, 这会告诉rabbitmqctl命令, 你想在指定节点而非默认节点<code>rabbit@</code>上执行命令;</li><li>记住, Erlang节点间通过Erlang cookie的方式来允许互相通信。因为rabbitmqctl使用Erlang OPT通信机制来和Rabbit节点通信, 运行rabbitmqctl的机器和所要连接的Rabbit节点必须使用相同的Erlang cookie, 否则你会得到一个错误;<br>当然, 上面的集群是在本机做伪集群, Erlang cookie 自然也都是一致的!</li></ul></li><li><p>将节点从集群中删除 <code>forget_cluster_node</code></p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_1@localhost</div><div class="line">Removing node rabbit_1@localhost from the cluster</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_2@localhost</div><div class="line">Removing node rabbit_2@localhost from the cluster</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_3@localhost</div><div class="line">Removing node rabbit_3@localhost from the cluster</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ol><h2 id="集群节点类型设置与修改"><a href="#集群节点类型设置与修改" class="headerlink" title="集群节点类型设置与修改"></a><a href="http://www.rabbitmq.com/clustering.html#change-type" target="_blank" rel="external">集群节点类型</a>设置与修改</h2><ol><li><p>可以在将节点加入集群时, 设定节点的类型 (<a href="http://www.rabbitmq.com/clustering.html#creating-ram" target="_blank" rel="external">参考</a>)<br> 比如 <code>rabbitmqctl -n rabbit_3@localhost join_cluster --ram rabbit@localhost</code></p></li><li><p>之前已经通过 <code>rabbitmqctl cluster_status</code> 查看了集群的状态, 里面比较重要的是 <code>nodes</code> 部分</p><ul><li><p>下面告诉你有三个节点加入了集群, 并且三个节点都是 disc 磁盘节点!</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line">     &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;,</div><div class="line">     &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line">     &#123;partitions,[]&#125;,</div><div class="line">     &#123;alarms,[&#123;rabbit@localhost,[]&#125;,</div><div class="line">              &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">              &#123;rabbit_2@localhost,[]&#125;]&#125;]</div></pre></td></tr></table></figure></li><li><p>running_nodes 部分告诉你集群中的哪些节点正在运行; </p></li></ul></li><li><p>现在你可以连接到这三个running_nodes中的任何一个, 并且开始创建队列, 发布消息或者执行任何其他AMQP任务; </p></li><li><p>你也可以对节点类型进行修改, 如下将rabbit_2节点类型修改为内存节点 (注意: 修改节点类型, 需要先停止节点应用)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_app</div><div class="line">Stopping rabbit application on node rabbit_2@localhost ...</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost change_cluster_node_type ram</div><div class="line">Turning rabbit_2@localhost into a ram node</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_app</div><div class="line">Starting node rabbit_2@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_status</div><div class="line">Cluster status of node rabbit_1@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost]&#125;,</div><div class="line">         &#123;ram,[rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;]&#125;]</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ol><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><ol><li>运行<a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/LocalClusterController.php" target="_blank" rel="external">生产者代码</a>, 在集群中的rabbit节点中创建持久化队列<ul><li>初始集群状态<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_status</div><div class="line">Cluster status of node rabbit@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindemacbook-pro.rrcoa.com&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;]&#125;]</div></pre></td></tr></table></figure></li></ul></li></ol><pre><code>- 运行生产者, 查看创建的队列(已经有一条msg放入队列中)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></code></pre><ol><li><p>kill掉该持久化队列localClusterQueue所在的主节点rabbit</p><ul><li><p>查看节点进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ ps aux | grep rabbitmq</div><div class="line">root              2656   0.4  0.3  4150148  58156   ??  S    三01下午   5:09.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5672&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost&quot; -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 -noshell -noinput</div><div class="line">renyimin         28537   0.0  0.0  2423384    232 s007  R+    3:12下午   0:00.00 grep rabbitmq</div><div class="line">root             72516   0.0  0.5  4143168  79400   ??  S     1:03下午   0:16.71 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_2@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5674&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost&quot; -kernel inet_dist_listen_min 25674 -kernel inet_dist_listen_max 25674 -noshell -noinput</div><div class="line">root             71841   0.0  0.5  4138448  77104   ??  S     1:01下午   0:15.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_1@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5673&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost&quot; -kernel inet_dist_listen_min 25673 -kernel inet_dist_listen_max 25673 -noshell -noinput</div></pre></td></tr></table></figure></li><li><p><code>sudo kill 2656</code></p></li></ul></li><li><p>将生产者改连 rabbit_1 节点, 重新运行生产者</p><ul><li>报错:<br><img src="/img/rabbitmq/cluster-error01.png"></li><li>挂掉的主节点中<strong>已存在该持久化队列</strong>, 如果在主节点挂掉后, 你能直接连接其他节点创建该队列的话, 此时创建的是个新队列, 要知道, 宕机的主节点中的持久化队列还在等待恢复呢, 它内部可能让然有很多msg需要恢复并被处理;<br>所以Rabbit集群的这个问题是有原因的!!</li></ul></li><li><p>可以重新启动该节点 <code>sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detached</code></p><ul><li>会发现之前的持久化队列会被恢复<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue1</div><div class="line">prefetchCountQueue0</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue1</div><div class="line">prefetchCountQueue0</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue1</div><div class="line">prefetchCountQueue0</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ul></li><li><p>此时即使生产者连接着 rabbit_1 也可以创建该同名持久化队列了</p><ul><li>重新运行刚才连接到 rabbit_1 的生产者, 不会报错了, 而是正确往队列发布了一条消息<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue2</div><div class="line">prefetchCountQueue0</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;当你需要在生产环境中部署RabbitMQ时, 需要注意的是, 单实例在生产环境虽然部署起来很容易, 但是当你的rabbitmq服务器遇到内存
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>20. 消费者预取 Consumer Prefetch</title>
    <link href="http://blog.renyimin.com/2018/06/13/rabbitmq/2018-06-13-rabbitmq-20/"/>
    <id>http://blog.renyimin.com/2018/06/13/rabbitmq/2018-06-13-rabbitmq-20/</id>
    <published>2018-06-13T11:23:36.000Z</published>
    <updated>2018-07-19T02:06:14.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Consumer-Prefetch"><a href="#Consumer-Prefetch" class="headerlink" title="Consumer Prefetch"></a><a href="https://www.rabbitmq.com/consumer-prefetch.html" target="_blank" rel="external">Consumer Prefetch</a></h2><ol><li><p>作为限制 unacked 消息数量的更自然有效的方法; AMQP 0-9-1 指定了 <code>basic.qos</code> 方法, 以便你在消费者进行消费时, 可以限制channel(或connection)上未确认消息的数量; </p><ul><li>但是值得注意的是: channel 并不是理想的设定范围, 因为单个channel可能从多个队列进行消费, channel和queue需要为每个发送的消息相互协调, 以确保它们不会超出限制, 这在单台机器上会慢, 而在整个集群中使用时会非常慢;</li><li>此外, 对于许多用途, 指定<strong>适用于每个消费者的预取计数</strong>更会简单一些;</li></ul></li><li><p>因此, RabbitMQ在 <code>basic.qos</code> 方法中重新定义了<strong>全局标志</strong>的含义 (在php-amqplib中basic_qos()的第三个参数a_global):<br> <img src="/img/rabbitmq/qos-global.png"><br> 请注意, 在大多数API中, 全局标志的默认值为false; (php-amqplib的basic_qos()方法的第三个参数a_global默认也为false)</p></li></ol><h2 id="简要分析"><a href="#简要分析" class="headerlink" title="简要分析"></a>简要分析</h2><ol><li><p>在使用RabbitMQ时, 如果完全不配置QoS, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是采用默认方式, 将队列中的所有消息按照网络和客户端允许的速度<strong>尽快轮发</strong>到与队列绑定的consumers端; 而consumers会在本地缓存所有投递过来的messages, 这样的话, 就可能会导致</p><ul><li>如果某个消费者的业务逻辑处理比较复杂(将会在较长时间之后才会操作完成并进行ack), 这也就导致消费慢的Consumer将会在本地堆积很多消息, 从而导致内存不足或者对其他进程造成影响 (<strong>消费者可能被撑到假死</strong>);</li><li>而其他消费能力强的Consumers, 可能已经很快地消费完成处于闲置状态, <strong>从而造成资源浪费</strong>; </li><li>同时, 新启的消费者也无法分担已经被之前消费者缓存到其本地的消息, 所以此时即便启动更多消费者, 也<strong>无力缓解大量的 unacked 消息积压, 让你产生疑惑</strong>;</li></ul></li><li><p><strong>而当你设置了Qos之后, RabbitMQ虽然也是将队列中的消息尽快轮发到Consumers中, 但是因为消费者具有的 prefetch_count 消息预取值上限, 所以RabbitMQ在轮发消息的时候, 如果发现消费者的 unacked 消息达到了 prefetch_count 的值, 即使rabbitmq中有很多ready的就绪消息, 也不会给该Consumer继续投递消息了(只有消费者的 unacked 消息小于prefetch_count的值时, 才会继续通过轮发方式给该consumer投递ready消息), 如果此时有新的消费者加入, 它也将会拿到未投递出去的ready消息!</strong></p><ul><li>可以通过启动 prefetchCountConsumer1，prefetchCountConsumer2 两个消费者(prefetch_count 均为10), 然后使用下面测试中的生产者发送100条消息, 前期观察会发现队列中消息的最大 unacked 为20, 并且你会发现队列中处于ready状态的消息会每次2个的递减, 这就预示着, 每次这两个消费者只要 unacked 的消息书小于prefetch_count(10), Rabbitmq才会给这两个consumer各自发送一条msg;</li><li>之后如果启动了 prefetchCountConsumer3(prefetch_count为20), 此时会发现队列中消息的最大 unacked 会为40, prefetchCountConsumer3的加入会使得队列中处于ready状态的消息直接骤减20个, 最后rabbitmq中的ready消息已经为0, 每个消费者还在继续消费各自未 unacked 的消息, 最终消费完成后, 整个队列中的 unacked 消息为0;</li></ul></li><li><p>Qos的设置只有在<strong>开启手动ack</strong>后才会生效 (即, prefetch_count 在 no_ask=false 的情况下生效)</p></li></ol><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><ol><li><p>一般情况下, 同一队列绑定的多个消费者都是处理同一个业务, 而且如果在同一台机器启动, 消费能力应该都差不多, 但也难免出现如: 消费者资源分配不均 或者 两个消费者在处理业务时所请求的服务端机器配置有差异(假设SLB后又2台配置不均的机器), 这种情况还是应该考虑进来的! </p></li><li><p>本测试比较简单, 主要测试在默认不设置Qos的情况下, 两个消费能力不同的消费者在处理消息时存在的问题之一: 由于这种情况下, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是只顾自己轮发消息, 这样就会导致消息被轮发完成后, 消费能力高的消费者可能很快消费完消息并处于闲置状态, 而消费能力低的消费者却在很慢地进行消费, <strong>这样就造成了资源的浪费</strong>;</p></li><li><p>准备</p><ul><li>创建消费者1 ‘qosCustomer1’ (简单打印消息内容) , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/qosConsumer1.php" target="_blank" rel="external">代码参考</a>, <strong>启动消费者</strong> <code>php artisan qosConsumer1</code></li><li>创建消费者2 ‘qosCustomer2’ (sleep 5秒, 模拟处理能力比较差) , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/qosConsumer2.php" target="_blank" rel="external">代码参考</a>, <strong>启动消费者</strong>  <code>php artisan qosConsumer2</code></li><li><p>创建生产者一次向队列 ‘qosQueue’ 中推送10条消息 , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/QosController.php" target="_blank" rel="external">代码参考</a>, <strong>请求一次生产者</strong> <a href="http://www.rabbit.com/testQos" target="_blank" rel="external">http://www.rabbit.com/testQos</a></p></li><li><p>注意需要先启动消费者, 再请求生产者; (如果先请求了生产者, 可能在启动第一个消费者之后, 其会迅速消费完10条消息, 这样就无法模拟效果了)</p></li></ul></li><li><p>测试发现</p><ul><li>qosCustomer1 : 迅速打印出结果(1,3,5,7,9), 然后就处于闲置状态了</li><li>qosCustomer2 : 还在缓慢打印(2,4,6,8,10)</li><li>可以看到, 如果不设置Qos, Rabbitmq会尽快将消息从队列中轮发投递出去, 不会对消费者的消费能力进行任何评估! </li></ul></li><li><p>所以: 为了避免这种浪费资源的情况, 你可能就需要根据上一篇讲解的 prefetch_count 来针对不同消费者进行设置;</p></li></ol><h2 id="问题答疑测试"><a href="#问题答疑测试" class="headerlink" title="问题答疑测试"></a>问题答疑测试</h2><ol><li><p>根据上面的描述, 有个疑问: 在默认不设置Qos的情况下, 既然生产者发布的消息会尽可能全部推送给消费者进程, 队列中会尽可能将消息全部推出, 缓存在消费者本地, 那当消费者断开时, 消息是如何恢复到队列中的? 或者不会恢复到队列中? 为了答疑, 下面进行测试 </p></li><li><p>准备测试代码</p><ul><li><p>创建消费者1 ‘prefetchCountConsumer1’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/prefetchCountConsumer1.php" target="_blank" rel="external">代码参考</a></p></li><li><p>创建消费者2 ‘prefetchCountConsumer2’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/prefetchCountConsumer2.php" target="_blank" rel="external">代码参考</a></p></li><li><p>生产者一次向队列 ‘prefetchCountQueue’ 中推送100条消息 , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/PrefetchCountController.php" target="_blank" rel="external">代码参考</a></p></li></ul></li><li><p>测试:</p><ul><li><p>在生产者请求一次之后(<a href="http://www.rabbit.com/prefetchCount" target="_blank" rel="external">http://www.rabbit.com/prefetchCount</a>), <code>ready : 100, unacked: 0, total : 100</code>, 表示队列中已经有100条消息已经就绪, 等待发出<br><img src="/img/rabbitmq/qos-test01.png" width="450"></p></li><li><p>运行第一个<code>php artisan prefetchCountConsumer1</code>之后, <code>ready : 0, unacked : 100, total : 100</code> (也就是说, queue中已经没有 ready状态, 即准备好待发送的消息了, 消息都传递给消费者1了)<br><img src="/img/rabbitmq/qos-test02.png" width="450"></p></li><li><p>随着消费者的缓慢消费, <code>ready : 0, unacked : 94, total : 94</code>  ()<br><img src="/img/rabbitmq/qos-test03.png" width="450"></p></li><li><p>如果模拟 挂掉第一个消费者之后, 会发现, <code>ready : 83， unacked : 0, total : 83</code> (<strong>也就是说消费者意外宕掉之后, 队列中的消息会重新处于就绪状态</strong>, 等待着新的消费者来消费)<br><img src="/img/rabbitmq/qos-test04.png" width="450"></p></li><li><p>再次启动消费者2 <code>php artisan testQosConsumerPrefetchCount2</code>之后, <code>ready : 0, unacked : 80, total : 80</code> (消息又会被全量发送给消费者2)</p></li><li><p>注意: 如果此时启动消费者1, 你会发现, 它是无法帮助消费者2进行消费的, 因为消息都在消费者2的本地, 所以队列中并没有 <strong>ready状态的就绪消息</strong>;</p></li></ul></li><li><p>测试注意: 上述测试过程如果先启动两个消费者, 然后再发布消息进行测试, 你会发现, 由于两个消费者都设置了预取值, 而且相等, 所以消息仍然会快速轮发给这两个消费者;</p><ul><li>如果将两个消费者的 prefetch_count 都设置为10, 那么你会发现, unacked 最多也就是两个消费者的prefetch_count和, 即20个<br><img src="/img/rabbitmq/qos-test05.png" width="450"></li></ul></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol><li><p>消费者的 unacked 消息数量如果未达到Qos设置的 prefetch_count 量, <strong>Rabbit不会顾及消费者的消费能力, 会尽可能将queue中的消息全部推送出去给消费者</strong>;</p></li><li><p>因此, 当你发现消费者消费缓慢, 产生大量 unacked 消息时, 即便增加新的消费者, 也无法帮助之前的消费者分担消息(除非消费者1的 unacked 达到了 prefetch_count 限制), 只能分担队列中处于 ready 状态的消息;</p></li><li><p>除非你断开之前的消费者, 然后启动一个新的消费者, 消费者中积压的消息才会重新放入队列中 (因为之前的消费者挂掉之后, 其处理后的剩余消息在 queue中会恢复为 ready 状态)<br> 但是注意: 新启动的这个消费者如果设置额prefetch_count不合理的话, 假设与之前消费者的 预取值 设置一样大, 它很快也会产生大量 unacked 消息<br> 所以, 在新启消费者的时候, 需要设计好 prefetch_count 的大小, 然后可以启动多个消费者来共同进行消费;</p></li></ol><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ol><li><p>rabbitmq对 basic.qos 信令的处理</p><ul><li>首先, basic.qos 是针对 channel 进行设置的, 也就是说只有在channel建立之后才能发送basic.qos信令; RabbitMQ只支持通道级的预取计数, 而不是connection级的 或者 基于大小的预取;<br><a href="http://www.bubuko.com/infodetail-1955647.html" target="_blank" rel="external">预取</a></li><li>在rabbitmq的实现中, 每个channel都对应会有一个rabbit_limiter进程, 当收到basic.qos信令后, 在rabbit_limiter进程中记录信令中prefetch_count的值, 同时记录的还有该channel未ack的消息个数;</li></ul></li><li><p>在<code>php-amqplib</code>中, 可以使用 channel 的 <code>basic_qos()</code> 方法来进行控制, <code>basic_qos()</code> 有三个参数:</p><ul><li>prefetch_size : 限制预取的消息大小的参数, rabbitmq暂时没有实现 (如果prefetch_size字段不是默认值0, 则会通知客户端出错, 通知客户端<strong>RabbitMQ系统没有实现该参数的功能</strong>, 还可以参考<a href="https://github.com/sky-big/RabbitMQ/blob/d7a773e11f93fcde4497c764c9fa185aad049ce2/src/rabbit_channel.erl" target="_blank" rel="external">此文</a>)<br>当你设置prefetch_size大于0的时候, 会出现如下报错<br><img src="/img/rabbitmq/qos-prefetch-size-error.png" width="400"></li><li>prefetch_count : 预取消息数量</li><li>global: 在3.3.0版本中对global这个参数的含义进行了重新定义, 即glotal=true时表示在当前channel上所有的consumer都生效(包括已有的), 否则只对设置了之后新建的consumer生效;</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Consumer-Prefetch&quot;&gt;&lt;a href=&quot;#Consumer-Prefetch&quot; class=&quot;headerlink&quot; title=&quot;Consumer Prefetch&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.rabbitmq.com/c
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>19. 消费者预取 Consumer Prefetch</title>
    <link href="http://blog.renyimin.com/2018/06/12/rabbitmq/2018-06-12-rabbitmq-19/"/>
    <id>http://blog.renyimin.com/2018/06/12/rabbitmq/2018-06-12-rabbitmq-19/</id>
    <published>2018-06-12T03:26:55.000Z</published>
    <updated>2018-07-20T11:29:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RabbitMQ关于吞吐量-延迟和带宽的一些理论"><a href="#RabbitMQ关于吞吐量-延迟和带宽的一些理论" class="headerlink" title="RabbitMQ关于吞吐量,延迟和带宽的一些理论"></a><a href="https://www.rabbitmq.com/blog/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth/" target="_blank" rel="external">RabbitMQ关于吞吐量,延迟和带宽的一些理论</a></h2><ol><li><p>假设你在Rabbit中有一个队列, 并有一些客户端从这个队列中进行消费, 如果你根本没有设置QoS, 那么Rabbit将尽可能快地按照网络和客户端允许的速度将所有队列的消息推送到客户端; 因此, 消费者所占用的内存将会激增, 因为它们将所有消息都缓存在自己的RAM中; 同时, 值得注意的是: 此时如果你询问Rabbit, <strong>队列可能会显示为空</strong>, 但是会有大量的 unacked 消息; 并且此时如果你添加新的消费者, 由于消息已经在现有的客户端中缓存, 队列中并没有 ready状态的 消息, 所以即使增加更多新的消费者, 也无法缓解队列中 unacked 消息数量, 这是相当次优的!</p></li><li><p>所以，默认的QoS预取给客户端(consumer)设置了无限的缓冲区, 这可能导致不良的行为和性能; 那么, 应该将QoS预取缓冲区大小设置为多少呢? 目标是让消费者保持工作饱和状态, <strong>但要尽量减少客户端的缓冲区大小, 以便让更多的消息保留在Rabbit的队列中, 这样就可以供新消费者来消费</strong>;</p></li><li><p>比方说, Rabbit从这个队列中拿出一条消息, 把它投递给消费者, 需要50ms, 而Consumer处理消息需要4ms; 一旦消费者处理了消息, 它就会发送一个ack给Rabbit, 这将再次花费50ms发送给Rabbit并被Rabbit进行处理; 所以 消费完成并进行一次ack的时间 + 一次消息从队列到Consumer的投递时间 总共会花费104ms的往返时间。</p><ul><li><p>如果我们消息设置了QoS预取值为1, 那么直到这个往返行程完成之前, Rabbit是不会发送下一个消息给客户端的;<br>因此, 每次往返的104ms中, Consumer只有4ms, 或者说只有3.8％的时间忙碌, 而我们希望Consumer百分之百的时间都在忙碌中;</p></li><li><p>如果我们在每个消息的客户端上执行 <code>总的往返时间/处理时间</code>, 会得到 <code>104/4 = 26</code><br>如果我们设置消息的QoS预取值为26, 那就解决了我们的问题: 如果每条消息需要4ms的处理来处理, 那么总共需要 <code>26×4 = 104ms</code> 来处理整个缓冲区(中的消息);<br>第一个4ms是第一个消息的处理时间, 处理完成后, 客户端然后发出一个确认(这需要50ms才能到达代理), 然后继续处理缓冲区中的下一条消息, 一次ack时间 + 新一轮消息的投递时间 = 100s, Consumer正好完成缓冲区剩下的25条消息, 然后新的26条消息也已经到达, 并准备好等待客户端来处理它;<br>因此, 客户端始终处于忙碌状态: 具有较大的QoS预取值也不会使其更快了, 但是我们最大限度地减少了缓冲区的大小, 并且减少了客户端消息的延迟;<br><strong>客户端能够在下一条消息到达之前完全排空缓冲区, 因此缓冲区实际上保持为空</strong>;</p></li><li><p>如果处理时间和网络行为保持不变, 此解决方案绝对没问题</p></li></ul></li><li><p>但考虑一下如果网络突然间速度减半会发生什么情况?</p><ul><li><p>显然, 网络传输时间就加长了, 此时你的预取缓冲区(也就是你设置的prefetch预取值)就不够大了, 现在Consumer会就会稍有闲置, 等待新消息到达, 因为客户端能够处理消息的速度比Rabbit能够提供新消息的速度要快;</p></li><li><p>为了解决这个问题, 我们可能会决定将QoS预取大小加倍(或接近两倍), 如果我们从26开始将它推到51, 那么如果客户端处理保持在每个消息4ms, 我们现在在缓冲区中会有51 * 4 = 204ms的消息处理时间, 其中4ms将用于处理消息, 而200ms用于发送消息回复rabbit并收到下一条消息, 因此, 我们现在可以应对网络速度的减半;</p></li></ul></li><li><p>再次分析: 如果网络又恢复正常运行, 现在将QoS预取加倍, 意味着每个消息都会驻留在客户端缓冲区中一段时间​​, 而不是在到达客户端时立即处理; 从现在51条消息的完整缓冲区开始, 我们知道新消息将在客户端完成处理第一条消息之后的100ms处开始出现在客户端, 但在这100毫秒内, 客户只能处理100/4 = 25个消息, 这意味着当新消息到达客户端时, 它会在客户端从缓冲区头部移除时被添加到缓冲区的末尾;</p><ul><li><p>而缓冲区将始终保持(50 - 25 = 25)个消息长度, <strong>因此每个消息将在缓冲区中保持 25 * 4 = 100ms</strong>;</p></li><li><p>因此, <strong>增加预取缓冲区大小, 可以使consumer应对恶化的网络性能, 同时保持客户端繁忙</strong>;</p></li></ul></li><li><p>同样, 如果不是网络性能的恶化, 而是客户端开始花费40ms来处理每条消息而不是之前的4ms, 会发生什么情况?</p><ul><li><p>假设原始的预取缓冲区大小设置的是26条消息, 客户端现在需要花40ms处理第一条消息, 然后将确认消息发送回Rabbit并移至下一条消息;<br>ack仍然需要50ms才能到达Rabbit, 而Rabbit发出一条新的消息需要50ms, 但在100ms内, 客户端只处理了 100/40 = 2.5 条消息, 而不是剩余的25条消息;<br>因此当新消息到来时, 缓冲区在这一点上仍然是有 25 - 3 = 22 个消息, 这样的话, 来自Rabbit的新消息就不会被立即处理, 而是位于第23位, 落后于其他22条仍在等待处理的消息;<br>客户端(Consumer)将会有 22 * 40 = 880ms 的时间都不会触及到那个新到的消息, 鉴于从Rabbit到客户端的网络延迟仅为50ms, 这个额外的880ms延迟现在为延迟的95％ (880 / (880 + 50) = 0.946);</p></li><li><p><strong>当你决定尝试通过添加更多消费者来处理这种增长的积压时, 需要注意, 现在有消息正在被现有客户端缓冲, 并不是说你增加消费者就能缓解这部分的压力!</strong></p></li><li><p>更糟糕的是, 如果我们将缓冲区大小设置为可以预取51条消息以应对网络性能下降,会发生什么?<br>处理第一条消息后, 将在客户端缓冲另外50条消息, 100ms后(假设网络运行正常), 一条新消息将从Rabbit到达客户端, consumer在100ms中只能处理这50条消息中的两条消息(缓冲区现在为47条消息长),<br>因此新消息将会在缓冲区中是第48位, 这样的话, 知道 47 <em> 40 = 1880ms 之后, 消费者才会开始处理新来的消息, 同样, 考虑到向客户端发送消息的网络延迟仅为50ms, 现在这个1880ms的延迟意味着客户端缓冲占延迟的97％(1880/(1880 + 50)= 0.974);<br>这可能是不可接受的: 数据只能在客户端收到后2秒内立即处理, 才能有效且有用！<br><em>*如果其他消费客户端空闲, 他们无能为力</em></em>: 一旦Rabbit向客户端发送消息, 消息就是客户端的责任, 直到他们拒绝或拒绝消息; 消息发送到客户端后，客户端不能窃取彼此的消息;<br>您希望客户端保持繁忙状态, 但客户端尽可能少地缓存消息, 以便客户端缓冲区不会延迟消息, 因此新消费客户端可以快速接收来自Rabbit队列的消息;</p></li><li><p>因此, 如果网络变慢, 缓冲区太小会导致客户端空闲; 但如果网络正常运行, 缓冲区太大会导致大量额外的延迟;<br>如果客户端突然开始花费更长时间来处理每个缓冲区, 则会导致大量额外的延迟;<br>很明显, 你真正想要的是可以变化的缓冲区大小, 这些问题在网络设备中很常见, 并且一直是很多研究的主题;<br>主动队列管理算法试图尝试放弃或拒绝消息，以避免消息长时间处于缓冲区。当缓冲区保持空闲时（每条消息只遭受网络延迟，并且根本不在缓冲区中），缓冲区在那里吸收峰值，从而实现最低延迟。从网络路由器的角度来看，Jim Gettys一直在研究这个问题：局域网和广域网性能之间的差异会遇到完全相同的问题。实际上，无论何时，在生产者（在我们的例子中为Rabbit）和消费者（客户端应用程序逻辑）之间都有一个缓冲区，双方的性能可以动态变化，您将会遇到这些问题。最近发布了一种名为Controlled Delay的新算法，该算法似乎在解决这些问题方面效果很好。</p></li></ul></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol><li><p>针对Qos的提前预习</p><ul><li><p><a href="https://www.rabbitmq.com/confirms.html#channel-qos-prefetch" target="_blank" rel="external">信道预取设置(QoS)</a><br>由于消息是异步发送(推送)给客户端的, 因此在任何给定时刻通常都有不止一条消息在信道上运行; 此外, 客户的手动确认本质上也是异步的, 所以有一个 未确认的交付标签的滑动窗口, 开发人员通常会倾向于限制此窗口的大小, <strong>以避免消费者端无限制的缓冲区问题</strong>。<br>这是通过使用 <code>basic.qos</code> 方法设置 <code>预取计数</code> 值完成的, 该值定义了<strong>channel上允许的最大未确认递送数量</strong>, 一旦数字达到配置的计数, RabbitMQ将停止在通道上传送更多消息, 除非至少有一个未确认的消息被确认;<br>例如, 假设在通道 “Ch” 上有未确认的交付标签5,6,7和8, 并且通道 “Ch” 的预取计数(后面会学到是<code>prefetch_count</code>)设置为4, 则RabbitMQ将不会在 “Ch” 上推送更多交付, 除非至少有一个未完成的交付被确认(当确认帧在 <code>delivery_tag=8</code> 的频道上到达时, <strong>RabbitMQ将会注意到并再发送一条消息</strong>)</p></li><li><p>QoS预取设置对使用 <code>basic.get</code>(<code>pull API</code>) 获取的消息没有影响, 即使在手动确认模式下也是如此;</p></li></ul></li><li><p>消费者确认模式, 预取和吞吐量<br> 确认模式 和 QoS预取值 对消费者吞吐量有显着影响, 一般来说, <strong>增加预取值将提高向消费者传递消息的速度, 当然, 自动确认模式可以产生最佳的传送速率</strong><br> 但是, 在上面两种情况下, 尚未完成交付处理的消息(unacked)数量也会增加, 从而增加消费者RAM消耗;<br> <strong>自动确认模式或带无限预取的手动确认模式应谨慎使用</strong>, 消费者在没有确认的情况下消耗大量消息将导致其所连接的节点上的内存消耗增长;<br> 预取值1是最保守的, 但这将显着降低吞吐量, 特别是在消费者连接延迟较高的环境中, 对于许多应用来说, 更高的价值是合适和最佳的;<br> 100到300范围内的Qos(<code>prefetch_count</code>)预取值通常提供最佳的吞吐量, 并且不会面临压垮consumer的重大风险, 而更高的值往往会遇到效率递减的规律; </p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RabbitMQ关于吞吐量-延迟和带宽的一些理论&quot;&gt;&lt;a href=&quot;#RabbitMQ关于吞吐量-延迟和带宽的一些理论&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ关于吞吐量,延迟和带宽的一些理论&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>08. 事务 VS Publisher Confirms(发布者确认机制)</title>
    <link href="http://blog.renyimin.com/2018/06/05/rabbitmq/2018-06-05-rabbitmq-08/"/>
    <id>http://blog.renyimin.com/2018/06/05/rabbitmq/2018-06-05-rabbitmq-08/</id>
    <published>2018-06-05T11:20:56.000Z</published>
    <updated>2018-07-20T11:29:01.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题的出现"><a href="#问题的出现" class="headerlink" title="问题的出现"></a>问题的出现</h2><ol><li><p>和消息持久化相关的一个概念是 AMQP 的事务(transaction)机制;</p></li><li><p>到目前为止, 我们讨论的是将 <code>消息</code>, <code>队列</code> 和 <code>交换器</code> 设置为持久化; 这一切都工作的很好, 并且RabbitMQ也负责保证消息的安全, 但是由于 <strong>发布消息的操作并不会反回任何信息给生产者</strong>, 所以你也无法得知是否消息已经到达了服务器并且服务器是否已经将消息持久化到了硬盘;</p><ul><li>服务器可能会在把消息写入到硬盘前就宕机了, 或者消息压根就还没有发送到服务器, 服务器就宕机了, 消息会因此而丢失, 而你却不知道; </li><li>另外, 你可能是发送多条消息, 如果部分发送成功, 部分失败呢? 这你也无法得知;</li></ul></li></ol><h2 id="事务机制"><a href="#事务机制" class="headerlink" title="事务机制"></a>事务机制</h2><ol><li><p>为了确保消息能够被安全发布到Broker, 如果使用标准的AMQP 0-9-1, 保证消息不会丢失的唯一方法是使用 <strong>事务机制</strong> (将channel事务化)</p></li><li><p>php-amqplib 中与事务机制有关的方法有三个, 分别是Channel里面的 <code>txSelect()</code>, <code>txCommit()</code> 以及 <code>txRollback()</code>;</p><ul><li>txSelect(): 用于将当前Channel设置成是transaction模式</li><li>txCommit(): 用于提交事务</li><li>txRollback(): 用于回滚事务</li></ul></li><li><p>但是值得注意的是事务存在的问题: </p><ul><li>AMQP 0-9-1 中的事务几乎吸干了RabbitMQ的性能, 会导致事务吞吐量严重下降;</li><li>事务会使得生产者应用程序变成同步的, 而你使用消息通信就是为了避免同步;</li></ul></li><li><p>鉴于上面的问题, 你可能不会在生产中使用事务机制, 此处只做了个简单的事务测试, <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/TxController.php" target="_blank" rel="external">测试代码</a></p></li></ol><h2 id="Publisher-Confirms"><a href="#Publisher-Confirms" class="headerlink" title="Publisher Confirms"></a><a href="https://www.rabbitmq.com/confirms.html#publisher-confirms" target="_blank" rel="external">Publisher Confirms</a></h2><ol><li><p>既然事务存在的问题让你拒绝使用它, 但是<code>确保消息被成功投递到服务器</code>这个问题仍需要解决; 为了避免事务机制在解决问题时导致的新问题, RabbitMQ团队拿出了更好的方案来保证消息的投递: <strong>发送方确认模式</strong></p></li><li><p>它模仿协议中已经存在的 <strong>消费者确认机制</strong></p></li><li><p>要启用这个确认机制，客户端可以通过使用 channel 的 <code>confirm.select</code> 方法</p><ul><li><p>如果设置了 <code>confirm.select</code> 方法的 <code>no-wait</code>, 代理会用 <code>confirm.select-ok</code> 进行响应, 不过这点你貌似也只能通过抓包来观察:<br><img src="/img/rabbitmq/wireshark-Confirm.Select-ok.png"></p></li><li><p>这里说的 <code>confirm.select-ok</code> 是代理对发布者的响应信息 (和 php-amqplib包中的 <code>confirm_select_ok()</code> 方法可不是一个意思, 而且php-amqplib也没对confirm_select_ok做实现)</p></li></ul></li><li><p>上面也提到了, 该确认机制是模仿已经存在的 消费者确认机制, 所以, Broker也会使用类似 <strong>ack</strong>, <strong>nack</strong> 来响应Publisher: </p><ul><li><p>可以通过为 <code>set_ack_handler</code> , <code>set_nack_handler</code> 设置回调, 来监测消息是否成功到达服务器, 成功则会触发 <code>set_ack_handler</code>, 失败则会触发 <code>set_nack_handler</code></p></li><li><p><strong>只有在负责队列的Erlang进程中发生内部错误时才会回应nack</strong>, 所以这个在测试中也一直没有使用 set_nack_handler 捕获到错误 (是对于nack的消息, 可以设置进行重发);</p></li><li><p>注意: <strong>这两监听函数是监听服务器对 publisher 的应答的, 可不是监听 consumer 对服务器的应答的</strong>;</p></li></ul></li><li><p>一旦在channel上使用 <code>confirm.select</code> 方法, 就说 channel 处于 <strong>确认模式</strong>, 一旦通道处于确认模式, 就不能进行事务处理; 也就是说 <strong>事务 和 Publisher Confirm 不能同时使用</strong>;  </p><ul><li>一旦通道处于确认模式, 代理和客户端都会对消息进行计数(在第一次confirm.select时从1开始计数), 然后, broker通过在相同channel上发送 <code>basic.ack</code> 来处理它们, 从而确认消息; </li><li><code>delivery-tag</code> 字段包含确认消息的序列号;<br>最大 Delivery Tag, 递送标签是一个64位长的值，因此其最大值为9223372036854775807.由于递送标签的范围是按每个通道划分的，因此发布商或消费者在实践中不太可能运行该值</li></ul></li><li><p>Publisher Confirms 的顺序考虑</p><ul><li>在大多数情况下, RabbitMQ将按发布顺序向publisher确认消息(这适用于在单个频道上发布的消息); 但是, 发布者确认是异步发出的, 并且可以确认一条消息或一组消息;<br>由于消息确认可以以不同的顺序到达, 所以, 应用程序应尽可能不取决于确认的顺序;</li></ul></li></ol><h2 id="发布者确认存在的问题"><a href="#发布者确认存在的问题" class="headerlink" title="发布者确认存在的问题"></a>发布者确认存在的问题</h2><ol><li><a href="https://yq.aliyun.com/articles/42206" target="_blank" rel="external">mandatory 属性问题</a></li></ol><h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h2><p>publisher confirm 不需要消费者参与, <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/PublisherConfirmController.php" target="_blank" rel="external">代码参考</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题的出现&quot;&gt;&lt;a href=&quot;#问题的出现&quot; class=&quot;headerlink&quot; title=&quot;问题的出现&quot;&gt;&lt;/a&gt;问题的出现&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;和消息持久化相关的一个概念是 AMQP 的事务(transaction)机制;&lt;/p&gt;
&lt;/li&gt;
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>06. 持久化策略</title>
    <link href="http://blog.renyimin.com/2018/05/28/rabbitmq/2018-05-28-rabbitmq-06/"/>
    <id>http://blog.renyimin.com/2018/05/28/rabbitmq/2018-05-28-rabbitmq-06/</id>
    <published>2018-05-28T09:32:11.000Z</published>
    <updated>2018-07-20T09:43:29.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="持久化原理"><a href="#持久化原理" class="headerlink" title="持久化原理"></a>持久化原理</h2><ol><li><p>RabbitMQ 默认情况下, <code>Exchange</code>, <code>队列</code>, <code>消息</code> 都是非持久的, 这意味着一旦消息服务器重启, 所有已声明的 <code>Exchange</code>, <code>队列</code>, 以及 <code>队列中的消息</code> 都会丢失;</p></li><li><p>RabbitMQ确保持久化的消息能在服务器重启之后恢复的方式是, 将它们写入磁盘上的一个持久化日志文件。当发布一条持久性消息到一个持久交换机上时, Rabbit会在消息提交到日志文件中之后才发送响应; </p><ul><li>还需要注意的是, 如果之后这条消息被路由到一个非持久化队列, 则消息又会从上面的日志文件中删除, 并且无法从服务器重启中恢复;</li><li>一旦你从持久化队列中消费了一条持久性消息(并且进行了确认), RabbitMQ会在持久化日志中把这条消息标记为等待垃圾收集;</li></ul></li></ol><h2 id="持久化方案"><a href="#持久化方案" class="headerlink" title="持久化方案"></a>持久化方案</h2><ol><li><p>要做到消息持久化, 必须保证如下三点设置正确:</p><ul><li>exchange交换器: durable属性为true;</li><li>queue队列: durable属性为true;</li><li>除了上述两点之外, 还需要在投递消息时候, 设置message的 <code>delivery_mode</code> 模式为<code>2</code>来标识消息为持久化消息;</li></ul></li><li><p>另外: 一个包含持久化消息的非持久化队列, 在Rabbit Server重启之后, 该队列将会不复存在, 消息就会变成孤儿;</p></li><li><p><a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/ParamsDetailController.php" target="_blank" rel="external">具体代码</a></p></li></ol><h2 id="持久化的问题"><a href="#持久化的问题" class="headerlink" title="持久化的问题"></a>持久化的问题</h2><ol><li><p>持久化由于会写磁盘, 所以会极大降低RabbitMQ每秒处理的消息总数, 降低吞吐量;</p></li><li><p>持久化在Rabbit内建集群环境下工作的并不好, 虽然RabbitMQ集群允许你和集群中的任何节点的任一队列进行通信, 但是如果队列所在的节点崩溃后, 如果队列是持久化的, 那么直到这个节点恢复之前, 这个队列都不会在整个集群中被创建出来;<br> 后面在学习集群时, 会给出相应的解决方案;</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;持久化原理&quot;&gt;&lt;a href=&quot;#持久化原理&quot; class=&quot;headerlink&quot; title=&quot;持久化原理&quot;&gt;&lt;/a&gt;持久化原理&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;RabbitMQ 默认情况下, &lt;code&gt;Exchange&lt;/code&gt;, &lt;code&gt;队列&lt;/
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
</feed>
