<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lant&#39;s</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.renyimin.com/"/>
  <updated>2019-11-12T02:33:14.000Z</updated>
  <id>http://blog.renyimin.com/</id>
  
  <author>
    <name>Lant</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Java IO 体系</title>
    <link href="http://blog.renyimin.com/2019/11/08/nginx/2019-11-08-IO-java/"/>
    <id>http://blog.renyimin.com/2019/11/08/nginx/2019-11-08-IO-java/</id>
    <published>2019-11-08T07:42:02.000Z</published>
    <updated>2019-11-12T02:33:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="BIO-同步阻塞"><a href="#BIO-同步阻塞" class="headerlink" title="BIO (同步阻塞)"></a>BIO (同步阻塞)</h1><ol><li><p>在JDK1.4以前, 使用Java建立网络连接时, 只能采用BIO方式 </p></li><li><p>采用BIO的方式进行网络连接时, 使用的是 <code>java.io.*</code> (即 Java 普通IO), java IO是面向流的(InputStream、OutputStream)</p></li><li><p>一个容易让初学者迷惑的 BIO小DEMO</p><ul><li>启动服务器端后, 程序便阻塞等待了客户端连接了</li><li>然后启动客户端, 服务器连接成功后直接打印出了客户端发来的数据<br><img src="/img/IO/bio-01.png"></li><li>所以整个过程非常容易让人误认为整个程序的阻塞点只是在 <code>serverSocket.accept()</code>, 即, 服务端等待客户端连接时</li></ul></li><li><p>新DEMO: 可以直观地看到 (我们重点讨论的) 阻塞点, 即 数据从内核空间 拷贝 到用户空间时的 阻塞 (当内核空间数据未准备好时)<br> <code>单线程 + 同步BIO</code><br> <img src="/img/IO/bio-02.png"></p></li><li><p>问题: <code>单线程+同步BIO</code> 有两处阻塞: <code>serverSocket.accept()</code> 和 <code>inputStream.read(b)</code></p><ul><li>第二处阻塞会造成的问题: 客户端A连接上来后, 如果不发送数据并被服务端处理, 服务端会一直阻塞在 <code>inputStream.read(b)</code>, 其他客户端是连接不上来的</li><li>第一处阻塞会造成的问题: 当客户端A连接上来后, 给服务端发送数据并被处理后, 他再次发送数据给服务端时, 由于服务端阻塞在 <code>serverSocket.accept()</code>, 是无法接收到该消息的</li></ul></li><li><p>小结: 采用如上这种单线程的方式, 是无法处理并发的(客户端连接上之后,就得发送数据, 服务器端处理完一个客户端之后, 才能有新的客户端连接上来)</p></li></ol><h1 id="多线程-BIO"><a href="#多线程-BIO" class="headerlink" title="多线程 + BIO"></a>多线程 + BIO</h1><p>每个客户端连接到服务器时, 服务器都会为该客户端创建一个新的线程(用来接收客户端发来的数据并进行处理), 所以 同步阻塞的代码段 <code>inputStream.read(b);</code> 发生在了每个子线程内, 这样主线程就只负责阻塞等待客户端连接了 (使用 <code>多线程+同步阻塞IO</code> 的模式时, 此处的阻塞是自然要做的, 这确实不是我们重点关注的阻塞点)<br><img src="/img/IO/multi-threading-sync-block-01.png"><br>还可以使用可视化窗口查看进程中的线程数<br><img src="/img/IO/thread-console-01.png"></p><p>在高并发场景下, 为每个任务(用户请求)创建一个进程或线程的开销非常大; 多线程编程的复杂度也比较高;</p><p>那么是否可以使用单线程进行并发处理?</p><h1 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>这里的 <code>非阻塞IO</code> 其实说的是 <code>IO多路复用</code>, 因为<code>传统非阻塞IO</code>是在用户空间进行轮询, 而 <code>IO多路复用</code> 是在内核进行轮询, 所以看上去 <code>IO多路复用</code> 对用户程序来说是阻塞的, 而 <code>非阻塞IO</code>对用户程序是非阻塞的, 其实 IO多路复用是将非阻塞的位置移到了内核</p><ol><li><p>要让单线程来并发处理多个客户端请求, 首先要知道, 之前的 <code>单线程+同步BIO</code> 有两处阻塞: <code>serverSocket.accept()</code> 和 <code>inputStream.read(b)</code></p></li><li><p>要解决这个问题, 那就得让 以上两处都为非阻塞, 即, “没有新的客户端连接时,旧的客户端仍然能发送消息”, “旧的客户端不发送消息时, 新的客户端也可以连接上来”</p></li><li><p><code>JAVA NIO</code> 有两种解释: 一种叫 <code>非阻塞IO (Non-blocking I/O)</code>, 另一种也叫 <code>新的IO(New I/O)</code>, 它是一种同步非阻塞的I/O模型<br> NIO 是 Java 1.4 引入的 <code>java.nio</code> 包, 提供了 Channel、Selector、Buffer 等新的抽象, 可以构建多路复用的、同步非阻塞 IO 程序, 同时提供了更接近操作系统底层高性能的数据操作方式<br> 由于这套API是JDK新提供的I/O API, 因此, 也叫New I/O, 这就是包名 <code>nio</code> 的由来<br> 在理解NIO的时候, 需要区分, 说的是 <code>New I/O</code> 还是 <code>非阻塞IO</code>, New I/O是Java的包, NIO是非阻塞IO概念</p></li><li><p>可以将 NIO 简单区分为两种：普通的NIO, 和多路复用的NIO（加入了selector管理） </p><ul><li>普通的NIO: 线程发起io请求后, 立即返回(非阻塞io), 用户线程不阻塞等待, 但是, 用户线程要定时轮询检查数据是否就绪, 当数据就绪后, 用户线程将数据从用户空间写入socket空间, 或从socket空间读取数据到用户空间(同步)</li><li><strong>多路复用的NIO</strong>: 上述NIO实现中, 需要用户线程定时轮训, 去检查IO数据是否就绪, 占用应用程序线程资源。IO多路复用模型中, 将检查IO数据是否就绪的任务, 交给系统级别的select或poll模型, 由系统进行监控, 减轻用户线程负担</li><li>参考: (<a href="https://www.jianshu.com/p/8ad464ed516e" target="_blank" rel="noopener">https://www.jianshu.com/p/8ad464ed516e</a>, <a href="https://my.oschina.net/ljhlgj/blog/1811319" target="_blank" rel="noopener">https://my.oschina.net/ljhlgj/blog/1811319</a>)</li></ul></li><li><p><code>Java BIO</code> 是面向流的, NIO是面向缓冲区的</p><ul><li>Java IO面向流意味着每次从流中读一个或多个字节, 直至读取所有字节, 它们没有被缓存在任何地方</li><li>NIO则能前后移动流中的数据, 因为是面向缓冲区的</li></ul></li></ol><h2 id="Java-NIO-组件"><a href="#Java-NIO-组件" class="headerlink" title="Java NIO 组件"></a>Java NIO 组件</h2><ol><li>NIO主要有三大核心部分: <code>Channel(通道)</code>, <code>Buffer(缓冲区)</code>, <code>Selector(选择器)</code></li><li>传统IO是基于字节流和字符流进行操作(基于流), 而NIO是基于Channel和Buffer(缓冲区)进行操作, 数据总是从通道读取到缓冲区中, 或者从缓冲区写入到通道中</li><li><code>Selector(选择器)</code> 用于监听多个通道的 事件(如连接打开, 数据到达), 因此, 单个线程可以监听多个数据通道</li></ol><h3 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h3><ol><li>Buffer(缓冲区) 是一个用于存储特定基本类型数据的容器。除了boolean外, 其余每种基本类型都有一个对应的buffer类</li><li>Buffer类的子类有 ByteBuffer, CharBuffer, DoubleBuffer, FloatBuffer, IntBuffer, LongBuffer, ShortBuffer</li></ol><h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><ol><li><p>Channel(通道) 表示到实体, 如硬件设备、文件、网络套接字或可以执行一个或多个不同 I/O 操作(如读取或写入) 的程序组件的开放的连接</p></li><li><p>Channel接口的常用实现类有 <code>FileChannel(对应文件IO)</code> 、<code>DatagramChannel(对应UDP)</code> 、<code>SocketChannel</code> 和 <code>ServerSocketChannel(对应TCP的客户端和服务器端)</code><br> Channel和IO中的Stream(流)是差不多一个等级的。只不过Stream是单向的, 譬如：InputStream, OutputStream.而Channel是双向的, 既可以用来进行读操作, 又可以用来进行写操作</p></li></ol><h3 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h3><p>Selector(选择器) 用于监听多个通道的 事件(如连接打开, 数据到达), 因此, 单个的线程可以监听多个数据通道。即用选择器, 借助单一线程, 就可对数量庞大的活动I/O通道实施监控和维护</p><h2 id="Java-NIO-实现-单线程-非阻塞IO"><a href="#Java-NIO-实现-单线程-非阻塞IO" class="headerlink" title="Java NIO 实现 单线程 非阻塞IO"></a>Java NIO 实现 单线程 非阻塞IO</h2><p>NIO是针对服务端的, 客户端没有NIO的概念<br><img src="/img/IO/non-blocking-io-demo-01.png"><br>上述例子中, 一旦并发很高, 那么 socketChannelList 将会变得非常大, 所以其实不应该将轮询交给应用系统来进行, 而是交给操作系统</p><p>Java的NIO这块目前底层技术还是IO多路复用为主(Linux 中 epoll 是主要解决方案)<br>Selector(选择器)是Java NIO中能够同时监测多个Channel通道, 并且还能知道Channel上读写事件是否准备好。这样一个Selector线程就可以管理多个Channel, 而不像Blocking IO那样一个线程对应一个监管一个IO事件。<br><img src="/img/IO/non-blocking-io-demo-02.png"></p><h1 id="NIO-1"><a href="#NIO-1" class="headerlink" title="NIO"></a>NIO</h1><ol><li></li><li></li><li></li></ol><h1 id="AIO-NIO-2"><a href="#AIO-NIO-2" class="headerlink" title="AIO (NIO 2)"></a>AIO (NIO 2)</h1><p>在 Java 7 中, NIO 有了进一步的改进, 也就是 NIO 2, 引入了异步非阻塞 IO 方式, 也有很多人叫它 AIO(Asynchronous IO) 。<br>异步 IO 操作基于事件和回调机制, 可以简单理解为, 应用操作直接返回, 而不会阻塞在那里,<br>当后台处理完成, 操作系统会通知相应线程进行后续工作。 </p><p>异步非阻塞, 服务器实现模式为一个有效请求一个线程, 客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理, </p><h1 id="深入理解NIO零拷贝及用户空间与内核空间切换"><a href="#深入理解NIO零拷贝及用户空间与内核空间切换" class="headerlink" title="深入理解NIO零拷贝及用户空间与内核空间切换"></a>深入理解NIO零拷贝及用户空间与内核空间切换</h1><p><a href="https://blog.csdn.net/lemon89/article/details/78290389" target="_blank" rel="noopener">https://blog.csdn.net/lemon89/article/details/78290389</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;mid=2247483941&amp;idx=1&amp;sn=97628f4d69d8607badf39bfeb7557457&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;mid=2247483941&amp;idx=1&amp;sn=97628f4d69d8607badf39bfeb7557457&amp;scene=21#wechat_redirect</a></p><h1 id="AIO-NIO2"><a href="#AIO-NIO2" class="headerlink" title="AIO(NIO2)"></a>AIO(NIO2)</h1><p>—&gt;</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;BIO-同步阻塞&quot;&gt;&lt;a href=&quot;#BIO-同步阻塞&quot; class=&quot;headerlink&quot; title=&quot;BIO (同步阻塞)&quot;&gt;&lt;/a&gt;BIO (同步阻塞)&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在JDK1.4以前, 使用Java建立网络连接时, 只能采用BIO
      
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>07. IO 多路复用 select 、poll、epoll</title>
    <link href="http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-07-IO/"/>
    <id>http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-07-IO/</id>
    <published>2019-11-07T11:31:15.000Z</published>
    <updated>2019-11-11T02:44:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>之前在学习Linux下的5种IO模型时, 已经简单介绍了 IO多路复用, 接下来对 <code>select、poll、epoll</code> 分别进行学习 <a href="https://blog.csdn.net/wukery/article/details/79295567" target="_blank" rel="noopener">linux系统调用表(system call table)</a></p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><ol><li><p>Linux 支持 IO多路复用 的 系统调用有 <code>select、poll、epoll</code>, 这些调用都是内核级别的, 但 select、poll、epoll 本质上都是同步I/O, 先是 block 住等待就绪的 socket, 再是block住将数据从内核拷贝到用户内存<br> (select\poll\epoll 均属于实现多路复用的SystemCall(系统调用))<br> epoll跟select都能提供多路I/O复用的解决方案, 在现在的Linux内核里有都能够支持, 其中<strong>epoll是Linux所特有</strong>, 而select则应该是POSIX所规定, 一般操作系统均有实现</p></li><li><p>多路复用是通过 Linux 的 <code>select\poll\epoll</code> 模型实现的, 但它们本质上都是 <strong>同步 IO</strong></p></li><li><p>IO 多路复用通过把多个 IO 阻塞复用到同一个 select 的阻塞上, 从而使得系统在单线程的情况下, 可以同时处理多个 client 请求</p></li><li><p>IO 多路复用技术其实就是通过使用Linux的系统函数 select, poll, epoll 等, 通过其底层的系统调用<strong>在操作系统内核层面实现的</strong> (tip: 所以一般说支不支持IO多路复用, 和你的代码关系不大, 主要看操作系统, 如 nginx 在 windows 只支持 select 不支持 epoll, epoll 是内核层面的东西, Windows 是不可支持的)</p></li></ol><h1 id="select"><a href="#select" class="headerlink" title="select"></a>select</h1><ol><li><p>说的通俗一点, 就是各个客户端连接的文件描述符也就是套接字, 都被放到了一个集合中, 调用select函数之后会一直监视这些文件描述符中有哪些可读, 如果有可读的描述符那么我们的工作进程就去读取资源<br> PHP 中有内置的函数来完成 <code>select</code> 系统调用, 函数原型: <code>int socket_select(array &amp;$read , array &amp;$write , array &amp;$except , int $tv_sec [, int $tv_usec= 0 ])</code><br> (php 貌似不支持epoll, 需要使用 libevet 拓展)</p></li><li><p>特点:</p><ul><li>最大缺陷是单个进程锁打开的 fd 是有限制的, 32位机器上是1024个, 64位机器上是2048个, 虽然可以改这个数值, 但是会造成性能下降</li><li>每次进行select调用都会线性扫描全部的fd集合, 不管哪个socket是活跃的, 都要遍历一遍fdset, 很耗时耗cpu, 当套接字比较多时, 效率就会呈现线性下降<br>(如果能给套接字注册某个回调函数, 当本套接字活跃时, 自动完成相关操作, 就不用轮询, 实际上 epoll 就是改了这儿)</li><li>需要维护一个用来存放大量fd的数据结构, select在解决将fd消息传递给用户空间时采用了内存拷贝的方式, 在kernel缓冲区和用户缓冲区之间拷贝这个结构的开销很大, 这样, 其处理效率不高</li></ul></li></ol><p>时间复杂度O(n)</p><h1 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h1><p>poll 本质上跟select没有区别, 只是 poll 没有最大连接数限制, 因为它是用基于链表来存储的<br>时间复杂度O(n)</p><h1 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h1><ol><li><p><code>epoll</code> 是当前在Linux下开发大规模并发网络程序的热门选择, epoll在Linux2.6内核中正式引入, 和select相似, 都是IO多路复用(IO multiplexing)技术<br> 按照man手册的说法, epoll是为处理大批量句柄而做了改进的poll</p></li><li><p>对比于其他模型, epoll 做了如下改进:</p><ul><li>epoll 没有对描述符数目的限制, 它所支持的文件描述符上限是整个系统最大可以打开的文件数目 (例如, 在1GB内存的机器上, 这个限制大概为10万左右)</li><li>IO效率不会随文件描述符(fd)的增加而线性下降<br>不同于 忙轮询和无差别轮询, epoll 可以理解为 event poll, 它只会对活跃的socket进行操作, 这是因为在内核实现中, epoll是根据每个fd上面的callback函数实现的。因此, 只有活跃的socket才会主动去调用callback函数, 其他状态的socket则不会, 在这一点上, epoll实现了一个伪AIO, 其内部推动力在内核, 此时我们对这些流的操作都是有意义的 (复杂度降低到了O(1))<br>传统的select/poll的一个致命弱点就是当你拥有一个很大的socket集合时, select/poll每次调用都会线性扫描整个socket集合, 这将导致IO处理效率呈现线性下降</li><li>使用 mmap 加速内核与用户空间的消息传递<br>无论是select, poll还是epoll, 它们都需要内核把fd消息通知给用户空间, 因此, 如何避免不必要的内存拷贝就很重要了。对于该问题, epoll 利用 mmap()文件映射内存加速与内核空间的消息传递,即epoll使用mmap减少复制开销</li></ul></li></ol><!--3. epoll有 epoll_create、epoll_ctl 和 epoll_wait这三个系统调用4. 参考https://www.jianshu.com/p/dfd940e7fca2https://blog.csdn.net/zhaobryant/article/details/80557262--><h1 id="Linux-底层的-epoll"><a href="#Linux-底层的-epoll" class="headerlink" title="Linux 底层的 epoll"></a>Linux 底层的 epoll</h1><p>Linux底层 epoll 的3个实现函数</p><ol><li><p><code>int epoll_create(int size);</code><br>epoll_create: 创建一个epoll对象<br>参数size是内核保证能处理最大的文件句柄数, 在socket编程里面就是处理的最大连接数<br>返回的int代表当前的句柄指针, 当然创建一个epoll对象的时候, 也会相应的消耗一个fd, 所以在使用完成的时候, 一定要关闭, 不然会耗费大量的文件句柄资源</p></li><li><p><code>int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);</code><br>epoll_ctl: 可以操作上面建立的 epoll<br>例如, 将刚建立的socket加入到epoll中让其监控, 或者把 epoll正在监控的某个socket句柄移出epoll, 不再监控它等等<br>epfd, 就是创建的文件句柄指针<br>op是要做的操作, 例如删除, 更新等<br>event 就是我们需要监控的事件</p></li><li><p><code>int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);</code><br>epoll_wait: 在调用时, 在给定的timeout时间内, 当在监控的所有句柄中有事件发生时, 就返回用户态的进程<br>epoll的高效就在于, 当我们调用epoll_ctl往里塞入百万个句柄时, epoll_wait仍然可以飞快的返回, 并有效的将发生事件的句柄发送给用户。这是由于我们在调用epoll_create时, 内核除了帮我们在epoll文件系统里建了个file结点, 在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外, 还会再建立一个list链表, 用于存储准备就绪的事件, 当epoll_wait调用时, 仅仅观察这个list链表里有没有数据即可。有数据就返回, 没有数据就sleep, 等到timeout时间到后即使链表没数据也返回。所以, epoll_wait非常高效。</p></li></ol><p>那么, 这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时, 除了把socket放到epoll文件系统里file对象对应的红黑树上之外, 还会给内核中断处理程序注册一个回调函数, 告诉内核, 如果这个句柄的中断到了, 就把它放到准备就绪list链表里。所以, 当一个socket上有数据到了, 内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。（当网卡里面有数据的时候, 会发起硬件中断, 提醒内核有数据到来可以拷贝数据。当网卡通知内核有数据的时候, 会产生一个回调函数, 这个回调函数是epoll_ctl创建的时候, 向内核里面注册的。回调函数会把当前有数据的socket（文件句柄）取出, 放到list列表中。这样就可以把存放着数据的socket发送给用户态, 减少遍历的时间, 和数据的拷贝）</p><h1 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h1><!--<img src="/img/IO/select-poll-epoll-01.png" />--><p><img src="/img/IO/select-poll-epoll-02.png"></p><h1 id="Linux-内存映射"><a href="#Linux-内存映射" class="headerlink" title="Linux 内存映射"></a>Linux 内存映射</h1><ol><li><p>内存映射, 简而言之就是将 用户空间 的一段内存区域映射到 内核空间, 映射成功后, 用户对这段内存区域的修改可以直接反映到内核空间, 相反, 内核空间对这段区域的修改也直接反映用户空间<br> 那么, <strong>对于内核空间&lt;——&gt;用户空间两者之间需要大量数据传输等操作的话效率是非常高的</strong></p></li><li><p>首先, 驱动程序先分配好一段内存, 接着用户进程通过库函数 <code>mmap()</code> 来告诉内核要将多大的内存映射到内核空间<br> 用户空间 <code>mmap()</code> 函数: <code>void *mmap(void *start, size_t length, int prot, int flags,int fd, off_t offset)</code><br> start: 用户进程中要映射的某段内存区域的起始地址, 通常为NULL（由内核来指定）<br> length: 要映射的内存区域的大小<br> prot: 期望的内存保护标志<br> flags: 指定映射对象的类型<br> fd: 文件描述符（由open函数返回）<br> offset: 要映射的用户空间的内存区域在内核空间中已经分配好的的内存区域中的偏移, 大小为PAGE_SIZE的整数倍</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前在学习Linux下的5种IO模型时, 已经简单介绍了 IO多路复用, 接下来对 &lt;code&gt;select、poll、epoll&lt;/code&gt; 分别进行学习 &lt;a href=&quot;https://blog.csdn.net/wukery/article/details/792
      
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>06. 网络IO 基础概念</title>
    <link href="http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-06-IO/"/>
    <id>http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-06-IO/</id>
    <published>2019-11-07T07:10:53.000Z</published>
    <updated>2019-11-11T06:54:06.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h1><ol><li><p>Linux 会把所有的外部设备都看成一个文件来操作, 对外部设备的操作可以看成是对文件的操作<br> 当我们对外部设备(文件)进行读写时, 都会通过内核提供的系统调用, 内核会给我们返回一个 File Descriptor, 这个描述符是一个数字, 指向内核的一个结构体, 我们应用程序对文件的读写就是对描述符指向的结构体的读写</p></li><li><p>文件描述符(File descriptor): 其形式上是一个非负整数 ,它是一个索引值, 指向内核为每一个进程所维护的该进程打开文件的记录表</p> <!--文件描述符 https://blog.csdn.net/Cooling88/article/details/52356865 https://blog.csdn.net/qq769651718/article/details/79459346--></li><li><p>注意, 文件描述符 是一个<strong>抽象</strong>的概念 (这里的 <code>文件</code> 应该理解为 <code>信息载体</code>, 而不要直接理解为磁盘上的文件)</p><blockquote><p>Socket 是最初就作为UNIX操作系统的一部分而开发的, 所以其API和系统其他IO设备集成在一起 (套接字是一个抽象出来的概念,本质上也是一个文件描述符)<br> 对于通常的文件IO来说, 其文件描述符最终是指向磁盘文件的<br> 但是对于网络IO来说, socket的读写也会有相应的描述符, 称为 <code>socketfd</code>( <code>socket 描述符</code>), Socket描述符是一个指向内部数据结构的指针, 它指向描述符表入口, 调用Socket函数时, socket执行体将建立一个Socket, 实际上”建立一个Socket”意味着为一个Socket数据结构分配存储空间</p></blockquote></li></ol><h1 id="简述-网络IO-主要工作"><a href="#简述-网络IO-主要工作" class="headerlink" title="简述 网络IO 主要工作"></a>简述 网络IO 主要工作</h1><ol><li><p>为了执行网络I/O, 一个进程必须做的第一件事就是调用 <code>socket()</code> 函数, 指定期望的通信协议类型。该函数只是作为一个简单的接口函数供用户调用, 调用该函数后将进入内核栈进行系统调用 <code>sys_socket()</code> (<a href="https://blog.csdn.net/wukery/article/details/79295567" target="_blank" rel="noopener">linux系统调用表(system call table)</a>)</p></li><li><p>网络 IO 和 磁盘IO 类似</p><ul><li>当进程读取磁盘上的文件时, 磁盘IO 的主要工作就是将 磁盘上的文件内容读取到 内核缓存中, 然后最终由 内核缓存 中拷贝到用户空间(缓存/无缓存), 最后被进程拿到数据</li><li>而网络IO与磁盘IO的读取过程类似, 他是将从网卡流入到内核空间的数据, 最终拷贝到用户空间的进程, 进而被进程所使用</li></ul></li><li><p>小结: 简单来说, <strong> IO 读取的过程就是将 从外部设备来的数据 从 内核空间 拷贝到 用户空间的 过程</strong>! （写入则相反）</p></li></ol><h1 id="Linux-五种-I-O-模型"><a href="#Linux-五种-I-O-模型" class="headerlink" title="Linux 五种 I/O 模型"></a>Linux 五种 I/O 模型</h1><h2 id="阻塞IO-blocking-IO"><a href="#阻塞IO-blocking-IO" class="headerlink" title="阻塞IO (blocking IO)"></a>阻塞IO (blocking IO)</h2><ol><li><p>在Unix中,默认情况下所有的socket都是blocking, 一个典型的读操作流程大概如下<br><img src="/img/IO/blocking-IO-01.png"></p></li><li><p>当用户进程调用了 <code>recvfrom()</code> 这个函数(其底层是进行 系统调用 <code>sys_recvfrom()</code> ), kernel内核 就开始了IO的第一个阶段: 准备数据</p><ul><li>对于 网络IO 来说, 很多时候数据在一开始可能还没有到达(比如, 还没有收到一个完整的UDP包), 这个时候kernel就要等待足够的数据到来, 这个过程是需要等待的, 也就是说数据被拷贝到 操作系统内核的缓冲区 是需要一个过程的, 在这个过程中, 内核在做等待(被阻塞), 用户进程也在等待(被阻塞)  </li><li><p>kernel一直等到数据准备好了, 也就是数据从外设拷贝到了 操作系统内核缓冲区 中了, 接下来才会将数据从 kernel缓冲区 拷贝到 用户内存, 拷贝完成一组数据, 用户进程才暂时会解除block的状态, 重新运行起来</p></li><li><p>上述过程中有两处可能会被阻塞的地方: <code>外设(网卡) --&gt; 操作系统内核缓冲区</code>, <code>操作系统内核缓冲区 --&gt; 用户空间</code><br>tip: 外设数据准备好后, 内核就处于非阻塞新状态了(数据会被拷贝到操作系统的内核缓冲区), 但缓冲区只要没满, 对于用户空间进程来说, 其实仍是处于阻塞状态, 因为它没有等到从内和缓冲区拷贝来的数据</p></li></ul></li><li><p>优点和缺点</p><ul><li>优点: 一个线程处理一个任务, 编程模型比较简单 （另外, 进程处于 阻塞状态 时, 是不占用CPU资源的）</li><li>缺点: 一个线程只能处理一个任务</li></ul></li></ol><h2 id="非阻塞IO-non-blocking-IO"><a href="#非阻塞IO-non-blocking-IO" class="headerlink" title="非阻塞IO (non-blocking IO)"></a>非阻塞IO (non-blocking IO)</h2><ol><li><p>进程把一个 套接字 设置成 非阻塞 是在告诉内核, 当 内核中的数据 因为某些原因(未准备好,或者内核区未满) 尚无法拷贝数据到用户内核空间 时, 需要返回一个error; 当对一个 non-blocking socket 执行读操作时, 流程如下:<br><img src="/img/IO/non-blocking-IO-01.png"></p></li><li><p>从用户进程角度讲, 它发起一个 read 操作后, 并不需要等待, 而是马上就得到了一个结果, 用户进程判断结果是一个error时, 它就知道数据还没有准备好, 于是它可以再次发送read操作, 一旦kernel中的数据准备好了, 并且又再次收到了用户进程的system call, 那么它马上就将数据拷贝到了用户内存, 然后返回, 所以, 用户进程其实是需要不断的主动询问kernel数据好了没有<br> 也就是我们的<strong>用户进程需要自己不断的测试数据是否已经准备好</strong>, 如果没有准备好, 继续测试, 直到数据准备好为止, 在这个不断测试的过程中, 会大量的占用CPU的时间<br> (Linux下, 可以通过设置 socket 使其变为 non-blocking, 当使用socket()函数和WSASocket()函数创建套接字时, 默认都是阻塞的。在创建套接字之后, 通过调用ioctlsocket()函数, 将该套接字设置为非阻塞模式。Linux下的函数是:fcntl())</p></li><li><p>优点和缺点</p><ul><li>优点: 相较于阻塞模型, 非阻塞模型下, 线程不用再等待任务, 而是可以把时间花费到其它任务上, 也就是说这个当前线程可以尝试去同时处理多个任务 (编程)</li><li>缺点: 导致任务完成的响应延迟增大了, 因为每隔一段时间才去执行询问的动作, 但是任务可能在两个询问动作的时间间隔内完成, 这会导致整体数据吞吐量的降低 (另外, 不停地轮询, 不是每次都成功, 所以可能会消耗大量CPU资源)</li></ul></li></ol><h2 id="IO-多路复用"><a href="#IO-多路复用" class="headerlink" title="IO 多路复用"></a>IO 多路复用</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ol><li><p>IO 多路复用 (IO multiplexing) 就是使用 <code>select</code>, <code>poll</code>, <code>epoll</code> (有些地方也称这种IO方式为 <code>event driven IO</code> ) 这些方法<br> (<a href="https://blog.csdn.net/wukery/article/details/79295567" target="_blank" rel="noopener">linux系统调用表(system call table)</a>) 可以找到这些方法及其底层对应的系统调用方法</p></li><li><p>有了I/O复用, 我们就可以调用 <code>select</code>, <code>poll</code>, <code>epoll</code>, 它们最终仍然是让用户进程处于阻塞状态, 只不过是<strong>内核在其内部对这几个方法所管辖的多个 socket fd 该进行轮询</strong><br> 在这些方法阻塞用户进程后, 内核会轮询检查每个IO连接的内核缓冲区的数据是否准备好了<br> 如果内核管理的某个 socket fd 的内核缓冲区的数据准备好了, 则 <code>select</code> 会有返回值, 用户进程可以进一步去调用 <code>recvfrom()</code><br> <img src="/img/IO/IO-multiplexing-01.png"></p></li><li><p>先看一下 <code>select</code> 函数原型</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/select.h&gt;</span><br><span class="line">int select(int nfds, fd_set* readfds, fd_set* writefds, fd_set* exceptfds, struct timeval* timeout);</span><br></pre></td></tr></table></figure><p> <strong>参数解释</strong>: </p><ul><li>nfds: 需要监视的最大文件描述符+1；</li><li>readfds: 监视可读文件描述符集合 （select在调用之前, 需要手动在应用程序里将要监控的文件描述符添加到 fed_set 集合中, 然后加载到内核进行监控)</li><li>writefds: 监视可写文件描述符集合</li><li>exceptfds: 监视异常文件描述符集合</li><li>timeout: 设置select的等待时间      (<strong>也就是select的阻塞进程的时间, 设置为NULL则表示没有timeout, 用户进程会一直阻塞</strong>, 该参数直接就明示了 select 阻塞用户进程的特性)<br>返回值:<br>负值: select错误<br>正值: 某些文件可读写或出错<br>0: 等待超时, 没有可读写或错误的文件<br>如果参数timeout设为NULL, 则表示select没有timeout</li></ul></li></ol><h3 id="IO-多路复用-VS-同步非阻塞"><a href="#IO-多路复用-VS-同步非阻塞" class="headerlink" title="IO 多路复用 VS 同步非阻塞"></a>IO 多路复用 VS 同步非阻塞</h3><ol><li><p><code>select</code> 调用是内核级别的, select的轮询也是内核在其内部执行的 (你事先需要把你需要执行的多个 IO操作的 socket fd 通过 select 传给内核, 让内核帮你进行轮询), 对用户进程来说,一个进程虽然是阻塞的,但其内部可以对多个socket fd进行监控<br> (另外, 在io复用模型下, 对于每一个socket, 一般都设置成 non-blocking, 但其实整个用户进程是一直被block的, 只不过用户进程不是被 socket IO 给block的, 而是被 select 这个函数block住的)</p></li><li><p>而 非阻塞模型中的轮询 是 应用程序进程在 用户空间 进行的轮询 (你也可以在一个进程中对多个 socket fd 进行轮询 ), 对用户层来说, 进程确实是非阻塞的</p></li><li><p>其实 <code>select</code> 相比较 <code>non-blocking</code> 来说, 在单个任务的情况下可能要更差一些, 因为这里调用了 <code>select</code> 和 <code>recvfrom</code> 两个 system call, 而 non-blocking 只调用了一个 <code>recvfrom</code> , 但是用select的优势在于它可以帮你同时处理多个 socket fd, 而不用你自己去处理多个 socket fd</p></li></ol><h3 id="IO-多路复用-VS-多线程-同步阻塞"><a href="#IO-多路复用-VS-多线程-同步阻塞" class="headerlink" title="IO 多路复用 VS 多线程+同步阻塞"></a>IO 多路复用 VS 多线程+同步阻塞</h3><p>IO多路复用的图 其实看着和 blocking IO的图 没有太大的不同, 事实上, 还更差一些, 因为这里需要使用两个system call (select 和 recvfrom), 而 blocking IO 只调用了一个system call (recvfrom)<br>但是, 用select的优势在于它可以同时处理多个socket fd, 所以, 如果处理的连结数目不高的话, 使用 <code>select/epoll</code> 的 web server 不一定比使用 <code>multi-threading + blocking IO</code> 的web server性能好, 可能延迟还更大(因为阻塞可以保证没有延迟, 但是多路复用是处理先存在的数据, 所以数据的顺序则不管, 导致处理一个完整的任务的时间上有延迟)</p><h3 id="同步非阻塞-VS-多线程-同步阻塞"><a href="#同步非阻塞-VS-多线程-同步阻塞" class="headerlink" title="同步非阻塞 VS 多线程+同步阻塞"></a>同步非阻塞 VS 多线程+同步阻塞</h3><p>高并发的程序一般使用 <code>同步非阻塞</code>方式 而非 <code>多线程 + 同步阻塞</code> 方式<br>因为在高并发场景下, 为每个任务(用户请求)创建一个进程或线程的开销非常大, 而 同步非阻塞 方式可以把多个 IO 请求丢到后台去, 这就可以在一个进程里服务大量的并发 IO 请求</p><h2 id="异步IO-asynchronous-IO"><a href="#异步IO-asynchronous-IO" class="headerlink" title="异步IO (asynchronous IO)"></a>异步IO (asynchronous IO)</h2><p>上面说的 阻塞, 非阻塞, IO多路复用 这几种方式, 对用户进程来说: 阻塞 和 IO多路复用 都是主动去等待; 非阻塞是用户进程主动去轮询; 总之都是用户进程都是自己主动去拿到了结果, 不是被回调通知的, 所以对用户进程来说都是同步的IO操作</p><ol><li>Unix下的 asynchronous IO 其实用得很少<br><img src="/img/IO/asynchronous-IO-01.png"></li></ol><p>用户进程发起读取操作之后, 立刻就可以开始去做其它的事, 而另一方面,  从kernel的角度, 当它收到一个asynchronous read之后, 首先它会立刻返回, 所以不会对用户进程产生任何block, 然后, kernel会等待数据准备完成, 然后将数据拷贝到用户内存, 当这一切都完成之后, kernel会给用户进程发送一个signal, 告诉它read操作完成了</p><h2 id="信号驱动式I-O模型"><a href="#信号驱动式I-O模型" class="headerlink" title="信号驱动式I/O模型"></a>信号驱动式I/O模型</h2><p>……</p><h1 id="各-IO-Model-对比"><a href="#各-IO-Model-对比" class="headerlink" title="各 IO Model 对比"></a>各 IO Model 对比</h1><p><img src="/img/IO/io-model-01.png"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>注意, 在上面讨论 <code>Linux 五种 I/O 模型</code> 时, 讨论的是Linux的系统调用函数是否实现了各模式(如图中的 <code>recvfrom</code> 就是Linux的系统调用函数)<br>貌似在系统调用函数层面, 对 异步 的实现并非很成熟(可参考:<a href="https://www.zhihu.com/question/26943558" target="_blank" rel="noopener">https://www.zhihu.com/question/26943558</a>); 而我们通常接触到的异步非阻塞, 只是用户态程序通过实现诸如 Proactor 模式来模拟的异步, 并不是真正的异步(操作系统层面(系统调用函数级别)的异步)</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.zhihu.com/question/26943558" target="_blank" rel="noopener">https://www.zhihu.com/question/26943558</a></p><p><a href="https://www.cnblogs.com/diegodu/p/6823855.html" target="_blank" rel="noopener">https://www.cnblogs.com/diegodu/p/6823855.html</a><br><a href="https://blog.csdn.net/jay900323/article/details/18141217#t6" target="_blank" rel="noopener">https://blog.csdn.net/jay900323/article/details/18141217#t6</a><br><a href="https://blog.csdn.net/lemon89/article/details/78290389#Reactor_183" target="_blank" rel="noopener">https://blog.csdn.net/lemon89/article/details/78290389#Reactor_183</a></p><p><a href="https://blog.csdn.net/u014730165/article/details/85044285" target="_blank" rel="noopener">https://blog.csdn.net/u014730165/article/details/85044285</a>   ？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;文件描述符&quot;&gt;&lt;a href=&quot;#文件描述符&quot; class=&quot;headerlink&quot; title=&quot;文件描述符&quot;&gt;&lt;/a&gt;文件描述符&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Linux 会把所有的外部设备都看成一个文件来操作, 对外部设备的操作可以看成是对文件的操作&lt;br
      
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>05. 文件IO, 标准IO</title>
    <link href="http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-05-IO/"/>
    <id>http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-05-IO/</id>
    <published>2019-11-07T07:03:29.000Z</published>
    <updated>2019-11-07T09:57:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>根据 有无用户态缓存 可以将IO分为以下两大类 (注意都有内核态缓存)</p><h1 id="文件IO"><a href="#文件IO" class="headerlink" title="文件IO"></a>文件IO</h1><ol><li><p><code>文件I/O</code> 又称为低级磁盘I/O(是操作系统提供的基本IO服务), 遵循POSIX相关标准, 与os绑定; 任何兼容POSIX标准的操作系统上都支持文件I/O  (特定于 Linux 或 unix平台)</p></li><li><p><code>文件I/O</code> 称之为不带缓存的IO(unbuffered I/O),  像 <code>open()</code>, <code>read()</code> 这些 posix 标准的会进行系统调用的函数, <strong>主要是指其在用户空间没有缓冲</strong>, 在内核空间还是进行了缓存的</p><ul><li>数据流转过程为: <strong><code>数据---&gt;内核缓存区--&gt;磁盘</code></strong></li><li>假设 内核缓存区 长度为100字节, 你调用 <code>write()</code> 进行写操作时, 设每次写入 10 个字节, 那么你要调用10次这个函数才能把 内核缓存区 写满, 没写满时数据还是在内核缓冲区中, 并没有写入到磁盘中, 内核缓存区满了之后或者执行了 <code>fsync</code>(强制写入硬盘)之后, 才进行实际的IO操作, 把数据写入磁盘上</li></ul></li></ol><h1 id="标准IO-缓存IO"><a href="#标准IO-缓存IO" class="headerlink" title="标准IO (缓存IO)"></a>标准IO (缓存IO)</h1><ol><li><p>标准I/O是 ANSI C 建立的一个标准I/O模型, 是一个 标准函数包 和 stdio.h 头文件中的定义, 具有一定的可移植性</p></li><li><p><code>标准I/O</code> 被称为 <code>高级磁盘I/O</code>, 又被称作 <code>缓存 IO</code>, 大多数文件系统的默认 IO 操作都是缓存 IO, 像 <code>fopen()</code>, <code>fwrite()</code>, <code>fget()</code> 等, 是c标准库中定义的</p><ul><li>数据流转过程为: <strong><code>数据--&gt;流缓存区--&gt;内核缓存区--&gt;磁盘</code></strong></li><li>假设 流缓存区 长度为50字节, 内核缓存区100字节, 我们用标准c库函数 <code>fwrite()</code> 将数据写入到这个流缓存中, 每次写10字节, 需要写5次流缓存区满后才会调用 <code>write()</code> (或调用 <code>fflush()</code> ), 将数据写到内核缓存区, 直到内核缓存区满了之后或者执行了 <code>fsync</code>(强制写入硬盘) 之后, 才进行实际的IO操作, 把数据写入磁盘上<br>标准IO操作 <code>fwrite()</code> 最后还是要调用 无缓存的IO操作 <code>write()</code><br>如 标准IO函数 <code>fopen()</code> 底层用的还是 低级的文件IO函数 <code>read()</code>  (这两个函数都是面向用户的用户编程接口API, 是用户空间的调用, 而 <code>read()</code> 底层则是进行 系统调用 (调用内核函数 <code>sys_read()</code>) )</li></ul></li><li><p>tip:</p><ul><li><code>fsync</code>: 是把内核缓冲刷到磁盘上</li><li><code>fflush</code>: 是把C库中的缓冲调用 <code>write()</code> 函数写到磁盘 (其实是写到内核的缓冲区, 内核缓冲区满了之后才会真正写入磁盘)</li></ul></li></ol><h1 id="标准IO的三种缓冲类型-隐藏"><a href="#标准IO的三种缓冲类型-隐藏" class="headerlink" title="标准IO的三种缓冲类型 (隐藏)"></a>标准IO的三种缓冲类型 (隐藏)</h1><!--## 不缓冲1. 虽然 标准IO 分配了缓冲区buffer, 但是也有标准IO的方法并不缓冲, 而是直接将数据刷出, 一般会用到这种类型操作的数据如: 紧急数据(出错处理)    > 举个例子: 在打开屏幕这个文件的时候, 有两个描述符指向屏幕, 分为: `stdout`、`stderr`    但是由于 stderr 为错误信息, 这种情况并不应该缓冲, 而是应该越快越好去让内核处理2. Demo<img src="/img/IO/standardio-no-buffer-stderr.png" />按照先后顺序应该是先输出小写的abcd, 而结果则是输出大写的ABCD## 全缓冲1. 这种类型的意思是, 要将分配的缓冲区buffer的大小全部填满, 才进行数据的刷新; 这种设定可能会造成很大的不便, 因此就产生了很多让全缓冲模式下也能强制让数据刷新的功能2. 下面一次性总结一下让全缓冲模式下刷新数据的条件:    - 数据填满缓冲区    - `fflush()` 函数    - `fclose()` 函数    - 正常退出程序    ....## 行缓冲1. 在缓冲区一行数据是有特定的大小的, 行缓冲就是数据在缓冲区收集够一行了, 就开始对数据进行刷新2. 让行缓冲刷新数据的条件：    - 数据填满缓冲区    - `fflush()` 函数    - `fclose()` 函数    - 正常退出程序    - `setbuf()/setvbuf()` 这个函数主要是设置缓冲区的大小    - 遇到换行符 `\n`3. Demo本来strerr没有缓冲区, 应该先输出大写的ABCD才对, 但是由于stdout包含了换行符, 所以导致其先输出<img src="/img/IO/standardio-has-buffer-stderr-01.png" />### 参考https://blog.csdn.net/RayCongLiang/article/details/99686022--><h1 id="文件IO-与-标准IO-区别"><a href="#文件IO-与-标准IO-区别" class="headerlink" title="文件IO 与 标准IO 区别"></a>文件IO 与 标准IO 区别</h1><!-- 对于 不带缓冲区的文件IO 和 带缓冲区的标准IO, 有些资料貌似说的不太对, 这些资料普遍认为这里说的缓冲区指的是 内核空间的缓冲区 , 如:https://blog.csdn.net/qq_42169059/article/details/93174353 (此文比较矛盾, 虽然花了不少篇幅说是内核缓冲区, 但是配图确实标准IO缓冲区)https://www.iteye.com/blog/q16964777-2228244其实 这里所说的缓冲区是指用户空间的缓冲区, 资料如下:https://blog.csdn.net/u011402017/article/details/53747232https://blog.csdn.net/qq_42169059/article/details/93174353--><p>有隐藏部分</p><p>标准IO 在用用户态下就有了缓存, 如调用 <code>fopen()</code>, <code>fwrite()</code> 的时候就减少了 用户态 和 内核态 的切换;<br>而 文件IO 如 <code>open()</code>, <code>write()</code> 每次调用都会进行 内核态 和 用户态 的切换</p><p>所以, 如果顺序访问文件, <code>fopen()</code> 系列的函数要比直接调用 <code>open()</code> 系列快, 如果随机访问文件 <code>open()</code> 要比 <code>fopen()</code> 快</p><p><img src="/img/IO/fileio-standardio.png"></p><p><img src="/img/IO/fileio-standardio-02.png"></p><p>缓存 IO 的缺点:<br>当然, 标准I/O库的并非没有缺点, 这与他需要复制的数据有关, 通常需要复制两次数据: 一次是在 <code>内核</code> 与 <code>标准I/O缓冲区</code> 之间(当标准IO缓冲区满后, 数据会被拷贝到内核缓冲区), 第二次是在 <code>标准I/O缓冲区</code> 和 <code>应用程序行缓存</code> 之间</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.cnblogs.com/orlion/p/6258691.html" target="_blank" rel="noopener">https://www.cnblogs.com/orlion/p/6258691.html</a><br><a href="https://blog.csdn.net/m0_37542524/article/details/83663124#1IOIO_2" target="_blank" rel="noopener">https://blog.csdn.net/m0_37542524/article/details/83663124#1IOIO_2</a><br><a href="https://blog.csdn.net/tanqiuwei/article/details/20641965" target="_blank" rel="noopener">https://blog.csdn.net/tanqiuwei/article/details/20641965</a><br><a href="https://www.jianshu.com/p/a77613045601" target="_blank" rel="noopener">https://www.jianshu.com/p/a77613045601</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;根据 有无用户态缓存 可以将IO分为以下两大类 (注意都有内核态缓存)&lt;/p&gt;
&lt;h1 id=&quot;文件IO&quot;&gt;&lt;a href=&quot;#文件IO&quot; class=&quot;headerlink&quot; title=&quot;文件IO&quot;&gt;&lt;/a&gt;文件IO&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;文件I/
      
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>04. 基础概念 -- 用户态, 内核态, 系统调用</title>
    <link href="http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-04-IO/"/>
    <id>http://blog.renyimin.com/2019/11/07/nginx/2019-11-07-04-IO/</id>
    <published>2019-11-07T06:20:18.000Z</published>
    <updated>2019-11-07T09:42:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>在了解 IO 的相关概念之前, 有必要先了解一下 <strong>系统调用</strong> 的概念<br>而在了解 系统调用 的概念前, 又不得不先了解Linux操作系统中 <strong>用户态与内核态</strong> 的概念</p><h1 id="用户态-与-内核态"><a href="#用户态-与-内核态" class="headerlink" title="用户态 与 内核态"></a>用户态 与 内核态</h1><ol><li><p>操作系统为什么需要分 内核空间 与 用户空间?</p><ul><li><p>在 CPU 的所有指令中, 有些指令是非常危险的, 如果错用, 将导致系统崩溃, 比如清内存、设置时钟等 </p></li><li><p>如果允许所有的程序都可以使用这些指令, 那么系统崩溃的概率将大大增加<br>所以, CPU 将指令分为 <code>特权指令</code> 和 <code>非特权指令</code>, 对于那些危险的指令, 只允许操作系统及其相关模块使用, 普通应用程序只能使用那些不会造成灾难的指令<br>(比如 Intel 的 CPU 将特权等级分为 4 个级别：Ring0~Ring3。其实 Linux 系统只使用了 Ring0 和 Ring3 两个运行级别(Windows 系统也是一样的)。 当进程运行在 Ring3 级别时被称为运行在用户态, 而运行在 Ring0 级别时被称为运行在内核态)</p></li></ul></li><li><p>Linux 从整体上分为 <code>内核态</code>(内核空间) 与 <code>用户态</code>(用户空间)</p><blockquote><p>比如一个32位的操作系统, 寻址地址(虚拟内存空间)是2的32次方, 也就是4G<br> 操作系统将较高的1G字节作为内核空间 (内核空间具有用户空间所不具备的操作权限)<br> 将较低的3G字节作为用户空间</p></blockquote><p> <img src="/img/IO/io-base-01.png"></p></li><li><p>内核态 与 用户态 </p></li></ol><ul><li><code>内核态</code> 就是内核所处的空间, 内核负责调用底层硬件资源, 并为上层应用程序提供运行环境</li><li><code>用户态</code> 即 应用程序的活动空间 (应用程序通常运行在用户空间, 当应用程序的某些操作需要内核权限时, 就需要通过 <strong>系统调用(System calls)</strong>, 进入内核态执行, 这也就是一次 <code>用户态</code> -&gt; <code>内核态</code> 的转换)</li></ul><h1 id="系统调用-System-calls"><a href="#系统调用-System-calls" class="headerlink" title="系统调用(System calls)"></a>系统调用(System calls)</h1><ol><li><p>应用程序的运行必须依托于内核提供的硬件资源(如cpu\存储\IO), 而内核是通过暴露外部接口来供应用程序进行调用的 （内核提供的这些外部接口就称为 <code>SystemCall, 系统调用</code>）</p></li><li><p>系统调用是操作系统的最小功能单位, <strong>每次系统调用都会发生一次 用户态与内核态 的切换, 切换过程中涉及了各种函数的调用以及数据的复制</strong></p><blockquote><p>系统调用是每个操作系统必不可少的一部分, 操作系统上的每个应用程序都必须依靠 系统调用 来进入内核态,进而实现对硬件资源的操作<br> 比如应用程序的 <code>read()</code> 的实现,其实是来源于内核空间的内核函数 <code>sys_read()</code>, 这样, 通过 <code>read()</code> 就形成一个系统调用<br> (更多系统调用可以搜索: Linux系统调用表(system call table) 去查看)</p></blockquote></li><li><p>系统调用是 用户态 进入 内核态 的唯一入口</p></li><li><p>用户空间 与 操作系统内核空间 的系统调用 架构简图1 如下:<br><img src="/img/IO/io-base-02.png"></p></li><li>用户空间 与 操作系统内核空间 的系统调用 架构简图2 如下:<br><img src="/img/IO/systemcall.jpg"></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在了解 IO 的相关概念之前, 有必要先了解一下 &lt;strong&gt;系统调用&lt;/strong&gt; 的概念&lt;br&gt;而在了解 系统调用 的概念前, 又不得不先了解Linux操作系统中 &lt;strong&gt;用户态与内核态&lt;/strong&gt; 的概念&lt;/p&gt;
&lt;h1 id=&quot;用户态-与-内核
      
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>03. postman 测试 MIME类型</title>
    <link href="http://blog.renyimin.com/2019/11/07/nginx/2019-11-06-03/"/>
    <id>http://blog.renyimin.com/2019/11/07/nginx/2019-11-06-03/</id>
    <published>2019-11-07T02:45:11.000Z</published>
    <updated>2019-11-07T02:45:35.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>02. nginx主配置文件(nginx.conf)结构</title>
    <link href="http://blog.renyimin.com/2019/11/06/nginx/2019-11-06-02/"/>
    <id>http://blog.renyimin.com/2019/11/06/nginx/2019-11-06-02/</id>
    <published>2019-11-06T07:32:11.000Z</published>
    <updated>2019-11-07T07:45:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><ol><li><p>整个conf文件分为 <code>全局块</code>、<code>events块</code>、<code>http块</code>、<code>server块</code>、<code>location块</code><br> 每个块有每个块的作用域, 外层块作用域就包含内部块的作用域, 如全局块作用域就包含events块、http块、server块和location块<br> 修改nginx.conf后是必须重启nginx才会生效</p></li><li><p>nginx.conf 大体结构如下  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">...                 #全局块</span><br><span class="line"></span><br><span class="line">event&#123;              #events块</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http&#123;               #http块</span><br><span class="line"></span><br><span class="line">    server&#123;         #server块</span><br><span class="line">        ...         #server全局块</span><br><span class="line"></span><br><span class="line">        location&#123;   #location块</span><br><span class="line">            ...</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location&#123;   #location块</span><br><span class="line">            ...</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server&#123;         #server块</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    ...             #http全局块</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>各块的作用</p></li></ol><div class="table-container"><table><thead><tr><th>名称</th><th style="text-align:left">作用</th></tr></thead><tbody><tr><td>全局块</td><td style="text-align:left">全局块是默认配置文件从开始到events块之间的一部分内容, 主要是设置一些影响Nginx服务器整体运行的配置指令。因此, 这些指令的作用域是Nginx服务器全局。作用通常包括: 配置Ngnix服务器的用户组、worker process数、Nginx进程PID存放路径、日志的存放路径和类型以及<strong>配置文件引入</strong>等</td></tr><tr><td>events块</td><td style="text-align:left">events块涉及的指令主要是影响Nginx服务器与用户的网络链接。 常用的设置包括: 是否开启多worker process下的网络连接进行序列化, 是否允许同时接收多个网络连接, 选取那种事件驱动模型处连接请求, 每个worker process可以同时支持的最大连接数等 (该部分的指令对nginx的性能影响较大, 实际配置中应该根据实际情况进行灵活调整)</td></tr><tr><td>http块</td><td style="text-align:left">http块是Nginx服务器配置中的重要部分, 代理、缓存和日志定义等绝大多数的功能和第三方模块的配置都可以放在这模块中。可以在http全局块中配置的指令包括：文件引入、MIME-Type定义、日志自定义、是否使用sendfile传输文件、连接超时时间、单连接请求数上限等; 一个http块可以包含多个server块) </td></tr><tr><td>server块</td><td style="text-align:left">server块, 虚拟主机（虚拟服务器）。作用：使得Nginx服务器可以在同一台服务器上至运行一组Nginx进程, 就可以运行多个网站。(注意: 在http全局块中介绍过的部分指令可以在server块, location块中使用)</td></tr><tr><td>location块</td><td style="text-align:left">location块是server块的一个指令, 每个server块可以包含多个location块。作用：基于Nginx服务器接收到的请求字符串, 虚拟主机名称（ip, 域名）、url匹配, 对特定请求进行处理。</td></tr></tbody></table></div><h1 id="配置项介绍"><a href="#配置项介绍" class="headerlink" title="配置项介绍"></a>配置项介绍</h1><ol><li><p>配置运行nginx服务器的用户(组)   <code>user [user] [group]</code> </p><ul><li>如果希望所有用户都可以启动nginx, 注释掉该行或者 <code>user nobody nobody</code></li><li>如果配置的用户或者用户组不存在, 则启动会报错</li><li><strong>此指令只能在全局块中配置</strong></li></ul></li><li><p><code>worker_processes number/auto</code> 该配置是服务器实现并发处理的关键所在 (rrc 是 auto)</p><ul><li>设置 number 会指定nginx进程最多可以产生的 worker process 数</li><li>设置 auto 时, nginx进程将自动检测</li><li><strong>此指令只能在全局块中配置</strong></li></ul></li><li><p><code>pid file</code> 用来设置nginx进程的pid文件位置, 该文件用来保存当前运行程序的主进程号</p><ul><li><strong>此指令只能在全局块中配置</strong></li></ul></li><li><p><code>error_log file/stderr [debug|info|notice....]</code> 配置错误日志的存放路径   (rrc是 error_log  /mnt/logs/nginx/error.log notice)</p><ul><li>注意 指定的文件需要对于运行nginx进程的用户具有写权限</li></ul></li><li><p><strong>配置文件的引入</strong> : 在一些情况下, 我们可能需要将其他的nginx配置或者第三方模块的配置引入到当前的主配置文件中</p><ul><li><code>include file</code></li><li>注意 引入的配置文件需要对于运行nginx进程的用户具有写权限</li><li>注意: <strong>该指令可以放在配置文件的任意位置</strong> (rrc 放在 http全局块中 <code>include conf.d/*.conf;</code>)</li></ul></li><li><p><code>accept_mutex on | off;</code> : 设置网络连接的序列化 (当一个新网络连接来到时, 多个worker进程会被同时唤醒, 但仅仅只有一个进程可以真正获得连接并处理之。如果每次唤醒的进程数目过多的话, 其实是会影响一部分性能的)</p><ul><li>如果accept_mutex on, 那么多个worker将是以串行方式来处理, 其中有一个worker会被唤醒；反之若accept_mutex off, 那么所有的worker都会被唤醒, 不过只有一个worker能获取新连接, 其它的worker会重新进入休眠状态</li><li><strong>默认是开启(on)状态</strong>, <strong>只能在 events块中进行配置</strong></li></ul></li><li><p><code>multi_accept on|off</code> : 每个worker process 一次只能接收一个新到达的网络连接。若想让每个Nginx的workerprocess都有能力同时接收多个网络连接, 则需要开启此配置</p><ul><li>该指令默认为off状态</li><li><strong>只能在 events块中进行配置</strong></li></ul></li><li><p><code>use method</code> 事件驱动模型的选择  (select/poll/kequeue/epoll…)</p><ul><li><strong>只能在 events块中进行配置</strong></li></ul></li><li><p><code>worker_connections number</code> 主要用来设置允许每一个 worker process 同时开启的最大连接数 (默认值为512), (rrc 为 <code>worker_connections  65535;</code>) </p><ul><li>这里的 number 不仅仅包括和前端用户建立的连接数, 而是包括所有可能建立的连接数</li><li>另外, number不能大于操作系统支持打开的最大文件句柄数</li><li><strong>只能在 events块中进行配置</strong></li></ul></li><li><p>include全局块中的 MIME类型 配置, 貌似一般不动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">include       mime.types;</span><br><span class="line">default_type  application/octet-stream;</span><br></pre></td></tr></table></figure></li><li><p>自定义服务日志</p><ul><li>在全局块中, 我们介绍过error_log指令, 其用于nginx进程运行时的日志存放和级别。此处所指的日志与常规日志不同, 它是记录nginx服务器提供服务过程应答前端请求的日志, 我们将其称为服务日志以示区分。</li><li><code>access_log path [format [buffer=size]]</code> <strong>可以在 http,server,location中配置</strong></li><li><code>log_format name string ...</code> <strong>只能在 http 全局块中进行配置</strong></li><li>(rrc 把 <code>log_format</code> 放在 http全局块中, 然后通过 <code>include</code> 引入每个项目的server配置, 每个项目在自己的server配置中指定自己的 <code>access_log</code> )</li></ul></li><li><p><code>keepalive_timeout imeout [header_timeout]</code> 配置连接超时时间 （rrc : <code>keepalive_timeout  30;</code>）</p><ul><li>timeout 服务端对连接的保持时间, 默认为65s</li><li>header_timeout 经测试, 会在响应头中加上 <code>Keep-Alive: timeout=所设置的时间</code>  </li><li><strong>可以在 http,server,location中配置</strong> </li></ul></li><li><p><code>keepalive_requests number</code>: 用于限制用户通过某一个连接向nginx发送请求的次数</p><ul><li>默认为100</li><li><strong>可以出现在server,location块中</strong></li></ul></li><li><p>配置网络监听, 有三种方式 (基于ip, port, UNIX Domain Socket), 直接看例子<br><strong>一般用在 server 块中</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">listen  *:80 | *:8000  (默认) 监听所有80和8000端口</span><br><span class="line">listen  8000  监听8000端口上所有ip,相当于 listen *:8000</span><br><span class="line">listen  192.168.1.10   监听具体IP的所有端口上的链接</span><br></pre></td></tr></table></figure></li><li><p>虚拟主机（基于端口,域名,ip）</p></li><li></li></ol><h1 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h1><h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><p>算法</p><h1 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h1><p>keepalived</p><h1 id="openresty"><a href="#openresty" class="headerlink" title="openresty"></a>openresty</h1><h1 id="lua"><a href="#lua" class="headerlink" title="lua"></a>lua</h1><p><a href="https://www.cnblogs.com/chenglc/p/8024994.html" target="_blank" rel="noopener">https://www.cnblogs.com/chenglc/p/8024994.html</a><br><a href="https://www.cnblogs.com/knowledgesea/p/5175711.html" target="_blank" rel="noopener">https://www.cnblogs.com/knowledgesea/p/5175711.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;整个conf文件分为 &lt;code&gt;全局块&lt;/code&gt;、&lt;code&gt;events块&lt;/code&gt;、&lt;code&gt;http块&lt;
      
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>01. nginx 安装</title>
    <link href="http://blog.renyimin.com/2019/11/06/nginx/2019-11-06-01/"/>
    <id>http://blog.renyimin.com/2019/11/06/nginx/2019-11-06-01/</id>
    <published>2019-11-06T03:31:23.000Z</published>
    <updated>2019-11-06T08:28:32.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="nginx下载"><a href="#nginx下载" class="headerlink" title="nginx下载"></a>nginx下载</h1><p>nginx <a href="http://nginx.org/en/download.html" target="_blank" rel="noopener">下载</a></p><h1 id="依赖准备"><a href="#依赖准备" class="headerlink" title="依赖准备"></a>依赖准备</h1><p>由于nginx的一些模块需要依赖第三方库, 通常有pcre库(支持rewrite模块), zlib库(支持gzip模块) 和 openssl库(支持ssl (Secure Sockets Layer 安全套接层) 模块)等 :（可以使用yum安装即可）<br><code>yum -y install gcc gcc-c++ automake pcre pcre-devel zlib zlib-devel open openssl-devel</code></p><h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><p>编译参数参考 <a href="http://nginx.org/en/docs/configure.html" target="_blank" rel="noopener">http://nginx.org/en/docs/configure.html</a>, 可以从如下几个角度来进行了解</p><h2 id="Path选项"><a href="#Path选项" class="headerlink" title="Path选项"></a>Path选项</h2><div class="table-container"><table><thead><tr><th>参数</th><th style="text-align:left">用途</th><th style="text-align:right">默认值</th></tr></thead><tbody><tr><td>—prefix=<path></path></td><td style="text-align:left">Nginx的安装目录</td><td style="text-align:right">/usr/local/nginx</td></tr><tr><td>—sbin-path=<path></path></td><td style="text-align:left">Nginx可执行文件安装路径</td><td style="text-align:right"><prefix>/sbin/nginx</prefix></td></tr><tr><td>—conf-path=<path></path></td><td style="text-align:left">主配置文件安装位置</td><td style="text-align:right"><prefix>/conf/nginx.conf</prefix></td></tr><tr><td>—error-log-path=<path></path></td><td style="text-align:left">错误日志位置, 在nginx.conf配置文件指定</td><td style="text-align:right"><prefix>/logs/error.log</prefix></td></tr><tr><td>—pid-path=<path></path></td><td style="text-align:left">Nginx pid文件路径, 在nginx.conf配置文件指定</td><td style="text-align:right"><prefix>/logs/nginx.pid</prefix></td></tr><tr><td>—lock-path=<path></path></td><td style="text-align:left">nginx.lock文件路径</td><td style="text-align:right"><prefix>/logs/nginx.lock</prefix></td></tr><tr><td>—with-perl_modules_path=…</td><td style="text-align:left">Perl模块位置</td><td style="text-align:right"></td></tr><tr><td>—with-perl=…</td><td style="text-align:left">Perl二进制文件路径</td><td style="text-align:right"></td></tr><tr><td>—http-log-path=…</td><td style="text-align:left">访问日志路径, 可以在配置文件指定</td><td style="text-align:right"><prefix>/logs/access.log</prefix></td></tr><tr><td>—http-client-body-temp-path=…</td><td style="text-align:left">存放由客户端请求生成的临时文件路径</td><td style="text-align:right"><prefix>/client_body_temp </prefix></td></tr><tr><td>—http-proxy-temp-path=…</td><td style="text-align:left">proxy产生的临时文件路径</td><td style="text-align:right"><prefix>/proxy_temp</prefix></td></tr><tr><td>…</td><td style="text-align:left">…</td><td style="text-align:right">…</td></tr></tbody></table></div><h2 id="依赖选项"><a href="#依赖选项" class="headerlink" title="依赖选项"></a>依赖选项</h2><p>依赖以库和二进制文件的形式出现, 现在, 它们应该已经全部安装在您的系统上了。但是, 即使它们存在于您的系统上, 也有可能出现配置脚本无法找到它们的情况。原因可能有所不同, 例如, 如果它们安装在非标准目录中。为了解决这些问题, 您可以使用以下选项来指定依赖的路径（其他依赖相关选项已组合在一起）</p><div class="table-container"><table><thead><tr><th>编译选项</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td>—with-cc=…</td><td style="text-align:left">指定C编译器的备用位置</td></tr><tr><td>—with-cpp=…</td><td style="text-align:left">指定C预处理器的备用位置</td></tr><tr><td>—with-cc-opt=…</td><td style="text-align:left">定义要传递到C编译器命令行的其他选项</td></tr><tr><td>—with-ld-opt=…</td><td style="text-align:left">定义要传递到C链接器命令行的其他选项</td></tr><tr><td>—with-cpu-opt=…</td><td style="text-align:left">在以下值中指定不同的目标处理器体系结构：pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64和ppc64</td></tr><tr><td><strong>PCRE选项</strong></td><td style="text-align:left"><strong>描述</strong></td></tr><tr><td>—without-pcre</td><td style="text-align:left">禁用PCRE库的使用。 不建议使用此设置, 因为它将删除对正则表达式的支持, 从而禁用Rewrite模块</td></tr><tr><td>—with-pcre</td><td style="text-align:left">强制使用PCRE库</td></tr><tr><td>—with-pcre=…</td><td style="text-align:left">允许您指定PCRE库源代码的路径</td></tr><tr><td>—with-pcre-opt=…</td><td style="text-align:left">构建PCRE库的其他选项</td></tr><tr><td>—with-pcre-jit=…</td><td style="text-align:left">构建PCRE与JIT编译的支持</td></tr><tr><td><strong>MD5选项</strong></td><td style="text-align:left"><strong>描述</strong></td></tr><tr><td>—with-md5=…</td><td style="text-align:left">指定MD5库源的路径</td></tr><tr><td>—with-md5-opt=…</td><td style="text-align:left">用于构建MD5库的其他选项</td></tr><tr><td>—with-md5-asm</td><td style="text-align:left">为MD5库指定汇编源</td></tr><tr><td><strong>SHA1选项</strong></td><td style="text-align:left"><strong>描述</strong></td></tr><tr><td>—with-sha1=…</td><td style="text-align:left">指定SHA1库源的路径</td></tr><tr><td>—with-sha1-opt=…</td><td style="text-align:left">构建SHA1库的其他选项</td></tr><tr><td>—with-sha1-asm</td><td style="text-align:left">为SHA1库指定汇编器源</td></tr><tr><td><strong>zlib选项</strong></td><td style="text-align:left"><strong>描述</strong></td></tr><tr><td>—with-zlib=…</td><td style="text-align:left">指定zlib library源的路径</td></tr><tr><td>—with-zlib-opt=…</td><td style="text-align:left">用于构建zlib库的其他选项</td></tr><tr><td>—with-zlib-asm=…</td><td style="text-align:left">为zlib库指定汇编器源</td></tr><tr><td><strong>OpenSSL选项</strong></td><td style="text-align:left"><strong>描述</strong></td></tr><tr><td>—with-openssl=…</td><td style="text-align:left">指定OpenSSL库源的路径</td></tr><tr><td>—with-openssl-opt=…</td><td style="text-align:left">用于构建OpenSSL库的其他选项</td></tr></tbody></table></div><h2 id="模块选项"><a href="#模块选项" class="headerlink" title="模块选项"></a>模块选项</h2><p>在编译程序之前, 需要指定要安装的模块。 有些是默认启用的, 有些需要手动启用</p><ul><li><p>默认启用的模块 (以下参数允许您禁用默认情况下启用的模块)</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">–without-http_charset_module</span><br><span class="line">–without-http_gzip_module</span><br><span class="line">–without-http_ssi_module</span><br><span class="line">–without-http_userid_module</span><br><span class="line">–without-http_access_module</span><br><span class="line">–without-http_access_module</span><br><span class="line">–without-http_autoindex_module</span><br><span class="line">–without-http_geo_module</span><br><span class="line">–without-http_map_module</span><br><span class="line">–without-http_referer_module</span><br><span class="line">–without-http_rewrite_module</span><br><span class="line">–without-http_proxy_module</span><br><span class="line">–without-http_fastcgi_module</span><br><span class="line">–without-http_uwsgi_module</span><br><span class="line">–without-http_scgi_module</span><br><span class="line">–without-http_memcached_module</span><br><span class="line">–without-http_limit_conn_module</span><br><span class="line">–without-http_limit_req_module</span><br><span class="line">–without-http_empty_gif_module</span><br><span class="line">–without-http_browser_module</span><br><span class="line">–without-http_upstream_ip_hash_module</span><br><span class="line">–without-http_upstream_least_conn_module</span><br><span class="line">–without-http_split_clients_module</span><br></pre></td></tr></table></figure></li><li><p>默认禁用的模块 (以下参数允许您启用默认禁用的模块)</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">–with-http_ssl_module</span><br><span class="line">–with-http_realip_module</span><br><span class="line">–with-http_addition_module</span><br><span class="line">–with-http_xslt_module</span><br><span class="line">–with-http_image_filter_module</span><br><span class="line">–with-http_geoip_module</span><br><span class="line">–with-http_sub_module</span><br><span class="line">–with-http_dav_module</span><br><span class="line">–with-http_flv_module</span><br><span class="line">–with-http_mp4_module</span><br><span class="line">–with-http_gzip_static_module</span><br><span class="line">–with-http_random_index_module</span><br><span class="line">–with-http_secure_link_module</span><br><span class="line">–with-http_stub_status_module</span><br><span class="line">–with-google_perftools_module</span><br><span class="line">–with-http_degradation_module</span><br><span class="line">–with-http_perl_module</span><br><span class="line">–with-http_spdy_module</span><br><span class="line">–with-http_gunzip_module</span><br><span class="line">–with-http_auth_request_module</span><br></pre></td></tr></table></figure></li><li><p>示例: <code>./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module</code></p></li></ul><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>然后 <code>make &amp;&amp; make install</code> </p><h1 id="二进制nginx文件相关用法"><a href="#二进制nginx文件相关用法" class="headerlink" title="二进制nginx文件相关用法"></a>二进制nginx文件相关用法</h1><ul><li><code>-v</code>: 打印版本号 并退出</li><li><code>-V</code>: 打印版本号和 nginx的编译情况 并退出</li><li><code>-s signal</code>: 向nginx的master进程发送信号 (signal可以是 <code>stop, quit, reopen, reload</code>)</li></ul><h1 id="nginx的启停"><a href="#nginx的启停" class="headerlink" title="nginx的启停"></a>nginx的启停</h1><p>向 nginx主进程发送信号有两种方法: 一种是使用 Nginx二进制文件, 用法是: <code>./nginx -s signal</code>; 另一种方法是使用kill命令发送信号, 用法是: <code>kill -SIGNAL PID</code></p><p><code>./nginx -s stop</code> = <code>kill -INT/-TERM PID</code><br><code>./nginx -s quit</code> = <code>kill -QUIT PID</code><br><code>./nginx -s reload</code> = <code>kill -HUP PID</code><br><code>./nginx -s reopen</code> = <code>kill -USR1 PID</code>   （重新打开日志文件, 切割日志时候用途较大）<br>…</p><p><a href="https://www.cnblogs.com/chenglc/p/8024994.html" target="_blank" rel="noopener">https://www.cnblogs.com/chenglc/p/8024994.html</a><br><a href="https://www.cnblogs.com/knowledgesea/p/5175711.html" target="_blank" rel="noopener">https://www.cnblogs.com/knowledgesea/p/5175711.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;nginx下载&quot;&gt;&lt;a href=&quot;#nginx下载&quot; class=&quot;headerlink&quot; title=&quot;nginx下载&quot;&gt;&lt;/a&gt;nginx下载&lt;/h1&gt;&lt;p&gt;nginx &lt;a href=&quot;http://nginx.org/en/download.html&quot; 
      
    
    </summary>
    
      <category term="nginx" scheme="http://blog.renyimin.com/categories/nginx/"/>
    
    
      <category term="nginx" scheme="http://blog.renyimin.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>01.</title>
    <link href="http://blog.renyimin.com/2019/11/04/math/2019-11-04-01/"/>
    <id>http://blog.renyimin.com/2019/11/04/math/2019-11-04-01/</id>
    <published>2019-11-04T06:39:46.000Z</published>
    <updated>2019-11-04T06:40:19.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="math" scheme="http://blog.renyimin.com/categories/math/"/>
    
    
      <category term="math" scheme="http://blog.renyimin.com/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>Chrome的Network分析 HTTP 报文</title>
    <link href="http://blog.renyimin.com/2019/10/28/http/2019-10-28-chrome-network-http/"/>
    <id>http://blog.renyimin.com/2019/10/28/http/2019-10-28-chrome-network-http/</id>
    <published>2019-10-28T03:37:56.000Z</published>
    <updated>2019-11-04T03:04:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>跨页面加载保存请求: <code>Preserve log</code><br>停用浏览器缓存: <code>Disable cache</code><br>模拟慢速网络连接: <code>Throttling</code>, 可自定义网速</p><p>过滤器, 属性过滤</p><ul><li><code>domain</code>: 仅显示来自指定域的资源 (你可以使用通配符字符 (*) 纳入多个域)</li><li><code>has-response-header</code>: 显示包含指定 HTTP 响应标头的资源</li><li><code>is</code>: 使用 <code>is:running</code> 可以查找 WebSocket 资源, <code>is:from-cache</code> 可查找缓存读出的资源<br><img src="/img/http/chrom-network-01.png"></li><li><code>larger-than</code>: 显示大于指定大小的资源(以字节为单位), 将值设为 1000 等同于设置为1k</li><li><code>method</code>: 显示通过指定 HTTP 方法类型检索的资源</li><li><p><code>mime-type</code>: 显示指定 MIME 类型的资源<br>多属性间通过空格实现 AND 操作</p></li><li><p><code>scheme</code>: 显示通过未保护 HTTP (<code>scheme:http</code>) 或受保护 HTTPS (<code>scheme:https</code>) 检索的资源</p></li><li><code>set-cookie-domain</code>: 显示具有 Set-Cookie 标头并且 Domain 属性与指定值匹配的资源</li><li><code>set-cookie-name</code>: 显示具有 Set-Cookie 标头并且名称与指定值匹配的资源</li><li><code>set-cookie-value</code>: 显示具有 Set-Cookie 标头并且值与指定值匹配的资源</li><li><code>status-code</code>: 仅显示 HTTP 状态代码与指定代码匹配的资源 (status-code:302)</li></ul><p>请求列表 Waterfall 列: 各请求相关活动的直观分析图<br>请求时间详细分布</p><ul><li>Queueing: 浏览器在以下情况下对请求排队<br>存在更高优先级的请求<br>此源已打开六个 TCP 连接，达到限值，仅适用于 HTTP/1.0 和 HTTP/1.1<br>浏览器正在短暂分配磁盘缓存中的空间</li><li>Stalled: 请求可能会因 Queueing 中描述的任何原因而停止</li><li>DNS Lookup: 浏览器正在解析请求的 IP 地址</li><li><p>Proxy Negotiation: 浏览器正在与代理服务器协商请求</p></li><li><p>Request sent: 正在发送请求</p></li><li>ServiceWorker Preparation: 浏览器正在启动 Service Worker</li><li>Request to ServiceWorker: 正在将请求发送到 Service Worker</li><li>Waiting (TTFB): 浏览器正在等待响应的第一个字节<br>TTFB 表示 Time To First Byte (至第一字节的时间)。 此时间包括 1 次往返延迟时间及服务器准备响应所用的时间</li><li>Content Download: 浏览器正在接收响应</li><li>Receiving Push: 浏览器正在通过 HTTP/2 服务器推送接收此响应的数据</li><li>Reading Push: 浏览器正在读取之前收到的本地数据</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;跨页面加载保存请求: &lt;code&gt;Preserve log&lt;/code&gt;&lt;br&gt;停用浏览器缓存: &lt;code&gt;Disable cache&lt;/code&gt;&lt;br&gt;模拟慢速网络连接: &lt;code&gt;Throttling&lt;/code&gt;, 可自定义网速&lt;/p&gt;
&lt;p&gt;过滤器, 属性过滤
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://blog.renyimin.com/2019/10/24/http/2019-10-24-OpenRestry/"/>
    <id>http://blog.renyimin.com/2019/10/24/http/2019-10-24-OpenRestry/</id>
    <published>2019-10-24T12:31:09.000Z</published>
    <updated>2019-10-28T02:47:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>OpenResty, 它是一个 “更好更灵活的 Nginx”</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;OpenResty, 它是一个 “更好更灵活的 Nginx”&lt;/p&gt;

      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>Wireshark 抓包分析 HTTPS</title>
    <link href="http://blog.renyimin.com/2019/10/24/network/https-wireshark/"/>
    <id>http://blog.renyimin.com/2019/10/24/network/https-wireshark/</id>
    <published>2019-10-24T09:10:36.000Z</published>
    <updated>2019-12-16T10:05:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HTTPS-实现原理简介"><a href="#HTTPS-实现原理简介" class="headerlink" title="HTTPS 实现原理简介"></a>HTTPS 实现原理简介</h1><p>混合加密技术: 证书校验是使用CA机构提供的非对称加密, 然后使用非对称加密传递一个秘钥, 再使用对称加密</p><ol><li>要使用HTTPS进行通信的服务端, 需要向CA机构申请数字证书, 来证明自己身份的有效性 (服务器会提供一对 公私钥)</li><li>当客户端请求的时候, 服务端把证书发给客户端, 客户端验证证书有效, 也就是认证了服务端的有效性, 并且拿出数字证书中包含的 (服务器)公钥</li><li>客户端生成一个随机数, 使用(服务器写入CA证书中的)公钥加密, 并且传递给服务端</li><li>服务端用私钥解密, 拿到随机数。之后客户端和服务端就用这个随机数进行加密通信</li></ol><p>小结: HTTPS最关键的就是使用数字证书来证明服务器的有效性, 然后使用非对称加密来传递对称加密的密钥 (这里要说明的是, 实际使用中对称加密的密钥, 并不是直接由客户端生成的随机数, 这里为了说明方便而简单这样理解。实际上的对称加密密钥是要根据协商的加密算法组件来决定的)</p><h1 id="HTTPS-数字证书的验证-概述"><a href="#HTTPS-数字证书的验证-概述" class="headerlink" title="HTTPS 数字证书的验证 概述"></a>HTTPS 数字证书的验证 概述</h1><h2 id="CA证书认证流程概述"><a href="#CA证书认证流程概述" class="headerlink" title="CA证书认证流程概述"></a>CA证书认证流程概述</h2><ol><li><p>浏览器通过URL请求后台服务器, 服务器接收到请求后, 会给浏览器发送一个自己的CA数字证书</p></li><li><p>浏览器接收到数字证书后</p><ul><li>首先从证书的内容中获取证书的颁发机构, 然后从浏览器系统中去寻找此颁发机构是否为浏览器的信任机构 (这里解析一下, 世界上就几个权威的CA机构, 这几个机构的信息都是预先嵌入到我们的浏览器系统中的), 如果收到的一个数字证书但其颁发机构没有在我们浏览器系统中的, 那么就会有警告提示无法确认证书的真假, 如果是受信任的机构, 那么就到下一步</li><li>此时, 就可以从浏览器中找到CA机构的根公钥, 用这个根公钥去解析证书的签名(这个签名是证书发布之前CA机构用自己的根私钥加密而成的, 所以这里只能由根证书的根公钥去解密)得到一个hash值H1<br>然后用证书的指纹算法对证书的内容再进行hash计算得到另一个hash值H2, 如果此时H1和H2是相等的, 就代表证书没有被篡改过<br>在证书没有被修改过的基础上, 再检查证书上的使用者的URL (比如csdn.net) 和我们请求的URL是否相等, 如果相等, 那么就可以证明当前浏览器连接的网址也是正确的, 而不是一些钓鱼网之类的<blockquote><p>假设, 浏览器的连接被某个钓鱼网截取了, 钓鱼网也可以发一个自己的证书给浏览器, 要知道如果钓鱼网站的证书和真实网站的整数是同一个CA机构的话, 前面也是会被内置在浏览器中的CA机构的根公钥解密的, 也会得到 H1, 然后也可以通过证书没有被篡改的验证<br><strong>但是在证书没有被篡改的情况下, 通过对比证书上的URL和我们请求的URL, 就可以发现这个证书的URL不是我们所要连接的网址, 所以说钓鱼网也骗不了我们</strong></p></blockquote></li></ul></li><li><p>到这里, 已经验证了证书是没有被篡改的并且确认连接的URL也是正确的, 然后我们获取到了证书上的公钥<br> 这个公钥是你访问的网站服务器在申请CA证书时, 所提供的服务器 公钥(私钥由服务器自己保管), 这个公钥会写在CA证书内, 该公钥和CA证书的根公钥不是一回事, 注意区分</p></li></ol><h2 id="对称秘钥的安全传递"><a href="#对称秘钥的安全传递" class="headerlink" title="对称秘钥的安全传递"></a>对称秘钥的安全传递</h2><ol><li><p>接下来就是, 如何将一个对称加密算法的秘钥安全地发给服务器</p><ul><li>首先随机生成一个字符串S作为我们的秘钥, 然后通过证书中(由网站服务器所提供)的 公钥 加密成密文, 将密文发送给服务器 (因为此密文是用公钥加密的, 这是一个非对称加密, 这个密文只有你访问的网站服务器上的 私钥 才能进行解密, 所以说任何第三方截取到密文也是没用的, 因为没有对应的私钥所以解析不出来)<br>当然, 发送密文的时候也会对消息内容进行签名操作, 即对密文内容进行hash计算得到一个hash值, 将这个签名加密以后和消息内容一起发送出去<br>接收方收到消息以后, 通过私钥解析出密文和签名的hash值, 同时也会对接收的消息内容进行同样的计算得到另一个hash值, 通过比对两个hash值是否相同来判断密文是否有修改过</li></ul></li><li><p>过了以上步骤, 客户端和服务端都持有了对称加密算法的秘钥, 然后兄弟两就可以愉快地安全通信了</p></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>HTTPS采用的是 <code>非对称加密</code> + <code>对称加密</code> 这种混合加密方式<br>数字证书的验证有两个重要的步骤, 第一是验证数字证书没有被篡改以及连接的URL是否正确, 第二是通过RSA机制的原理安全地将对称加密算法的秘钥发送给对方。这两步都完成以后, 整个HTTPS的数字证书的验证就算是成功了。</p><h1 id="抓包分析"><a href="#抓包分析" class="headerlink" title="抓包分析"></a>抓包分析</h1><ol><li><p>所用连接: <a href="https://cdn.staticfile.org/font-awesome/4.6.3/css/font-awesome.min.css" target="_blank" rel="noopener">https://cdn.staticfile.org/font-awesome/4.6.3/css/font-awesome.min.css</a><br><img src="/img/https/wireshark-https-01.png"></p></li><li><p>抓包<br><img src="/img/https/wireshark-https-02.png"></p></li><li><p>分析<br>~~<br>参考: <a href="https://blog.csdn.net/firefile/article/details/80537053#1__3" target="_blank" rel="noopener">https://blog.csdn.net/firefile/article/details/80537053#1__3</a></p></li></ol><p><a href="https://blog.csdn.net/u011803341/article/details/79708886" target="_blank" rel="noopener">https://blog.csdn.net/u011803341/article/details/79708886</a><br><a href="https://blog.csdn.net/qq_32998153/article/details/80022489" target="_blank" rel="noopener">https://blog.csdn.net/qq_32998153/article/details/80022489</a><br><a href="https://segmentfault.com/a/1190000014835279" target="_blank" rel="noopener">https://segmentfault.com/a/1190000014835279</a></p><p>https加密在应用层其实还是明文传输的!!!<br><strong><a href="https://www.cnblogs.com/evan-blog/p/9867561.html" target="_blank" rel="noopener">https://www.cnblogs.com/evan-blog/p/9867561.html</a></strong></p><p><a href="https://blog.csdn.net/u014294681/article/details/86599741" target="_blank" rel="noopener">https://blog.csdn.net/u014294681/article/details/86599741</a></p><h2 id="https-传输的数据是否需要二次加密"><a href="#https-传输的数据是否需要二次加密" class="headerlink" title="https 传输的数据是否需要二次加密"></a>https 传输的数据是否需要二次加密</h2><p>https 能保证的是连接的安全，当我们打开网站的时候，是需要和服务器进行通信的，那么 https 能够保证在通信时数据传输是安全的。</p><p>如果我们打开一个网页，在网址的前面有标明”https”的话，那么就说明这个网站有证书并且有进行加密的操作。但是，不少钓鱼网页其实也可以使用 https，这就说明了 https 并不能保证网站本身是安全的。举个例子，如果你在一个网页上输入账号密码的话，使用 https 的网页能够保证你的账号密码在传到网站服务器的过程中不会被其他的东西干扰或者盗取，但是，你输入的账号密码却有可能被你正在访问的这个网页盗用。</p><p>再举个例子：移动端手机种了木马，终端被攻击了，那么对于传输通道进行加密就毫无意义，试想人家都跑到你家里面去了，所有的东西在内存跟硬盘里面都有，再进行网络监听毫无意义。</p><p>所以 https 本身是安全的，至少在网络传输过程中，能够保证传输数据的完整性和一致性。但是并不代表它的宿主是安全的，所以如果是金融类，支付类等对安全等级要求很高的软件，最好进行二次加密。</p><p>可以用生活中的场景做个类比:</p><ol><li>使用了https，可以这样认为: 你正在沟通的这个人, 是个合法的公民, 是被法律上认可的一个人, 他在公安局有备案,身份证等信息;<br>也仅此而已</li></ol><ul><li>虽然是个合法公民, 你和他的沟通也要小心谨慎, 因为这只能保证你正在沟通的这个人是合法的, 但它未必是个守法的</li><li>另外, 你和这个合法公民的沟通也要防止被截获, 因为你两的沟通只是在传输层以下进行了保证, 应用层如果必要的话, 也是需要有一套安全措施的</li></ul><ol><li>不用https, 那你正在沟通的这个人可能根本就不是个合法公民, 连身份证都没有, 没有被政府所认可</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HTTPS-实现原理简介&quot;&gt;&lt;a href=&quot;#HTTPS-实现原理简介&quot; class=&quot;headerlink&quot; title=&quot;HTTPS 实现原理简介&quot;&gt;&lt;/a&gt;HTTPS 实现原理简介&lt;/h1&gt;&lt;p&gt;混合加密技术: 证书校验是使用CA机构提供的非对称加密, 然
      
    
    </summary>
    
      <category term="network" scheme="http://blog.renyimin.com/categories/network/"/>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/network/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
      <category term="network" scheme="http://blog.renyimin.com/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS 证书申请</title>
    <link href="http://blog.renyimin.com/2019/10/24/http/2019-10-24-HTTS/"/>
    <id>http://blog.renyimin.com/2019/10/24/http/2019-10-24-HTTS/</id>
    <published>2019-10-24T09:10:36.000Z</published>
    <updated>2019-11-04T10:59:46.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS是什么?SSL/TLS又是什么?</title>
    <link href="http://blog.renyimin.com/2019/10/23/http/2019-10-23-HTTS/"/>
    <id>http://blog.renyimin.com/2019/10/23/http/2019-10-23-HTTS/</id>
    <published>2019-10-23T12:31:09.000Z</published>
    <updated>2019-11-05T03:32:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前曾谈到过 HTTP 的一些缺点, 其中的 <code>无状态</code> 在加入 <code>Cookie</code> 后得到了解决, 而另两个缺点 — <code>明文</code> 和 <code>不安全</code> 仅凭 HTTP 自身是无力解决的, 需要引 入新的 <code>HTTPS</code> 协议</p><blockquote><p>由于 HTTP 天生 <code>明文</code> 的特点, 整个传输过程完全透明, 任何人都能够在链路中截获、 修改或者伪造请求 / 响应报文, 数据不具有可信性<br>比如, “代理服务”, 它作为 HTTP 通信的中间人, 在数据上下行的时候可以添加或删除部分头字段, 也可以使用黑白名单过滤 body 里的关键字, 甚至直接发送虚假的请求、响应, 而浏览器和源服务器都没有办法判断报文的真伪<br>因此 HTTP 明文这一特性, 对于网络购物、网上银行、证券交易等需要高度信任的应用场景来说是非常致命的。<br>如果没有基本的安全保护, 使用互联网进行各种电子商务、电子政务就根本无从谈起<br>对于安全性要求不那么高的新闻、视频、搜索等网站来说, 由于互联网上的恶意用户、恶意代理越来越多, 也很容易遭到 “流量劫持” 的攻击, 在页面里强行嵌入广告, 或者分流用户, 导致各种利益损失<br>对于你我这样的普通网民来说, HTTP 不安全的隐患就更大了, 上网的记录会被轻易截获, 网站是否真实也无法验证, 黑客可以伪装成银行网站, 盗取真实姓名、密码、银行卡等敏感信息, 威胁人身安全和财产安全</p></blockquote><h1 id="什么是安全"><a href="#什么是安全" class="headerlink" title="什么是安全?"></a>什么是安全?</h1><p>通常认为, 如果通信过程具备了四个特性, 就可以认为是安全的, 这四个特性是: <code>机密性</code>、<code>完整性</code>, <code>身份认证(真实性)</code> 和 <code>不可否认</code> (HTTPS 的出场, 为 HTTP 增加了这四大安全特性)</p><h2 id="机密性-Secrecy-Confidentiality"><a href="#机密性-Secrecy-Confidentiality" class="headerlink" title="机密性(Secrecy/Confidentiality)"></a>机密性(Secrecy/Confidentiality)</h2><p>机密性是指传输的数据是采用Session Key（会话密钥）加密的, 在网络上是看不到明文的</p><h2 id="完整性-Integrity-也叫一致性"><a href="#完整性-Integrity-也叫一致性" class="headerlink" title="完整性(Integrity, 也叫一致性)"></a>完整性(Integrity, 也叫一致性)</h2><p>是指为了避免网络中传输的数据被非法篡改, 使用MAC算法来保证消息的完整性 (每部分数据均有mac验证, 验证时计算数据的mac然后与接收到的mac比较, 即可确定数据是否完整)</p><h2 id="身份认证-Authentication"><a href="#身份认证-Authentication" class="headerlink" title="身份认证(Authentication)"></a>身份认证(Authentication)</h2><p>真实性是指通信的对方是可信的, 利用了PKI（Public Key Infrastructure 即『公钥基础设施』）来保证公钥的真实性</p><h2 id="不可否认-Non-repudiation-Undeniable"><a href="#不可否认-Non-repudiation-Undeniable" class="headerlink" title="不可否认(Non-repudiation/Undeniable)"></a>不可否认(Non-repudiation/Undeniable)</h2><p>是这个消息就是你给我发的, 无法伪装和否认, 是因为使用了签名的技术来保证的<br>session key 只有通信双方有, 并且不在网络上传输, 因此攻击者无法伪造使用session key加密的数据, 所以具有不可抵赖性<br><a href="https://zhidao.baidu.com/question/1435954777259099899.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/1435954777259099899.html</a></p><p>（机密性由对称加密AES保证, 完整性由SHA384摘要算法保证, 身份认证和不可否认由RSA 非对称加密保证）</p><h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><p>HTTPS 是如何做到这些安全特性呢?<br>秘密就在于 HTTPS 名字里的 <code>S</code>, 它把 HTTP 下层的传输协议由 <code>TCP/IP</code> 换成了 <code>SSL/TLS</code>, 由 <code>HTTP over TCP/IP</code> 变成了 <code>HTTP over SSL/TLS</code>, 让 HTTP 运行在了安全的 SSL/TLS 协议上, 收发报文不再使用 Socket API, 而是调用专门的安全接口<br><img src="/img/http/https-01.png"><br>所以说, HTTPS 本身并没有什么 惊世骇俗的本事, 全是靠着后面的 <code>SSL/TLS</code> “撑腰”, 只要学会了 SSL/TLS, HTTPS 自然就OK了</p><blockquote><p>SSL 即安全套接层(Secure Sockets Layer), 在 OSI 模型中处于第 5 层(会话层), 由 网景公司于 1994 年发明, 有 v2 和 v3 两个版本, 而 v1 因为有严重的缺陷从未公开过<br>SSL 发展到 v3 时已经证明了它自身是一个非常好的安全通信协议, 于是互联网工程组 IETF 在 1999 年把它改名为 TLS(传输层安全, Transport Layer Security), 正式标准化, 版 本号从 1.0 重新算起, 所以 TLS1.0 实际上就是 SSLv3.1<br>到今天 TLS 已经发展出了三个版本, 分别是 2006 年的 1.1、2008 年的 1.2 和去年 (2018)的 1.3, 每个新版本都紧跟密码学的发展和互联网的现状, 持续强化安全和性能, 已经成为了信息安全领域中的权威标准<br>目前应用的最广泛的 TLS 是 1.2, 而之前的协议(TLS1.1/1.0、SSLv3/v2)都已经被认为是不安全的, 各大浏览器即将在 2020 年左右停止支持, 所以接下来的讲解都针对的是 TLS1.2</p></blockquote><ol><li><p>TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成,  综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术</p></li><li><p>浏览器 和 服务器在使用 TLS 建立连接时需要选择一组恰当的加密算法来实现安全通信, 这些算法的组合被称为 <code>密码套件</code>(cipher suite, 也叫加密套件)<br>TLS 的密码套件命名非常规范, 格式很固定, 基本的形式是 <code>密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法</code><br>(比如 <code>ECDHE-RSA-AES256-GCM-SHA384</code> 的意思就是: “握手时使用 ECDHE 算法进行密钥交换, 用 RSA 签名和身份认证, 握手后的通信使用 AES 对称算法, 密钥长度 256 位, 分组模式是 GCM, 摘要算法 SHA384 用于消息认证和 产生随机数”)</p></li></ol><blockquote><p>说到 TLS, 就不能不谈到 OpenSSL, 它是一个著名的开源密码学程序库和工具包, 几乎支 持所有公开的加密算法和协议, 已经成为了事实上的标准, 许多应用软件都会使用它作为底层库来实现 TLS 功能, 包括常用的 Web 服务器 Apache、Nginx 等<br>OpenSSL 目前有三个主要的分支, 1.0.2 和 1.1.0 都将在今年(2019)年底不再维护, 最新的长期支持版本是 1.1.1<br>由于 OpenSSL 是开源的, 所以它还有一些代码分支, 比如 Google 的 BoringSSL、 OpenBSD 的 LibreSSL, 这些分支在 OpenSSL 的基础上删除了一些老旧代码, 也增加了一些新特性, 虽然背后有 大金主, 但离取代 OpenSSL 还差得很远</p></blockquote><h1 id="HTTPS如何为-HTTP-增加四个特性的"><a href="#HTTPS如何为-HTTP-增加四个特性的" class="headerlink" title="HTTPS如何为 HTTP 增加四个特性的"></a>HTTPS如何为 HTTP 增加四个特性的</h1><h2 id="机密性"><a href="#机密性" class="headerlink" title="机密性"></a>机密性</h2><p>机密性是信息安全的基础; 实现机密性最常用的手段是 “加密(encrypt)”, 只有掌握特殊 “钥匙”(密钥(key)) 的人才能再转换出原始文本; 加密前的消息叫 “明文”(plain text/clear text), 加密后的乱码叫”密文”(cipher text), 加密解密的操作过程就是”加密算法”<br>所有的加密算法都是公开的, 任何人都可以去分析研究, 而算法使用的 “密钥” 则必须保密, “密钥”就是一长串的数字, 但约定俗成的度量单位是 “位”(bit), 而不是”字节”(byte)<br>按照密钥的使用方式, 加密可以分为两大类: 对称加密和非对称加密</p><h3 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h3><ol><li><p>“对称加密”就是指加密和解密时使用的密钥都是同一个, 是 “对称” 的。只要保证了密钥的安全, 那整个通信过程就可以说具有了 机密性</p></li><li><p>TLS 里有非常多的对称加密算法可供选择, 比如 RC4、DES、3DES、AES、ChaCha20 等, 但前三种算法都被认为是不安全的, 通常都禁止使用, 目前常用的只有 <code>AES</code> 和 <code>ChaCha20</code></p><ul><li><code>AES</code> 的意思是 高级加密标准(Advanced Encryption Standard), 密钥长度可以是 128、192 或 256; 它是 DES 算法的替代者, 安全强度很高, 性能也很好, 而且有的硬件还会做特殊优化, 所以非常流行, 是应用最广泛的对称加密算法</li><li><code>ChaCha20</code> 是 Google 设计的另一种加密算法, 密钥长度固定为 256 位, 纯软件运行性能要超过 AES, 曾经在移动客户端上比较流行, 但 ARMv8 之后也加入了 AES 硬件优化, 所以现在不再具有明显的优势, 但仍然算得上是一个不错算法</li></ul></li></ol><h3 id="加密分组模式"><a href="#加密分组模式" class="headerlink" title="加密分组模式"></a>加密分组模式</h3><p>对称算法还有一个 <code>分组模式</code> 的概念, 它可以让算法用固定长度的密钥加密任意长度的明文<br>最早的分组模式有 ECB、CBC、CFB、OFB 等几种, 但都陆续被发现有安全漏洞, 所以现在基本都不怎么用了; 最新的分组模式被称为 AEAD(Authenticated Encryption with Associated Data),在加密的同时增加了认证的功能, 常用的是 GCM、CCM 和 Poly1305<br>把上面这些组合起来, 就可以得到 TLS 密码套件中定义的对称加密算法。比如:<br><code>AES128-GCM</code>, 意思是密钥长度为 128 位的 AES 算法, 使用的分组模式是 GCM;<br><code>ChaCha20-Poly1305</code> 的意思是 ChaCha20 算法, 使用的分组模式是 Poly1305;</p><h3 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h3><p>对称加密看上去好像完美地实现了机密性, 但其中有一个很大的问题: 如何把密钥安全地传递给对方, 术语叫 “密钥交换”; 因为在对称加密算法中只要持有密钥就可以解密, 如果你和网站约定的密钥在传递途中被黑客窃取, 那他就可以在之后随意解密收发的数据, 通信过程也就没有机密性可言了, 这个问题该怎么解决呢?</p><blockquote><p>这个问题该怎么解决呢?<br>你或许会说:“把密钥再加密一下发过去就好了”, 但传输“加密密钥的密钥”又成了新问题。这就像是”鸡生蛋、蛋生鸡”, 可以无限递归下去。只用对称加密算法, 是绝对无法解决密钥交换的问题的</p></blockquote><p>所以就出现了 非对称加密(也叫公钥加密算法)</p><ol><li>非对称加密 有两个密钥, 一个叫 <code>公钥</code>(public key), 一个叫 <code>私钥</code>(private key), 两个密钥是不同的(不对称), 公钥可以公开给任何人使用, 而私钥必须严格保密</li><li>公钥和私钥有个特别的 <code>单向</code> 性, 虽然都可以用来加密解密, 但公钥加密后只能用私钥解密, 反过来, 私钥加密后也只能用公钥解密</li><li><p>非对称加密可以解决 密钥交换 的问题。网站秘密保管私钥, 在网上任意分发公钥, 你想要登录网站只要用公钥加密就行了, 密文只能由私钥持有者才能解密。而黑客因为没有私钥, 所以就无法破解密文<br><img src="/img/http/https-publickey-01.png"></p></li><li><p>非对称加密算法的设计要比对称算法难得多, 在 TLS 里只有很少的几种, 比如 <code>DH</code>、 <code>DSA</code>、<code>RSA</code>、<code>ECC</code> 等</p></li></ol><ul><li><p><code>RSA</code> 可能是其中最著名的一个, 几乎可以说是非对称加密的代名词, 它的安全性基于 “整数分解” 的数学难题, 使用两个超大素数的乘积作为生成密钥的材料, 想要从公钥推算出私钥是非常困难的<br>10 年前 RSA 密钥的推荐长度是 1024, 但随着计算机运算能力的提高, 现在 1024 已经不安全, 普遍认为至少要 2048 位</p></li><li><p><code>ECC(Elliptic Curve Cryptography)</code> 是非对称加密里的 “后起之秀”, 它基于 “椭圆曲线 离散对数” 的数学难题, 使用特定的曲线方程和基点生成公钥和私钥<br>子算法 <code>ECDHE</code> 用于 密钥交换, <code>ECDSA</code> 用于数字签名<br>(比起 RSA, ECC 在安全强度和性能上都有明显的优势。160 位的 ECC 相当于 1024 位的 RSA, 而 224 位的 ECC 则相当于 2048 位的 RSA。因为密钥短, 所以相应的计算量、消耗 的内存和带宽也就少, 加密解密的性能就上去了, 对于现在的移动互联网非常有吸引力。)</p></li></ul><h3 id="混合加密"><a href="#混合加密" class="headerlink" title="混合加密"></a>混合加密</h3><ol><li><p>虽然非对称加密没有 密钥交换 的问题, 但因为它们都是基于复杂的数学难题, 运算速度很慢(即使是 ECC 也要比 对称加密算法AES 差上好几个数量级), 如果仅用非对称加密, 虽然保证了安全, 但实用性就变成了零</p></li><li><p>因此就需要考虑, 是不是能够把对称加密和非对称加密结合起来呢, 两者互相取长补短, 即能高效地加密解密, 又能安全地密钥交换, <strong>这就是现在 TLS 里使用的混合加密方式</strong>: </p><ul><li>在通信刚开始的时候使用 非对称算法, 比如 <code>RSA</code>、<code>ECDHE</code>, 首先解决密钥交换的问题</li><li>然后用随机数产生对称算法使用的 <code>会话密钥 (session key)</code>, 再用公钥加密。因为会话密钥很短, 通常只有 16 字节或 32 字节, 所以慢一点也无所谓</li><li>对方拿到密文后用私钥解密, 取出会话密钥。这样, 双方就实现了对称密钥的安全交换, 后续就不再使用非对称加密, 全都使用对称加密</li></ul></li><li><p>从下往上如下图<br><img src="/img/http/https-publickey-02.png"><br>这样混合加密就解决了对称加密算法的密钥交换问题, 而且安全和性能兼顾, 完美地实现了机密性</p></li></ol><p>不过这只是 “万里长征的第一步”, 后面还有完整性、身份认证、不可否认等特性没有实现, 所以现在的通信还不是绝对安全</p><h1 id="TLS1-2连接过程解析"><a href="#TLS1-2连接过程解析" class="headerlink" title="TLS1.2连接过程解析"></a>TLS1.2连接过程解析</h1><h2 id="HTTPS-建立连接"><a href="#HTTPS-建立连接" class="headerlink" title="HTTPS 建立连接"></a>HTTPS 建立连接</h2><ol><li><p>当你在浏览器地址栏里键入 <code>https</code> 开头的 URI, 再按下回车, 会发生什么呢?<br>浏览器首先要从 URI 里提取出协议名和域名, 因为协议名是 https, 所以浏览器就知道了端口号是默认的 443, 它再用 DNS 解析域名,  得到目标的 IP 地址, 然后就可以使用三次握手与网站建立 TCP 连接了</p></li><li><p>在 HTTP 协议里, 建立连接后, 浏览器会立即发送请求报文。但现在是 HTTPS 协议, 它需要再用另外一个 握手 过程, 在 TCP 上建立安全连接, 之后才是收发 HTTP 报文。<br> 这个 握手 过程与 TCP 有些类似, 是 HTTPS 和 TLS 协议里最重要、最核心的部分, 懂了它, 你就可以自豪地说自己 掌握了HTTPS</p></li></ol><h2 id="TLS-协议的组成"><a href="#TLS-协议的组成" class="headerlink" title="TLS 协议的组成"></a>TLS 协议的组成</h2><p>在讲 TLS 握手之前, 先简单介绍一下 TLS 协议的组成<br>TLS 包含几个子协议, 你也可以理解为它是由几个不同职责的模块组成, 比较常用的有 <code>记录协议</code>、<code>警报协议</code>、<code>握手协议</code>、<code>变更密码规范协议</code> 等</p><ul><li><code>记录协议</code>(Record Protocol) 规定了 TLS 收发数据的基本单位: 记录(record), 它有点像是 TCP 里的 segment, 所有的其他子协议都需要通过记录协议发出。但多个记录数据可以在一个 TCP 包里一次性发出, 也并不需要像 TCP 那样返回 ACK</li><li><code>警报协议</code>(Alert Protocol) 的职责是向对方发出警报信息, 有点像是 HTTP 协议里的状态码。比如, protocol_version 就是不支持旧版本, bad_certificate 就是证书有问题, 收到 警报后另一方可以选择继续, 也可以立即终止连接</li><li><code>握手协议</code>(Handshake Protocol) 是 TLS 里最复杂的子协议, 要比 TCP 的 SYN/ACK 复 杂的多, 浏览器和服务器会在握手过程中协商 TLS 版本号、随机数、密码套件等信息, 然 后交换证书和密钥参数, 最终双方协商得到会话密钥, 用于后续的混合加密系统</li><li>最后一个是 <code>变更密码规范协议</code>(Change Cipher Spec Protocol), 它非常简单, 就是一个“通知”, 告诉对方, 后续的数据都将使用加密保护。那么反过来, 在它之前, 数据都是明文的</li></ul><p>……………</p><h1 id="迁移HTTPS的必要性"><a href="#迁移HTTPS的必要性" class="headerlink" title="迁移HTTPS的必要性"></a>迁移HTTPS的必要性</h1><p>如果你做移动应用开发的话, 那么就一定知道, Apple、Android、某信等开发平台在 2017 年就相继发出通知, 要求所有的应用必须使用 HTTPS 连接, 禁止不安全的 HTTP<br>在台式机上, 主流的浏览器 Chrome、Firefox 等也早就开始 强推 HTTPS, 把 HTTP 站 点打上 不安全 的标签, 给用户以 心理压力<br>Google 等搜索巨头还利用自身的“话语权”优势, 降低 HTTP 站点的排名, 而给 HTTPS 更大的权重, 力图让网民只访问到 HTTPS 网站<br>这些手段都逐渐 挤压 了纯明文 HTTP 的生存空间,  迁移到 HTTPS 已经不是要不要做的问题, 而是要怎么做的问题了, HTTPS 的大潮无法阻挡, 如果还是死守着 HTTP, 那么无疑会被冲刷到互联网的角落里<br>目前国内外的许多知名大站都已经实现了 全站 HTTPS , 打开常用的某宝、某东、某 浪, 都可以在浏览器的地址栏里看到 小锁头 , 如果你正在维护的网站还没有实施 HTTPS,  那可要抓点紧了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;之前曾谈到过 HTTP 的一些缺点, 其中的 &lt;code&gt;无状态&lt;/code&gt; 在加入 &lt;code&gt;Cookie&lt;/code&gt; 后得到了解决
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>HTTP 缓存代理</title>
    <link href="http://blog.renyimin.com/2019/10/23/http/2019-10-23-HTTP-Proxy-cache/"/>
    <id>http://blog.renyimin.com/2019/10/23/http/2019-10-23-HTTP-Proxy-cache/</id>
    <published>2019-10-23T11:50:17.000Z</published>
    <updated>2019-10-23T11:33:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>把之前介绍的 HTTP 缓存控制 和 HTTP 的代理服务 结合起来就是这节所要说的 <strong>缓存代理</strong>, 也就是支持缓存控制的代理服务</p><p>之前谈到缓存时, 主要讲了客户端(浏览器)上的缓存控制, 它能够减少响应时间、节约带宽, 提升客户端的用户体验。但 HTTP 传输链路上, 不只是客户端有缓存, 服务器上的缓存也是非常有价值的, 可以让请求不必走完整个后续处理流程, 而是”就近”获得响应结果</p><p>HTTP 的服务器缓存功能主要由代理服务器来实现(即缓存代理), 而源服务器系统内部虽然也经常有各种缓存(如 Memcache、Redis、Varnish 等), 但与 HTTP 没有太多关系, 所以这里暂且不说</p><p><img src="/img/http/http-proxy-cache.png" width="500/"></p><p>1。 代理服务收到源服务器发来的响应数据后需要做两件事</p><pre><code>- 第一个当然是把报文转发给客户端, 而第二个就是把报文存入自己的 Cache 里- 下一次再有相同的请求, 代理服务器就可以直接发送 304 或者缓存数据, 不必再从源服务器那里获取。这样就降低了客户端的等待时间, 同时节约了源服务器的网络带宽</code></pre><ol><li>作为中转站的 代理服务器, 它除了具备 客户端和服务器的双重角色, 可以使用之前的 <code>Cache-Control</code> 属性外, 还有一些特有的 <code>Cache-Control</code> 属性<br> 因为它和客户端还是有一些不一样, 客户端的缓存只是用户自己使用, 而代理的缓存可能会为非常多的客户端提供服务。所以, 需要对它的缓存再多一些限制条件</li></ol><h1 id="代理服务器-Cache-Control"><a href="#代理服务器-Cache-Control" class="headerlink" title="代理服务器 Cache-Control"></a>代理服务器 Cache-Control</h1><ol><li>代理服务器首先要区分源服务器给他的缓存, 是让客户端缓存还是让代理缓存, 可以使用两个新属性 <code>private</code> 和 <code>public</code><ul><li>private 表示缓存只能在客户端保存, 是用户 私有的, 不能放在代理上与别人共享</li><li>而 public 的意思就是缓存完全开放, 是存在代理服务器上, 谁都可以存, 谁都可以用</li></ul></li></ol><ol><li><p>其次, 缓存失效后的重新验证也要区分开 (即 条件请求 <code>Last-modified</code> 和 <code>ETag</code>)</p><ul><li><code>must-revalidate</code> 是只要过期就必须回源服务器验证</li><li>而新的 <code>proxy-revalidate</code> 只要求代理的缓存过期后必须验证, 客户端不必回源, 只验证到代理这个环节就行了</li></ul></li><li><p>再其次, 缓存的生存时间可以使用新的 <code>s-maxage</code> (s 是 share 的意思, 注意 maxage 中间没有 “-“), 只限定在代理上能够存多久, 而客户端仍然使用 “max-age”</p></li><li><p>还有一个代理专用的属性 <code>no-transform</code><br> 代理有时候会对缓存下来的数据做一些优化, 比如把图片生成 png、webp 等几种格式, 方便今后的请求处理, 而 <code>no-transform</code> 就会禁止这样做, 不许“偷偷摸摸搞小动作”</p></li><li><p>注意: 源服务器在设置完“Cache-Control”后必须要为报文加上“Last- modified”或“ETag”字段。否则, 客户端和代理后面就无法使用条件请求来验证缓存是否有效, 也就不会有 304 缓存重定向</p></li><li><p>下面的流程图是完整的服务器端缓存控制策略, 可以同时控制客户端和代理<br><img src="/img/http/http-proxy-cache-001.png"><br><img src="/img/http/http-proxy-cache-002.png"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;把之前介绍的 HTTP 缓存控制 和 HTTP 的代理服务 结合起来就是这节所要说的 &lt;strong&gt;缓存代理&lt;/strong&gt;, 也就是支持缓存控制的代理服务&lt;/p&gt;
&lt;p&gt;之前谈到缓存时, 主要讲了客户端(浏览器)上的缓存控制, 它能够减少响应时间、节约带宽, 提升客户
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>HTTP 代理服务</title>
    <link href="http://blog.renyimin.com/2019/10/23/http/2019-10-23-HTTP-Proxy/"/>
    <id>http://blog.renyimin.com/2019/10/23/http/2019-10-23-HTTP-Proxy/</id>
    <published>2019-10-23T08:41:43.000Z</published>
    <updated>2019-10-23T06:09:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>引入 HTTP 代理后, 原来简单的双方通信就变复杂了一些, 加入了一个或者多个中间人,  但整体上来看, 还是一个有顺序关系的链条, 而且链条里相邻的两个角色仍然是简单的一对一通信, 不会出现越级的情况<br><img src="/img/http/http-proxy-01.png" width="500/"><br>链条的起点还是客户端(也就是浏览器), 中间的角色被称为代理服务器(proxy server), 链条的终点被称为源服务器(origin server)</p><h1 id="代理服务"><a href="#代理服务" class="headerlink" title="代理服务"></a>代理服务</h1><ol><li><p>“代理” 这个词听起来好像很神秘, 有点“高大上”的感觉, 但其实 HTTP 协议里对它并没有什么特别的描述, 它就是在客户端和服务器原本的通信链路中插入的一个中间环节, 也是一台服务器, 但提供的是 “代理服务”<br>所谓的“代理服务”就是指服务本身不生产内容, 而是处于中间位置转发上下游的请求和响应, 具有双重身份:面向下游的用户时, 表现为服务器, 代表源服务器响应客户端的请求;<br>而面向上游的源服务器时, 又表现为客户端, 代表客户端发送请求;</p></li><li><p>代理有很多的种类, 例如 匿名代理、透明代理、正向代理和反 向代理, 这里主要是聊聊实际工作中最常见的 反向代理, 它在传输链路中更靠近源服务器, 为源服务器提供代理服务</p></li></ol><h1 id="代理的作用"><a href="#代理的作用" class="headerlink" title="代理的作用"></a>代理的作用</h1><p>由于代理处在 HTTP 通信过程的中间位置, 相应地就对上屏蔽了真实客户端, 对下屏蔽了真实服务器。在这个中间层的里就可以做很多的事情, 为 HTTP 协议增加更多的灵活性, 实现客户端和服务器的 “双赢”</p><ol><li><p>代理最基本的一个功能是 <strong>负载均衡</strong><br>因为在面向客户端时屏蔽了源服务器, 客户端看到的只是代理服务器, 源服务器究竟有多少台、是哪些 IP 地址 客户端都不知道, 于是代理服务器就可以掌握请求分发的“大权”, 决定由后面的哪台服务器来响应请求<br>(代理中常用的负载均衡算法如轮询、一致性哈希等等, 这些算法的目标都是尽量把外部的流量合理地分散到多台源服务器, 提高系统的整体资源利用率和性能)</p></li><li><p>除了负载均衡, 代理服务还可以执行其他的更多功能, 如:</p><ul><li>健康检查: 使用“心跳”等机制监控后端服务器, 发现有故障就及时“踢出”集群, 保证服务高可用;</li><li>安全防护: 保护被代理的后端服务器, 限制 IP 地址或流量, 抵御网络攻击和过载; </li><li>加密卸载: 对外网使用 SSL/TLS 加密通信认证, 而在安全的内网不加密, 消除加解密成本;</li><li>数据过滤: 拦截上下行的数据, 任意指定策略修改请求或者响应; </li><li>内容缓存: 暂存、复用服务器响应</li></ul></li></ol><h1 id="代理相关头字段"><a href="#代理相关头字段" class="headerlink" title="代理相关头字段"></a>代理相关头字段</h1><p>代理的好处很多, 但因为它“欺上瞒下”的特点, 隐藏了真实客户端和服务器, 如果双方想要获得这些“丢失”的原始信息, 该怎么办呢?</p><h2 id="via"><a href="#via" class="headerlink" title="via"></a>via</h2><p>首先, 代理服务器需要用字段 <code>Via</code> 标明代理的身份<br>Via 是一个通用字段, 请求头 或 响应头里都可以出现, 每当报文经过一个代理节点, 代理服务器就会把自身的信息追加到字段的末尾, 就像是经手人盖了一个章; 如果通信链路中有很多中间代理, 就会在 Via 里形成一个链表, 这样就可以知道报文究竟走过了多少个环节才到达了目的地。<br>例如下图中有两个代理: proxy1 和 proxy2, 客户端发送请求会经过这两个代理, 依次添加就是 “Via: proxy1, proxy2”, 等到服务器返回响应报文的时候就要反过来走, 头字段就是 “Via: proxy2, proxy1”<br><img src="/img/http/http-via-01.png" width="500/"></p><p>不过, Via 字段只解决了客户端和源服务器判断是否存在代理的问题, 还不能知道对方的真实信息</p><h2 id="X-Forwarded-For、X-Real-IP"><a href="#X-Forwarded-For、X-Real-IP" class="headerlink" title="X-Forwarded-For、X-Real-IP"></a>X-Forwarded-For、X-Real-IP</h2><p>比如, 服务器的 IP 地址应该是保密的, 关系到企业的内网安全, 所以一般不会让客户端知道。 但反过来看, 服务器通常是需要知道客户端的真实 IP 地址, 方便做访问控制、用户画像、统计分析<br>可惜的是 HTTP 标准里并没有为此定义头字段, 但已经出现了很多 “事实上的标准”, 最 常用的两个头字段是 <code>X-Forwarded-For</code> 和 <code>X-Real-IP</code></p><ol><li><p><code>X-Forwarded-For</code> 的字面意思是 “为谁而转发”, 形式上和 “Via” 差不多, 也是每经过一个代理节点就会在字段里追加一个信息; 但 <code>Via</code> 追加的是代理主机名(或者域名), 而 <code>X-Forwarded-For</code> 追加的是请求方的 IP 地址, 所以, 在字段里最左边的 IP 地址就客户端的地址</p></li><li><p><code>X-Real-IP</code> 是另一种获取客户端真实 IP 的手段, 它的作用很简单, 就是记录客户端 IP 地址, 没有中间的代理信息, 相当于是 <code>X-Forwarded-For</code> 的简化版。如果客户端和源 服务器之间只有一个代理, 那么这两个字段的值就是相同的<br>…</p></li></ol><h1 id="代理协议"><a href="#代理协议" class="headerlink" title="代理协议"></a>代理协议</h1><ol><li><p>有了 <code>X-Forwarded-For</code> 等头字段, 源服务器就可以拿到准确的客户端信息了, 但对于代理服务器来说它并不是一个最佳的解决方案<br> 因为通过 “X-Forwarded-For” 操作代理信息必须要解析 HTTP 报文头, 这对于代理来说成本比较高, 原本只需要简单地转发消息就好, 而现在却必须要费力解析数据再修改数据, 会降低代理的转发性能<br> 另一个问题是 “X-Forwarded-For” 等头必须要修改原始报文, 而有些情况下是不允许甚至不可能的(比如使用 HTTPS 通信被加密)</p></li><li><p>所以就出现了一个专门的“代理协议”(The PROXY protocol), 它由知名的代理软件 HAProxy 所定义, 也是一个“事实标准”, 被广泛采用(注意并不是 RFC)</p></li><li><p>……</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;引入 HTTP 代理后, 原来简单的双方通信就变复杂了一些, 加入了一个或者多个中间人,  但整体上来看, 还是一个有顺序关系的链条, 而且链条里相邻的两个角色仍然是简单的一对一通信, 不会出现越级的情况&lt;br&gt;&lt;img src=&quot;/img/http/http-proxy-
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>HTTP 缓存控制 和 条件请求</title>
    <link href="http://blog.renyimin.com/2019/10/22/http/2019-10-22-HTTP-CacheControl/"/>
    <id>http://blog.renyimin.com/2019/10/22/http/2019-10-22-HTTP-CacheControl/</id>
    <published>2019-10-22T06:30:12.000Z</published>
    <updated>2019-11-04T02:59:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>鉴于 HTTP “请求 - 应答” 模式的特点, 这里将 HTTP的缓存 大致分为 <strong>客户端缓存</strong>(也就是浏览器的缓存) 和 <strong>服务器端缓存</strong></p><h1 id="服务器端缓存控制"><a href="#服务器端缓存控制" class="headerlink" title="服务器端缓存控制"></a>服务器端缓存控制</h1><p>服务器标记资源有效期使用的头字段是 <code>Cache-Control</code> </p><ol><li><p><code>Cache-Control</code> 字段里的 <code>max-age</code> 属性 是用来标记资源的有效期 (<code>Cache-Control: max-age=30</code> 相当于告诉浏览器, 这个页面只能缓存30秒, 之后就算是过期)<br> 注意: <code>max-age</code> 是 “生存时间” (又叫 “新鲜度” “缓存寿命”), 时间的计算起点是 响应报文的创建时刻(即 <code>Date</code> 字段, 也就是离开服务器的时刻), 而不是客户端收到报文的时刻, 也就是说包含了在链路传输过程中所有节点所停留的时间<br> (比如, 服务器设定 <code>Cache-Control: max-age=5</code>, 但因为网络质量很糟糕, 等浏览器收到响应报文已经过去了 4 秒, 那么这个资源在客户端就最多能够再存 1 秒钟, 之后就会失效)<br> <code>max-age</code> 是 HTTP 缓存控制最常用的属性, 此外在响应报文里还可以用如下其他的属性来更精确地指示浏览器应该如何使用缓存</p></li><li><p><code>no_store</code>: 不允许缓存, 用于某些变化非常频繁的数据, 例如秒杀页面</p></li><li><p><code>no_cache</code>: 它的字面含义容易与 <code>no_store</code> 搞混, 实际的意思并不是不允许缓存, 而是可以缓存, 但在使用之前必须要去服务器验证是否过期, 是否有最新的版本 (貌似就是虽然存了, 但是不用)<br> 如果验证没有过期, 则直接取客户端浏览器中的缓存; 否则, 客户端重新缓存新的数据, 然后再返回;<br> “no-cache” 属性可以理解为 “max-age=0, must-revalidate” </p></li><li><p><code>must-revalidate</code>: 又是一个和 <code>no_cache</code> 相似的词, 它的意思是如果缓存不过期就可以继续使用, 但过期了如果还想用就必须去服务器验证<br> 这个状态貌似比较正常, 缓存有效就用, 缓存没效就重新取~~ </p></li><li><p>除了 <code>Cache-Control</code>, 服务器也可以使用 <code>Expires</code> 字段来标记资源的有效期, 不过其优先级低于 Cache-Control; 另外还有一个历史遗留字段 <code>Pragma: no-cache</code>, 它相当于 <code>Cache-Control: no-cache</code>, 除非是为了兼容HTTP/1.0 否则不建议使用</p></li><li><p>小结<br>服务器的缓存控制策略流程图大致如下, 对照着它就可以在今后的后台开发里明确 <code>Cache-Control</code> 的用法了<br><img src="/img/http/http-cache-control-01.png" width="500/"></p></li></ol><p><img src="/img/http/http-cache-control-02.png"></p><h1 id="客户端缓存控制"><a href="#客户端缓存控制" class="headerlink" title="客户端缓存控制"></a>客户端缓存控制</h1><ol><li><p>注意: 仅仅当 服务器端 使用了 <code>Cache-Control: max-age=30</code> 时, 你点击浏览器 “刷新” 按钮会发现, 貌似缓存并未生效, 如下测试:<br>~~<br>这是因为: 不止是服务器可以发 <code>Cache-Control</code> 头, 客户端浏览器也可以发 <code>Cache-Control</code>, 也就是说 “请求-应答” 的双方都可以用这个字段进行缓存控制, 互相协商缓存的使用策略<br>(而当你点 “刷新” 按钮的时候, 浏览器会在请求头里加一个 <code>Cache-Control: max-age=0</code>, 由于 <code>max-age</code> 是 “生存时间”, max-age=0 的意思就是 不进行缓存,而是每次都去服务器去最新数据, 而本地缓存里的数据至少保存了几秒钟)</p></li><li><p><code>Ctrl+F5</code>(MacOS是 <code>shift+command+r</code>) 的 <strong>强制刷新</strong> 又是什么样的呢?<br>尝试发现, 它是发了一个 <code>Cache-Control: no-cache</code>, 含义和 <code>max-age=0</code> 基本一样, 就看后台的服务器怎么理解, 通常两者的效果是相同的</p></li><li><p>那么, 浏览器的缓存究竟什么时候才能生效呢?</p><ul><li>试着点一下浏览器的 <code>前进</code> <code>后退</code> 按钮, 再看开发者工具, 你就会惊喜地发现 <code>from disk cache</code> 的字样, 意思是没有发送网络请求, 而是读取的磁盘上的缓存<br>~~</li><li>如果用第 18 讲里的重定向跳转功能, 也可以发现浏览器使用了缓存<br>~~</li></ul></li></ol><h1 id="条件请求"><a href="#条件请求" class="headerlink" title="条件请求"></a>条件请求</h1><p>HTTP 协议定义了一系列 <code>If</code> 开头的 <code>条件请求</code> 字段, 专门用来验证资源是否过期 (验证的责任是服务器的责任, 浏览器只需”坐享其成”)</p><p>1.客户端的 条件请求 一共有5个头字段, 我们最常用的是 <code>if-Modified-Since</code> 和 <code>If-None-Match</code> 这两个<br>它们需要第一次的响应报文预先提供 <code>last-modified</code> 和 <code>ETag</code>, 然后第二次请求时就可以带上缓存里的原值, 验证资源是否是最新的, 如果资源没有变, 服务器就回应一个 <code>304 Not Modified</code>, 表示缓存依然有效, 浏览器就可以更新一下有效期, 然后放心大胆地使用缓存了<br><img src="/img/http/http-cache-if-01.png"></p><ul><li><code>Last-modified</code> 很好理解, 就是文件的最后修改时间</li><li><code>ETag</code> 是 “实体标签(Entity Tag)” 的缩写, 是资源的一个唯一标识, 主要是用来解决 修改时间无法准确区分文件变化的问题<br>比如, 一个文件在一秒内修改了多次, 但因为修改时间是秒级, 所以这一秒内的新版本无法区分<br>再比如, 一个文件定期更新, 但有时会是同样的内容, 实际上没有变化, 如果用修改时间判断 就会误以为发生了变化, 传送给浏览器就会浪费带宽<br>使用 ETag 就可以精确地识别资源的变动情况, 让浏览器能够更有效地利用缓存</li><li>ETag 还有 “强”、”弱” 之分<br>强 ETag 要求资源在字节级别必须完全相符<br>弱 ETag 在值前有个 <code>W/</code> 标记, 只要求资源在语义上没有变化, 但内部可能会有部分发生了改变(例如 HTML 里的标签顺序调整, 或者多了几个空格)</li><li>小结<blockquote><p>还是拿生鲜速递做比喻最容易理解:<br>你打电话给超市, “我这个西瓜是 3 天前买的, 还有最新的吗?”。超市看了一下库存,  说:“没有啊, 我这里都是 3 天前的。”于是你就知道了, 再让超市送货也没用, 还是吃 冰箱里的西瓜吧。这就是“if-Modified-Since”和“Last-modified”<br>但你还是想要最新的, 就又打电话:“有不是沙瓤的西瓜吗?”, 超市告诉你都是沙瓤的 (Match), 于是你还是只能吃冰箱里的沙瓤西瓜。这就是“If-None-Match”和“弱 ETag”<br>第三次打电话, 你说 “有不是 8 斤的沙瓤西瓜吗?”, 这回超市给了你满意的答复:“有 个 10 斤的沙瓤西瓜”。于是, 你就扔掉了冰箱里的存货, 让超市重新送了一个新的大西瓜。这就是“If-None-Match”和“强 ETag”</p></blockquote></li></ul><p>2.条件请求里其他的三个头字段是 <code>If-Unmodified-Since</code>、<code>If-Match</code> 和 <code>If-Range</code>, 其实只要你掌握了 <code>if-Modified-Since</code> 和 <code>If-None-Match</code>, 可以轻易地举一反三</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>用好 HTTP 的缓存控制和条件请求, 可以减少响应时间、节约网络流量</p><ol><li>服务器使用 Cache-Control 设置缓存策略, 常用的是 <code>max-age</code>, 表示资源的有效期</li><li>浏览器收到数据就会存入缓存, 如果没过期就可以直接使用, 过期就要去服务器验证是否仍然可用</li><li>验证资源是否失效需要使用 <strong>条件请求</strong>, 常用的是 <code>if-Modified-Since</code> 和 <code>If-None-Match</code>, 收到 304 就可以复用缓存里的资源</li><li>验证资源是否被修改的条件有两个: <code>Last-modified</code> 和 <code>ETag</code>, 需要服务器预先在响应报文里设置, 搭配条件请求使用</li><li>浏览器也可以发送 <code>Cache-Control</code> 字段, 使用 <code>max-age=0</code> 或 <code>no_cache</code> 刷新数据</li></ol><h1 id="客户端缓存控制补充"><a href="#客户端缓存控制补充" class="headerlink" title="客户端缓存控制补充"></a>客户端缓存控制补充</h1><p>客户端在 HTTP 缓存体系里要面对的是 代理 和 源服务器, 所以是必须区别对待的, 直接上图<br><img src="/img/http/http-proxy-cache-003.png"><br><img src="/img/http/http-proxy-cache-004.png"><br>比如 如果服务端返回的响应头设置了 <code>Cache-Control: public, max-age=10, s-maxage=30</code>, 数据可以在浏览器里存 10 秒, 在代理上存 30 秒</p><ol><li><p>可以看到, 关于缓存的生存时间, 多了两个新属性 <code>max-stale</code> 和 <code>min-fresh</code></p><ul><li><code>max-stale</code> 的意思是如果代理上的缓存过期了也可以接受, 但不能过期太多, 超过 x 秒就会不要了</li><li><code>min-fresh</code> 的意思是缓存必须有效, 而且必须在 x 秒后依然有效<br>(max-stale是可以接受的过期时间, min-fresh是可以接受的新鲜时间。 不好理解也没事, 这两个属性用的不多, 可以以后实际遇到了再体会)</li></ul></li><li><p>有的时候客户端还会发出一个特别的 <code>only-if-cached</code> 属性, 表示只接受代理缓存的数据, 不接受源服务器的响应。如果代理上没有缓存或者缓存过期, 就应该给客户端返回一个 504(Gateway Timeout)</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;鉴于 HTTP “请求 - 应答” 模式的特点, 这里将 HTTP的缓存 大致分为 &lt;strong&gt;客户端缓存&lt;/strong&gt;(也就是浏览器的缓存) 和 &lt;strong&gt;服务器端缓存&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;服务器端缓存控制&quot;&gt;&lt;a href=&quot;#服务器
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>XSS(Cross Site Scripting) 跨站脚本攻击</title>
    <link href="http://blog.renyimin.com/2019/10/22/http/2019-10-22-XSS/"/>
    <id>http://blog.renyimin.com/2019/10/22/http/2019-10-22-XSS/</id>
    <published>2019-10-22T02:29:12.000Z</published>
    <updated>2019-11-05T09:10:09.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="XSS-简介"><a href="#XSS-简介" class="headerlink" title="XSS 简介"></a>XSS 简介</h1><ol><li><p>XSS(Cross Site Scripting)攻击 全称 跨站脚本攻击, 是为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆, 故将跨站脚本攻击缩写为XSS, XSS是一种经常出现在web应用中的计算机安全漏洞</p></li><li><p>XSS 通常指黑客通过 “HTML注入” 篡改了网页, 插入了恶意的脚本, 从而在用户浏览网页时, 控制用户浏览器的一种攻击;</p></li><li><p>XSS根据效果的不同可以分多种</p></li></ol><h1 id="XSS分类"><a href="#XSS分类" class="headerlink" title="XSS分类"></a>XSS分类</h1><h2 id="反射型-XSS"><a href="#反射型-XSS" class="headerlink" title="反射型 XSS"></a>反射型 XSS</h2><p>反射型XSS: 反射型XSS又被称为非存储型XSS, 攻击者通常会通过URL参数传入恶意语句从而实现攻击<br>由于我们的payload未经过一个存储的过程直接传到了用户浏览的页面上, 所以也称之为非存储型XSS</p><p>(反射型XSS只是简单地把用户输入的数据 “反射” 给浏览器。也就是说, 黑客往往需要诱使用户”点击”一个恶意链接, 才能攻击成功)</p><p>最简单的反射型XSS拿cookie: <a href="https://blog.csdn.net/thislocal/article/details/51010021" target="_blank" rel="noopener">https://blog.csdn.net/thislocal/article/details/51010021</a></p><h2 id="存储型-XSS"><a href="#存储型-XSS" class="headerlink" title="存储型 XSS"></a>存储型 XSS</h2><p>存储型XSS：攻击者在页面中插入XSS代码, 服务器将恶意代码传至数据库, 当受害者浏览页面时服务器将代码取出从而实现攻击。<br>(存储型xss与反射型xss的区别在于存储型会将用户输入的数据存入服务器, 在用户下一次点击时便会触发, 由于其隐蔽性较高, 所以危害也普遍大于反射型xss)<br><img src="/img/http/persistent-xss.png" width="500/"></p><h2 id="DOM-Based-XSS"><a href="#DOM-Based-XSS" class="headerlink" title="DOM Based XSS"></a>DOM Based XSS</h2><p>DOM型XSS: DOM型XSS与反射型XSS漏洞大同小异, 但是区别在于反射型XSS会将语句存储于后端再出现在前端页面, 而DOM型XSS漏洞直接将语句存储于前端</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p><img src="/img/http/xss.png" width="500/"></p><p><a href="http://www.imooc.com/article/252521" target="_blank" rel="noopener">http://www.imooc.com/article/252521</a></p><h1 id="XSS-漏洞修复方法"><a href="#XSS-漏洞修复方法" class="headerlink" title="XSS 漏洞修复方法"></a>XSS 漏洞修复方法</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;XSS-简介&quot;&gt;&lt;a href=&quot;#XSS-简介&quot; class=&quot;headerlink&quot; title=&quot;XSS 简介&quot;&gt;&lt;/a&gt;XSS 简介&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;XSS(Cross Site Scripting)攻击 全称 跨站脚本攻击, 是为不和层叠
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>CSRF</title>
    <link href="http://blog.renyimin.com/2019/10/22/http/2019-10-22-CSRF/"/>
    <id>http://blog.renyimin.com/2019/10/22/http/2019-10-22-CSRF/</id>
    <published>2019-10-22T02:29:12.000Z</published>
    <updated>2019-11-06T02:38:44.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>Cookie</title>
    <link href="http://blog.renyimin.com/2019/10/21/http/2019-10-21-HTTP-Cookie/"/>
    <id>http://blog.renyimin.com/2019/10/21/http/2019-10-21-HTTP-Cookie/</id>
    <published>2019-10-21T05:10:31.000Z</published>
    <updated>2019-11-04T02:59:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>HTTP协议 是 “无状态” 的, 但却是可扩展的, 后来发明的 Cookie 技术, 就给 HTTP 增加了 “记忆能力”</p><h1 id="Cookie-的工作过程"><a href="#Cookie-的工作过程" class="headerlink" title="Cookie 的工作过程"></a>Cookie 的工作过程</h1><p>Cookie 的传递主要用到两个字段: 响应头字段 <code>Set-Cookie</code> 和 请求头字段 <code>Cookie</code></p><ol><li><p>当用户通过浏览器第一次访问服务器的时候, 服务器肯定是不知道他的身份的。所以, 服务器就要创建一个独特的身份标识数据, 格式是 <code>key=value</code>, 然后放进 <code>Set-Cookie</code> 字段里,  随着响应报文一同发给浏览器<br> 浏览器收到响应报文, 看到里面有 <code>Set-Cookie</code>, 知道这是服务器给的身份标识, 于是就保存起来, 下次再请求的时候就自动把这个值放进 <code>Cookie</code> 字段里发给服务器 </p></li><li><p>浏览器第二次请求时, 请求头字段里面有了 Cookie 字段, 服务器就知道这个用户不是新人, 之前来过, 就拿出 Cookie 里的值, 识别出用户的身份, 然后提供个性化的服务<br> 服务器可以在响应头里添加多个 <code>Set-Cookie</code>, 存储多个 “key=value”, 但浏览器这边发送时不需要用多个 Cookie 字段, 只要在一行里用 <code>;</code> 隔开就行</p></li></ol><h1 id="Cookie-的属性"><a href="#Cookie-的属性" class="headerlink" title="Cookie 的属性"></a>Cookie 的属性</h1><p>Cookie 就是服务器委托浏览器存储在客户端里的一些数据, 而这些数据通常都会记录用户的关键识别信息。所以在 “key=value” 外, 还需要再用一些手段来保护Cookie, 防止外泄或窃取, 这些手段就是 Cookie 的属性<br><img src="/img/http/http-cookie-01.png"></p><p>为了保护 Cookie, 还要给它设置有效期、作用域等属性, 常用的有 Max-Age、Expires、Domain、HttpOnly 等</p><h2 id="Expires、Max-Age"><a href="#Expires、Max-Age" class="headerlink" title="Expires、Max-Age"></a>Expires、Max-Age</h2><p>首先, 我们应该设置 Cookie 的生存周期, 也就是它的有效期, 让它只能在一段时间内可用, 就像是食品的” 保鲜期”, 一旦超过这个期限浏览器就认为是 Cookie 失效, 在存储里删除, 也不会发送给服务器<br>Cookie 的有效期可以使用 <code>Expires</code> 和 <code>Max-Age</code> 两个属性来设置:</p><ul><li><code>Expires</code> 俗称 “过期时间”, 用的是绝对时间点, 可以理解为 “截止日期”(deadline)</li><li><code>Max-Age</code> 用的是相对时间, 单位是<strong>秒</strong>, 浏览器用收到报文的时间点再加上 Max-Age, 就可以得到失效的绝对时间</li><li><code>Expires</code> 和 <code>Max-Age</code> 可以同时出现, 两者的失效时间可以一致, 也可以不一致, <strong>但浏览器会优先采用 Max-Age 计算失效期</strong></li></ul><h2 id="Domain、Path"><a href="#Domain、Path" class="headerlink" title="Domain、Path"></a>Domain、Path</h2><p>其次, 需要设置 Cookie 的作用域, 让浏览器仅发送给特定的服务器 和 URI, 避免被其他网站盗用<br>作用域的设置比较简单, <code>Domain</code> 和 <code>Path</code> 指定了 Cookie 所属的域名和路径, 浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分, 对比 Cookie 的属性, 如果不满足条件, 就不会在请求头里发送 Cookie</p><p>使用这两个属性可以为不同的 域名 和 路径 分别设置各自的 Cookie (比如 “/19-1” 用一个 Cookie, “/19-2” 再用另外一个 Cookie, 两者互不干扰, 不过现实中为了省事, 通常 Path 就用一个 “/“ 或者直接省略,表示域名下的任意路径都允许使用该Cookie)</p><h2 id="HttpOnly"><a href="#HttpOnly" class="headerlink" title="HttpOnly"></a>HttpOnly</h2><p>最后要考虑的就是Cookie 的安全性了, 尽量不要让服务器以外的人看到<br>写过前端的同学一定知道, 在 JS 脚本里可以用 <code>document.cookie</code> 来读写 Cookie 数据,这就带来了安全隐患, 有可能会导致 “跨站脚本”(XSS)攻击窃取数据</p><p>属性 “HttpOnly” 会告诉浏览器, 此 Cookie 只能通过浏览器 HTTP 协议传输, 禁止其他方式访问, 浏览器的 JS 引擎就无法使用 document.cookie 等一切相关的 API, 脚本攻击也就无从谈起了</p><h2 id="SameSite"><a href="#SameSite" class="headerlink" title="SameSite"></a>SameSite</h2><p>另一个属性 “SameSite”, 可以防范”跨站请求伪造”(XSRF)攻击, 设置 <code>SameSite=Strict</code> 可以严格限定 Cookie 不能随着跳转链接跨站发送, 而 <code>SameSite=Lax</code> 则略宽松一点, 允许 GET/HEAD 等安全方法, 但禁止 POST 跨站发送</p><h2 id="Secure"><a href="#Secure" class="headerlink" title="Secure"></a>Secure</h2><p>还有一个属性叫 “Secure”, 表示这个 Cookie 仅能用 HTTPS 协议加密传输, 明文的 HTTP 协议会禁止发送, 但 Cookie 本身不是加密的,浏览器里还是以明文的形式存在</p><h1 id="Cookie-应用"><a href="#Cookie-应用" class="headerlink" title="Cookie 应用"></a>Cookie 应用</h1><p>Cookie 最基本的一个用途就是身份识别, 保存用户的登录信息, 实现会话事务 (比如, 你用账号和密码登录某电商, 登录成功后网站服务器就会发给浏览器一个 Cookie, 内容大概是“name=yourid”, 这样就成功地把身份标签贴在了你身上)</p><p>Cookie 的另一个常见用途是广告跟踪</p><h1 id="Tip"><a href="#Tip" class="headerlink" title="Tip"></a>Tip</h1><p>Cookie 是由浏览器负责存储的, 而不是操作系统。所以, 它是 <strong>浏览器绑定</strong> 的, 只能在本浏览器内生效 (如果你换个浏览器或者换台电脑, 新的浏览器里没有服务器对应的 Cookie, 只能再走一遍 Set-Cookie 流程)<br>Cookie 这个词来源于计算机编程里的术语 <code>Magic Cookie</code>, 意思是不透明的数据, 并不是 “小甜饼” 的含义 (虽然字面意思如此)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;HTTP协议 是 “无状态” 的, 但却是可扩展的, 后来发明的 Cookie 技术, 就给 HTTP 增加了 “记忆能力”&lt;/p&gt;
&lt;h1 id=&quot;Cookie-的工作过程&quot;&gt;&lt;a href=&quot;#Cookie-的工作过程&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
</feed>
