<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lant&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.renyimin.com/"/>
  <updated>2018-08-01T03:02:02.000Z</updated>
  <id>http://blog.renyimin.com/</id>
  
  <author>
    <name>Lant</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://blog.renyimin.com/2018/08/01/nginx/2017-04-21-02/"/>
    <id>http://blog.renyimin.com/2018/08/01/nginx/2017-04-21-02/</id>
    <published>2018-08-01T03:02:02.000Z</published>
    <updated>2018-08-01T03:02:02.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://blog.renyimin.com/2018/08/01/nginx/2017-04-28-07/"/>
    <id>http://blog.renyimin.com/2018/08/01/nginx/2017-04-28-07/</id>
    <published>2018-08-01T03:02:02.000Z</published>
    <updated>2018-08-01T03:02:02.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://blog.renyimin.com/2018/08/01/nginx/2017-04-22-03/"/>
    <id>http://blog.renyimin.com/2018/08/01/nginx/2017-04-22-03/</id>
    <published>2018-08-01T03:02:02.000Z</published>
    <updated>2018-08-01T03:02:02.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>33. 单机部署集群 -- 镜像模式</title>
    <link href="http://blog.renyimin.com/2018/06/29/rabbitmq/2018-06-29-rabbitmq-33/"/>
    <id>http://blog.renyimin.com/2018/06/29/rabbitmq/2018-06-29-rabbitmq-33/</id>
    <published>2018-06-29T13:28:16.000Z</published>
    <updated>2018-07-27T12:40:08.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ol><li><p>上一篇在学习普通模式的集群时, 已经知道在该模式下, 队列只存活于集群中的一个节点上(在RabbitMQ2.6.0之前, 这也是唯一的选择);<br> 在RabbitMQ2.6.0时, RabbitMQ团队带来了内建的双活冗余选项: <strong>镜像队列</strong>;</p></li><li><p>像普通队列那样, 镜像队列的主拷贝仅存在于一个节点(主队列, master)上, 但与普通队列的不同点是, 镜像节点在集群中的其他节点上拥有从队列(slave拷贝); 一旦队列主节点不可用, 最老的从队列将会被选举为新的主队列; (这貌似就是探索集群时一直寻找的高可用)</p></li></ol><h2 id="声明并使用镜像队列"><a href="#声明并使用镜像队列" class="headerlink" title="声明并使用镜像队列"></a>声明并使用镜像队列</h2><ol><li><p>你的应用程序并不使用 <code>rabbitmqctl</code> 来定义镜像(mirrored)队列; 声明镜像队列就像声明普通队列一样, 不过, 你需要传入一个额外的参数 <code>x-ha-policy</code> 参数到 <code>queue.declare</code> 调用中;</p></li><li><p>测试:</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;上一篇在学习普通模式的集群时, 已经知道在该模式下, 队列只存活于集群中的一个节点上(在RabbitMQ2.6.0之前, 
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>32. 单机部署集群 -- 普通模式</title>
    <link href="http://blog.renyimin.com/2018/06/26/rabbitmq/2018-06-26-rabbitmq-32/"/>
    <id>http://blog.renyimin.com/2018/06/26/rabbitmq/2018-06-26-rabbitmq-32/</id>
    <published>2018-06-26T07:28:16.000Z</published>
    <updated>2018-07-27T07:49:14.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>当你需要在生产环境中部署RabbitMQ时, 需要注意的是, 单实例在生产环境虽然部署起来很容易, 但是当你的rabbitmq服务器遇到内存崩溃或者断电的情况时, 这款高性能的产品就要成为你的耻辱了, 将会为你造成极大的问题!<br>因此你需要将你的RabbitMQ变成高可用的才行;</p><h2 id="内建集群简介"><a href="#内建集群简介" class="headerlink" title="内建集群简介"></a>内建集群简介</h2><ol><li><p>RabbitMQ最优秀的功能之一就是其内建集群, 这款消息队列中间件产品本身是基于Erlang编写, Erlang语言天生具备分布式特性(通过同步Erlang集群各节点的magic cookie来实现), 因此, RabbitMQ天然支持Clustering, 这使得RabbitMQ本身不需要像ActiveMQ、Kafka那样通过ZooKeeper分别来实现HA方案和保存集群的元数据。</p></li><li><p>RabbitMQ内建集群用来完成两个目标:</p><ul><li>允许生产者和消费者在RabbitMQ节点崩溃的情况下继续运行;<br>你可以失去一个RabbitMQ节点, 同时客户端可以重新连接到集群中的任何其他节点并继续生产或者消费消息, 就像什么都没有发生一样;</li><li>通过增加更多的节点来线性扩展消息吞吐量;<br>如果RabbitMQ正疲于应对庞大的消息通信量的话, 那么线性地增加更多的节点则会增加更多性能;</li></ul></li></ol><h2 id="集群的类型"><a href="#集群的类型" class="headerlink" title="集群的类型"></a>集群的类型</h2><p>Rabbit集群模式大概分为两种: <strong>普通模式</strong>、<strong>镜像模式</strong>; 本篇主要介绍普通模式</p><h2 id="普通模式"><a href="#普通模式" class="headerlink" title="普通模式"></a>普通模式</h2><ol><li><p>普通模式(也就是默认的集群模式), 对于该集群模式, 当你将多个节点组合成集群后, 需要注意的是: <strong>不是每一个节点都有所有队列的完全拷贝</strong></p><ul><li><p>在非集群的单一节点中, 所有关于队列的信息(元数据、状态、内容)都完全存储在该节点上;</p></li><li><p>但是如果在普通集群模式下创建队列的话, 集群只会在当前节点而不是所有节点上创建完整的队列信息(元数据、状态、内容); 而其他非所有者的节点, 只知道队列的元数据和指向该队列存在的哪个节点的指针;</p></li><li><p>因此当集群中队列所有者的节点崩溃时, 该节点的队列和关联的绑定就都消失了, 并且附加在这些队列上的消费者就会无法获取其订阅的信息, 并且生产者也无法将匹配该队列绑定信息的消息发送到队列中;</p></li></ul></li><li><p><strong>接下来需要了解的一个问题是</strong>: 为什么在默认的集群模式下, RabbitMQ不将队列内容和状态复制到所有的节点上? 其实有两个原因</p><ul><li>存储空间: 如果每个集群节点都拥有所有Queue的完全数据拷贝, 那么每个节点的存储空间会非常大, 集群的消息积压能力会非常弱(无法通过集群节点的扩容提高消息积压能力);</li><li><p>性能: 消息的发布者需要将消息复制到每一个集群节点, 对于持久化消息来说, 网络和磁盘的负载都会明显增加, 最终只能保持集群性能平稳(甚至更糟);</p></li><li><p>所以, 通过设置集群中的唯一节点来负责特定队列, <strong>只有该负责节点才会因队列消息而遭受磁盘活动的影响</strong><br>所有其他节点需要将接受到的该队列的消息传递给该队列的所有者节点, 因此, 往RabbitMQ集群添加更多的节点意味着你将拥有更多的节点来传播队列, 这些新增节点为你带来了性能的提升;</p></li></ul></li><li><p>但是有人可能会想: 是否可以让消费者重新连接到集群上, 这样不就可以重新创建队列了? 但需要注意的是: </p><ul><li>因为一般如果我们的队列设置的是持久化的, 而在该队列的主节点挂掉之后, 重新连接到队列时, 一般也不会修改队列的持久化属性; </li><li>这就需要注意一个问题, 仅当你之前创建的队列为非持久化时, 你才可以重新创建该队列为持久化, 因为这是为了保证你之前的持久化队列节点在重新被恢复启动后, 其中的消息还会被恢复, 而如果你创建一个新的持久化队列, 如果覆盖之前的持久化队列, 那消息不就丢了!!<br>所以如果之前是持久化队列, 而且还是以持久化的方式创建该队列, 集群就会报错误, 后面会进行测试! </li></ul></li></ol><h2 id="了解内部元数据"><a href="#了解内部元数据" class="headerlink" title="了解内部元数据"></a>了解内部元数据</h2><p>RabbitMQ内部会始终同步四种类型的内部元数据:</p><ul><li>队列元数据: 队列名称和它的属性 (是否可持久化, 是否自动删除);</li><li>交换器元数据: 交换器名称、类型和属性 (可持久化等);</li><li>绑定元数据: 一张简单的表格展示了如何将消息路由到队列;</li><li>vhost元数据: 为vhost内的队列、交换器和绑定提供命名空间和安全属性;</li></ul><h2 id="内存or磁盘节点"><a href="#内存or磁盘节点" class="headerlink" title="内存or磁盘节点"></a>内存or磁盘节点</h2><ol><li><p>每个Rabbitmq节点, 不管是单一节点系统或者是庞大集群的一部分, 要么是内存节点(RAM node), 要么是磁盘节点(disk node):</p><ul><li>内存节点将所有的队列、交换器、绑定、用户、权限和vhost的元数据定义都仅存储在内存中;</li><li>而磁盘节点则将元数据存储在磁盘中;</li></ul></li><li><p>非集群单一节点: 在单一节点的非集群环境中, RabbitMQ默认会将元数据都存放在<strong>内存中</strong>; 但是, 会将标记为可持久化的队列和交换器(以及它们的绑定)存储到硬盘上, 存储到硬盘上可以确保队列和交换器在重启Rabbitmq节点后重新被创建;</p></li><li><p>集群节点类型 </p><ul><li>当你引入Rabbitmq集群后, RabbitMQ需要追踪的元数据类型包括: 集群节点位置, 以及节点与已记录的其他类型的元数据的关系;</li><li>集群对元数据的存储提供了选择:<br>将元数据存储到磁盘上 (集群中创建节点时的默认设置) 或者 存储到RAM内存中</li></ul></li><li><p>注意, RabbitMQ要求在集群中至少要有一个磁盘节点, 所有其他节点可以是内存节点。当节点加入或者离开集群时, 它们必须要将变更至少通知到一个磁盘节点; 如果只有一个磁盘节点, 而不凑巧的是它有刚好崩溃, 那么集群虽然可以继续路由消息, 但是不能做一下操作:</p><ul><li>创建队列</li><li>创建交换器</li><li>创建绑定</li><li>添加用户</li><li>更改权限</li><li>添加或删除集群节点</li></ul></li></ol><h2 id="集群配置钱准备"><a href="#集群配置钱准备" class="headerlink" title="集群配置钱准备"></a>集群配置钱准备</h2><ol><li><p>在开始配置集群前, 首先要确保现存的Rabbitmq没有运行, 因此需要关闭节点 (本机为mac, 关闭操作如下)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ brew services stop rabbitmq</div><div class="line">Stopping `rabbitmq`... (might take a while)</div><div class="line">==&gt; Successfully stopped `rabbitmq` (label: homebrew.mxcl.rabbitmq)</div></pre></td></tr></table></figure><p> 可以发现一个问题, 就是停止Rabbitmq服务之后, 貌似 RabbitMQ Management 的Web UI界面还是可以正常打开运行; 所以正确的关闭节点貌似是 <code>rabbitmqctl stop</code></p></li><li><p>开始配置集群前需要注意:</p><ul><li><p>通常来讲, 使用 <code>rabbitmq-server</code> 命令启动节点之后就大功告成了, 但是如果不用额外参数的话, 该命令会使用默认的节点名称 <code>rabbit</code> 和监听端口 <code>5672</code>;<br>所以如果你想用该命令在一台机器上同时启动3个节点的话, 那么第2，3个节点都会因为节点名称和端口号冲突而导致启动失败; </p></li><li><p>因此, 为了在本机正常启动5个节点, 可以在每次调用 <code>rabbitmq-server</code>前, 通过设置环境变量 <code>RABBITMQ_NODENAME</code>, <code>RABBITMQ_NODE_PORT</code> 来明确指定唯一的节点名称和端口号!<br>在此处做实验时, 将会采用 rabbit, rabbit_1,rabbit_2 命名节点名; 端口号为5612，5613, 5614</p></li><li><p><strong>注意</strong>, 到目前为止, 虽然尚未谈论RabbitMQ的插件, 不过你有可能已经启用了一部分插件了; 如果确实如此的话, 你需要在启动集群节点前将插件禁用!<br>这是因为像 RabbitMQ Management 这样的插件会监听专门的端口来提供服务(例如 Management 插件的 Web UI), 目前还没讲到如何设置插件监听不同的端口, 所以当第二个节点和之后的节点启动了它们的插件后, 就会和第一个启动节点的c插件相冲突, 然后节点就都崩溃了;<br>可以先不禁用插件, 这样在启动多个节点时, 可以根据报错一个个关闭插件也可以; (<code>rabbitmq-plugins disable 插件名</code>)</p></li></ul></li></ol><h2 id="RabbitMQ集群的搭建"><a href="#RabbitMQ集群的搭建" class="headerlink" title="RabbitMQ集群的搭建"></a><a href="http://www.rabbitmq.com/clustering.html#creating" target="_blank" rel="external">RabbitMQ集群的搭建</a></h2><ol><li><p>启动节点</p><ul><li><p>注意: 启动的时候, 直接加上 <code>-detached</code> 参数的话, 可能会有些报错信息比如 <code>error : cannot_delete_plugins_expand_dir</code>, 这就是因为需要使用root权限才可以, 你可以使用 <code>pa aux | grep rabbitmq</code> 查看是否三个进程都成功启动了</p></li><li><p>注意: 启动时, 貌似不能像书上那样, RABBITMQ_NODENAME 只设置节点名, 最好设置上节点host</p></li><li><p>如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detached</div><div class="line">Warning: PID file not written; -detached was passed.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit_1@localhost rabbitmq-server -detached</div><div class="line">Warning: PID file not written; -detached was passed.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ sudo RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit_2@localhost rabbitmq-server -detached</div><div class="line">Warning: PID file not written; -detached was passed.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>然后可以查看个节点状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost status</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost status</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost status</div></pre></td></tr></table></figure></li></ul></li><li><p>现在启动了三个节点 rabbit, rabbit_1, rabbit_2, 并且每个节点都会有系统的主机名在@后; 但是每个节点仍然是独立节点, 拥有自己的元数据, 并且不知道其他节点的存在;</p><ul><li>集群中的第一个节点rabbit,将初始元数据带入集群, 并且无需被告知加入;</li><li>而第二个和之后的节点, 将加入第一个节点rabbit, 并获取rabbit节点的元数据;  </li></ul></li><li><p>要将rabbit_1和rabbit_2节点加入rabbit, 要停止该Erlang节点上运行的rabbitmq应用程序, 并重设它们的元数据, 这样它们才可以被加入rabbit节点并且获取rabbit节点的元数据; 可以使用 <code>rabbitmqctl</code> 来完成这些工作</p><ul><li><p>停止rabbit_1节点上的应用程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost stop_app</div><div class="line">Stopping rabbit application on node rabbit_1@renyimindeMacBook-Pro ...</div></pre></td></tr></table></figure></li><li><p>重设rabbit_1节点的元数据和状态为清空状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost reset</div><div class="line">Resetting node rabbit_1@renyimindeMacBook-Pro ...</div></pre></td></tr></table></figure></li><li><p>这样你就准备好了一个 停止运行的并且清空了的 rabbit 应用, 现在可以准备好将其加入到集群中的第一个节点rabbit中:<br>注意书上的 <code>cluster</code> 命令好像已经不用了, 换成了 <code>join_cluster</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost join_cluster rabbit@localhost</div><div class="line">Clustering node rabbit_1@localhost with rabbit@localhost</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>最后, 可以重启第二个节点的应用程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_app</div><div class="line">Starting node rabbit_1@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>节点rabbit_2加入集群的步骤同上, 具体操作如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost start_app</div><div class="line">Starting node rabbit_1@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_app</div><div class="line">Stopping rabbit application on node rabbit_2@localhost ...</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost reset</div><div class="line">Resetting node rabbit_2@localhost ...</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost join_cluster rabbit@localhost</div><div class="line">Clustering node rabbit_2@localhost with rabbit@localhost</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_app</div><div class="line">Starting node rabbit_2@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ul></li><li><p>查看集群状态, 可以在任意一个节点通过 <code>rabbitmqctl cluster_status</code> 进行查看</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_status</div><div class="line">Cluster status of node rabbit@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;]&#125;]</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_status</div><div class="line">Cluster status of node rabbit_1@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;]&#125;]</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost cluster_status</div><div class="line">Cluster status of node rabbit_2@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_2@localhost,[]&#125;]&#125;]</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>注意: </p><ul><li>上面使用比较多的 <code>rabbitmqctl</code> 命令的关键参数是 <code>-n</code>, 这会告诉rabbitmqctl命令, 你想在指定节点而非默认节点<code>rabbit@</code>上执行命令;</li><li>记住, Erlang节点间通过Erlang cookie的方式来允许互相通信。因为rabbitmqctl使用Erlang OPT通信机制来和Rabbit节点通信, 运行rabbitmqctl的机器和所要连接的Rabbit节点必须使用相同的Erlang cookie, 否则你会得到一个错误;<br>当然, 上面的集群是在本机做伪集群, Erlang cookie 自然也都是一致的!</li></ul></li><li><p>将节点从集群中删除 <code>forget_cluster_node</code></p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_1@localhost</div><div class="line">Removing node rabbit_1@localhost from the cluster</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_2@localhost</div><div class="line">Removing node rabbit_2@localhost from the cluster</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl forget_cluster_node rabbit_3@localhost</div><div class="line">Removing node rabbit_3@localhost from the cluster</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ol><h2 id="集群节点类型设置与修改"><a href="#集群节点类型设置与修改" class="headerlink" title="集群节点类型设置与修改"></a><a href="http://www.rabbitmq.com/clustering.html#change-type" target="_blank" rel="external">集群节点类型</a>设置与修改</h2><ol><li><p>可以在将节点加入集群时, 设定节点的类型 (<a href="http://www.rabbitmq.com/clustering.html#creating-ram" target="_blank" rel="external">参考</a>)<br> 比如 <code>rabbitmqctl -n rabbit_3@localhost join_cluster --ram rabbit@localhost</code></p></li><li><p>之前已经通过 <code>rabbitmqctl cluster_status</code> 查看了集群的状态, 里面比较重要的是 <code>nodes</code> 部分</p><ul><li><p>下面告诉你有三个节点加入了集群, 并且三个节点都是 disc 磁盘节点!</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line">     &#123;running_nodes,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;,</div><div class="line">     &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line">     &#123;partitions,[]&#125;,</div><div class="line">     &#123;alarms,[&#123;rabbit@localhost,[]&#125;,</div><div class="line">              &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">              &#123;rabbit_2@localhost,[]&#125;]&#125;]</div></pre></td></tr></table></figure></li><li><p>running_nodes 部分告诉你集群中的哪些节点正在运行; </p></li></ul></li><li><p>现在你可以连接到这三个running_nodes中的任何一个, 并且开始创建队列, 发布消息或者执行任何其他AMQP任务; </p></li><li><p>你也可以对节点类型进行修改, 如下将rabbit_2节点类型修改为内存节点 (注意: 修改节点类型, 需要先停止节点应用)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost stop_app</div><div class="line">Stopping rabbit application on node rabbit_2@localhost ...</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost change_cluster_node_type ram</div><div class="line">Turning rabbit_2@localhost into a ram node</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost start_app</div><div class="line">Starting node rabbit_2@localhost ...</div><div class="line"> completed with 1 plugins.</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost cluster_status</div><div class="line">Cluster status of node rabbit_1@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost]&#125;,</div><div class="line">         &#123;ram,[rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit@localhost,rabbit_1@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindeMacBook-Pro&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;]&#125;]</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ol><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><ol><li>运行<a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/LocalClusterController.php" target="_blank" rel="external">生产者代码</a>, 在集群中的rabbit节点中创建持久化队列<ul><li>初始集群状态<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl cluster_status</div><div class="line">Cluster status of node rabbit@localhost ...</div><div class="line">[&#123;nodes,[&#123;disc,[rabbit@localhost,rabbit_1@localhost,rabbit_2@localhost]&#125;]&#125;,</div><div class="line"> &#123;running_nodes,[rabbit_2@localhost,rabbit_1@localhost,rabbit@localhost]&#125;,</div><div class="line"> &#123;cluster_name,&lt;&lt;&quot;rabbit@renyimindemacbook-pro.rrcoa.com&quot;&gt;&gt;&#125;,</div><div class="line"> &#123;partitions,[]&#125;,</div><div class="line"> &#123;alarms,[&#123;rabbit_2@localhost,[]&#125;,</div><div class="line">          &#123;rabbit_1@localhost,[]&#125;,</div><div class="line">          &#123;rabbit@localhost,[]&#125;]&#125;]</div></pre></td></tr></table></figure></li></ul></li></ol><pre><code>- 运行生产者, 查看创建的队列(已经有一条msg放入队列中)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">prefetchCountQueue0</div><div class="line">localClusterQueue1</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></code></pre><ol><li><p>kill掉该持久化队列localClusterQueue所在的主节点rabbit</p><ul><li><p>查看节点进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ ps aux | grep rabbitmq</div><div class="line">root              2656   0.4  0.3  4150148  58156   ??  S    三01下午   5:09.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5672&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit@localhost&quot; -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 -noshell -noinput</div><div class="line">renyimin         28537   0.0  0.0  2423384    232 s007  R+    3:12下午   0:00.00 grep rabbitmq</div><div class="line">root             72516   0.0  0.5  4143168  79400   ??  S     1:03下午   0:16.71 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_2@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5674&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_2@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_2@localhost&quot; -kernel inet_dist_listen_min 25674 -kernel inet_dist_listen_max 25674 -noshell -noinput</div><div class="line">root             71841   0.0  0.5  4138448  77104   ??  S     1:01下午   0:15.15 /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang/erts-9.3.3.1/bin/beam.smp -W w -A 64 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000 -K true -- -root /usr/local/Cellar/erlang@20/20.3.8.2/lib/erlang -progname erl -- -home /Users/renyimin -- -pa /usr/local/Cellar/rabbitmq/3.7.7/ebin -noshell -noinput -s rabbit boot -sname rabbit_1@localhost -boot /usr/local/opt/erlang@20/lib/erlang/bin/start_clean -conf /usr/local/Cellar/rabbitmq/3.7.5/etc/rabbitmq/rabbitmq -conf_dir /usr/local/var/lib/rabbitmq/config -conf_script_dir /usr/local/sbin -conf_schema_dir /usr/local/var/lib/rabbitmq/schema -kernel inet_default_connect_options [&#123;nodelay,true&#125;] -rabbit tcp_listeners [&#123;&quot;127.0.0.1&quot;,5673&#125;] -sasl errlog_type error -sasl sasl_error_logger false -rabbit lager_log_root &quot;/usr/local/var/log/rabbitmq&quot; -rabbit lager_default_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost.log&quot; -rabbit lager_upgrade_file &quot;/usr/local/var/log/rabbitmq/rabbit_1@localhost_upgrade.log&quot; -rabbit enabled_plugins_file &quot;/usr/local/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/Cellar/rabbitmq/3.7.7/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/var/lib/rabbitmq/mnesia/rabbit_1@localhost&quot; -kernel inet_dist_listen_min 25673 -kernel inet_dist_listen_max 25673 -noshell -noinput</div></pre></td></tr></table></figure></li><li><p><code>sudo kill 2656</code></p></li></ul></li><li><p>将生产者改连 rabbit_1 节点, 重新运行生产者</p><ul><li>报错:<br><img src="/img/rabbitmq/cluster-error01.png"></li><li>挂掉的主节点中<strong>已存在该持久化队列</strong>, 如果在主节点挂掉后, 你能直接连接其他节点创建该队列的话, 此时创建的是个新队列, 要知道, 宕机的主节点中的持久化队列还在等待恢复呢, 它内部可能让然有很多msg需要恢复并被处理;<br>所以Rabbit集群的这个问题是有原因的!!</li></ul></li><li><p>可以重新启动该节点 <code>sudo RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit@localhost rabbitmq-server -detached</code></p><ul><li>会发现之前的持久化队列会被恢复<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue1</div><div class="line">prefetchCountQueue0</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_1@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue1</div><div class="line">prefetchCountQueue0</div><div class="line"></div><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue1</div><div class="line">prefetchCountQueue0</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ul></li><li><p>此时即使生产者连接着 rabbit_1 也可以创建该同名持久化队列了</p><ul><li>重新运行刚才连接到 rabbit_1 的生产者, 不会报错了, 而是正确往队列发布了一条消息<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ rabbitmqctl -n rabbit_2@localhost list_queues</div><div class="line">Timeout: 60.0 seconds ...</div><div class="line">Listing queues for vhost / ...</div><div class="line">localClusterQueue2</div><div class="line">prefetchCountQueue0</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;当你需要在生产环境中部署RabbitMQ时, 需要注意的是, 单实例在生产环境虽然部署起来很容易, 但是当你的rabbitmq服务器遇到内存
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>20. 消费者预取 Consumer Prefetch</title>
    <link href="http://blog.renyimin.com/2018/06/13/rabbitmq/2018-06-13-rabbitmq-20/"/>
    <id>http://blog.renyimin.com/2018/06/13/rabbitmq/2018-06-13-rabbitmq-20/</id>
    <published>2018-06-13T11:23:36.000Z</published>
    <updated>2018-07-19T02:06:14.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Consumer-Prefetch"><a href="#Consumer-Prefetch" class="headerlink" title="Consumer Prefetch"></a><a href="https://www.rabbitmq.com/consumer-prefetch.html" target="_blank" rel="external">Consumer Prefetch</a></h2><ol><li><p>作为限制 unacked 消息数量的更自然有效的方法; AMQP 0-9-1 指定了 <code>basic.qos</code> 方法, 以便你在消费者进行消费时, 可以限制channel(或connection)上未确认消息的数量; </p><ul><li>但是值得注意的是: channel 并不是理想的设定范围, 因为单个channel可能从多个队列进行消费, channel和queue需要为每个发送的消息相互协调, 以确保它们不会超出限制, 这在单台机器上会慢, 而在整个集群中使用时会非常慢;</li><li>此外, 对于许多用途, 指定<strong>适用于每个消费者的预取计数</strong>更会简单一些;</li></ul></li><li><p>因此, RabbitMQ在 <code>basic.qos</code> 方法中重新定义了<strong>全局标志</strong>的含义 (在php-amqplib中basic_qos()的第三个参数a_global):<br> <img src="/img/rabbitmq/qos-global.png"><br> 请注意, 在大多数API中, 全局标志的默认值为false; (php-amqplib的basic_qos()方法的第三个参数a_global默认也为false)</p></li></ol><h2 id="简要分析"><a href="#简要分析" class="headerlink" title="简要分析"></a>简要分析</h2><ol><li><p>在使用RabbitMQ时, 如果完全不配置QoS, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是采用默认方式, 将队列中的所有消息按照网络和客户端允许的速度<strong>尽快轮发</strong>到与队列绑定的consumers端; 而consumers会在本地缓存所有投递过来的messages, 这样的话, 就可能会导致</p><ul><li>如果某个消费者的业务逻辑处理比较复杂(将会在较长时间之后才会操作完成并进行ack), 这也就导致消费慢的Consumer将会在本地堆积很多消息, 从而导致内存不足或者对其他进程造成影响 (<strong>消费者可能被撑到假死</strong>);</li><li>而其他消费能力强的Consumers, 可能已经很快地消费完成处于闲置状态, <strong>从而造成资源浪费</strong>; </li><li>同时, 新启的消费者也无法分担已经被之前消费者缓存到其本地的消息, 所以此时即便启动更多消费者, 也<strong>无力缓解大量的 unacked 消息积压, 让你产生疑惑</strong>;</li></ul></li><li><p><strong>而当你设置了Qos之后, RabbitMQ虽然也是将队列中的消息尽快轮发到Consumers中, 但是因为消费者具有的 prefetch_count 消息预取值上限, 所以RabbitMQ在轮发消息的时候, 如果发现消费者的 unacked 消息达到了 prefetch_count 的值, 即使rabbitmq中有很多ready的就绪消息, 也不会给该Consumer继续投递消息了(只有消费者的 unacked 消息小于prefetch_count的值时, 才会继续通过轮发方式给该consumer投递ready消息), 如果此时有新的消费者加入, 它也将会拿到未投递出去的ready消息!</strong></p><ul><li>可以通过启动 prefetchCountConsumer1，prefetchCountConsumer2 两个消费者(prefetch_count 均为10), 然后使用下面测试中的生产者发送100条消息, 前期观察会发现队列中消息的最大 unacked 为20, 并且你会发现队列中处于ready状态的消息会每次2个的递减, 这就预示着, 每次这两个消费者只要 unacked 的消息书小于prefetch_count(10), Rabbitmq才会给这两个consumer各自发送一条msg;</li><li>之后如果启动了 prefetchCountConsumer3(prefetch_count为20), 此时会发现队列中消息的最大 unacked 会为40, prefetchCountConsumer3的加入会使得队列中处于ready状态的消息直接骤减20个, 最后rabbitmq中的ready消息已经为0, 每个消费者还在继续消费各自未 unacked 的消息, 最终消费完成后, 整个队列中的 unacked 消息为0;</li></ul></li><li><p>Qos的设置只有在<strong>开启手动ack</strong>后才会生效 (即, prefetch_count 在 no_ask=false 的情况下生效)</p></li></ol><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><ol><li><p>一般情况下, 同一队列绑定的多个消费者都是处理同一个业务, 而且如果在同一台机器启动, 消费能力应该都差不多, 但也难免出现如: 消费者资源分配不均 或者 两个消费者在处理业务时所请求的服务端机器配置有差异(假设SLB后又2台配置不均的机器), 这种情况还是应该考虑进来的! </p></li><li><p>本测试比较简单, 主要测试在默认不设置Qos的情况下, 两个消费能力不同的消费者在处理消息时存在的问题之一: 由于这种情况下, RabbitMQ是不会考虑到Consumers端是否ack的情况, 而是只顾自己轮发消息, 这样就会导致消息被轮发完成后, 消费能力高的消费者可能很快消费完消息并处于闲置状态, 而消费能力低的消费者却在很慢地进行消费, <strong>这样就造成了资源的浪费</strong>;</p></li><li><p>准备</p><ul><li>创建消费者1 ‘qosCustomer1’ (简单打印消息内容) , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/qosConsumer1.php" target="_blank" rel="external">代码参考</a>, <strong>启动消费者</strong> <code>php artisan qosConsumer1</code></li><li>创建消费者2 ‘qosCustomer2’ (sleep 5秒, 模拟处理能力比较差) , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/qosConsumer2.php" target="_blank" rel="external">代码参考</a>, <strong>启动消费者</strong>  <code>php artisan qosConsumer2</code></li><li><p>创建生产者一次向队列 ‘qosQueue’ 中推送10条消息 , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/QosController.php" target="_blank" rel="external">代码参考</a>, <strong>请求一次生产者</strong> <a href="http://www.rabbit.com/testQos" target="_blank" rel="external">http://www.rabbit.com/testQos</a></p></li><li><p>注意需要先启动消费者, 再请求生产者; (如果先请求了生产者, 可能在启动第一个消费者之后, 其会迅速消费完10条消息, 这样就无法模拟效果了)</p></li></ul></li><li><p>测试发现</p><ul><li>qosCustomer1 : 迅速打印出结果(1,3,5,7,9), 然后就处于闲置状态了</li><li>qosCustomer2 : 还在缓慢打印(2,4,6,8,10)</li><li>可以看到, 如果不设置Qos, Rabbitmq会尽快将消息从队列中轮发投递出去, 不会对消费者的消费能力进行任何评估! </li></ul></li><li><p>所以: 为了避免这种浪费资源的情况, 你可能就需要根据上一篇讲解的 prefetch_count 来针对不同消费者进行设置;</p></li></ol><h2 id="问题答疑测试"><a href="#问题答疑测试" class="headerlink" title="问题答疑测试"></a>问题答疑测试</h2><ol><li><p>根据上面的描述, 有个疑问: 在默认不设置Qos的情况下, 既然生产者发布的消息会尽可能全部推送给消费者进程, 队列中会尽可能将消息全部推出, 缓存在消费者本地, 那当消费者断开时, 消息是如何恢复到队列中的? 或者不会恢复到队列中? 为了答疑, 下面进行测试 </p></li><li><p>准备测试代码</p><ul><li><p>创建消费者1 ‘prefetchCountConsumer1’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/prefetchCountConsumer1.php" target="_blank" rel="external">代码参考</a></p></li><li><p>创建消费者2 ‘prefetchCountConsumer2’ (sleep 5秒, 模拟耗时业务需求; prefetch=100; 简单打印消息内容), <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Console/Commands/prefetchCountConsumer2.php" target="_blank" rel="external">代码参考</a></p></li><li><p>生产者一次向队列 ‘prefetchCountQueue’ 中推送100条消息 , <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/PrefetchCountController.php" target="_blank" rel="external">代码参考</a></p></li></ul></li><li><p>测试:</p><ul><li><p>在生产者请求一次之后(<a href="http://www.rabbit.com/prefetchCount" target="_blank" rel="external">http://www.rabbit.com/prefetchCount</a>), <code>ready : 100, unacked: 0, total : 100</code>, 表示队列中已经有100条消息已经就绪, 等待发出<br><img src="/img/rabbitmq/qos-test01.png" width="450"></p></li><li><p>运行第一个<code>php artisan prefetchCountConsumer1</code>之后, <code>ready : 0, unacked : 100, total : 100</code> (也就是说, queue中已经没有 ready状态, 即准备好待发送的消息了, 消息都传递给消费者1了)<br><img src="/img/rabbitmq/qos-test02.png" width="450"></p></li><li><p>随着消费者的缓慢消费, <code>ready : 0, unacked : 94, total : 94</code>  ()<br><img src="/img/rabbitmq/qos-test03.png" width="450"></p></li><li><p>如果模拟 挂掉第一个消费者之后, 会发现, <code>ready : 83， unacked : 0, total : 83</code> (<strong>也就是说消费者意外宕掉之后, 队列中的消息会重新处于就绪状态</strong>, 等待着新的消费者来消费)<br><img src="/img/rabbitmq/qos-test04.png" width="450"></p></li><li><p>再次启动消费者2 <code>php artisan testQosConsumerPrefetchCount2</code>之后, <code>ready : 0, unacked : 80, total : 80</code> (消息又会被全量发送给消费者2)</p></li><li><p>注意: 如果此时启动消费者1, 你会发现, 它是无法帮助消费者2进行消费的, 因为消息都在消费者2的本地, 所以队列中并没有 <strong>ready状态的就绪消息</strong>;</p></li></ul></li><li><p>测试注意: 上述测试过程如果先启动两个消费者, 然后再发布消息进行测试, 你会发现, 由于两个消费者都设置了预取值, 而且相等, 所以消息仍然会快速轮发给这两个消费者;</p><ul><li>如果将两个消费者的 prefetch_count 都设置为10, 那么你会发现, unacked 最多也就是两个消费者的prefetch_count和, 即20个<br><img src="/img/rabbitmq/qos-test05.png" width="450"></li></ul></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol><li><p>消费者的 unacked 消息数量如果未达到Qos设置的 prefetch_count 量, <strong>Rabbit不会顾及消费者的消费能力, 会尽可能将queue中的消息全部推送出去给消费者</strong>;</p></li><li><p>因此, 当你发现消费者消费缓慢, 产生大量 unacked 消息时, 即便增加新的消费者, 也无法帮助之前的消费者分担消息(除非消费者1的 unacked 达到了 prefetch_count 限制), 只能分担队列中处于 ready 状态的消息;</p></li><li><p>除非你断开之前的消费者, 然后启动一个新的消费者, 消费者中积压的消息才会重新放入队列中 (因为之前的消费者挂掉之后, 其处理后的剩余消息在 queue中会恢复为 ready 状态)<br> 但是注意: 新启动的这个消费者如果设置额prefetch_count不合理的话, 假设与之前消费者的 预取值 设置一样大, 它很快也会产生大量 unacked 消息<br> 所以, 在新启消费者的时候, 需要设计好 prefetch_count 的大小, 然后可以启动多个消费者来共同进行消费;</p></li></ol><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ol><li><p>rabbitmq对 basic.qos 信令的处理</p><ul><li>首先, basic.qos 是针对 channel 进行设置的, 也就是说只有在channel建立之后才能发送basic.qos信令; RabbitMQ只支持通道级的预取计数, 而不是connection级的 或者 基于大小的预取;<br><a href="http://www.bubuko.com/infodetail-1955647.html" target="_blank" rel="external">预取</a></li><li>在rabbitmq的实现中, 每个channel都对应会有一个rabbit_limiter进程, 当收到basic.qos信令后, 在rabbit_limiter进程中记录信令中prefetch_count的值, 同时记录的还有该channel未ack的消息个数;</li></ul></li><li><p>在<code>php-amqplib</code>中, 可以使用 channel 的 <code>basic_qos()</code> 方法来进行控制, <code>basic_qos()</code> 有三个参数:</p><ul><li>prefetch_size : 限制预取的消息大小的参数, rabbitmq暂时没有实现 (如果prefetch_size字段不是默认值0, 则会通知客户端出错, 通知客户端<strong>RabbitMQ系统没有实现该参数的功能</strong>, 还可以参考<a href="https://github.com/sky-big/RabbitMQ/blob/d7a773e11f93fcde4497c764c9fa185aad049ce2/src/rabbit_channel.erl" target="_blank" rel="external">此文</a>)<br>当你设置prefetch_size大于0的时候, 会出现如下报错<br><img src="/img/rabbitmq/qos-prefetch-size-error.png" width="400"></li><li>prefetch_count : 预取消息数量</li><li>global: 在3.3.0版本中对global这个参数的含义进行了重新定义, 即glotal=true时表示在当前channel上所有的consumer都生效(包括已有的), 否则只对设置了之后新建的consumer生效;</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Consumer-Prefetch&quot;&gt;&lt;a href=&quot;#Consumer-Prefetch&quot; class=&quot;headerlink&quot; title=&quot;Consumer Prefetch&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://www.rabbitmq.com/c
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>19. 消费者预取 Consumer Prefetch (避免队列大量unacked积压及Consumer假死)</title>
    <link href="http://blog.renyimin.com/2018/06/12/rabbitmq/2018-06-12-rabbitmq-19/"/>
    <id>http://blog.renyimin.com/2018/06/12/rabbitmq/2018-06-12-rabbitmq-19/</id>
    <published>2018-06-12T03:26:55.000Z</published>
    <updated>2018-07-21T03:21:13.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RabbitMQ关于吞吐量-延迟和带宽的一些理论"><a href="#RabbitMQ关于吞吐量-延迟和带宽的一些理论" class="headerlink" title="RabbitMQ关于吞吐量,延迟和带宽的一些理论"></a><a href="https://www.rabbitmq.com/blog/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth/" target="_blank" rel="external">RabbitMQ关于吞吐量,延迟和带宽的一些理论</a></h2><ol><li><p>假设你在Rabbit中有一个队列, 并有一些客户端从这个队列中进行消费, 如果你根本没有设置QoS, 那么Rabbit将尽可能快地按照网络和客户端允许的速度将所有队列的消息推送到客户端; 因此, 消费者所占用的内存将会激增, 因为它们将所有消息都缓存在自己的RAM中; 同时, 值得注意的是: 此时如果你询问Rabbit, <strong>队列可能会显示为空</strong>, 但是会有大量的 unacked 消息; 并且此时如果你添加新的消费者, 由于消息已经在现有的客户端中缓存, 队列中并没有 ready状态的 消息, 所以即使增加更多新的消费者, 也无法缓解队列中 unacked 消息数量, 这是相当次优的!</p></li><li><p>所以，默认的QoS预取给客户端(consumer)设置了无限的缓冲区, 这可能导致不良的行为和性能; 那么, 应该将QoS预取缓冲区大小设置为多少呢? 目标是让消费者保持工作饱和状态, <strong>但要尽量减少客户端的缓冲区大小, 以便让更多的消息保留在Rabbit的队列中, 这样就可以供新消费者来消费</strong>;</p></li><li><p>比方说, Rabbit从这个队列中拿出一条消息, 把它投递给消费者, 需要50ms, 而Consumer处理消息需要4ms; 一旦消费者处理了消息, 它就会发送一个ack给Rabbit, 这将再次花费50ms发送给Rabbit并被Rabbit进行处理; 所以 消费完成并进行一次ack的时间 + 一次消息从队列到Consumer的投递时间 总共会花费104ms的往返时间。</p><ul><li><p>如果我们消息设置了QoS预取值为1, 那么直到这个往返行程完成之前, Rabbit是不会发送下一个消息给客户端的;<br>因此, 每次往返的104ms中, Consumer只有4ms, 或者说只有3.8％的时间忙碌, 而我们希望Consumer百分之百的时间都在忙碌中;</p></li><li><p>如果我们在每个消息的客户端上执行 <code>总的往返时间/处理时间</code>, 会得到 <code>104/4 = 26</code><br>如果我们设置消息的QoS预取值为26, 那就解决了我们的问题: 如果每条消息需要4ms的处理来处理, 那么总共需要 <code>26×4 = 104ms</code> 来处理整个缓冲区(中的消息);<br>第一个4ms是第一个消息的处理时间, 处理完成后, 客户端然后发出一个确认(这需要50ms才能到达代理), 然后继续处理缓冲区中的下一条消息, 一次ack时间 + 新一轮消息的投递时间 = 100s, Consumer正好完成缓冲区剩下的25条消息, 然后新的26条消息也已经到达, 并准备好等待客户端来处理它;<br>因此, 客户端始终处于忙碌状态: 具有较大的QoS预取值也不会使其更快了, 但是我们最大限度地减少了缓冲区的大小, 并且减少了客户端消息的延迟;<br><strong>客户端能够在下一条消息到达之前完全排空缓冲区, 因此缓冲区实际上保持为空</strong>;</p></li><li><p>如果处理时间和网络行为保持不变, 此解决方案绝对没问题</p></li></ul></li><li><p>但考虑一下如果网络突然间速度减半会发生什么情况?</p><ul><li><p>显然, 网络传输时间就加长了, 此时你的预取缓冲区(也就是你设置的prefetch预取值)就不够大了, 现在Consumer会就会稍有闲置, 等待新消息到达, 因为客户端能够处理消息的速度比Rabbit能够提供新消息的速度要快;</p></li><li><p>为了解决这个问题, 我们可能会决定将QoS预取大小加倍(或接近两倍), 如果我们从26开始将它推到51, 那么如果客户端处理保持在每个消息4ms, 我们现在在缓冲区中会有51 * 4 = 204ms的消息处理时间, 其中4ms将用于处理消息, 而200ms用于发送消息回复rabbit并收到下一条消息, 因此, 我们现在可以应对网络速度的减半;</p></li></ul></li><li><p>再次分析: 如果网络又恢复正常运行, 现在将QoS预取加倍, 意味着每个消息都会驻留在客户端缓冲区中一段时间​​, 而不是在到达客户端时立即处理; 从现在51条消息的完整缓冲区开始, 我们知道新消息将在客户端完成处理第一条消息之后的100ms处开始出现在客户端, 但在这100毫秒内, 客户只能处理100/4 = 25个消息, 这意味着当新消息到达客户端时, 它会在客户端从缓冲区头部移除时被添加到缓冲区的末尾;</p><ul><li><p>而缓冲区将始终保持(50 - 25 = 25)个消息长度, <strong>因此每个消息将在缓冲区中保持 25 * 4 = 100ms</strong>;</p></li><li><p>因此, <strong>增加预取缓冲区大小, 可以使consumer应对恶化的网络性能, 同时保持客户端繁忙</strong>;</p></li></ul></li><li><p>同样, 如果不是网络性能的恶化, 而是客户端开始花费40ms来处理每条消息而不是之前的4ms, 会发生什么情况?</p><ul><li><p>假设原始的预取缓冲区大小设置的是26条消息, 客户端现在需要花40ms处理第一条消息, 然后将确认消息发送回Rabbit并移至下一条消息;<br>ack仍然需要50ms才能到达Rabbit, 而Rabbit发出一条新的消息需要50ms, 但在100ms内, 客户端只处理了 100/40 = 2.5 条消息, 而不是剩余的25条消息;<br>因此当新消息到来时, 缓冲区在这一点上仍然是有 25 - 3 = 22 个消息, 这样的话, 来自Rabbit的新消息就不会被立即处理, 而是位于第23位, 落后于其他22条仍在等待处理的消息;<br>客户端(Consumer)将会有 22 * 40 = 880ms 的时间都不会触及到那个新到的消息, 鉴于从Rabbit到客户端的网络延迟仅为50ms, 这个额外的880ms延迟现在为延迟的95％ (880 / (880 + 50) = 0.946);</p></li><li><p><strong>当你决定尝试通过添加更多消费者来处理这种增长的积压时, 需要注意, 现在有消息正在被现有客户端缓冲, 并不是说你增加消费者就能缓解这部分的压力!</strong></p></li><li><p>更糟糕的是, 如果我们将缓冲区大小设置为可以预取51条消息以应对网络性能下降,会发生什么?<br>处理第一条消息后, 将在客户端缓冲另外50条消息, 100ms后(假设网络运行正常), 一条新消息将从Rabbit到达客户端, consumer在100ms中只能处理这50条消息中的两条消息(缓冲区现在为47条消息长),<br>因此新消息将会在缓冲区中是第48位, 这样的话, 知道 47 <em> 40 = 1880ms 之后, 消费者才会开始处理新来的消息, 同样, 考虑到向客户端发送消息的网络延迟仅为50ms, 现在这个1880ms的延迟意味着客户端缓冲占延迟的97％(1880/(1880 + 50)= 0.974);<br>这可能是不可接受的: 数据只能在客户端收到后2秒内立即处理, 才能有效且有用！<br><em>*如果其他消费客户端空闲, 他们无能为力</em></em>: 一旦Rabbit向客户端发送消息, 消息就是客户端的责任, 直到他们拒绝或拒绝消息; 消息发送到客户端后，客户端不能窃取彼此的消息;<br>您希望客户端保持繁忙状态, 但客户端尽可能少地缓存消息, 以便客户端缓冲区不会延迟消息, 因此新消费客户端可以快速接收来自Rabbit队列的消息;</p></li><li><p>因此, 如果网络变慢, 缓冲区太小会导致客户端空闲; 但如果网络正常运行, 缓冲区太大会导致大量额外的延迟;<br>如果客户端突然开始花费更长时间来处理每个缓冲区, 则会导致大量额外的延迟;<br>很明显, 你真正想要的是可以变化的缓冲区大小, 这些问题在网络设备中很常见, 并且一直是很多研究的主题;<br>主动队列管理算法试图尝试放弃或拒绝消息，以避免消息长时间处于缓冲区。当缓冲区保持空闲时（每条消息只遭受网络延迟，并且根本不在缓冲区中），缓冲区在那里吸收峰值，从而实现最低延迟。从网络路由器的角度来看，Jim Gettys一直在研究这个问题：局域网和广域网性能之间的差异会遇到完全相同的问题。实际上，无论何时，在生产者（在我们的例子中为Rabbit）和消费者（客户端应用程序逻辑）之间都有一个缓冲区，双方的性能可以动态变化，您将会遇到这些问题。最近发布了一种名为Controlled Delay的新算法，该算法似乎在解决这些问题方面效果很好。</p></li></ul></li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol><li><p>针对Qos的提前预习</p><ul><li><p><a href="https://www.rabbitmq.com/confirms.html#channel-qos-prefetch" target="_blank" rel="external">信道预取设置(QoS)</a><br>由于消息是异步发送(推送)给客户端的, 因此在任何给定时刻通常都有不止一条消息在信道上运行; 此外, 客户的手动确认本质上也是异步的, 所以有一个 未确认的交付标签的滑动窗口, 开发人员通常会倾向于限制此窗口的大小, <strong>以避免消费者端无限制的缓冲区问题</strong>。<br>这是通过使用 <code>basic.qos</code> 方法设置 <code>预取计数</code> 值完成的, 该值定义了<strong>channel上允许的最大未确认递送数量</strong>, 一旦数字达到配置的计数, RabbitMQ将停止在通道上传送更多消息, 除非至少有一个未确认的消息被确认;<br>例如, 假设在通道 “Ch” 上有未确认的交付标签5,6,7和8, 并且通道 “Ch” 的预取计数(后面会学到是<code>prefetch_count</code>)设置为4, 则RabbitMQ将不会在 “Ch” 上推送更多交付, 除非至少有一个未完成的交付被确认(当确认帧在 <code>delivery_tag=8</code> 的频道上到达时, <strong>RabbitMQ将会注意到并再发送一条消息</strong>)</p></li><li><p>QoS预取设置对使用 <code>basic.get</code>(<code>pull API</code>) 获取的消息没有影响, 即使在手动确认模式下也是如此;</p></li></ul></li><li><p>消费者确认模式, 预取和吞吐量<br> 确认模式 和 QoS预取值 对消费者吞吐量有显着影响, 一般来说, <strong>增加预取值将提高向消费者传递消息的速度, 当然, 自动确认模式可以产生最佳的传送速率</strong><br> 但是, 在上面两种情况下, 尚未完成交付处理的消息(unacked)数量也会增加, 从而增加消费者RAM消耗;<br> <strong>自动确认模式或带无限预取的手动确认模式应谨慎使用</strong>, 消费者在没有确认的情况下消耗大量消息将导致其所连接的节点上的内存消耗增长;<br> 预取值1是最保守的, 但这将显着降低吞吐量, 特别是在消费者连接延迟较高的环境中, 对于许多应用来说, 更高的价值是合适和最佳的;<br> 100到300范围内的Qos(<code>prefetch_count</code>)预取值通常提供最佳的吞吐量, 并且不会面临压垮consumer的重大风险, 而更高的值往往会遇到效率递减的规律; </p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;RabbitMQ关于吞吐量-延迟和带宽的一些理论&quot;&gt;&lt;a href=&quot;#RabbitMQ关于吞吐量-延迟和带宽的一些理论&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ关于吞吐量,延迟和带宽的一些理论&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>08. 事务 VS Publisher Confirms(发布者确认机制)</title>
    <link href="http://blog.renyimin.com/2018/06/05/rabbitmq/2018-06-05-rabbitmq-08/"/>
    <id>http://blog.renyimin.com/2018/06/05/rabbitmq/2018-06-05-rabbitmq-08/</id>
    <published>2018-06-05T11:20:56.000Z</published>
    <updated>2018-07-20T11:29:01.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题的出现"><a href="#问题的出现" class="headerlink" title="问题的出现"></a>问题的出现</h2><ol><li><p>和消息持久化相关的一个概念是 AMQP 的事务(transaction)机制;</p></li><li><p>到目前为止, 我们讨论的是将 <code>消息</code>, <code>队列</code> 和 <code>交换器</code> 设置为持久化; 这一切都工作的很好, 并且RabbitMQ也负责保证消息的安全, 但是由于 <strong>发布消息的操作并不会反回任何信息给生产者</strong>, 所以你也无法得知是否消息已经到达了服务器并且服务器是否已经将消息持久化到了硬盘;</p><ul><li>服务器可能会在把消息写入到硬盘前就宕机了, 或者消息压根就还没有发送到服务器, 服务器就宕机了, 消息会因此而丢失, 而你却不知道; </li><li>另外, 你可能是发送多条消息, 如果部分发送成功, 部分失败呢? 这你也无法得知;</li></ul></li></ol><h2 id="事务机制"><a href="#事务机制" class="headerlink" title="事务机制"></a>事务机制</h2><ol><li><p>为了确保消息能够被安全发布到Broker, 如果使用标准的AMQP 0-9-1, 保证消息不会丢失的唯一方法是使用 <strong>事务机制</strong> (将channel事务化)</p></li><li><p>php-amqplib 中与事务机制有关的方法有三个, 分别是Channel里面的 <code>txSelect()</code>, <code>txCommit()</code> 以及 <code>txRollback()</code>;</p><ul><li>txSelect(): 用于将当前Channel设置成是transaction模式</li><li>txCommit(): 用于提交事务</li><li>txRollback(): 用于回滚事务</li></ul></li><li><p>但是值得注意的是事务存在的问题: </p><ul><li>AMQP 0-9-1 中的事务几乎吸干了RabbitMQ的性能, 会导致事务吞吐量严重下降;</li><li>事务会使得生产者应用程序变成同步的, 而你使用消息通信就是为了避免同步;</li></ul></li><li><p>鉴于上面的问题, 你可能不会在生产中使用事务机制, 此处只做了个简单的事务测试, <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/TxController.php" target="_blank" rel="external">测试代码</a></p></li></ol><h2 id="Publisher-Confirms"><a href="#Publisher-Confirms" class="headerlink" title="Publisher Confirms"></a><a href="https://www.rabbitmq.com/confirms.html#publisher-confirms" target="_blank" rel="external">Publisher Confirms</a></h2><ol><li><p>既然事务存在的问题让你拒绝使用它, 但是<code>确保消息被成功投递到服务器</code>这个问题仍需要解决; 为了避免事务机制在解决问题时导致的新问题, RabbitMQ团队拿出了更好的方案来保证消息的投递: <strong>发送方确认模式</strong></p></li><li><p>它模仿协议中已经存在的 <strong>消费者确认机制</strong></p></li><li><p>要启用这个确认机制，客户端可以通过使用 channel 的 <code>confirm.select</code> 方法</p><ul><li><p>如果设置了 <code>confirm.select</code> 方法的 <code>no-wait</code>, 代理会用 <code>confirm.select-ok</code> 进行响应, 不过这点你貌似也只能通过抓包来观察:<br><img src="/img/rabbitmq/wireshark-Confirm.Select-ok.png"></p></li><li><p>这里说的 <code>confirm.select-ok</code> 是代理对发布者的响应信息 (和 php-amqplib包中的 <code>confirm_select_ok()</code> 方法可不是一个意思, 而且php-amqplib也没对confirm_select_ok做实现)</p></li></ul></li><li><p>上面也提到了, 该确认机制是模仿已经存在的 消费者确认机制, 所以, Broker也会使用类似 <strong>ack</strong>, <strong>nack</strong> 来响应Publisher: </p><ul><li><p>可以通过为 <code>set_ack_handler</code> , <code>set_nack_handler</code> 设置回调, 来监测消息是否成功到达服务器, 成功则会触发 <code>set_ack_handler</code>, 失败则会触发 <code>set_nack_handler</code></p></li><li><p><strong>只有在负责队列的Erlang进程中发生内部错误时才会回应nack</strong>, 所以这个在测试中也一直没有使用 set_nack_handler 捕获到错误 (是对于nack的消息, 可以设置进行重发);</p></li><li><p>注意: <strong>这两监听函数是监听服务器对 publisher 的应答的, 可不是监听 consumer 对服务器的应答的</strong>;</p></li></ul></li><li><p>一旦在channel上使用 <code>confirm.select</code> 方法, 就说 channel 处于 <strong>确认模式</strong>, 一旦通道处于确认模式, 就不能进行事务处理; 也就是说 <strong>事务 和 Publisher Confirm 不能同时使用</strong>;  </p><ul><li>一旦通道处于确认模式, 代理和客户端都会对消息进行计数(在第一次confirm.select时从1开始计数), 然后, broker通过在相同channel上发送 <code>basic.ack</code> 来处理它们, 从而确认消息; </li><li><code>delivery-tag</code> 字段包含确认消息的序列号;<br>最大 Delivery Tag, 递送标签是一个64位长的值，因此其最大值为9223372036854775807.由于递送标签的范围是按每个通道划分的，因此发布商或消费者在实践中不太可能运行该值</li></ul></li><li><p>Publisher Confirms 的顺序考虑</p><ul><li>在大多数情况下, RabbitMQ将按发布顺序向publisher确认消息(这适用于在单个频道上发布的消息); 但是, 发布者确认是异步发出的, 并且可以确认一条消息或一组消息;<br>由于消息确认可以以不同的顺序到达, 所以, 应用程序应尽可能不取决于确认的顺序;</li></ul></li></ol><h2 id="发布者确认存在的问题"><a href="#发布者确认存在的问题" class="headerlink" title="发布者确认存在的问题"></a>发布者确认存在的问题</h2><ol><li><a href="https://yq.aliyun.com/articles/42206" target="_blank" rel="external">mandatory 属性问题</a></li></ol><h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h2><p>publisher confirm 不需要消费者参与, <a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/PublisherConfirmController.php" target="_blank" rel="external">代码参考</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题的出现&quot;&gt;&lt;a href=&quot;#问题的出现&quot; class=&quot;headerlink&quot; title=&quot;问题的出现&quot;&gt;&lt;/a&gt;问题的出现&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;和消息持久化相关的一个概念是 AMQP 的事务(transaction)机制;&lt;/p&gt;
&lt;/li&gt;
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>06. 持久化策略</title>
    <link href="http://blog.renyimin.com/2018/05/28/rabbitmq/2018-05-28-rabbitmq-06/"/>
    <id>http://blog.renyimin.com/2018/05/28/rabbitmq/2018-05-28-rabbitmq-06/</id>
    <published>2018-05-28T09:32:11.000Z</published>
    <updated>2018-07-20T09:43:29.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="持久化原理"><a href="#持久化原理" class="headerlink" title="持久化原理"></a>持久化原理</h2><ol><li><p>RabbitMQ 默认情况下, <code>Exchange</code>, <code>队列</code>, <code>消息</code> 都是非持久的, 这意味着一旦消息服务器重启, 所有已声明的 <code>Exchange</code>, <code>队列</code>, 以及 <code>队列中的消息</code> 都会丢失;</p></li><li><p>RabbitMQ确保持久化的消息能在服务器重启之后恢复的方式是, 将它们写入磁盘上的一个持久化日志文件。当发布一条持久性消息到一个持久交换机上时, Rabbit会在消息提交到日志文件中之后才发送响应; </p><ul><li>还需要注意的是, 如果之后这条消息被路由到一个非持久化队列, 则消息又会从上面的日志文件中删除, 并且无法从服务器重启中恢复;</li><li>一旦你从持久化队列中消费了一条持久性消息(并且进行了确认), RabbitMQ会在持久化日志中把这条消息标记为等待垃圾收集;</li></ul></li></ol><h2 id="持久化方案"><a href="#持久化方案" class="headerlink" title="持久化方案"></a>持久化方案</h2><ol><li><p>要做到消息持久化, 必须保证如下三点设置正确:</p><ul><li>exchange交换器: durable属性为true;</li><li>queue队列: durable属性为true;</li><li>除了上述两点之外, 还需要在投递消息时候, 设置message的 <code>delivery_mode</code> 模式为<code>2</code>来标识消息为持久化消息;</li></ul></li><li><p>另外: 一个包含持久化消息的非持久化队列, 在Rabbit Server重启之后, 该队列将会不复存在, 消息就会变成孤儿;</p></li><li><p><a href="https://github.com/rymuscle/Laravel-RabbitMQ/blob/master/app/Http/Controllers/Demo/ParamsDetailController.php" target="_blank" rel="external">具体代码</a></p></li></ol><h2 id="持久化的问题"><a href="#持久化的问题" class="headerlink" title="持久化的问题"></a>持久化的问题</h2><ol><li><p>持久化由于会写磁盘, 所以会极大降低RabbitMQ每秒处理的消息总数, 降低吞吐量;</p></li><li><p>持久化在Rabbit内建集群环境下工作的并不好, 虽然RabbitMQ集群允许你和集群中的任何节点的任一队列进行通信, 但是如果队列所在的节点崩溃后, 如果队列是持久化的, 那么直到这个节点恢复之前, 这个队列都不会在整个集群中被创建出来;<br> 后面在学习集群时, 会给出相应的解决方案;</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;持久化原理&quot;&gt;&lt;a href=&quot;#持久化原理&quot; class=&quot;headerlink&quot; title=&quot;持久化原理&quot;&gt;&lt;/a&gt;持久化原理&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;RabbitMQ 默认情况下, &lt;code&gt;Exchange&lt;/code&gt;, &lt;code&gt;队列&lt;/
      
    
    </summary>
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/categories/RabbitMQ/"/>
    
    
      <category term="RabbitMQ" scheme="http://blog.renyimin.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>06. Docker数据管理</title>
    <link href="http://blog.renyimin.com/2017/12/17/docker/2017-12-17-06-docker/"/>
    <id>http://blog.renyimin.com/2017/12/17/docker/2017-12-17-06-docker/</id>
    <published>2017-12-17T07:30:21.000Z</published>
    <updated>2018-08-04T09:12:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>容器中管理数据主要有两种方式：<strong>数据卷(Volumes)</strong> 和 <strong>挂载主机目录(Bind mounts)</strong></p><h2 id="数据卷-Volumes"><a href="#数据卷-Volumes" class="headerlink" title="数据卷(Volumes)"></a>数据卷(Volumes)</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ol><li><p>数据卷 是一个可供<strong>一个或多个</strong>容器使用的特殊目录, 它绕过UFS, 可以提供很多有用的特性:</p><ul><li>数据卷可以在容器之间共享和重用</li><li>对数据卷的修改会立马生效</li><li>对数据卷的更新,不会影响镜像</li><li>数据卷默认会一直存在, 即使容器被删除</li></ul></li><li><p>注意: 数据卷的使用, 类似于 Linux 下对目录或文件进行 <code>mount</code>, 镜像中被指定为挂载点的目录中的文件会隐藏掉, 能显示看的是挂载的数据卷;</p></li></ol><h3 id="数据卷操作"><a href="#数据卷操作" class="headerlink" title="数据卷操作"></a>数据卷操作</h3><ol><li><p>创建一个数据卷: <code>docker volume create my-vol</code> (其实还有一种方式就是在docker run的时候直接指定一个数据卷名, 就会自动帮你创建数据卷)</p></li><li><p>查看所有数据卷: <code>docker volume ls</code></p></li><li><p>查看指定数据卷的信息: <code>docker volume inspect my-vol</code><br> 查看容器的数据卷挂载信息: <code>docker inspect 容器名</code></p></li><li><p>删除数据卷 <code>$ docker volume rm my-vol</code></p><ul><li>数据卷 是被设计用来<strong>持久化</strong>数据的, 它的生命周期独立于容器, Docker不会在容器被删除后自动删除数据卷, 并且<strong>也不存在垃圾回收这样的机制来处理没有任何容器引用的数据卷</strong>;</li><li>如果需要在删除容器的同时移除数据卷, 可以在删除容器的时候使用 <code>docker rm -v</code> 这个命令, <strong>这个命令貌似只是移除该容器和数据卷之间的关系</strong>, 除非这个数据卷没有任何容器引用了, 才可以使用下面介绍的命令来删除掉;</li></ul></li><li><p><strong>无主的数据卷</strong>可能会占据很多空间，要清理请使用命令 <code>$ docker volume prune</code></p><ul><li>可以看到清除时会提醒你 <code>WARNING! This will remove all volumes not used by at least one container</code></li><li>清除的是没有被<strong>至少一个</strong>容器使用的数据卷!</li></ul></li></ol><h2 id="启动容器时挂载数据卷"><a href="#启动容器时挂载数据卷" class="headerlink" title="启动容器时挂载数据卷"></a>启动容器时挂载数据卷</h2><ol><li><p>在使用 <code>docker run</code> 命令的时候, 还可以使用 <code>--mount</code> 参数来将 <code>数据卷</code> 挂载到容器里, 另外, 在一次 <code>docker run</code> 中可以挂载多个数据卷</p></li><li><p>下面创建一个名为 <code>nginx_conf</code> 的数据卷</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker volume create nginx-default-html-root</div><div class="line">nginx-default-html-root</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker volume inspect nginx-default-html-root</div><div class="line">[</div><div class="line">    &#123;</div><div class="line">        &quot;CreatedAt&quot;: &quot;2017-12-17T08:28:10Z&quot;,</div><div class="line">        &quot;Driver&quot;: &quot;local&quot;,</div><div class="line">        &quot;Labels&quot;: &#123;&#125;,</div><div class="line">        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/nginx-default-html-root/_data&quot;,</div><div class="line">        &quot;Name&quot;: &quot;nginx-default-html-root&quot;,</div><div class="line">        &quot;Options&quot;: &#123;&#125;,</div><div class="line">        &quot;Scope&quot;: &quot;local&quot;</div><div class="line">    &#125;</div><div class="line">]</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>以 <code>nginx:stable</code> 镜像运行容器, 同时加载上面的数据卷’nginx-default-html-root’到容器内的 ‘/usr/share/nginx/html’ 目录</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker run -d -p 8000:80 --name nginx --mount source=nginx-default-html-root,target=/usr/shar/nginx/html nginx:stable</div><div class="line">d9272900ba7f2a59e6ff402aeee642856679ac073787e08997baa4c97fff051c</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ol><ol><li><p><strong>另外值得注意的是</strong>:</p><ul><li>如果容器中对应的目录不存在, 容器会自动创建目录;</li><li>如果运行容器时, 加载的数据卷不存在, 则会自动创建, 通过<code>docker volume ls</code>也可以看到自动创建的数据卷</li><li>数据卷只能挂在到容器中的目录, 不能挂载到文件</li></ul></li><li><p>可以在主机里使用以下命令查看 <code>nginx</code> 容器的信息, 数据卷信息在 <code>&quot;Mounts&quot;</code> Key 下面</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">$ docker inspect nginx</div><div class="line">&quot;Mounts&quot;: [</div><div class="line">    &#123;</div><div class="line">        &quot;Type&quot;: &quot;volume&quot;,</div><div class="line">        &quot;Name&quot;: &quot;nginx-default-html-root&quot;,</div><div class="line">        &quot;Source&quot;: &quot;/var/lib/docker/volumes/nginx-default-html-root/_data&quot;,</div><div class="line">        &quot;Destination&quot;: &quot;/usr/shar/nginx/html&quot;,</div><div class="line">        &quot;Driver&quot;: &quot;local&quot;,</div><div class="line">        &quot;Mode&quot;: &quot;z&quot;,</div><div class="line">        &quot;RW&quot;: true,</div><div class="line">        &quot;Propagation&quot;: &quot;&quot;</div><div class="line">    &#125;</div><div class="line">],</div><div class="line">...</div></pre></td></tr></table></figure></li></ol><h2 id="挂载主机目录-文件"><a href="#挂载主机目录-文件" class="headerlink" title="挂载主机目录/文件"></a>挂载主机目录/文件</h2><ol><li><p>挂载一个主机目录作为数据卷: 使用 <code>--mount</code> 标记可以指定挂载一个本地主机的目录到容器中去</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker run -d -p 8001:80 --name nginx_t1 --mount type=bind,source=/Users/renyimin/Desktop/nginx_transfer,target=/transfer nginx:stable</div><div class="line">f5313881baa9bb4522552ba0b02dcad9f315d8a4e5245e2b362dc674ac9d4c4f</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker exec -it f5313881baa9bb4522552ba0b02dcad9f315d8a4e5245e2b362dc674ac9d4c4f /bin/sh</div><div class="line">// 下面可以看到容器自己创建的transfer目录</div><div class="line"># ls</div><div class="line">bin  boot  devetc  home  liblib64  media  mnt  optproc  root  run  sbin  srv  sys  tmp  transferusr  var</div></pre></td></tr></table></figure></li><li><p>查看容器的挂载信息, 发现和数据卷相比, <code>Type</code> 信息是 <code>bind</code> 而不是 <code>volume</code>, 并且没有数据卷的 <code>name</code> 信息, <code>docker volume ls</code> 也不会看到有新的数据卷被创建, 所以…可以认为只是一次简单的目录绑定</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:testVip renyimin$ docker inspect testVip</div><div class="line">&quot;Mounts&quot;: [</div><div class="line">    &#123;</div><div class="line">        &quot;Type&quot;: &quot;bind&quot;,</div><div class="line">        &quot;Source&quot;: &quot;/Users/renyimin/Desktop/nginx_transfer&quot;,</div><div class="line">        &quot;Destination&quot;: &quot;/transfer&quot;,</div><div class="line">        &quot;Mode&quot;: &quot;&quot;,</div><div class="line">        &quot;RW&quot;: true,</div><div class="line">        &quot;Propagation&quot;: &quot;rprivate&quot;</div><div class="line">    &#125;</div><div class="line">],</div></pre></td></tr></table></figure></li><li><p>也可以挂载文件</p><ul><li>注意, 如果你直接在本地新建一个nginx.conf就想在启动的时候直接挂载到容器中的nginx.conf, 那么nginx容器可能压根就启动不起来了, 后面会使用 <code>docker cp</code> 来解决这个问题<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker run -d -p 8002:80 --name nginx_t2 --mount type=bind,source=/Users/renyimin/Desktop/nginx_transfer1/index.html,target=/usr/share/nginx/html/index.html nginx:stable</div><div class="line">b85543ee9562647195ab094579b8e17fd8f439094ab5f0054215af435d33681c</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ul></li><li><p>选择 <code>-v</code> 还是 <code>--mount</code> 参数?</p><ul><li>Docker 新用户应该选择 <code>--mount</code> 参数, 经验丰富的 Docker 使用者对 <code>-v</code> 或者 <code>--volume</code> 已经很熟悉了, 但是推荐使用 <code>--mount</code> 参数;</li><li>可以理解为, <code>--mount</code> 参数应该可以挂载数据卷, 也可以代替-v来进行目录关联;</li></ul></li><li><p>Docker 挂载主机目录的默认权限是 <code>读写</code>, 用户也可以通过增加 <code>readonly</code> 指定为 <strong>只读</strong></p><ul><li><p>加了 readonly 之后, 就挂载为 只读 了, 如果你在容器内 /haha 目录新建文件, 会显示如下错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:testVip renyimin$ docker run -d -p 8090:80 --name testVip --mount type=bind,source=/Users/renyimin/Desktop/testVip,target=/haha,readonly vipservice</div><div class="line">27863a3a8f70fa4bddb9c97fabfee2db7f35d5615d4b90ad0be13717dc23d092</div><div class="line">renyimindeMacBook-Pro:testVip renyimin$ docker exec -it 27863a3a8f70fa4bddb9c97fabfee2db7f35d5615d4b90ad0be13717dc23d092 /bin/sh</div><div class="line">sh-4.2# </div><div class="line">sh-4.2# cd /</div><div class="line">sh-4.2# ls</div><div class="line">anaconda-post.log  bindata  dev  etchaha  home  lib  lib64lost+found  media  mntopt  proc  root  run  run.sh  sbin  srv  sys  tmp  usrvar</div><div class="line">sh-4.2# cd haha</div><div class="line">sh-4.2# ls</div><div class="line">myfirstregistry  registry.tar</div><div class="line">// 可以看到报错了</div><div class="line">sh-4.2# touch a.txt</div><div class="line">touch: cannot touch &apos;a.txt&apos;: Read-only file system</div><div class="line">sh-4.2#</div></pre></td></tr></table></figure></li><li><p>查看数据卷的具体信息 <code>$ docker inspect testVip</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&quot;Mounts&quot;: [</div><div class="line">    &#123;</div><div class="line">        &quot;Type&quot;: &quot;bind&quot;,</div><div class="line">        &quot;Source&quot;: &quot;/Users/renyimin/Desktop/testVip&quot;,</div><div class="line">        &quot;Destination&quot;: &quot;/haha&quot;,</div><div class="line">        &quot;Mode&quot;: &quot;&quot;,</div><div class="line">        &quot;RW&quot;: false,</div><div class="line">        &quot;Propagation&quot;: &quot;rprivate&quot;</div><div class="line">    &#125;</div><div class="line">],</div></pre></td></tr></table></figure></li></ul></li></ol><h2 id="数据卷挂载的问题"><a href="#数据卷挂载的问题" class="headerlink" title="数据卷挂载的问题"></a>数据卷挂载的问题</h2><ol><li><p>上面提到的数据卷, 对很多容器都非常有用, 比如 </p><ul><li>mysql容器中存储数据文件的 <code>/var/lib/mysql</code> 目录你就需要挂载数据卷;</li><li>mysql, php-fpm, nginx等容器中, 关于服务配置的目录你也需要挂载到数据卷, 这些配置你可能需要进行改动;</li></ul></li><li><p>但是挂载数据卷有个问题, 一旦挂载之后, 容器中的目录就是空的, 原本服务的配置文件就被清空了, 也就导致有些容器在挂载数据卷之后, 无法正常启动;</p></li></ol><h2 id="docker-cp-命令"><a href="#docker-cp-命令" class="headerlink" title="docker cp 命令"></a>docker cp 命令</h2><ol><li><p>可以将本地目录/文件拷贝到容器, 也可以将容器中的目录/文件拷贝到本地; 格式: </p><ul><li><code>docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH</code></li><li><code>docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-</code></li></ul></li><li><p>所以为了避免挂载导致容器无法正常启动, 挂载的可以这样来:</p><ul><li>先确定你需要挂载的容器中目录的位置(比如: nginx容器中的配置文件在<code>/etc/nginx/conf.d/default.conf</code> )</li><li>使用 <code>docker cp</code> 命令, 将需要映射的目录从容器复制到本地; (比如:  <code>docker cp nginx_test:/etc/nginx/ ./conf/</code>)</li><li>然后再将本地default.conf文件挂载到nginx容器的/etc/nginx/conf.d/default.conf</li></ul></li></ol><p>参考: <a href="https://yeasy.gitbooks.io/docker_practice/content/data_management/" target="_blank" rel="external">https://yeasy.gitbooks.io/docker_practice/content/data_management/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;容器中管理数据主要有两种方式：&lt;strong&gt;数据卷(Volumes)&lt;/strong&gt; 和 &lt;strong&gt;挂载主机目录(Bind mounts)&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;数据卷-Volumes&quot;&gt;&lt;a href=&quot;#数据卷-Volumes&quot; class
      
    
    </summary>
    
      <category term="Docker" scheme="http://blog.renyimin.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://blog.renyimin.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>05. 容器</title>
    <link href="http://blog.renyimin.com/2017/12/16/docker/2017-12-16-05-docker/"/>
    <id>http://blog.renyimin.com/2017/12/16/docker/2017-12-16-05-docker/</id>
    <published>2017-12-16T03:06:58.000Z</published>
    <updated>2018-08-04T07:41:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><ol><li><p>镜像(Image)和容器(Container)的关系, 就像是面向对象程序设计中的 类 和 实例 的关系一样, 镜像是静态的定义, 容器是镜像运行时的实体; 容器可以被 <code>创建</code>、<code>启动</code>、<code>停止</code>、<code>删除</code>、<code>暂停</code>等;</p></li><li><p>容器的实质是<strong>进程</strong>, 但与直接在宿主执行的进程不同, 容器进程运行于属于自己的独立的命名空间</p><ul><li>因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间, 甚至自己的用户ID空间;</li><li>容器内的进程是运行在一个隔离的环境里, 使用起来, 就好像是在一个独立于宿主的系统下操作一样, 这种特性使得容器封装的应用比直接在宿主运行更加安全, 也因为这种隔离的特性, 很多人初学 Docker 时常常会把容器和虚拟机搞混;</li></ul></li><li><p>前面讲过镜像使用的是<strong>分层存储</strong>, 容器也是如此, 每一个容器运行时, 是以镜像为基础层, 在其上创建一个当前容器的存储层, 这是为容器运行时读写而准备的存储层;<br> <code>容器存储层</code>的生存周期和容器一样, 容器消亡时, 容器存储层也随之消亡, 因此, <strong>任何保存于容器存储层的信息都会随容器的删除而丢失</strong>;</p></li><li><p>按照 Docker 最佳实践的要求, 容器不应该向其存储层内写入任何数据, <strong>容器存储层要保持无状态化</strong></p><ul><li>所有的文件写入操作, 都应该使用 <code>数据卷(Volume)</code>、或者 <code>绑定宿主目录</code>, 在这些位置的读写会跳过容器存储层, 直接对宿主(或网络存储)发生读写, 其性能和稳定性更高;</li><li>数据卷的生存周期独立于容器, 容器消亡, 数据卷不会消亡, 因此, 使用数据卷后, 容器可以随意删除、重新run, 数据却不会丢失;</li></ul></li></ol><h2 id="容器操作"><a href="#容器操作" class="headerlink" title="容器操作"></a>容器操作</h2><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><ol><li><p>启动容器有两种方式：一种是基于镜像新建一个容器并启动; 另外一个是将在终止状态(stopped)的容器启动</p></li><li><p>创建并启动</p><ul><li>因为 Docker 的容器<strong>实在太轻量级了</strong>, 很多时候用户都是<strong>随时删除和新创建容器</strong>;</li><li>新建并启动一个容器所需的命令主要为 <code>docker run</code>, 例如: <code>$ docker run -d -p 5000:5000 --name myFirstRegistry registry</code>, 是根据名为registry的镜像创建并运行一个名为myFirstRegistry容器;</li></ul></li><li><p>当利用 <code>docker run</code> 来创建容器时, Docker 在后台运行的标准操作包括:</p><ul><li>检查本地是否存在指定的镜像, 不存在就从公有仓库下载</li><li>利用镜像创建并启动一个容器</li><li>分配一个文件系统, 并在只读的镜像层外面挂载一层可读写层 </li><li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 </li><li>从地址池配置一个 ip 地址给容器</li><li>执行用户指定的应用程序</li><li>执行完毕后容器被终止</li></ul></li><li><p><strong>容器被启动后, 设置的挂载目录, 端口映射都会随着此容器, 容器stop后, 再次start, 这些设置都还在;</strong></p></li><li><p>启动已终止容器: 可以利用 <code>docker start [containerID or NAME]</code> 命令, 直接将一个已经终止的容器启动运行;</p></li></ol><h3 id="守护态运行容器"><a href="#守护态运行容器" class="headerlink" title="守护态运行容器"></a>守护态运行容器</h3><p>其实更多时候, 我们需要让容器在后台运行, 而不是直接运行容器并展示出结果, 此时只用在运行时加上 <code>-d 参数</code>即可; (在容器的第一种启动方式中已经介绍过了)</p><h3 id="查看容器信息"><a href="#查看容器信息" class="headerlink" title="查看容器信息"></a>查看容器信息</h3><p>可以通过 <code>docker ps</code> 命令来查看正在运行的容器信息</p><p>可以通过 <code>docker ps -a</code> 命令来查看 正在运行的和终止的 容器信息</p><h3 id="终止容器"><a href="#终止容器" class="headerlink" title="终止容器"></a>终止容器</h3><p>可以使用 <code>docker stop [containerID or NAME]</code> 来终止一个运行中的容器</p><h3 id="重启容器"><a href="#重启容器" class="headerlink" title="重启容器"></a>重启容器</h3><p>可以使用 <code>docker restart [containerID or NAME]</code> 来重启一个运行中的容器</p><h3 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h3><ol><li><p>可以使用 <code>docker rm 容器ID/容器NAME</code> 来删除一个<strong>处于终止状态</strong>的容器;</p></li><li><p>如果要删除一个运行中的容器，可以添加 <code>-f</code> 参数;</p></li></ol><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><ol><li><p>可参考<a href="https://yeasy.gitbooks.io/docker_practice/content/container/attach_exec.html" target="_blank" rel="external">书中介绍</a></p></li><li><p>推荐使用 <code>docker exec -it [containerID or NAME] /bin/sh</code></p><ul><li>其中, <code>/bin/bash</code> 有可能是 <code>/bin/sh</code>，因为不一定所有的docker都安装了shell</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;容器&quot;&gt;&lt;a href=&quot;#容器&quot; class=&quot;headerlink&quot; title=&quot;容器&quot;&gt;&lt;/a&gt;容器&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;镜像(Image)和容器(Container)的关系, 就像是面向对象程序设计中的 类 和 实例 的关系一样, 镜像是静态
      
    
    </summary>
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/categories/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/tags/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>04.定制镜像 - docker commit手动定制</title>
    <link href="http://blog.renyimin.com/2017/12/03/docker/2017-12-03-04-docker/"/>
    <id>http://blog.renyimin.com/2017/12/03/docker/2017-12-03-04-docker/</id>
    <published>2017-12-03T06:09:21.000Z</published>
    <updated>2018-08-04T03:27:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>镜像是容器的基础, 每次执行 <code>docker run</code> 的时候都需要指定哪个镜像作为容器运行的基础。<br>在之前的例子中, 我们所使用的都是来自于 Docker Hub 的镜像, 直接使用这些镜像是可以满足一定的需求, 而当这些镜像无法直接满足需求时, 我们就需要<strong>定制这些镜像</strong>。</p><h2 id="docker-commit-手动定制镜像"><a href="#docker-commit-手动定制镜像" class="headerlink" title="docker commit 手动定制镜像"></a>docker commit 手动定制镜像</h2><ol><li><p>当运行一个容器后(如果不使用<code>数据卷</code>的话), 你所做的任何文件修改都会被记录于<code>容器存储层</code>里, 注意: 容器存储层的生存周期和容器一样, 容器被删除后, 存储层中的内容也就会被删除掉, 而不会保留到镜像中</p><ul><li>如果改动了容器的存储层, 我们可以通过 <code>docker diff</code> 命令看到具体的改动</li><li>但是如果改动的是数据卷挂载到容器对应目录下的内容, <code>docker diff</code> 看不到具体的改动</li></ul></li><li><p>Docker提供了一个 <code>docker commit</code> 命令，可以将容器的存储层保存下来成为镜像</p><ul><li>换句话说，就是在原有镜像的基础上，<strong>再叠加上容器的存储层，并构成新的镜像</strong></li><li>以后我们运行这个新镜像的时候, 就会拥有原有容器最后的文件变化</li></ul></li><li><p>docker commit 的语法格式为: <code>docker commit [选项] &lt;容器ID或容器名&gt; [&lt;仓库名&gt;[:&lt;标签&gt;]]</code>, 如下:</p><ul><li>其中 <code>--author</code> 是指定修改的作者，而 <code>--message</code> 则是记录本次修改的内容。这点和 git 版本控制相似，不过这里这些信息可以省略留空<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker commit --author &quot;Tao Wang &lt;twang2218@gmail.com&gt;&quot; --message &quot;修改了默认网页&quot; webserver nginx:v2</div></pre></td></tr></table></figure></li></ul></li></ol><h2 id="手动定制镜像-挂载数据卷问题"><a href="#手动定制镜像-挂载数据卷问题" class="headerlink" title="手动定制镜像~~挂载数据卷问题"></a>手动定制镜像~~挂载数据卷问题</h2><ol><li><p>之前已经配置了docker中国加速镜像, 现在通过 <code>docker pull nginx:stable</code> 获取一个<a href="https://hub.docker.com/_/nginx/" target="_blank" rel="external">nginx基础镜像</a>;</p></li><li><p>直接运行这个nginx基础镜像为一个容器</p><ul><li><p>由于该镜像非常基础, 甚至没有像vi的工具, 因此在启动时可以将nginx的项目根目录 <code>/usr/share/nginx/html</code> 映射出来, 以便于测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker run -d -p 8088:80 --mount type=bind,source=/Users/renyimin/Desktop/nginx_test,target=/usr/share/nginx/html --name nginx_test nginx:stable</div><div class="line">983a6495386490f36e58d194a15d3dabbf86ccbadf2e44bab67d841e2abd0efe</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker ps</div><div class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</div><div class="line">983a64953864        nginx:stable        &quot;nginx -g &apos;daemon ...&quot;   20 seconds ago      Up 18 seconds       0.0.0.0:8088-&gt;80/tcp     nginx_test</div></pre></td></tr></table></figure></li><li><p>然后直接访问 <code>localhost:8088</code> 会发现nginx报错<code>403 Forbidden</code>, 这是因为挂载到容器中/usr/share/nginx/html目录的本地目录/Users/renyimin/Desktop/nginx_test中没有任何内容</p></li><li>接下来, 在/Users/renyimin/Desktop/nginx_test中创建一个index.html文件, 然后直接刷新<code>localhost:8088</code>, 就会看到效果!</li></ul></li><li><p>现在修改了容器的文件，也就是改动了容器的存储层, 我们可以通过 <code>docker diff</code> 命令看到容器当前存储层的所有改动</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker diff nginx_test</div><div class="line">C /run</div><div class="line">A /run/nginx.pid</div><div class="line">C /var/cache/nginx</div><div class="line">A /var/cache/nginx/client_temp</div><div class="line">A /var/cache/nginx/fastcgi_temp</div><div class="line">A /var/cache/nginx/proxy_temp</div><div class="line">A /var/cache/nginx/scgi_temp</div><div class="line">A /var/cache/nginx/uwsgi_temp</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>你会发现自己最直接的改动并没有体现出来, 其实这主要是因为你直接改动的文件是被挂载出来的, 如果不是挂载出来, 而是直接在容器中修改的话, 则会体现出来; 比如, 直接进入nginx容器, 在非挂载目录中创建一个新文件, 然后观察差异</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker exec -it nginx_test /bin/sh</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker diff nginx_test</div><div class="line">C /run</div><div class="line">A /run/nginx.pid</div><div class="line">C /tmp</div><div class="line">// 可以看到, 此次直接改动就体现出来了</div><div class="line">A /tmp/renyimin.html</div><div class="line">C /var/cache/nginx</div><div class="line">A /var/cache/nginx/client_temp</div><div class="line">A /var/cache/nginx/fastcgi_temp</div><div class="line">A /var/cache/nginx/proxy_temp</div><div class="line">A /var/cache/nginx/scgi_temp</div><div class="line">A /var/cache/nginx/uwsgi_temp</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li></ol><h3 id="手动定制镜像"><a href="#手动定制镜像" class="headerlink" title="手动定制镜像"></a>手动定制镜像</h3><ol><li><p><code>docker commit --author &#39;renyimin&#39; --message &quot;在/tmp下touch了一个renyimin.html文件&quot; nginx_test nginx:test01</code></p></li><li><p><code>docker image ls</code> 可以看到这个新定制的镜像</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker image ls</div><div class="line">REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">nginx                                                 test01              ad0f6d04a963        4 seconds ago       109MB</div><div class="line">nginx                                                 stable              8ae4d16b741a        2 weeks ago         109MB</div><div class="line">......</div></pre></td></tr></table></figure></li></ol><ol><li><p>还可以用 <code>docker history</code> 具体查看镜像内的历史记录, 如果比较 nginx:v1 的历史记录, 我们会发现新增了我们刚刚提交的这一层</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker history nginx:test01</div><div class="line">IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</div><div class="line">ad0f6d04a963        57 seconds ago      nginx -g daemon off;                            2B                  在/tmp下touch了一个renyimin.html文件</div><div class="line">8ae4d16b741a        2 weeks ago         /bin/sh -c #(nop)  CMD [&quot;nginx&quot; &quot;-g&quot; &quot;daem...   0B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop)  EXPOSE 80/tcp                0B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c ln -sf /dev/stdout /var/log/ngi...   22B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c set -x  &amp;&amp; apt-get update  &amp;&amp; a...   53.7MB</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop)  ENV NJS_VERSION=1.14.0....   0B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop)  ENV NGINX_VERSION=1.14....   0B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop)  LABEL maintainer=NGINX ...   0B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop)  CMD [&quot;bash&quot;]                 0B</div><div class="line">&lt;missing&gt;           2 weeks ago         /bin/sh -c #(nop) ADD file:919939fa0224727...   55.3MB</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>新的镜像定制好后，就可以来尝试运行这个镜像</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker run -d -p 8089:80 --name nginx_test01 nginx:test01</div><div class="line">88f45a479da70c07a0510edb4730773387541fd5dd16a8d379afc2d405f296bf</div><div class="line">renyimindeMacBook-Pro:~ renyimin$ docker ps</div><div class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</div><div class="line">88f45a479da7        nginx:test01        &quot;nginx -g &apos;daemon ...&quot;   3 seconds ago       Up 2 seconds        0.0.0.0:8089-&gt;80/tcp     nginx_test01</div><div class="line">983a64953864        nginx:stable        &quot;nginx -g &apos;daemon ...&quot;   19 minutes ago      Up 19 minutes       0.0.0.0:8088-&gt;80/tcp     nginx_test</div><div class="line">renyimindeMacBook-Pro:~ renyimin$</div></pre></td></tr></table></figure></li><li><p>进入此容器, 会发现使用新的镜像启动容器后, 容器中的/tmp目录下包含我们提交的index.html个文件, 当然, localhost:8089和localhost:8088不同, 8089访问的还是默认欢迎页<br> renyimindeMacBook-Pro:~ renyimin$ docker exec -it nginx_test01 /bin/sh</p><h1 id="cd-tmp"><a href="#cd-tmp" class="headerlink" title="cd /tmp"></a>cd /tmp</h1><h1 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h1><p> renyimin.html<br> #<br> ```</p></li><li><p>至此, 第一次使用 <code>docker commit</code> 命令完成了镜像定制, <strong>手动操作给旧的镜像添加了新的一层, 形成新的镜像, 对镜像多层存储应该有了更直观的感觉</strong>;</p></li></ol><h2 id="慎用-docker-commit"><a href="#慎用-docker-commit" class="headerlink" title="慎用 docker commit"></a>慎用 docker commit</h2><ol><li><p>使用 docker commit 命令虽然可以比较直观的帮助理解镜像分层存储的概念, <strong>但是实际环境中并不会这样使用</strong>;</p></li><li><p>因为如果仔细观察之前的 <code>docker diff nginx_test</code> 的结果, 会发现还有很多文件被改动或添加了, 但这些都是无关紧要的改动</p><ul><li>这还仅仅是最简单的操作, 如果是安装软件包、编译构建, 那会有大量的无关内容被添加进来, 如果不小心清理, 将会导致镜像极为臃肿;</li><li>此外, 使用 <code>docker commit</code> 意味着所有对镜像的操作都是<strong>黑箱操作</strong>, 生成的镜像也被称为<strong>黑箱镜像</strong>, 换句话说, 就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像, 别人根本无从得知;<br>而且, 即使是这个制作镜像的人, 过一段时间后也无法记清具体在操作的, 虽然 docker diff 或许可以告诉得到一些线索, 但是这种黑箱镜像的维护工作是非常痛苦的;</li></ul></li><li><p>而且, 回顾之前提及的镜像所使用的分层存储的概念, 除当前层外, 之前的每一层都是不会发生改变的, 换句话说, 任何修改的结果仅仅是在当前层进行标记、添加、修改, 而不会改动上一层;<br> 如果使用 docker commit 制作镜像, 每一次修改都会让镜像更加臃肿一次, 所删除的上一层的东西并不会丢失, 会一直如影随形的跟着这个镜像, 即使根本无法访问到, 这会让镜像更加臃肿;</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;镜像是容器的基础, 每次执行 &lt;code&gt;docker run&lt;/code&gt; 的时候都需要指定哪个镜像作为容器运行的基础。&lt;br&gt;在之前的例
      
    
    </summary>
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/categories/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/tags/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>03. Docker Registry 仓库</title>
    <link href="http://blog.renyimin.com/2017/12/02/docker/2017-12-02-03-docker/"/>
    <id>http://blog.renyimin.com/2017/12/02/docker/2017-12-02-03-docker/</id>
    <published>2017-12-02T09:40:28.000Z</published>
    <updated>2018-08-04T06:43:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="公开-Docker-Registry"><a href="#公开-Docker-Registry" class="headerlink" title="公开 Docker Registry"></a>公开 Docker Registry</h2><ol><li><p>Docker Registry 公开服务是开放给用户使用、允许用户管理镜像的 Registry 服务</p><ul><li>一般这类公开服务允许用户免费上传、下载公开的镜像, 并可能提供收费服务供用户管理私有镜像;</li><li>最常使用的Registry公开服务是官方的 <code>Docker Hub</code>, 这也是默认的 Registry，并拥有大量的高质量的官方镜像;</li></ul></li><li><p>不过由于某些原因, 在国内访问这些服务可能会比较慢, 国内的一些云服务商提供了针对 Docker Hub 的镜像服务(Registry Mirror), 这些镜像服务被称为加速器;</p></li><li><p>但有时使用 Docker Hub 或其他公共仓库仍然不方便(比如, 有时候我们的服务器无法访问互联网 或者 你不希望将自己的镜像放到公网当中), 那就需要创建一个 <strong>本地私有仓库供</strong>;</p></li></ol><h2 id="私有-Docker-Registry"><a href="#私有-Docker-Registry" class="headerlink" title="私有 Docker Registry"></a>私有 Docker Registry</h2><ol><li><p>除了使用公开服务外, 用户还可以在本地搭建私有Docker Registry, <a href="https://docs.docker.com/registry/" target="_blank" rel="external"><code>docker-registry</code></a>是官方提供的工具, 可以用于构建私有的镜像仓库;</p></li><li><p>安装运行 <code>docker-registry</code></p><ul><li>你可以通过获取官方registry镜像来在本地运行一个自己的私有镜像仓库 (如 <code>$ docker run -d -p 5000:5000 --restart=always --name registry registry</code>, 将使用官方的registry镜像来启动一个私有仓库)</li><li>默认情况下, 仓库中的镜像会被创建在容器的 <code>/var/lib/registry</code> 目录下, 你可以通过 <code>-v</code> 参数来将镜像文件映射到本地的指定路径中;</li><li>另外, 可以将私有仓库的配置文件指定到本地的路径下 (如 ~/Desktop/registry-config/ 下 )</li></ul></li><li><p>我们大可不必这么麻烦, 只是简单运行一个私有仓库服务 <code>$ docker run -d -p 5000:5000 --restart=always --name registry registry</code></p></li></ol><h3 id="查看私有仓库中镜像"><a href="#查看私有仓库中镜像" class="headerlink" title="查看私有仓库中镜像"></a>查看私有仓库中镜像</h3><ol><li><p>用 <code>curl</code> 查看仓库中的镜像, 可以看到你的私有仓库暂时还是空的</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ curl 127.0.0.1:5000/v2/_catalog</div><div class="line">&#123;&quot;repositories&quot;:[]&#125;</div><div class="line">$</div></pre></td></tr></table></figure></li><li><p>还可以在浏览器中直接查看私有仓库中的镜像(并且内网其他机器也可以通过内网地址来访问你所搭建的私有仓库的镜像):<br> <img src="/img/docker/private_registry_01.png" width="200/"></p></li></ol><h3 id="上传镜像到私有仓库中"><a href="#上传镜像到私有仓库中" class="headerlink" title="上传镜像到私有仓库中"></a>上传镜像到私有仓库中</h3><ol><li><p>之前我们已经通过获取官方 <code>registry镜像</code> 来创建好了自己的私有仓库, 接下来就可以使用 <code>docker tag</code> 来标记一个镜像, 然后推送它到仓库;</p></li><li><p>先查看一下本地已有的镜像 <code>docker image ls</code> :</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ docker image ls</div><div class="line">REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">registry                                              latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">vipservice                                            latest              47c844c76c53        2 months ago        2.92GB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.3               47c844c76c53        2 months ago        2.92GB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.1               52bd20b1d39b        3 months ago        2.46GB</div><div class="line">devhdjfapi.haodai.com_full                            latest              52bd20b1d39b        3 months ago        2.46GB</div><div class="line">oldvip.haodai.com                                     latest              52bd20b1d39b        3 months ago        2.46GB</div></pre></td></tr></table></figure></li><li><p>使用 <code>docker tag</code> 将 <code>registry:lates</code> 这个镜像标记为一个新的本地镜像 <code>127.0.0.1:5000/registry:latest</code> ; </p><ul><li>格式为 <code>docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ docker tag registry:latest 127.0.0.1:5000/registry:latest</div><div class="line">$ docker image ls</div><div class="line">REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">127.0.0.1:5000/registry                               latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">registry                                              latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.3               47c844c76c53        2 months ago        2.92GB</div><div class="line">vipservice                                            latest              47c844c76c53        2 months ago        2.92GB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.1               52bd20b1d39b        3 months ago        2.46GB</div><div class="line">devhdjfapi.haodai.com_full                            latest              52bd20b1d39b        3 months ago        2.46GB</div><div class="line">oldvip.haodai.com                                     latest              52bd20b1d39b        3 months ago        2.46GB</div></pre></td></tr></table></figure></li></ul></li><li><p>使用 <code>docker push</code> 上传标记的镜像</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ docker push 127.0.0.1:5000/registry:latest</div><div class="line">The push refers to a repository [127.0.0.1:5000/registry]</div><div class="line">9113493eaae1: Pushed </div><div class="line">621c2399d41a: Pushed </div><div class="line">59e80739ed3f: Pushed </div><div class="line">febf19f93653: Pushed </div><div class="line">e53f74215d12: Pushed </div><div class="line">latest: digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c size: 1364</div></pre></td></tr></table></figure></li><li><p>然后查看仓库中的镜像，可以看到镜像已经被成功上传了</p><ul><li><p>curl 查看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">curl 127.0.0.1:5000/v2/_catalog</div><div class="line">&#123;&quot;repositories&quot;:[&quot;registry&quot;]&#125;</div></pre></td></tr></table></figure></li><li><p>浏览器查看<br><img src="/img/docker/private_registry_02.png" width="200/"></p></li><li>查看某个镜像的tag列表 <code>curl -XGET http://127.0.0.1:5000/v2/nginx/tags/list</code></li></ul></li></ol><h3 id="上传私有仓库问题"><a href="#上传私有仓库问题" class="headerlink" title="上传私有仓库问题"></a>上传私有仓库问题</h3><ol><li>如果上传的时候, 打包的镜像使用的是本机的内网地址, 最后在上传的时候, 你会发现<strong>如下报错信息</strong>: <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ docker push 192.168.1.3:5000/registry:latest</div><div class="line">The push refers to a repository [192.168.1.3:5000/registry]</div><div class="line">Get https://192.168.1.3:5000/v2/: http: server gave HTTP response to HTTPS client</div><div class="line">renyimindembp:vipvip renyimin$</div></pre></td></tr></table></figure></li></ol><ol><li><p>此时, 你需要将内网地址配置到本机docker的 <code>insecure registries</code> 中, 如下:<br> <img src="/img/docker/insecure_registries_01.png" width="300"></p></li><li><p>之后, 无论本机还是在同一内网中的其他机器也都可以推送镜像到仓库中了(之前打包好的两个镜像, 都可以成功推送到私有仓库中):</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">$ docker push 192.168.1.3:5000/registry</div><div class="line">The push refers to a repository [192.168.1.3:5000/registry]</div><div class="line">9113493eaae1: Pushed </div><div class="line">621c2399d41a: Pushed </div><div class="line">59e80739ed3f: Pushed </div><div class="line">febf19f93653: Pushed </div><div class="line">e53f74215d12: Pushed </div><div class="line">latest: digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c size: 1364</div><div class="line">   </div><div class="line">$ docker push 127.0.0.1:5000/registry</div><div class="line">The push refers to a repository [127.0.0.1:5000/registry]</div><div class="line">9113493eaae1: Layer already exists </div><div class="line">621c2399d41a: Layer already exists </div><div class="line">59e80739ed3f: Layer already exists </div><div class="line">febf19f93653: Layer already exists </div><div class="line">e53f74215d12: Layer already exists </div><div class="line">latest: digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c size: 1364</div></pre></td></tr></table></figure></li></ol><h3 id="从私有仓库中下载镜像"><a href="#从私有仓库中下载镜像" class="headerlink" title="从私有仓库中下载镜像"></a>从私有仓库中下载镜像</h3><ol><li><p>先删除已有镜像</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">$ docker image ls</div><div class="line">REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">registry                                              latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">127.0.0.1:5000/registry                               latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">192.168.1.3:5000/registry                             latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.3               47c844c76c53        2 months ago        2.92GB</div><div class="line">vipservice                                            latest              47c844c76c53        2 months ago        2.92GB</div><div class="line">oldvip.haodai.com                                     latest              52bd20b1d39b        3 months ago        2.46GB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.1               52bd20b1d39b        3 months ago        2.46GB</div><div class="line">devhdjfapi.haodai.com_full                            latest              52bd20b1d39b        3 months ago        2.46GB</div><div class="line"></div><div class="line">$ docker image rm 127.0.0.1:5000/registry:latest 192.168.1.3:5000/registry:latest</div><div class="line">Untagged: 127.0.0.1:5000/registry:latest</div><div class="line">Untagged: 127.0.0.1:5000/registry@sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c</div><div class="line">Untagged: 192.168.1.3:5000/registry:latest</div><div class="line">Untagged: 192.168.1.3:5000/registry@sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c</div></pre></td></tr></table></figure></li><li><p>再尝试从私有仓库中下载这个镜像 (两个地址都可以下载, 也是因为之前配置了 <code>Insecure registries</code>, 这里最后才可以使用内网地址来下载)</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">$ docker pull 127.0.0.1:5000/registry:latest</div><div class="line">latest: Pulling from registry</div><div class="line">Digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c</div><div class="line">Status: Downloaded newer image for 127.0.0.1:5000/registry:latest</div><div class="line"></div><div class="line">$ docker image ls</div><div class="line">REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">127.0.0.1:5000/registry                               latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">registry                                              latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.3               47c844c76c53        2 months ago        2.92GB</div><div class="line">vipservice                                            latest              47c844c76c53        2 months ago        2.92GB</div><div class="line">devhdjfapi.haodai.com_full                            latest              52bd20b1d39b        3 months ago        2.46GB</div><div class="line">oldvip.haodai.com                                     latest              52bd20b1d39b        3 months ago        2.46GB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.1               52bd20b1d39b        3 months ago        2.46GB</div><div class="line"></div><div class="line">$ docker pull 192.168.1.3:5000/registry:latest</div><div class="line">latest: Pulling from registry</div><div class="line">Digest: sha256:feb40d14cd33e646b9985e2d6754ed66616fedb840226c4d917ef53d616dcd6c</div><div class="line">Status: Downloaded newer image for 192.168.1.3:5000/registry:latest</div><div class="line"></div><div class="line">$ docker image ls</div><div class="line">REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">192.168.1.3:5000/registry                             latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">registry                                              latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">127.0.0.1:5000/registry                               latest              d1fd7d86a825        4 weeks ago         33.3MB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.3               47c844c76c53        2 months ago        2.92GB</div><div class="line">vipservice                                            latest              47c844c76c53        2 months ago        2.92GB</div><div class="line">docker-registry.haodai.com:80/devhdjfapi.haodai.com   1.1.1               52bd20b1d39b        3 months ago        2.46GB</div><div class="line">devhdjfapi.haodai.com_full                            latest              52bd20b1d39b        3 months ago        2.46GB</div><div class="line">oldvip.haodai.com                                     latest              52bd20b1d39b        3 months ago        2.46GB</div></pre></td></tr></table></figure></li></ol><h2 id="几个简单问题"><a href="#几个简单问题" class="headerlink" title="几个简单问题"></a>几个简单问题</h2><ol><li><p><a href="https://docs.docker.com/registry/spec/api/#deleting-an-image" target="_blank" rel="external">删除<code>仓库</code>镜像</a></p><ul><li>自己的docker仓库中存放的镜像, 时间长了难免存在一些废弃的镜像在里面, 如果不删除就造成空间的浪费</li><li>需要对registry做适当配置, 可参考: <a href="https://docs.docker.com/registry/configuration/#override-specific-configuration-options" target="_blank" rel="external">https://docs.docker.com/registry/configuration/#override-specific-configuration-options</a></li></ul></li><li><p>容器启动之后, 如果忘记挂载某个目录, 能否再进行挂载? 其实没有必要, 直接停止删除, 重开一个即可！</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;公开-Docker-Registry&quot;&gt;&lt;a href=&quot;#公开-Docker-Registry&quot; class=&quot;headerlink&quot; title=&quot;公开 Docker Registry&quot;&gt;&lt;/a&gt;公开 Docker Registry&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
      
    
    </summary>
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/categories/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/tags/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>02. 镜像</title>
    <link href="http://blog.renyimin.com/2017/12/02/docker/2017-12-02-02-docker/"/>
    <id>http://blog.renyimin.com/2017/12/02/docker/2017-12-02-02-docker/</id>
    <published>2017-12-02T03:56:23.000Z</published>
    <updated>2018-08-04T03:26:37.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样, 镜像是静态的定义, 容器是镜像运行时的实体; 所以, Docker运行容器前首先需要本地存在对应的镜像, 如果本地不存在该镜像, Docker会先尝试从镜像仓库下载该镜像;</p><h2 id="镜像的获取"><a href="#镜像的获取" class="headerlink" title="镜像的获取"></a>镜像的获取</h2><ol><li><p><a href="https://hub.docker.com/explore/" target="_blank" rel="external">Docker Hub</a>上有大量的高质量的镜像可以用, 如何获取这些镜像呢?</p></li><li><p>从Docker镜像仓库获取镜像的命令是 <code>docker pull</code>, 其命令格式为：<code>docker pull [选项] [Docker Registry地址[:端口号]/]仓库名[:标签]</code></p><ul><li>docker pull命令的具体选项可以通过 <code>docker pull --help</code> 命令看到</li><li>Docker镜像仓库地址: 地址的格式一般是 <code>&lt;域名/IP&gt;[:端口号]</code> (默认地址是 Docker Hub 仓库地址)</li><li>仓库名: 仓库名是 两段式名称, 即 <code>&lt;用户名&gt;/&lt;软件名&gt;</code> (对于 Docker Hub, 如果不给出用户名, 则默认为 library, 也就是官方镜像)</li></ul></li><li><p>比如 <code>$ docker pull ubuntu:16.04</code>: </p><ul><li>由于没有给出Docker镜像仓库地址, 因此将会从Docker Hub获取镜像;</li><li>而仓库名称是 <code>ubuntu</code>(没有用户名), 因此将会去官方仓库 <code>library/ubuntu</code> 中, 获取标签为 <code>16.04</code> 的镜像;</li></ul></li><li><p>另外, 如果从 Docker Hub 下载镜像非常缓慢，可以 配置镜像加速器。</p></li></ol><h2 id="配置镜像加速器"><a href="#配置镜像加速器" class="headerlink" title="配置镜像加速器"></a>配置镜像加速器</h2><ol><li><p>国内从 Docker Hub 镜像仓库拉取镜像有时会遇到困难, 此时可以配置镜像加速器, Docker 官方和国内很多云服务商都提供了国内加速器服务, 例如:</p><ul><li><a href="https://docs.docker.com/registry/recipes/mirror/#use-case-the-china-registry-mirror" target="_blank" rel="external">Docker 官方提供的中国 registry mirror</a></li><li><a href="https://cr.console.aliyun.com/?accounttraceid=d520cfad-1577-4905-91cd-09aa8b4964cd#/imageSearch" target="_blank" rel="external">阿里云加速器</a></li><li><a href="https://www.daocloud.io/mirror#accelerator-doc" target="_blank" rel="external">DaoCloud 加速器</a></li></ul></li><li><p>此处以 Docker 官方加速器为例进行介绍(由于本人使用macOS系统,下面只列出macOS上如何配置镜像加速器, 其他系统请<a href="https://yeasy.gitbooks.io/docker_practice/content/install/mirror.html" target="_blank" rel="external">参考</a>)</p><ul><li>在任务栏点击<code>Docker for mac</code> 应用图标 -&gt; <code>Perferences</code>… -&gt; <code>Daemon</code> -&gt; <code>Basic</code> -&gt; <code>Registry mirrors</code></li><li>在列表中填写加速器地址即可, 修改完成之后，点击 <code>Apply &amp; Restart</code> 按钮, Docker 就会重启并应用配置的镜像地址了</li></ul></li><li><p>如果在添加加速器地址后出现 <code>registry-mirrors no certs for egistry.docker-....</code><br> <img src="/img/docker/jiasuqi-error-macOS.png" width="300">  </p></li><li><p>网上查找资料后, <a href="https://yq.aliyun.com/articles/29941" target="_blank" rel="external">有人说是证书问题</a>, 尝试修改https为http后正常<br> <img src="/img/docker/jiasuqi-macOS.png" width="300"> </p></li><li><p>检查加速器是否生效</p><ul><li>配置加速器之后, 如果拉取镜像仍然十分缓慢, 请手动检查加速器配置是否生效, 在命令行执行 <code>docker info</code></li><li>由于我配置的是docker hub提供的中国镜像站点, 所以如果从结果中看到了如下内容，说明配置成功(你看到的可能和我的不一样)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Registry Mirrors:</div><div class="line">http://registry.docker-cn.com/</div><div class="line">//如果添加了多个加速站点, 此处也会有多个</div></pre></td></tr></table></figure></li></ul></li></ol><h2 id="镜像相关基础操作"><a href="#镜像相关基础操作" class="headerlink" title="镜像相关基础操作"></a>镜像相关基础操作</h2><ol><li>列出已存在镜像: <strong>docker images</strong>：列表包含了 仓库名、标签、镜像ID、创建时间 以及 所占用的空间;<ul><li>注意: 虽然 <code>镜像ID</code> 是镜像的唯一标识, 但是一个镜像可以打包出多个不同标签的镜像(如何打包,后面会学到), 所以有些镜像的ID一样, 但是tag会不一样<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">renyimindeMacBook-Pro:testVip renyimin$ docker images</div><div class="line">REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">127.0.0.1:5000/registry                               latest              d1fd7d86a825        7 weeks ago         33.3MB</div><div class="line">registry                                              latest              d1fd7d86a825        7 weeks ago         33.3MB</div><div class="line">renyimindeMacBook-Pro:testVip renyimin$</div></pre></td></tr></table></figure></li></ul></li></ol><ol><li><p><a href="https://yeasy.gitbooks.io/docker_practice/content/image/rm.html#untagged-%E5%92%8C-deleted" target="_blank" rel="external">删除镜像</a>: 如果要删除本地的镜像, 可以使用 <code>$ docker image rm [选项] &lt;镜像名1&gt; [&lt;镜像名2&gt; ...]</code> 命令; (因为镜像ID可能会一样, 所以删除镜像用的是镜像名)<br> 注意, 镜像名是 <code>仓库名:标签</code>, 如 <code>docker image rm nginx:1.12.2</code></p></li><li><p>镜像更名: 镜像更改名称也很简单, 直接 <code>$ docker tag 镜像名 新镜像名:标签</code></p></li><li><p>在 Docker 1.13+ 版本中推荐使用 <code>docker image</code> 来管理镜像 (比如 <code>docker image ls</code> 会列出所有镜像);</p></li></ol><h2 id="理解分层存储"><a href="#理解分层存储" class="headerlink" title="理解分层存储"></a>理解分层存储</h2><ol><li><p>镜像是多层存储，每一层是在前一层的基础上进行的修改; 而容器同样也是多层存储，是在以镜像为基础层，<strong>在其基础上加一层作为容器运行时的存储层</strong>;</p></li><li><p>镜像构建时, 会一层层构建, 前一层是后一层的基础。每一层构建完就不会再发生改变, 后一层上的任何改变只发生在自己这一层;</p></li><li><p><strong>容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡, 这里的消亡是指容器被删除, 而不是stop容器, stop容器后, 容器中发生的改变不会被忽略, 除非容器被删除掉</strong>;</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样, 镜像是静态的定义, 容器是镜像运行时的实体;
      
    
    </summary>
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/categories/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/tags/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>01. 认识Docker</title>
    <link href="http://blog.renyimin.com/2017/12/02/docker/2017-12-02-01-docker/"/>
    <id>http://blog.renyimin.com/2017/12/02/docker/2017-12-02-01-docker/</id>
    <published>2017-12-02T03:03:06.000Z</published>
    <updated>2018-08-04T03:26:15.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ol><li><p>Docker使用Google公司推出的Go语言实现; 属于<strong>操作系统层面的虚拟化技术</strong>; 也称其为容器; </p></li><li><p>docker 与 传统虚拟机技术 对比</p><ul><li><p>传统虚拟机技术是: 虚拟出一套硬件后; 在其上运行一个完整操作系统; 最后在该系统上再运行所需应用进程;</p></li><li><p>而容器内的应用进程直接运行于宿主的内核, 容器内没有自己的内核, 而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便;</p></li><li><p>如下图, 可以看到有<code>应用A</code>和<code>应用B</code>两个应用, 相比于传统虚拟技术, docker少了<code>Hypervisor</code>(所有虚拟化技术的核心)和<code>Guest OS</code>这两层<br><img src="/img/docker/docker-vs-virtualmachines.png" width="600"></p></li></ul></li></ol><h2 id="为什么使用docker"><a href="#为什么使用docker" class="headerlink" title="为什么使用docker?"></a><a href="https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html" target="_blank" rel="external">为什么使用docker?</a></h2><p>作为一种新兴的虚拟化方式, Docker 跟传统的虚拟化方式相比具有众多的优势</p><h3 id="更高效的利用系统资源"><a href="#更高效的利用系统资源" class="headerlink" title="更高效的利用系统资源"></a>更高效的利用系统资源</h3><p>由于容器不需要进行 <code>硬件虚拟</code> 以及 <code>运行完整操作系统</code> 等额外开销, 所以其实<strong>Docker对系统资源的利用率更高</strong>。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。<br>因此，相比虚拟机技术，<strong>一个相同配置的主机，往往可以运行更多数量的应用</strong>。</p><h3 id="更快速的启动时间"><a href="#更快速的启动时间" class="headerlink" title="更快速的启动时间"></a>更快速的启动时间</h3><p>传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，<strong>由于直接运行于宿主内核，无需启动完整的操作系统</strong>，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。</p><h3 id="一致的运行环境"><a href="#一致的运行环境" class="headerlink" title="一致的运行环境"></a>一致的运行环境</h3><p>开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。<br>而 Docker 的镜像提供了<strong>除内核外完整的运行时环境</strong>，确保了应用运行环境一致性，从而不会再出现 <code>「这段代码在我机器上没问题啊」</code> 这类问题。</p><p>更多好处请参考(<a href="https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html" target="_blank" rel="external">https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html</a>)</p><h2 id="对比传统虚拟机总结"><a href="#对比传统虚拟机总结" class="headerlink" title="对比传统虚拟机总结"></a>对比传统虚拟机总结</h2><table><thead><tr><th style="text-align:center">特性</th><th style="text-align:center">容器</th><th style="text-align:center">虚拟机</th></tr></thead><tbody><tr><td style="text-align:center">启动</td><td style="text-align:center">秒级</td><td style="text-align:center">分钟级</td></tr><tr><td style="text-align:center">硬盘使用</td><td style="text-align:center">一般为MB</td><td style="text-align:center">一般为GB</td></tr><tr><td style="text-align:center">性能</td><td style="text-align:center">接近原生</td><td style="text-align:center">弱于原生</td></tr><tr><td style="text-align:center">系统支持量</td><td style="text-align:center">单机支持上千个容器</td><td style="text-align:center">一般几十个</td></tr></tbody></table><h2 id="Docker三个基本概念"><a href="#Docker三个基本概念" class="headerlink" title="Docker三个基本概念"></a>Docker三个基本概念</h2><p>理解了这三个概念，就理解了 Docker 的整个生命周期</p><h3 id="镜像-Image"><a href="#镜像-Image" class="headerlink" title="镜像 (Image)"></a><a href="/2017/10/12/2017-10-12-02-docker/">镜像 (Image)</a></h3><h3 id="容器-Container"><a href="#容器-Container" class="headerlink" title="容器 (Container)"></a>容器 (Container)</h3><h3 id="仓库-Repository"><a href="#仓库-Repository" class="headerlink" title="仓库 (Repository)"></a>仓库 (Repository)</h3><blockquote><p><a href="https://www.gitbook.com/book/yeasy/docker_practice/details" target="_blank" rel="external">《Docker从入门到实践》</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Docker使用Google公司推出的Go语言实现; 属于&lt;strong&gt;操作系统层面的虚拟化技术&lt;/strong&gt;; 也
      
    
    </summary>
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/categories/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Docker读书笔记" scheme="http://blog.renyimin.com/tags/Docker%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>03. HTTP状态码详解</title>
    <link href="http://blog.renyimin.com/2017/11/30/http/2017-11-30-HTTP-03/"/>
    <id>http://blog.renyimin.com/2017/11/30/http/2017-11-30-HTTP-03/</id>
    <published>2017-11-30T06:30:12.000Z</published>
    <updated>2018-07-20T13:42:17.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1xx"><a href="#1xx" class="headerlink" title="1xx"></a>1xx</h2><ol><li><code>101</code>: 参考博文<a href="/2017/10/28/WebSocket/2017-10-28-websocket-02/">WebSocket简单示例分析</a> (做协议升级, 还会响应: <code>Connection: Upgrade</code>)</li></ol><h2 id="2xx"><a href="#2xx" class="headerlink" title="2xx"></a>2xx</h2><blockquote><p><strong>Web API的设计与开发 P109</strong></p></blockquote><p><strong>200 OK</strong> : 200码非常出名, 似乎没有对它进一步说明的必要;</p><p><strong>201 Created</strong> : 当在服务器端创建数据成功时, 会返回201状态码;</p><ul><li>也就是使用 <code>POST</code> 请求方法的场景 (如:用户登录后添加了新用户, 上传了图片等新创建数据的场景)</li></ul><p><strong>202 Accepted</strong> : 在异步处理客户端请求时, 它用来表示服务器端已经接受了来自客户端的请求, 但处理尚未结束;</p><ul><li>在文件格式转换, 处理远程通知(Apple Push Notification等)这类很耗时的场景中, 如果等到所有处理都结束后才向客户端返回响应消息, 就会花费相当长的时间, 造成应用可用性不高; 这时采用的方法是服务器向客户端返回一次响应消息, 然后立刻开始异步处理。</li><li>202状态码就被用于告知客户端服务器端已经开始处理请求, 但整个处理过程尚未结束;</li><li>比如: 以LinkedIn的参与讨论的API为例<br>如果成功参与讨论并发表意见, 服务器端通常会返回201状态码;<br>但如果需要得到群主的确认, 那么所发表的意见就无法立即在页面显示出来, 这时服务器端就需要返回202状态码; 从广义上来看, 该场景也属于异步处理, 但和程序设计里的异步执行当然不同;</li></ul><p><strong><a href="http://www.laruence.com/2011/01/20/1844.html" target="_blank" rel="external">204 No Content</a></strong> : 正如其字面意思, 当响应消息为空时会返回该状态码。</p><ul><li>其实就是告诉浏览器, 服务端执行成功了, 但是没什么数据返回给你, 所以你不用刷新页面, 也不用导向新的页面; </li><li>在用 <code>DELETE</code> 方法删除数据时, 服务器端通常会返回204状态码(阮一峰博文也提到过, 对<code>DELETE</code>适用);</li><li>除此之外, 也有人认为在使用 <code>PUT</code>或<code>PATCH</code> 方法更新数据时, 因为只是更新已有数据, 所以返回204状态码更加自然;<br>书中建议 <code>DELETE</code> 返回204; <code>PUT</code>或<code>PATCH</code>返回200并返回该方法所操作的数据; </li><li>关于204状态码的讨论可以参考 p111;</li></ul><p><strong>205 Reset Content</strong> : 告诉浏览器, 页面表单需要被重置; </p><ul><li>205的意思是服务端在接收了浏览器POST请求以后, 处理成功以后, 告诉浏览器, 执行成功了, 请清空用户填写的Form表单, 方便用户再次填写;</li></ul><p><strong>206 Partial Content</strong> : 成功执行了一个部分或Range(范围)的请求; </p><ul><li>206响应中, 必须包含 <code>Content-Range</code>, <code>Date</code> 以及 <code>ETag</code>或<code>Content-Location</code>首部;</li></ul><h2 id="3xx"><a href="#3xx" class="headerlink" title="3xx"></a>3xx</h2><p><strong>300 Multiple Choices</strong> : 客户端驱动方式进行内容协商时, 服务器可能返回多个连接供客户端进行选择 (比如多语言网站可能会出现);</p><p><strong>301 Moved Permanently</strong> : 在请求的URL已经被移除时使用, 响应的Location首部中应该包含资源现在所处的URL; (比较适合永久重定向)</p><ul><li>比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是301;</li><li><p>则即便稍后取消了location.php中的跳转(或者修改了跳转地址), 由于浏览器还是会认为你之前的跳转是永久性的, 再次访问www.test.com/location.php仍然会跳转到之前的跳转链接(除非清浏览器缓存);</p></li><li><p>另外, 假设你之前是先访问www.test.com/test.html, 然后通过<strong>post</strong>提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成<strong>GET</strong>;</p></li></ul><p><strong>302 Found</strong>: 与301类似, 但是客户端应该使用Location首部给出的URL来进行<strong>临时</strong>定位资源, 将来的请求仍应该使用老的URL;</p><ul><li>比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是302;</li><li><p>如果稍后取消了location.php中的跳转, 再次访问www.test.com/location.php, 会发现不会进行跳转, 而是访问到 location.php 修改后的代码 (不用清浏览器缓存);</p></li><li><p>另外, 假设你之前是先访问www.test.com/test.html, 然后通过<strong>post</strong>提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成<strong>GET</strong>;</p></li></ul><p><strong>303 See Other</strong> : HTTP/1.1使用303来实现和302一样的<strong>临时</strong>重定向;</p><p><strong>307 Temporary Redirect</strong></p><ul><li>HTTP/1.1规范要求用307来取代302进行临时重定向; (302临时重定向留给HTTP/1.0)</li><li>所以他也具备302临时重定向的特点;</li><li>但是, 与 302, 303 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过<strong>post</strong>提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是<strong>POST</strong>;</li></ul><p><strong><a href="https://tools.ietf.org/html/draft-reschke-http-status-308-07" target="_blank" rel="external">308 Permanent Redirect</a></strong></p><ul><li>貌似不是rfc2616的标准</li><li>具备和301永久重定向的特点, 需要清除浏览器缓存才行;</li><li>但是, 与 301 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过<strong>post</strong>提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是<strong>POST</strong>;</li></ul><p><strong>304 Not Modified</strong> : 参考博文<a href="/2017/11/30/http/2017-11-30-HTTP-05/">缓存相关</a></p><h2 id="4xx"><a href="#4xx" class="headerlink" title="4xx"></a>4xx</h2><blockquote><p><strong>Web API的设计与开发 P113</strong><br>4字头状态码主要用于描述因客户端请求的问题而引发的错误。<br>也就是说, 服务器端不存在问题, 但服务器端无法理解客户端发送的请求, 或虽然服务器端能够理解但请求却没有被执行, 当遇到这些情况引发的错误时, 服务器端便会向客户端返回这一类别的状态码。<br>因此, 当服务器端返回4字头的状态码时, 就表示客户端的访问方式发生了问题, 用户需要检查一下客户端的访问方式或访问的目标资源等。</p></blockquote><p><strong>400 Bad Request</strong> : 表示其他错误的意思, 即其他4字头状态码都无法描述的错误类型;</p><p><strong>401 Unauthorized</strong> : 表示<code>认证(Authentication)</code>类型的错误</p><ul><li>比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因;</li></ul><p><strong>403 Forbidden</strong> : 和401状态码比较相似, 所以也经常被混淆; 其实403表示的是<code>授权(Authotization)</code>类型的错误, 授权和认证的不同之处是:</p><ul><li><code>认证</code>表示”识别前来访问的是谁”, 而<code>授权</code>则表示”赋予特定用户执行特定操作的权限”</li><li>通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限”</li></ul><p><strong>404 Not Found</strong> : 表示访问的数据不存在, 但是</p><ul><li>例如当客户端湿度获取不存在的用户信息时, 或者试图访问原本就不存在的端点时, 服务器就会返回404状态码;</li><li>所以, 如果客户端想要获取用户信息, 却得到服务器端返回的404状态码, 客户端仅凭”404 Not Found”将难以区分究竟是用户不存在, 还是端点URI错误导致访问了原本不存在的URI;</li></ul><p><strong>405 Method Not Allowed</strong> : 表示虽然访问的端点存在, 但客户端使用的HTTP方法不被服务器端允许;</p><ul><li>比如客户端使用了POST方法来访问只支持GET方法的信息检索专用的API;</li><li>又比如客户端用了GET方法来访问更新数据专用的API等;</li></ul><p><strong>406 Not Acceptable</strong> : 服务器端API不支持客户端指定的数据格式时, 服务器端所返回的状态码; </p><ul><li>比如, 服务器端只支持JSON和XML输出的API被客户端指定返回YAML的数据格式时, 服务器端就会返回406状态码;</li></ul><p><strong>408 Request Timeout</strong> : 当客户端发送请求至服务器端所需的时间过长时, 就会触发服务器端的超时处理, 从而使服务器端返回该状态码;</p><p><strong>409 Conflict</strong>: 用于表示资源发生冲突时的错误 (est中就会有该错误码)</p><ul><li>比如通过指定ID等唯一键值信息来调用注册功能的API时, 倘若已有相同ID的数据存在, 就会导致服务器端返回409状态码;</li><li>在使用邮箱地址及Facebook ID等信息进行新用户注册时, 如果该邮箱地址或者ID已经被其他用户注册, 就会引起冲突, 这时服务器端就会返回409状态码告知客户端该邮箱地址或ID已被使用;</li></ul><p><strong>410 Gone</strong> : 和 404状态码 相同, 都表示访问资源不存在, 只是410状态码不单表示资源不存在, 还进一步告知<strong>资源曾经存在</strong>, 只是目前已经消失了;</p><ul><li>因此服务器端常在访问被删除的数据时返回该状态码, 但是为了返回该状态码, 服务器必须保存该数据已被删除的信息, 而且客户端也应该知晓服务器端保存了这样的信息;</li><li>但是在通过邮箱地址搜索用户信息的API中, 从保护个人信息的角度来说, <strong>返回410状态码的做法也会受到质疑</strong>; (所以在此种资源不存在的情况下, 为了稍微安全一些, 返回410状态码需要慎重)</li></ul><p><strong>413 Request Entity Too Large</strong> : 413也是比较容易出现的一种状态码, 表示请求实体过大而引发的错误</p><ul><li>请求消息体过长是指, 比如在上传文件这样的API中, 如果发送的数据超过了所允许的最大值, 就会引发这样的错误;</li></ul><p><strong>414 Request-URI Too Large</strong> : 414是表示请求首部过长而引发的错误</p><ul><li>如果在进行GET请求时, 查询参数被指定了过长的数据, 就会导致服务器端返回414状态码</li></ul><p><strong>415 Unsupported Media Type</strong> : 和406比较相似</p><ul><li>406我们知道是表示服务器端不支持客户端想要接收的数据格式</li><li>而415表示的是服务器端不支持客户端请求首部 <code>Content-Type</code> 里指定的数据格式, 也就是说, 当客户端通过POST,PUT,PATCH等方法发送的请求消息体的数据格式不被服务器支持时, 服务器端就会返回415状态码;</li><li>例如在只接收JSON格式的API里, 如果客户端请求时发送的是XML格式的数据去请求服务器端, 或者在 <code>Content-Type</code> 首部指定 <code>application/xml</code>, 都会导致该类型错误;</li></ul><p><strong>429 Too Many Requests</strong> : 是2012年RFC6585文档中新定义的状态码, 表示访问次数超过了所允许的范围;</p><ul><li>例如某API存在一小时内只允许访问100次的访问限制, 这种情况下入股哦客户端视图进行第101次访问, 服务器便会返回该状态码;</li><li>表示在一定的时间内用户发送了太多的请求, 即超出了”频次限制”, 在响应中，可以提供一个 <code>Retry-After</code> 首部来提示用户需要等待多长时间之后再发送新的请求;</li></ul><h2 id="5xx"><a href="#5xx" class="headerlink" title="5xx"></a>5xx</h2><blockquote><p>5字头状态码表示错误不发生在客户端, 而是由服务器自身问题引发的。</p></blockquote><p><strong>500 Internal Server Error</strong> : 是web应用程序开发里非常常见的错误, 当服务器代码里存在bug, 输出错误信息并停止运行等情况下, 就会返回该类型的错误;</p><ul><li>因此, 不仅限于API, 对于5字头状态码的错误, 都要认真监视错误日志, 使系统在出错时及时告知管理员, 以便在错误发生时做好应对措施, 防止再次发生。</li></ul><p><strong>501 Not Implemented</strong> : ???</p><p><strong>502 Bad GateWay</strong> : ???</p><p><strong>503 Service Unavaliable</strong> : 用来表示服务器当前处于<strong>暂</strong>不可用状态</p><ul><li>可以回送:响应首部 <code>Retry-After</code> 表示多久恢复;</li><li>不同的客户端与服务器端应用对于 Retry-After 首部的支持依然不太一致;</li><li>不过，一些爬虫程序，比如谷歌的爬虫程序Googlebot, 会遵循Retry-After响应首部的规则, 将其与503(Service Unavailable,当前服务不存在)响应一起发送有助于互联网引擎做出判断,在宕机结束之后继续对网站构建索引。</li><li>参考:<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Retry-After" target="_blank" rel="external">https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Retry-After</a></li></ul><p><strong>504 Gateway Time-out</strong>: 复现这个错误码比较简单, 让你的php程序模拟耗时请求, 如下代码<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&lt;?php</div><div class="line">sleep(70);//模拟耗时，睡70秒</div><div class="line">echo &quot;睡醒了&quot;;</div></pre></td></tr></table></figure></p><pre><code>就会返回```504 Gateway Time-outnginx/1.11.4``` </code></pre><p><strong>505 HTTP Version Not Supported</strong>: 服务器收到的请求, 使用的是它无法支持的HTTP协议版本;</p><p>参考:《HTTP权威指南》、《Web API的设计与开发》</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1xx&quot;&gt;&lt;a href=&quot;#1xx&quot; class=&quot;headerlink&quot; title=&quot;1xx&quot;&gt;&lt;/a&gt;1xx&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;code&gt;101&lt;/code&gt;: 参考博文&lt;a href=&quot;/2017/10/28/WebSocket/2017-10
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>02. HTTP请求方法</title>
    <link href="http://blog.renyimin.com/2017/11/30/http/2017-11-30-HTTP-02/"/>
    <id>http://blog.renyimin.com/2017/11/30/http/2017-11-30-HTTP-02/</id>
    <published>2017-11-30T03:29:12.000Z</published>
    <updated>2018-07-20T13:20:39.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ol><li><p>HTTP/1.1 中实现的method, <a href="https://tools.ietf.org/html/rfc2616" target="_blank" rel="external">参考RFC2616</a>, 可以看到有: <code>OPTIONS</code>, <code>HEAD</code>, <code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code>, <code>TRACE</code>, <code>CONNECT</code></p></li><li><p>RFC2616中提到: PATCH, LINK, UNLINK方法被定义, 但并不常见; (《图解http协议》中也提到 <code>LINK</code>, <code>UNLINK</code> 已经被http1.1废弃);</p></li><li><p>不同应用各自的实现不同, 有些应用会完整实现, 有些还会扩展, 有些可能只会实现一部分;</p></li></ol><h2 id="PUT"><a href="#PUT" class="headerlink" title="PUT"></a>PUT</h2><ol><li><p><code>PUT</code>: 替换资源;</p></li><li><p><code>PUT</code> 和 <code>POST</code>的区别: 在HTTP中, PUT被定义为 <a href="https://tools.ietf.org/html/rfc2616#section-9.1.2" target="_blank" rel="external"><code>idempotent(幂等性)</code></a> 的方法, POST则不是, <strong>这是一个很重要的区别</strong></p></li><li><p>应该用 <code>PUT</code> 还是 <code>POST</code>?</p><ul><li><p>取决于这个REST服务的行为是否是idempotent(幂等)的<br>假如发送两个请求, 希望服务器端是产生两个新数据，那就说明这个服务不是idempotent的, 因为多次使用产生了副作用了, 那就应该使用 <code>POST</code> 方法;<br>但如果是希望后一个请求把第一个请求覆盖掉(这不正是修改么), 那这个服务就是idempotent的, 那就应该使用 <code>PUT</code> 方法;</p></li><li><p>虽然 <code>POST</code> 和 <code>PUT</code> 差别不大, 用错了也没关系, 但是你的服务一放到internet上，如果不遵从HTTP协议的规范，就可能给自己带来麻烦;</p></li></ul></li></ol><h2 id="POST"><a href="#POST" class="headerlink" title="POST"></a>POST</h2><ol><li><p><code>POST</code>: 上面已经提过了, <strong>POST是非幂等的</strong>;</p></li><li><p><code>POST</code> 和 <code>PUT</code> 都可以上传文件或者创建新信息, 但主要看你的REST服务行为是否是幂等的;</p></li></ol><h2 id="PATCH"><a href="#PATCH" class="headerlink" title="PATCH"></a>PATCH</h2><p><strong>PATCH不是HTTP标准方法的，服务端需要考虑客户端是否能够支持的问题</strong>;</p><ol><li><p>对已有资源的操作: 用于对资源的 <strong>部分内容</strong> 进行更新 (例如更新某一个字段, 具体比如说只更新用户信息的电话号码字段);   </p></li><li><p>而 <code>PUT</code> 则用于更新某个资源较完整的内容, 比如说用户要重填完整表单更新所有信息, 后台处理更新时可能只是保留内部记录ID不变;</p></li></ol><h2 id="HEAD"><a href="#HEAD" class="headerlink" title="HEAD"></a>HEAD</h2><ol><li>HEAD和 <code>GET</code> 本质是一样的, 区别在于如果使用HEAD, 响应体将不会被返回, 而仅仅返回HTTP头信息;<br> 比如: 欲判断某个资源是否存在, 我们通常使用GET, <strong>但这里用HEAD则意义更加明确</strong>;</li></ol><h2 id="GET"><a href="#GET" class="headerlink" title="GET"></a>GET</h2><p>比较简单, 直接获取资源;</p><h2 id="OPTIONS"><a href="#OPTIONS" class="headerlink" title="OPTIONS"></a>OPTIONS</h2><p>这个方法使用比较少, 它用于获取当前URL所支持的方法;<br>若请求成功, 则它会在HTTP头中包含一个名为 <code>Allow</code> 的头, 值是服务器所支持的方法, 如 GET, POST;<br>之前跨域相关博文 <a href="/2016/09/18/2016-09-18-sameoriginpolicy-06/">CORS方案 not-so-simple request</a> 中的”预检”请求用的请求方法就是 <code>OPTIONS</code>;</p><h2 id="CONNECT"><a href="#CONNECT" class="headerlink" title="CONNECT"></a>CONNECT</h2><p>要求用隧道协议连接代理, 如使用SSL</p><h2 id="TRACE"><a href="#TRACE" class="headerlink" title="TRACE"></a>TRACE</h2><p>~~未完待续</p><h2 id="DELETE"><a href="#DELETE" class="headerlink" title="DELETE"></a>DELETE</h2><p><a href="https://tools.ietf.org/html/rfc2616#section-9.7" target="_blank" rel="external">参考</a></p><h2 id="PURGE"><a href="#PURGE" class="headerlink" title="PURGE"></a>PURGE</h2><p>非规范中定义的方法</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;HTTP/1.1 中实现的method, &lt;a href=&quot;https://tools.ietf.org/html/rfc
      
    
    </summary>
    
      <category term="HTTP" scheme="http://blog.renyimin.com/categories/HTTP/"/>
    
    
      <category term="HTTP" scheme="http://blog.renyimin.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>29. binlog 与 事务</title>
    <link href="http://blog.renyimin.com/2017/10/05/mysql/2017-10-05-mysql-29/"/>
    <id>http://blog.renyimin.com/2017/10/05/mysql/2017-10-05-mysql-29/</id>
    <published>2017-10-05T14:16:31.000Z</published>
    <updated>2018-08-02T09:25:48.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="MySQL" scheme="http://blog.renyimin.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://blog.renyimin.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>28. 认识MySQL的 Binary Log</title>
    <link href="http://blog.renyimin.com/2017/09/30/mysql/2017-09-30-mysql-28/"/>
    <id>http://blog.renyimin.com/2017/09/30/mysql/2017-09-30-mysql-28/</id>
    <published>2017-09-30T14:16:31.000Z</published>
    <updated>2018-08-02T10:21:32.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Binary-Log概述"><a href="#Binary-Log概述" class="headerlink" title="Binary Log概述"></a><a href="https://dev.mysql.com/doc/refman/5.5/en/binary-log.html" target="_blank" rel="external">Binary Log</a>概述</h2><ol><li><p>MySQL的二进制日志binlog可以说是MySQL最重要的日志, 它包含了描述数据库更改的”事件”, 例如 表创建操作 或 对表数据的更改; 它还包含可能进行更改的语句的事件(例如, 不匹配任何行的DELETE), 除非使用基于行的日志记录;</p></li><li><p>也就是说, mysql的binlog记录了所有的DDL和DML语句(除了select、show之类的语句), 以事件形式记录, 还包含语句所执行的消耗的时间;</p></li><li><p>开启Binlog的性能方面的损耗?</p></li></ol><ol><li><p>binlog日志有两个最重要的使用场景</p><ul><li><a href="">MySQL主从复制</a></li><li><a href="">数据恢复</a></li></ul></li><li><p>binlog日志包括两类文件:</p><ul><li>二进制日志索引文件(文件名后缀为<code>.index</code>) 用于记录所有的二进制文件</li><li>二进制日志文件(文件名后缀为<code>.00000*</code>) 记录数据库所有的DDL和DML(除了数据查询语句select)语句事件</li></ul></li></ol><h2 id="binlog配置"><a href="#binlog配置" class="headerlink" title="binlog配置"></a>binlog配置</h2><ol><li>开启binlog日志：<ul><li>编辑打开mysql配置文件 <code>/etc/mys.cnf</code></li><li>在 <code>[mysqld]</code> 区块添加 <code>log-bin=mysql-bin</code> 确认是打开状态( ‘mysql-bin’ 是日志的基本名或前缀名);</li><li>重启mysqld使配置生效</li></ul></li></ol><h2 id="binlog-相关操作命令"><a href="#binlog-相关操作命令" class="headerlink" title="binlog 相关操作命令"></a>binlog 相关操作命令</h2><ol><li><p>常用的binlog日志操作命令</p><ul><li>查看binlog是否开启 : <code>show variables like &#39;log_%&#39;;</code></li><li>查看所有binlog日志列表 : <code>show master logs;</code></li><li>查看master状态, 即, 最后(最新)一个binlog日志的编号名称, 及其最后一个操作事件pos结束点(Position)值 : <code>show master status;</code></li><li>flush刷新log日志, 自此刻开始产生一个新编号的binlog日志文件 : <code>flush logs;</code><br>注意: 每当mysqld服务重启时, 会自动执行此命令, 刷新binlog日志; 在mysqldump备份数据时加 -F 选项也会刷新binlog日志;</li><li>重置(清空)所有binlog日志 : <code>mysql&gt; reset master;</code></li></ul></li><li><p>查看binlog日志内容, 常用有两种方式:</p><ul><li>注意 binlog 是二进制文件, 普通文件查看器无法打开, 可以使用自带的 <code>mysqlbinlog</code> 命令查看</li><li>binlog日志与数据库文件在同目录中</li><li>使用 mysqlbinlog 自带查看命令法:<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">// 从下面结果可知mysql的存放目录为</div><div class="line">// 使用mysqlbinlog命令查看binlog日志内容, 下面截取其中的一个片段分析：</div><div class="line">mysqlbinlog mysql-bin.000002</div></pre></td></tr></table></figure></li></ul></li></ol><h2 id="数据备份与恢复"><a href="#数据备份与恢复" class="headerlink" title="数据备份与恢复"></a>数据备份与恢复</h2><h3 id="mysqldump备份与恢复"><a href="#mysqldump备份与恢复" class="headerlink" title="mysqldump备份与恢复"></a>mysqldump备份与恢复</h3><h3 id="binlog恢复"><a href="#binlog恢复" class="headerlink" title="binlog恢复"></a>binlog恢复</h3><p><a href="https://www.cnblogs.com/kevingrace/p/5907254.html" target="_blank" rel="external">https://www.cnblogs.com/kevingrace/p/5907254.html</a><br><a href="https://cloud.tencent.com/developer/article/1032755" target="_blank" rel="external">https://cloud.tencent.com/developer/article/1032755</a><br><a href="https://www.jianshu.com/p/0f0c16c40a52" target="_blank" rel="external">https://www.jianshu.com/p/0f0c16c40a52</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Binary-Log概述&quot;&gt;&lt;a href=&quot;#Binary-Log概述&quot; class=&quot;headerlink&quot; title=&quot;Binary Log概述&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/5.5/en/b
      
    
    </summary>
    
      <category term="MySQL" scheme="http://blog.renyimin.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://blog.renyimin.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>27. 认识MySQL的 undo Log 和 redo Log</title>
    <link href="http://blog.renyimin.com/2017/09/27/mysql/2017-09-23-mysql-27/"/>
    <id>http://blog.renyimin.com/2017/09/27/mysql/2017-09-23-mysql-27/</id>
    <published>2017-09-27T14:16:31.000Z</published>
    <updated>2018-07-27T05:36:43.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h2><ol><li><p>Undo日志记录某数据被修改前的值, 可以用来在事务失败时进行rollback;</p></li><li><p>Undo log 是 InnoDB MVCC 事务特性的重要组成部分, 当我们对记录做了变更操作时就会产生undo记录, Undo记录默认被记录到系统表空间(ibdata)中, 但从5.6开始, 也可以使用独立的 Undo 表空间;</p></li><li><p>Undo记录中存储的是老版本数据, 当一个旧的事务需要读取数据时, 为了能读取到老版本的数据, 需要顺着 undo链 找到满足其可见性的记录; 当版本链很长时, <strong>通常可以认为这是个比较耗时的操作</strong>(例如bug#69812)</p></li><li><p>大多数对数据的变更操作包括 INSERT/DELETE/UPDATE, 其中INSERT操作在事务提交前只对当前事务可见, 因此产生的Undo日志可以在事务提交后直接删除(谁会对刚插入的数据有可见性需求呢), 而对于 UPDATE/DELETE 则需要维护多版本信息; 在InnoDB里, UPDATE和DELETE操作产生的Undo日志被归成一类, 即 update_undo。</p></li></ol><p>更多细节可参考<a href="http://mysql.taobao.org/monthly/2015/04/01/" target="_blank" rel="external">数据库内核月报 － 2015 / 04</a></p><h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><ol><li><p>InnoDB 有两块非常重要的日志, 一个是 <code>undo log</code>, 另外一个是 <code>redo log</code>; 前者用来保证事务的原子性以及InnoDB的MVCC, 后者用来保证事务的持久性;<br> Redo日志记录某数据块被修改后的值, 可以用来恢复未写入data file的已成功事务更新的数据;</p></li><li><p>和大多数关系型数据库一样, InnoDB记录了对数据文件的物理更改, 并保证总是<strong>日志先行</strong>, 也就是所谓的WAL, 即在持久化数据文件前, 保证之前的redo日志已经写到磁盘;</p></li><li><p>LSN(log sequence number)用于记录日志序号, 它是一个不断递增的 unsigned long long 类型整数;</p><ul><li>在 InnoDB 的日志系统中, LSN 无处不在, 它既用于表示修改脏页时的日志序号, 也用于记录checkpoint, 通过LSN, 可以具体的定位到其在redo log文件中的位置;</li><li>为了管理脏页, 在 Buffer Pool 的每个instance上都维持了一个flush list, flush list 上的 page 按照修改这些 page 的LSN号进行排序;<br>因此定期做redo checkpoint点时, 选择的 LSN 总是所有 bp instance 的 flush list 上最老的那个page(拥有最小的LSN);</li></ul></li><li><p>由于采用WAL的策略, 每次事务提交时需要持久化 redo log 才能保证事务不丢; 而延迟刷脏页则起到了合并多次修改的效果, 避免频繁写数据文件造成的性能问题;</p></li></ol><p>更多细节可参考<a href="http://mysql.taobao.org/monthly/2015/05/01/" target="_blank" rel="external">阿里数据库内核月报</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;undo-log&quot;&gt;&lt;a href=&quot;#undo-log&quot; class=&quot;headerlink&quot; title=&quot;undo log&quot;&gt;&lt;/a&gt;undo log&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Undo日志记录某数据被修改前的值, 可以用来在事务失败时进行rollba
      
    
    </summary>
    
      <category term="MySQL" scheme="http://blog.renyimin.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://blog.renyimin.com/tags/MySQL/"/>
    
  </entry>
  
</feed>
